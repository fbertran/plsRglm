[{"path":"https://fbertran.github.io/plsRglm/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Frederic Bertrand. Maintainer, author. Myriam Maumy-Bertrand. Author.","code":""},{"path":"https://fbertran.github.io/plsRglm/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Frederic Bertrand Myriam Maumy-Bertrand (2025). Partial Least Squares Regression Generalized Linear Models, R package version 1.6.0. doi:10.32614/CRAN.package.plsRglm. Frederic Bertrand Myriam Maumy-Bertrand (2025). Partial Least Squares Regression Generalized Linear Models, book abstracts, User2014!, Los Angeles, page 172. Nicolas Meyer, Myriam Maumy-Bertrand et Frederic Bertrand (2010). Comparaison de la regression PLS et de la regression logistique PLS : application aux donnees d'allelotypage. Journal de la Societe Francaise de Statistique 151(2) pages 1-18.","code":"@Manual{,   title = {Partial Least Squares Regression for Generalized Linear Models},   author = {Frederic Bertrand and Myriam Maumy},   publisher = {manual},   year = {2025},   note = {R package version 1.6.0},   url = {https://fbertran.github.io/homepage/},   doi = {10.32614/CRAN.package.plsRglm}, } @Manual{,   title = {Partial Least Squares Regression for Generalized Linear Models},   author = {Frederic Bertrand and Myriam Maumy},   publisher = {manual},   year = {2014},   note = {book of abstracts, User2014!, Los Angeles, page 172},   url = {https://fbertran.github.io/homepage/}, } @Article{,   title = {Comparaison de la regression PLS et de la regression logistique PLS : application aux donnees d'allelotypage},   author = {Nicolas Meyer and Myriam Maumy and Frederic Bertrand},   journal = {Journal de la Societe Francaise de Statistique},   publisher = {Societe Francaise de Statistique},   year = {2010},   volume = {151},   issue = {2},   pages = {1-18},   url = {https://www.numdam.org/item/JSFS_2010__151_2_1_0/}, }"},{"path":[]},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/index.html","id":"frédéric-bertrand-and-myriam-maumy-bertrand","dir":"","previous_headings":"","what":"Frédéric Bertrand and Myriam Maumy-Bertrand","title":"Partial Least Squares Regression for Generalized Linear Models","text":"https://doi.org/10.32614/CRAN.package.plsRglm goal plsRglm <arXiv:1810.01005> provide (weighted) Partial least squares Regression generalized linear models repeated k-fold cross-validation models using various criteria. allows missing data explanatory variables. Bootstrap confidence intervals constructions also available. Partial least squares Regression generalized linear models introduced Bastien, P., Vinzi, V. E. et Tenenhaus, M. (2005). “PLS generalised linear regression”. Computational Statistics & Data Analysis, 48(1), 17–46, http://www.sciencedirect.com/science/article/pii/S0167947304000271. package first developped article, written French, Nicolas Meyer, Myriam Maumy-Bertrand Frédéric Bertrand (2010), “Comparaison de la régression PLS et de la régression logistique PLS : application aux données d’allélotypage”, Journal de la Société Française de Statistique, 151(2), pages 1-18, http://journal-sfds.fr/article/view/47. package presented User2014! conference. Frédéric Bertrand, Jérémy Magnanensi, Nicolas Meyer Myriam Bertrand (2014). “plsRglm, PLS generalized linear models R”, book abstracts, User2014!, Los Angeles, page 172, http://user2014.r-project.org/abstracts/posters/172_Bertrand.pdf. involved number component selection techniques, see “new universal resample-stable bootstrap-based stopping criterion PLS component construction”“, Jérémy Magnanensi, Frédéric Bertrand, Myriam Maumy-Bertrand Nicolas Meyer, Statistics Computing (2017) 27:757–774, https://doi.org/10.1007/s11222-016-9651-4. new methods presented article packaged soon. short paper sums features package available arxiv, Frédéric Bertrand Myriam Maumy-Bertrand (2018), “plsRglm: Partial least squares linear generalized linear regression processing incomplete datasets cross-validation bootstrap techniques R”, arxiv, <arXiv:1810.01005>. vignette available package “plsRglm: Algorithmic insights applications”. plsRglm package contains interesting datasets including: Cornell dataset Kettaneh-Wold, “Analysis mixture data partial least squares”, Chemometrics Intelligent Laboratory Systems, 14(1):57–69, 1992, study pine processionary caterpillars R. Tomassone, S. Audrain, E. Lesquoy-de Turckeim, C. Millier, “La régression, nouveaux regards sur une ancienne méethode statistique”, Actualitées scientifiques et agronomiques, Masson, Paris, 1992, allelotyping study cancer cells dataset missing values N. Meyer, M. Maumy-Bertrand, F. Bertrand, “Comparaison de variantes de régressions logistiques pls et de régression pls sur variables qualitatives: application aux donnéees d’allélotypage”. Journal de la Sociéetée Franç̧aise de Statistique, 151(2):1–18, 2010, Bordeaux wines quality study, M. Tenenhaus. “La régression logistique PLS”. J.-J. Droesbeke, M. Lejeune, G. Saporta, editors, Modèles statistiques pour donnéees qualitatives, Éditions Technip, Paris, 2005. package also applied Phenyl Hyptis datasets chemometrics colonCA dataset colonCA package. website examples created F. Bertrand M. Maumy-Bertrand. Support parallel computation GPU developped.","code":""},{"path":"https://fbertran.github.io/plsRglm/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Partial Least Squares Regression for Generalized Linear Models","text":"can install released version plsRglm CRAN : can install development version plsRglm github :","code":"install.packages(\"plsRglm\") devtools::install_github(\"fbertran/plsRglm\")"},{"path":"https://fbertran.github.io/plsRglm/index.html","id":"example-for-regular-pls-regression-cornell","dir":"","previous_headings":"","what":"Example for regular PLS regression: Cornell","title":"Partial Least Squares Regression for Generalized Linear Models","text":"Read vignette package algorithmic insights examples.","code":""},{"path":"https://fbertran.github.io/plsRglm/index.html","id":"cross-validation","dir":"","previous_headings":"Example for regular PLS regression: Cornell","what":"Cross validation","title":"Partial Least Squares Regression for Generalized Linear Models","text":"use k = 6 balanced groups 2 subjects perform repeated k-fold cross validation. set 10, thanks option nt=6, maximal number components cross-validation function -cv.plsR- since rank design matrix equal 6. grouplist option enables user provide custom splits datasets cross validation carried . consequence, one can use caret (Max Kuhn et al., 2019) package find balanced splits dataset folds respect response values. sum results single table using summary. can perform leave one cross validation similar one existed previous versions SIMCA setting TypeVC=“standard”. Two options, TypeVC=“missing” TypeVC=“standard”, exists handle incomplete datasets. Indeed, cross validation required case, one needs selects way predicting response left observations. complete rows, without missing value, two different ways computing predictions. consequence, mixed datasets, complete incomplete rows, two ways computing prediction : either predicts row missing values (missingdata) selects prediction method accordingly completeness row (adaptative). number significant predictors per components, criteria significance Bastien et al. (2005), can obtained via following code: number significant predictors within component tell us build 3 components AIC criteria gives us 5 components BIC concludes 5 components. cross-validated Q2cum criterion advocates retaining 3 components either leave one 1 6-fold CV. 6-fold CV cross-validation run 100 times randomly creating groups. command lines: Analyze results cross-validation. Plot results cross-validation. plot chunk chunk10 results cross-validation, using Q^2 criterion, confirm first 6-fold CV cross validation: decide retain 1 components. Even linear case, cross validation repeated select number components PLSR model. Now, fit PLSGLR regression one component get chc_h coefficients intercept. also possible obtain matrix W∗ following command line: also possible display biplot observations predictors. plot chunk chunk15 Hard thresholding PLS regression automatic selection number components (Bastien et al. (2005)) also available:","code":"library(plsRglm) data(Cornell) cv.modpls<-cv.plsR(Y~.,data=Cornell,nt=6,K=6) #> NK: 1  #> Number of groups : 6  #> 1  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 5 components could thus be extracted #> ****________________________________________________**** #>  #> 6  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** res.cv.modpls<-cvtable(summary(cv.modpls)) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #>  #> CV Q2 criterion: #> 0 1 2  #> 0 0 1  #>  #> CV Press criterion: #> 1 2 3  #> 0 0 1 res6<-plsR(Y~.,data=Cornell, nt=6, typeVC=\"standard\", pvals.expli=TRUE) #> ____************************************************____ #> ____TypeVC____ standard ____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** colSums(res6$pvalstep) #> [1] 0 0 3 0 0 0 res6$InfCrit #>                AIC   Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y      RSS_Y #> Nb_Comp_0 82.01205        NA      NA          NA        NA 467.796667 #> Nb_Comp_1 53.15173 0.8966556  0.0975  0.89665563 48.344150  35.742486 #> Nb_Comp_2 41.08283 0.9175426  0.0975  0.20210989 28.518576  11.066606 #> Nb_Comp_3 32.06411 0.9399676  0.0975  0.27195907  8.056942   4.418081 #> Nb_Comp_4 33.76477 0.9197009  0.0975 -0.33759604  5.909608   4.309235 #> Nb_Comp_5 33.34373 0.9281373  0.0975  0.10506161  3.856500   3.521924 #> Nb_Comp_6 35.25533 0.9232562  0.0975 -0.06792167  3.761138   3.496074 #>                R2_Y R2_residY  RSS_residY PRESS_residY   Q2_residY  LimQ2 #> Nb_Comp_0        NA        NA 11.00000000           NA          NA     NA #> Nb_Comp_1 0.9235940 0.9235940  0.84046633   1.13678803  0.89665563 0.0975 #> Nb_Comp_2 0.9763431 0.9763431  0.26022559   0.67059977  0.20210989 0.0975 #> Nb_Comp_3 0.9905556 0.9905556  0.10388893   0.18945488  0.27195907 0.0975 #> Nb_Comp_4 0.9907882 0.9907882  0.10132947   0.13896142 -0.33759604 0.0975 #> Nb_Comp_5 0.9924713 0.9924713  0.08281624   0.09068364  0.10506161 0.0975 #> Nb_Comp_6 0.9925265 0.9925265  0.08220840   0.08844125 -0.06792167 0.0975 #>           Q2cum_residY    AIC.std  DoF.dof sigmahat.dof    AIC.dof #> Nb_Comp_0           NA  37.010388 1.000000    6.5212706 46.0708838 #> Nb_Comp_1    0.8966556   8.150064 2.740749    1.8665281  4.5699686 #> Nb_Comp_2    0.9175426  -3.918831 5.085967    1.1825195  2.1075461 #> Nb_Comp_3    0.9399676 -12.937550 5.121086    0.7488308  0.8467795 #> Nb_Comp_4    0.9197009 -11.236891 5.103312    0.7387162  0.8232505 #> Nb_Comp_5    0.9281373 -11.657929 6.006316    0.7096382  0.7976101 #> Nb_Comp_6    0.9232562  -9.746328 7.000002    0.7633343  0.9711322 #>              BIC.dof GMDL.dof DoF.naive sigmahat.naive  AIC.naive  BIC.naive #> Nb_Comp_0 47.7893514 27.59461         1      6.5212706 46.0708838 47.7893514 #> Nb_Comp_1  4.9558156 21.34020         2      1.8905683  4.1699567  4.4588195 #> Nb_Comp_2  2.3949331 27.40202         3      1.1088836  1.5370286  1.6860917 #> Nb_Comp_3  0.9628191 24.40842         4      0.7431421  0.7363469  0.8256118 #> Nb_Comp_4  0.9357846 24.23105         5      0.7846050  0.8721072  0.9964867 #> Nb_Comp_5  0.9198348 28.21184         6      0.7661509  0.8804809  1.0227979 #> Nb_Comp_6  1.1359502 33.18348         7      0.8361907  1.1070902  1.3048716 #>           GMDL.naive #> Nb_Comp_0   27.59461 #> Nb_Comp_1   18.37545 #> Nb_Comp_2   17.71117 #> Nb_Comp_3   19.01033 #> Nb_Comp_4   24.16510 #> Nb_Comp_5   28.64206 #> Nb_Comp_6   33.63927 res6<-plsR(Y~.,data=Cornell, nt=6, pvals.expli=TRUE) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** colSums(res6$pvalstep) #> [1] 0 0 3 0 0 0 set.seed(123) cv.modpls<-cv.plsR(Y~.,data=Cornell,nt=6,K=6,NK=100,random=TRUE,verbose = FALSE) res.cv.modpls=cvtable(summary(cv.modpls)) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1,  2,  3,  4,  5,  6,  7,  8,  9,  10 #> NK: 11,  12,  13,  14,  15,  16,  17,  18,  19,  20 #> NK: 21,  22,  23,  24,  25,  26,  27,  28,  29,  30 #> NK: 31,  32,  33,  34,  35,  36,  37,  38,  39,  40 #> NK: 41,  42,  43,  44,  45,  46,  47,  48,  49,  50 #> NK: 51,  52,  53,  54,  55,  56,  57,  58,  59,  60 #> NK: 61,  62,  63,  64,  65,  66,  67,  68,  69,  70 #> NK: 71,  72,  73,  74,  75,  76,  77,  78,  79,  80 #> NK: 81,  82,  83,  84,  85,  86,  87,  88,  89,  90 #> NK: 91,  92,  93,  94,  95,  96,  97,  98,  99,  100 #>  #> CV Q2 criterion: #>  0  1  2  #>  0 87 13  #>  #> CV Press criterion: #>  1  2  3  4  5  #>  0  0 44 45 11 plot(res.cv.modpls) res<-plsR(Y~.,data=Cornell,nt=1,pvals.expli=TRUE) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** res #> Number of required components: #> [1] 1 #> Number of successfully computed components: #> [1] 1 #> Coefficients: #>                  [,1] #> Intercept  92.4321920 #> X1        -14.8845522 #> X2         -0.5942086 #> X3        -25.5423703 #> X4         -5.1075228 #> X5         14.1877035 #> X6          5.5177190 #> X7        -44.9000310 #> Information criteria and Fit statistics: #>                AIC     RSS_Y     R2_Y R2_residY RSS_residY   AIC.std #> Nb_Comp_0 82.01205 467.79667       NA        NA 11.0000000 37.010388 #> Nb_Comp_1 53.15173  35.74249 0.923594  0.923594  0.8404663  8.150064 #>            DoF.dof sigmahat.dof   AIC.dof   BIC.dof GMDL.dof DoF.naive #> Nb_Comp_0 1.000000     6.521271 46.070884 47.789351 27.59461         1 #> Nb_Comp_1 2.740749     1.866528  4.569969  4.955816 21.34020         2 #>           sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0       6.521271 46.070884  47.78935   27.59461 #> Nb_Comp_1       1.890568  4.169957   4.45882   18.37545 res$wwetoile #>    Coord_Comp_1 #> X1  -0.43699629 #> X2  -0.03696135 #> X3  -0.43734182 #> X4  -0.36884361 #> X5   0.25772058 #> X6   0.51412193 #> X7  -0.38679886 biplot(res6$tt,res6$pp) modpls2 <- plsR(Y~.,data=Cornell,6,sparse=TRUE) #> ____************************************************____ #> No significant predictors (<0.05) found #> Warning only one standard component (without sparse option) was thus extracted #> ____Component____ 1 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** modpls3 <- plsR(Y~.,data=Cornell,6,sparse=TRUE,sparseStop=FALSE) #> ____************************************************____ #> No significant predictors (<0.05) found #> Warning only one standard component (without sparse option) was thus extracted #> ____Component____ 1 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________****"},{"path":"https://fbertran.github.io/plsRglm/index.html","id":"bootstrap-yx","dir":"","previous_headings":"Example for regular PLS regression: Cornell","what":"Bootstrap (y,X)","title":"Partial Least Squares Regression for Generalized Linear Models","text":"bootstrap intercept since boostrap done centered scaled response predictors. consequence exclude boxplots using option indice=2:8 must exclude CI computations, request BCa ones, option indice=2:8. Graphical results bootstrap (Y,X): distributions estimators. plot chunk chunk19 Graphical results bootstrap (Y,X): confidence intervals plot chunk chunk20 Bootstrap perfomed using boot package. allows user apply functions, including jack..boot plot.boot, package bootstrapped PLSR PLSGLR models. plot chunk chunk21 Using dataEllipse car can plot confidence ellipses two parameters PLSR PLSGLR models. plot chunk chunk22 ###Bootstrap (y, T) Re-sampling couple (Y,T) (Bastien et al. (2005)) stable faster first one. set 1000 number re-sampling. Boxplots predictors. plot chunk chunk24 bootstrap intercept since boostrap done centered scaled response predictors. consequence exclude boxplots using option indice=2:8 must exclude CI computations, request BCa ones, option indice=2:8. CIs predictors. plot chunk chunk25 Since cross validation empirical distribution retained number components, makes sense perform (y,T) bootstrap numbers components compare resulting significance predictors 5% level. signpred function can used plot summary selection. addition, one can compute empirical measure significance πe\\pi_e computing weighted -respect empirical distribution components- average significance indicatrices. case, predictors significant 1 2 components model hence empirical mesure significance equal 1 . Compute empirical measures significance πe\\pi_e. signpred function can used plot summary variable selection. plot chunk chunk32","code":"set.seed(123) Cornell.bootYX1=bootpls(res,R=1000,verbose=FALSE) boxplots.bootpls(Cornell.bootYX1,indice=2:8) temp.ci=confints.bootpls(Cornell.bootYX1,indice=2:8) plots.confints.bootpls(temp.ci,typeIC=\"BCa\",colIC=c(\"blue\",\"blue\",\"blue\",\"blue\"), legendpos =\"topright\") plot(Cornell.bootYX1,index=2,jack=TRUE) car::dataEllipse(Cornell.bootYX1$t[,2], Cornell.bootYX1$t[,3], cex=.3, levels=c(.5, .95, .99), robust=T, xlab=\"X2\", ylab=\"X3\") set.seed(123) Cornell.bootYT1=bootpls(res,typeboot=\"fmodel_np\",R=1000) boxplots.bootpls(Cornell.bootYT1,indices=2:8) temp.ci=confints.bootpls(Cornell.bootYT1,indices=2:8) plots.confints.bootpls(temp.ci,typeIC=\"BCa\",colIC=c(\"blue\",\"blue\",\"blue\",\"blue\"), legendpos =\"topright\") res2<-plsR(Y~.,data=Cornell,nt=2) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** Cornell.bootYT2=bootpls(res2,typeboot=\"fmodel_np\",R=1000) temp.ci2<-confints.bootpls(Cornell.bootYT2,indices=2:8) ind.BCa.CornellYT1 <- (temp.ci[,7]<0&temp.ci[,8]<0)|(temp.ci[,7]>0&temp.ci[,8]>0) ind.BCa.CornellYT2 <- (temp.ci2[,7]<0&temp.ci2[,8]<0)|(temp.ci2[,7]>0&temp.ci2[,8]>0) (matind=(rbind(YT1=ind.BCa.CornellYT1,YT2=ind.BCa.CornellYT2))) #>       X1   X2   X3   X4    X5   X6   X7 #> YT1 TRUE TRUE TRUE TRUE  TRUE TRUE TRUE #> YT2 TRUE TRUE TRUE TRUE FALSE TRUE TRUE pi.e=prop.table(res.cv.modpls$CVQ2)[-1]%*%matind pi.e #>      X1 X2 X3 X4   X5 X6 X7 #> [1,]  1  1  1  1 0.87  1  1 signpred(t(matind),labsize=.5, plotsize = 12) text(1:(ncol(matind))-.5,-.5,pi.e,cex=1.4) mtext(expression(pi[e]),side=2,las=1,line=2,at=-.5,cex=1.4)"},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/index.html","id":"cross-validation-1","dir":"","previous_headings":"Example for PLS ordinal logistic regression: Bordeaux wine quality","what":"Cross-validation","title":"Partial Least Squares Regression for Generalized Linear Models","text":"discrepancy formula specification (formula data) datasets (dataY dataX) ones. Number components retained: * AIC -> 2. * BIC -> 1. * Non cross validated missclassed -> 1. * Non significant predictor criterion -> 1. According results cross validation procedure, retain single component, also, chance dataset, BIC raw cross-validation choices. plot chunk chunk41 Fit model selected according cross validated missclassed criterion. final model. also possible display biplot observations predictors. plot chunk chunk44 Application PLSGLR ordinal regression incomplete dataset. warning raised since missing value, longer possible use 4 (= number variables dataset) component model.","code":"rm(list = ls()) set.seed(12345) data(bordeaux) bordeaux$Quality<-factor(bordeaux$Quality,ordered=TRUE) modpls1 <- plsRglm(Quality~.,data=bordeaux,4,modele=\"pls-glm-polr\",pvals.expli=TRUE) #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** modpls1 #> Number of required components: #> [1] 4 #> Number of successfully computed components: #> [1] 4 #> Coefficients: #>                     [,1] #> 1|2         -85.50956454 #> 2|3         -80.55155990 #> Temperature   0.02427235 #> Sunshine      0.01379029 #> Heat         -0.08876364 #> Rain         -0.02589509 #> Information criteria and Fit statistics: #>                AIC      BIC Missclassed Chi2_Pearson_Y #> Nb_Comp_0 78.64736 81.70009          22      62.333333 #> Nb_Comp_1 36.50286 41.08194           6       9.356521 #> Nb_Comp_2 35.58058 41.68602           6       8.568956 #> Nb_Comp_3 36.26588 43.89768           7       8.281011 #> Nb_Comp_4 38.15799 47.31616           7       8.321689 Xbordeaux<-bordeaux[,1:4] ybordeaux<-bordeaux$Quality modpls2 <- plsRglm(ybordeaux,Xbordeaux,4,modele=\"pls-glm-polr\",pvals.expli=TRUE) #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** modpls2 #> Number of required components: #> [1] 4 #> Number of successfully computed components: #> [1] 4 #> Coefficients: #>                     [,1] #> 1|2         -85.50956454 #> 2|3         -80.55155990 #> Temperature   0.02427235 #> Sunshine      0.01379029 #> Heat         -0.08876364 #> Rain         -0.02589509 #> Information criteria and Fit statistics: #>                AIC      BIC Missclassed Chi2_Pearson_Y #> Nb_Comp_0 78.64736 81.70009          22      62.333333 #> Nb_Comp_1 36.50286 41.08194           6       9.356521 #> Nb_Comp_2 35.58058 41.68602           6       8.568956 #> Nb_Comp_3 36.26588 43.89768           7       8.281011 #> Nb_Comp_4 38.15799 47.31616           7       8.321689 all(modpls1$InfCrit==modpls2$InfCrit) #> [1] TRUE colSums(modpls2$pvalstep) #> temppvalstep temppvalstep temppvalstep temppvalstep  #>            4            0            0            0 set.seed(123) cv.modpls<-cv.plsRglm(ybordeaux,Xbordeaux,nt=4,modele=\"pls-glm-polr\",NK=100,verbose=FALSE) res.cv.modpls=cvtable(summary(cv.modpls, MClassed = TRUE)) #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1,  2,  3,  4,  5,  6,  7,  8,  9,  10 #> NK: 11,  12,  13,  14,  15,  16,  17,  18,  19,  20 #> NK: 21,  22,  23,  24,  25,  26,  27,  28,  29,  30 #> NK: 31,  32,  33,  34,  35,  36,  37,  38,  39,  40 #> NK: 41,  42,  43,  44,  45,  46,  47,  48,  49,  50 #> NK: 51,  52,  53,  54,  55,  56,  57,  58,  59,  60 #> NK: 61,  62,  63,  64,  65,  66,  67,  68,  69,  70 #> NK: 71,  72,  73,  74,  75,  76,  77,  78,  79,  80 #> NK: 81,  82,  83,  84,  85,  86,  87,  88,  89,  90 #> NK: 91,  92,  93,  94,  95,  96,  97,  98,  99,  100 #> CV MissClassed criterion: #>  1  2  3  4  #> 89  7  1  3  #>  #> CV Q2Chi2 criterion: #>   0  #> 100  #>  #> CV PreChi2 criterion: #>  1  2  3  4  #> 35 59  4  2 plot(res.cv.modpls) res<-plsRglm(ybordeaux,Xbordeaux,1,modele=\"pls-glm-polr\") #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Component____ 1 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** res$FinalModel #> Call: #> MASS::polr(formula = YwotNA ~ ., data = tttrain, na.action = na.exclude,  #>     Hess = TRUE, method = method) #>  #> Coefficients: #>        tt  #> -2.689946  #>  #> Intercepts: #>       1|2       2|3  #> -2.265213  2.298934  #>  #> Residual Deviance: 30.50286  #> AIC: 36.50286 biplot(modpls1$tt,modpls1$pp) XbordeauxNA<-Xbordeaux XbordeauxNA[1,1] <- NA modplsNA <- plsRglm(ybordeaux,XbordeauxNA,4,modele=\"pls-glm-polr\") #> ____************************************************____ #> Only naive DoF can be used with missing data #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____There are some NAs in X but not in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> Warning : reciprocal condition number of t(cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE])%*%cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE] < 10^{-12} #> Warning only 3 components could thus be extracted #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** modplsNA #> Number of required components: #> [1] 4 #> Number of successfully computed components: #> [1] 3 #> Coefficients: #>                     [,1] #> 1|2         -89.16630231 #> 2|3         -84.11693439 #> Temperature   0.02461148 #> Sunshine      0.01535315 #> Heat         -0.09542680 #> Rain         -0.02399436 #> Information criteria and Fit statistics: #>                AIC      BIC Missclassed Chi2_Pearson_Y #> Nb_Comp_0 78.64736 81.70009          22      62.333333 #> Nb_Comp_1 36.21263 40.79171           6       9.454055 #> Nb_Comp_2 35.29582 41.40126           5       8.234674 #> Nb_Comp_3 35.81623 43.44803           7       7.803408 data.frame(formula=modpls1$Coeffs,datasets=modpls2$Coeffs,datasetsNA=modplsNA$Coeffs) #>                  formula     datasets   datasetsNA #> 1|2         -85.50956454 -85.50956454 -89.16630231 #> 2|3         -80.55155990 -80.55155990 -84.11693439 #> Temperature   0.02427235   0.02427235   0.02461148 #> Sunshine      0.01379029   0.01379029   0.01535315 #> Heat         -0.08876364  -0.08876364  -0.09542680 #> Rain         -0.02589509  -0.02589509  -0.02399436"},{"path":"https://fbertran.github.io/plsRglm/index.html","id":"bootstrap-yx-1","dir":"","previous_headings":"Example for PLS ordinal logistic regression: Bordeaux wine quality","what":"Bootstrap (y,X)","title":"Partial Least Squares Regression for Generalized Linear Models","text":"now work full dataset apply ordinary balanced bootstrap technique.   Ordinary balanced bootstrap: Boxplots predictors distribution. plot chunk chunk49 Ordinary balanced bootstrap: CIs predictors distribution. Ordinary balanced bootstrap: plot CIs predictors distribution. plot chunk chunk51 strata option integer vector factor specifying strata multi-sample problems. ensures , nonparametric bootstrap, resampling done within specified strata. case improves results bootstrap can seen plot CIs predictors plots boxplots well. apply stratified balanced bootstrap technique. Stratified balanced bootstrap: Boxplots predictors distribution. plot chunk chunk53 Stratified balanced bootstrap: CIs predictors distribution. Stratified balanced bootstrap: plot CIs predictors distribution. plot chunk chunk55","code":"options(contrasts = c(\"contr.treatment\", \"contr.poly\")) modplsglm3 <- plsRglm(ybordeaux,Xbordeaux,1,modele=\"pls-glm-polr\") #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Component____ 1 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** bordeaux.bootYT<- bootplsglm(modplsglm3, sim=\"permutation\", R=250, verbose=FALSE) boxplots.bootpls(bordeaux.bootYT) boxplots.bootpls(bordeaux.bootYT,ranget0=TRUE) bordeaux.bootYX1<- bootplsglm(res, typeboot = \"plsmodel\", sim=\"balanced\", R=1000, verbose=FALSE) boxplots.bootpls(bordeaux.bootYX1) temp.ci=confints.bootpls(bordeaux.bootYX1) plots.confints.bootpls(temp.ci,typeIC=\"BCa\",colIC=c(\"blue\",\"blue\",\"blue\",\"blue\"),legendpos =\"topright\") bordeaux.bootYX1strata<- bootplsglm(res,typeboot = \"plsmodel\", sim=\"balanced\", R=1000, strata=unclass(ybordeaux), verbose=FALSE) boxplots.bootpls(bordeaux.bootYX1strata) confints.bootpls(bordeaux.bootYX1strata) #>                                                                             #> 1|2         -5.2285517 1.8448908 -3.0266055 2.1579125 -6.6883385 -1.5038206 #> 2|3         -1.4216229 4.9525537 -2.3021666 3.1831363  1.4147309  6.9000338 #> Temperature -0.7320271 3.1003955 -1.6883027 2.0324540  1.0278307  4.7485873 #> Sunshine    -0.8132215 3.5499277 -0.7684357 2.2776395  1.1162563  4.1623315 #> Heat        -0.7762493 2.4414119 -1.4124977 1.6043794  0.5748209  3.5916981 #> Rain        -1.8637554 0.3290778 -1.4058759 0.4748013 -2.2942690 -0.4135918 #>                                   #> 1|2         -4.5562748 -1.3483662 #> 2|3          1.2896677  4.7862147 #> Temperature  0.9261003  3.2057586 #> Sunshine     1.0299078  3.0499807 #> Heat         0.5437488  2.7944714 #> Rain        -1.9548575 -0.3625478 #> attr(,\"typeBCa\") #> [1] TRUE plots.confints.bootpls(temp.ci,typeIC=\"BCa\",colIC=c(\"blue\",\"blue\",\"blue\",\"blue\"),legendpos =\"topright\")"},{"path":"https://fbertran.github.io/plsRglm/index.html","id":"bootstrap-yt","dir":"","previous_headings":"Example for PLS ordinal logistic regression: Bordeaux wine quality","what":"Bootstrap (y,T)","title":"Partial Least Squares Regression for Generalized Linear Models","text":"apply ordinary balanced bootstrap technique. Ordinary balanced bootstrap: Boxplots predictors distribution. plot chunk chunk57 Ordinary balanced bootstrap: CIs predictors distribution. Ordinary balanced bootstrap: plot CIs predictors distribution. plot chunk chunk59 strata option improve results bootstrap can seen CIs predictors boxplots well. apply stratified balanced bootstrap technique. Stratified balanced bootstrap: Boxplots predictors distribution. plot chunk chunk61 Stratified balanced bootstrap: CIs predictors distribution. Stratified balanced bootstrap: plot CIs predictors distribution. plot chunk chunk63 interesting display, models 1 4 components, predictors significantly different zero know stability significant predictors . function available package, called signpred, kind analysis can see , single difference stratified bootstrap regular one. Indeed, 1 predictor significant stratified bootstrap 2 component model turn non-significant regular bootstrap 2 components model. cross-validation miss-classified criterion, 84 percents results give 1 component 7 percents give 2 components, representing 91 percents results obtained 100 cross-validation made beginning. bootstrap technique used study, clearly faster stable one, results (y,X) (y,T) bootstrap techniques really different interesting confront help simulations. first compute bootstrap distributions coefficients 1000 resampling. derive corresponding CIs. variable significant model 0 lie inside BCa CI. matrix summing results ordinary balanced bootstrap. Compute empirical measures significance πe\\pi_e ordinary balanced bootstrap. Display empirical measures significance πe\\pi_e ordinary balanced bootstrap. Plot variable selection results empirical measures significance πe\\pi_e ordinary balanced bootstrap. plot chunk chunk69 matrix summing results stratified balanced bootstrap. Compute empirical measures significance πe\\pi_e stratified balanced bootstrap. Display empirical measures significance πe\\pi_e stratified balanced bootstrap. Plot variable selection results empirical measures significance πe\\pi_e stratified balanced bootstrap. plot chunk chunk73 examples can found vignette online references. Unfortunately, number examples compatible online viewing even work without problem computer.","code":"bordeaux.bootYT1<- bootplsglm(res,sim=\"balanced\", R=1000, verbose=FALSE) boxplots.bootpls(bordeaux.bootYT1) temp.ci=confints.bootpls(bordeaux.bootYT1) plots.confints.bootpls(temp.ci,typeIC=\"BCa\",colIC=c(\"blue\",\"blue\",\"blue\",\"blue\"),legendpos =\"topright\") bordeaux.bootYT1strata<- bootplsglm(res, sim=\"balanced\", R=1000, strata=unclass(ybordeaux), verbose=FALSE) boxplots.bootpls(bordeaux.bootYT1strata) temp.cis <- confints.bootpls(bordeaux.bootYT1strata) plots.confints.bootpls(temp.cis,typeIC=\"BCa\",colIC=c(\"blue\",\"blue\",\"blue\",\"blue\"),legendpos =\"topright\") res2<-plsRglm(ybordeaux,Xbordeaux,2,modele=\"pls-glm-polr\", verbose=FALSE) res3<-plsRglm(ybordeaux,Xbordeaux,3,modele=\"pls-glm-polr\", verbose=FALSE) res4<-plsRglm(ybordeaux,Xbordeaux,4,modele=\"pls-glm-polr\", verbose=FALSE) bordeaux.bootYT2=bootplsglm(res2,sim=\"balanced\", R=1000, verbose=FALSE) bordeaux.bootYT3=bootplsglm(res3,sim=\"balanced\", R=1000, verbose=FALSE) bordeaux.bootYT4=bootplsglm(res4,sim=\"balanced\", R=1000, verbose=FALSE) bordeaux.bootYT2s=bootplsglm(res2,sim=\"balanced\", R=1000,strata=unclass(ybordeaux), verbose=FALSE) bordeaux.bootYT3s=bootplsglm(res3,sim=\"balanced\", R=1000,strata=unclass(ybordeaux), verbose=FALSE) bordeaux.bootYT4s=bootplsglm(res4,sim=\"balanced\", R=1000,strata=unclass(ybordeaux), verbose=FALSE) temp.ci2<-confints.bootpls(bordeaux.bootYT2) temp.ci3<-confints.bootpls(bordeaux.bootYT3) temp.ci4<-confints.bootpls(bordeaux.bootYT4) temp.cis2<-confints.bootpls(bordeaux.bootYT2s) temp.cis3<-confints.bootpls(bordeaux.bootYT3s) temp.cis4<-confints.bootpls(bordeaux.bootYT4s) ind.BCa.bordeauxYT1 <- (temp.ci[,7]<0&temp.ci[,8]<0)|(temp.ci[,7]>0&temp.ci[,8]>0) ind.BCa.bordeauxYT2 <- (temp.ci2[,7]<0&temp.ci2[,8]<0)|(temp.ci2[,7]>0&temp.ci2[,8]>0) ind.BCa.bordeauxYT3 <- (temp.ci3[,7]<0&temp.ci3[,8]<0)|(temp.ci3[,7]>0&temp.ci3[,8]>0) ind.BCa.bordeauxYT4 <- (temp.ci4[,7]<0&temp.ci4[,8]<0)|(temp.ci4[,7]>0&temp.ci4[,8]>0) ind.BCa.bordeauxYT1s <- (temp.cis[,7]<0&temp.cis[,8]<0)|(temp.cis[,7]>0&temp.cis[,8]>0) ind.BCa.bordeauxYT2s <- (temp.cis2[,7]<0&temp.cis2[,8]<0)|(temp.cis2[,7]>0&temp.cis2[,8]>0) ind.BCa.bordeauxYT3s <- (temp.cis3[,7]<0&temp.cis3[,8]<0)|(temp.cis3[,7]>0&temp.cis3[,8]>0) ind.BCa.bordeauxYT4s <- (temp.cis4[,7]<0&temp.cis4[,8]<0)|(temp.cis4[,7]>0&temp.cis4[,8]>0) (matind=(rbind(YT1=ind.BCa.bordeauxYT1,YT2=ind.BCa.bordeauxYT2,YT3=ind.BCa.bordeauxYT3,YT4=ind.BCa.bordeauxYT4))) #>     Temperature Sunshine  Heat  Rain #> YT1        TRUE     TRUE  TRUE  TRUE #> YT2       FALSE    FALSE FALSE FALSE #> YT3       FALSE    FALSE FALSE FALSE #> YT4       FALSE    FALSE FALSE FALSE pi.e=prop.table(res.cv.modpls$CVMC)%*%matind pi.e #>      Temperature Sunshine Heat Rain #> [1,]        0.89     0.89 0.89 0.89 signpred(t(matind),labsize=.5, plotsize = 12) mtext(expression(pi[e]),side=2,las=1,line=2,at=-.3,cex=1.4) text(1:(ncol(matind))-.5,-.3,pi.e,cex=1.4) text(1:(ncol(matind))-.5,-.75,c(\"Temp\",\"Sun\",\"Heat\",\"Rain\"),cex=1.4) (matinds=(rbind(YT1=ind.BCa.bordeauxYT1s,YT2=ind.BCa.bordeauxYT2s,YT3=ind.BCa.bordeauxYT3s,YT4=ind.BCa.bordeauxYT4s))) #>     Temperature Sunshine  Heat  Rain #> YT1        TRUE     TRUE  TRUE  TRUE #> YT2        TRUE    FALSE FALSE FALSE #> YT3       FALSE    FALSE FALSE FALSE #> YT4       FALSE    FALSE FALSE FALSE pi.es=prop.table(res.cv.modpls$CVMC)%*%matinds pi.es #>      Temperature Sunshine Heat Rain #> [1,]        0.96     0.89 0.89 0.89 signpred(t(matinds),pred.lablength=10,labsize=.5, plotsize = 12) mtext(expression(pi[es]),side=2,las=1,line=2,at=-.3,cex=1.4) text(1:(ncol(matinds))-.5,-.3,pi.es,cex=1.4) text(1:(ncol(matinds))-.5,-.75,c(\"Temp\",\"Sun\",\"Heat\",\"Rain\"),cex=1.4)"},{"path":"https://fbertran.github.io/plsRglm/reference/AICpls.html","id":null,"dir":"Reference","previous_headings":"","what":"AIC function for plsR models — AICpls","title":"AIC function for plsR models — AICpls","text":"function provides AIC computation univariate plsR model.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/AICpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AIC function for plsR models — AICpls","text":"","code":"AICpls(ncomp, residpls, weights = rep.int(1, length(residpls)))"},{"path":"https://fbertran.github.io/plsRglm/reference/AICpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"AIC function for plsR models — AICpls","text":"ncomp Number components residpls Residuals fitted univariate plsR model weights Weights observations","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/AICpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"AIC function for plsR models — AICpls","text":"real AIC value","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/AICpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"AIC function for plsR models — AICpls","text":"AIC function plsR models univariate response.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/AICpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"AIC function for plsR models — AICpls","text":"Baibing Li, Julian Morris, Elaine B. Martin, Model selection partial least squares regression, Chemometrics Intelligent Laboratory Systems 64 (2002) 79-89, doi:10.1016/S0169-7439(02)00051-5 .","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/AICpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"AIC function for plsR models — AICpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/AICpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"AIC function for plsR models — AICpls","text":"","code":"data(pine) ypine <- pine[,11] Xpine <- pine[,1:10] (Pinscaled <- as.data.frame(cbind(scale(ypine),scale(as.matrix(Xpine))))) #>             V1           x1           x2          x3          x4          x5 #> 1   1.93343137 -0.893800639 -0.962578437 -1.09627645 -0.43382827 -0.10494125 #> 2   0.81712282  0.206659107 -0.141067529 -0.36224787 -0.04949719  0.63880345 #> 3   0.39540626 -0.653559427 -0.141067529 -0.67683154 -1.97115262 -1.73188279 #> 4   0.04811027 -0.475315947 -0.141067529  0.68636438 -1.39465599 -1.40649448 #> 5  -0.70849886  0.322904855  0.406606409 -0.46710909 -0.72207659 -1.05786415 #> 6   0.84192968 -0.506314813 -0.277986014 -1.09627645 -0.04949719 -0.10494125 #> 7  -0.63407829  0.826636429  1.091198831  1.10580928 -1.39465599 -1.66215672 #> 8  -0.91935714 -0.049081538  2.323465192 -0.46710909  1.19957885  1.01067580 #> 9   2.71484735 -1.459529946 -0.688741468 -0.99141522 -0.91424213 -0.61626573 #> 10  0.49463369 -1.862515205  0.680443378 -0.25738664 -0.14557996 -0.75571786 #> 11 -0.53485086 -1.157291001 -0.688741468  0.58150316  1.00741330  0.33665717 #> 12 -0.13794116 -1.033295537  1.638872769  2.15442154  0.91133053  1.47551624 #> 13  2.26832393 -1.056544686 -1.921007828 -1.20113767 -1.20249045 -1.10434819 #> 14  1.53652166 -0.459816514 -1.099496921 -1.20113767  0.62308222  0.98743378 #> 15  1.16441881 -0.498565096 -0.414904499 -0.99141522 -0.24166273  0.26693110 #> 16 -0.93176057  1.710104113  1.228117316  2.04956031  1.19957885  0.59231941 #> 17 -0.84493657  1.849599011 -0.277986014  0.89608683  1.10349607  1.15012793 #> 18  0.23416169 -0.080080404  0.132769440 -0.57197032 -0.62599382  0.10423695 #> 19 -0.49764058  0.005166478  0.680443378 -0.36224787 -1.29857322 -0.89517000 #> 20 -0.11313430  0.865385012  1.365035800  0.79122561  0.14266836 -0.01197316 #> 21 -0.17515144  2.012343058 -1.236415406  2.15442154  0.71916499  0.84798165 #> 22 -0.85734000  0.632893516 -0.414904499  0.47664193 -0.24166273 -0.10494125 #> 23  0.19695141  0.477899186 -0.004149045 -0.78169277  0.81524776  1.05715985 #> 24 -0.91935714  2.004593341 -0.688741468  1.21067051  0.71916499  0.59231941 #> 25 -0.88214685  0.625143800  2.186546707  0.16205826  0.23875113 -0.01197316 #> 26 -0.16274801  0.601894650 -0.277986014 -0.67683154  0.23875113  0.70852952 #> 27 -0.84493657  0.911883311 -0.825659952  0.68636438  1.96824102  1.33606411 #> 28 -0.75811257  0.260907123 -0.688741468 -1.09627645 -1.68290430 -2.19672323 #> 29  0.34579255 -0.831802907 -0.825659952 -0.99141522 -0.91424213 -0.87192797 #> 30 -0.78291943 -0.909300072 -0.141067529  0.37178071 -0.52991104 -0.91841202 #> 31 -0.57206115 -0.676808577  0.269687924 -0.57197032  0.91133053  1.52200029 #> 32 -0.74570914 -0.669058860 -1.099496921 -0.04766419  1.29566162  0.33665717 #> 33 -0.96897085 -0.041331821  0.954280347  0.58150316  0.71916499  0.59231941 #>            x6         x7          x8          x9        x10 #> 1  -1.1025308 -2.9795617 -0.69706483 -1.02706110 -1.3713833 #> 2  -0.4055286 -0.8420501 -0.48446650 -0.49748272 -0.2009786 #> 3  -0.6843294 -0.3076721 -1.37737948 -0.85053497 -1.3713833 #> 4   0.7096750  0.2267058 -0.27186817  0.56167404 -0.5911135 #> 5  -0.5449290  0.2267058 -0.39942716 -0.32095659 -1.7615182 #> 6  -1.1025308  0.2267058 -0.73958449 -1.20358722 -1.3713833 #> 7   1.2672767  1.2954616  0.32340716  0.91472629  0.9694261 #> 8  -0.4055286 -1.9108059  0.11080883 -0.32095659 -0.5911135 #> 9  -1.1025308  0.2267058 -1.12226148 -0.85053497  0.9694261 #> 10 -0.2661281  0.7610837 -0.31438783  0.03209566  0.9694261 #> 11  0.8490754 -0.8420501  1.68403646  1.62083079 -0.2009786 #> 12  2.1036794 -1.3764280  1.59899713  1.44430467  0.9694261 #> 13 -1.1025308  0.2267058 -1.50493848 -1.55663947 -0.5911135 #> 14 -1.1025308  0.7610837 -0.73958449 -1.55663947 -1.3713833 #> 15 -0.9631303  0.2267058 -0.56950583 -1.20358722  0.1891563 #> 16  1.8248785  0.2267058  1.64151680  1.44430467  0.5792912 #> 17  1.4066772  1.2954616  0.70608415  1.26777854 -1.7615182 #> 18 -0.5449290 -2.4451838 -0.14430917  0.20862179  0.5792912 #> 19 -0.4055286  0.7610837 -1.07974182 -0.67400884  0.9694261 #> 20  0.8490754 -0.3076721  0.66356448  0.73820016  0.5792912 #> 21  1.6854781  0.2267058  0.79112348  0.91472629  0.1891563 #> 22  0.5702745 -0.3076721  0.06828916  0.38514791  0.1891563 #> 23 -0.8237299  0.7610837 -0.31438783 -0.67400884  0.5792912 #> 24  0.8490754  0.7610837  0.11080883  0.38514791  0.9694261 #> 25 -0.1267277 -0.3076721  0.11080883  0.20862179 -1.3713833 #> 26 -0.8237299  0.2267058 -0.01675017 -0.49748272  0.9694261 #> 27  1.2672767  0.7610837  2.61946911  1.26777854 -1.7615182 #> 28 -1.1025308  0.2267058 -1.67501714 -1.20358722  0.1891563 #> 29 -0.9631303  0.2267058 -0.90966315 -1.20358722  0.9694261 #> 30  0.2914737 -0.3076721 -0.05926984  1.44430467  0.9694261 #> 31 -0.6843294  0.2267058 -0.22934850 -0.85053497  0.5792912 #> 32 -0.1267277  0.7610837  1.04624148  0.56167404  0.9694261 #> 33  0.7096750  1.2954616  1.17380047  1.09125241  0.9694261 colnames(Pinscaled)[1] <- \"yy\"  lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled) #>  #> Call: #> lm(formula = yy ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 +  #>     x10, data = Pinscaled) #>  #> Coefficients: #> (Intercept)           x1           x2           x3           x4           x5   #>   1.119e-16   -4.601e-01   -3.175e-01    3.298e-01   -6.020e-01    5.539e-01   #>          x6           x7           x8           x9          x10   #>   6.720e-02   -6.054e-02    6.865e-02   -6.231e-01   -1.058e-01   #>   modpls <- plsR(ypine,Xpine,10) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X nor in Y____ #> Loading required namespace: plsdof #> ****________________________________________________**** #>  modpls$Std.Coeffs #>                  [,1] #> Intercept  0.00000000 #> x1        -0.46014550 #> x2        -0.31750091 #> x3         0.32980012 #> x4        -0.60199305 #> x5         0.55393816 #> x6         0.06720419 #> x7        -0.06054179 #> x8         0.06864663 #> x9        -0.62312421 #> x10       -0.10578863 lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled) #>  #> Call: #> lm(formula = yy ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 +  #>     x10, data = Pinscaled) #>  #> Coefficients: #> (Intercept)           x1           x2           x3           x4           x5   #>   1.119e-16   -4.601e-01   -3.175e-01    3.298e-01   -6.020e-01    5.539e-01   #>          x6           x7           x8           x9          x10   #>   6.720e-02   -6.054e-02    6.865e-02   -6.231e-01   -1.058e-01   #>   AIC(lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled)) #> [1] 79.37542 print(logLik(lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled))) #> 'log Lik.' -27.68771 (df=12)  sum(dnorm(modpls$RepY, modpls$Std.ValsPredictY, sqrt(mean(modpls$residY^2)), log=TRUE)) #> [1] -27.68771 sum(dnorm(Pinscaled$yy,fitted(lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled)), sqrt(mean(residuals(lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled))^2)), log=TRUE)) #> [1] -27.68771 loglikpls(modpls$residY) #> [1] -27.68771 loglikpls(residuals(lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled))) #> [1] -27.68771 AICpls(10,residuals(lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled))) #> [1] 79.37542 AICpls(10,modpls$residY) #> [1] 79.37542"},{"path":"https://fbertran.github.io/plsRglm/reference/CorMat.html","id":null,"dir":"Reference","previous_headings":"","what":"Correlation matrix for simulating plsR datasets — CorMat","title":"Correlation matrix for simulating plsR datasets — CorMat","text":"correlation matrix simulate datasets","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/CorMat.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Correlation matrix for simulating plsR datasets — CorMat","text":"data frame 17 observations following 17 variables. y numeric vector x11 numeric vector x12 numeric vector x13 numeric vector x21 numeric vector x22 numeric vector x31 numeric vector x32 numeric vector x33 numeric vector x34 numeric vector x41 numeric vector x42 numeric vector x51 numeric vector x61 numeric vector x62 numeric vector x63 numeric vector x64 numeric vector","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/CorMat.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Correlation matrix for simulating plsR datasets — CorMat","text":"Handmade.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/CorMat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Correlation matrix for simulating plsR datasets — CorMat","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/CorMat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Correlation matrix for simulating plsR datasets — CorMat","text":"","code":"data(CorMat) str(CorMat) #> 'data.frame':\t17 obs. of  17 variables: #>  $ y  : num  1 0.9 0.88 0.92 0.77 0.8 0.65 0.7 0.66 0.6 ... #>  $ x11: num  0.9 1 0.75 0.8 0.1 0.1 0.05 0.1 0.1 0.05 ... #>  $ x12: num  0.88 0.75 1 0.65 0.1 0.05 0.1 0.1 0.05 0.1 ... #>  $ x13: num  0.92 0.8 0.65 1 0.05 0.1 0.15 0.05 0.1 0.15 ... #>  $ x21: num  0.77 0.1 0.1 0.05 1 0.95 0.1 0.05 0.1 0.1 ... #>  $ x22: num  0.8 0.1 0.05 0.1 0.95 1 0.05 0.1 0.15 0.05 ... #>  $ x31: num  0.65 0.05 0.1 0.15 0.1 0.05 1 0.75 0.8 0.92 ... #>  $ x32: num  0.7 0.1 0.1 0.05 0.05 0.1 0.75 1 0.65 0.55 ... #>  $ x33: num  0.66 0.1 0.05 0.1 0.1 0.15 0.8 0.65 1 0.7 ... #>  $ x34: num  0.6 0.05 0.1 0.15 0.1 0.05 0.92 0.55 0.7 1 ... #>  $ x41: num  0.2 0.1 0.1 0.05 0.1 0.1 0.1 0.1 0.05 0.1 ... #>  $ x42: num  0.15 0.1 0.05 0.1 0.1 0.05 0.1 0.05 0.1 0.1 ... #>  $ x51: num  0.1 0.05 0.1 0.15 0.05 0.1 0.05 0.1 0.1 0.1 ... #>  $ x61: num  0.05 0.1 0.1 0.05 0.1 0.1 0.1 0.1 0.1 0.1 ... #>  $ x62: num  0.07 0.1 0.05 0.1 0.1 0.05 0.1 0.05 0.05 0.1 ... #>  $ x63: num  0.08 0.05 0.1 0.15 0.05 0.1 0.05 0.1 0.1 0.05 ... #>  $ x64: num  0.02 0.15 0.1 0.05 0.1 0.1 0.1 0.1 0.05 0.1 ..."},{"path":"https://fbertran.github.io/plsRglm/reference/Cornell.html","id":null,"dir":"Reference","previous_headings":"","what":"Cornell dataset — Cornell","title":"Cornell dataset — Cornell","text":"famous Cornell dataset. mixture experiment X1, X2, X3, X4, X5, X6 X7 analyse octane degree (Y) gazoline.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/Cornell.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cornell dataset — Cornell","text":"data frame 12 observations following 8 variables. X1 numeric vector X2 numeric vector X3 numeric vector X4 numeric vector X5 numeric vector X6 numeric vector X7 numeric vector Y response value: numeric vector","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/Cornell.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Cornell dataset — Cornell","text":"M. Tenenhaus. (1998). La regression PLS, Theorie et pratique. Editions Technip, Paris.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/Cornell.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cornell dataset — Cornell","text":"N. Kettaneh-Wold. Analysis mixture data partial least squares. (1992). Chemometrics Intelligent Laboratory Systems, 14(1):57-69.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/Cornell.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cornell dataset — Cornell","text":"","code":"data(Cornell) str(Cornell) #> 'data.frame':\t12 obs. of  8 variables: #>  $ X1: num  0 0 0 0 0 0 0.17 0.17 0.17 0.17 ... #>  $ X2: num  0.23 0.1 0 0.49 0 0.62 0.27 0.19 0.21 0.15 ... #>  $ X3: num  0 0 0 0 0 0 0.1 0.1 0.1 0.1 ... #>  $ X4: num  0 0 0.1 0 0.62 0 0.38 0.38 0.38 0.38 ... #>  $ X5: num  0 0.12 0.12 0.12 0.12 0 0 0.02 0 0.02 ... #>  $ X6: num  0.74 0.74 0.74 0.37 0.18 0.37 0 0.06 0.06 0.1 ... #>  $ X7: num  0.03 0.04 0.04 0.02 0.08 0.01 0.08 0.08 0.08 0.08 ... #>  $ Y : num  98.7 97.8 96.6 92 86.6 91.2 81.9 83.1 82.4 83.2 ..."},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_glm_wvc.html","id":null,"dir":"Reference","previous_headings":"","what":"Light version of PLS_glm for cross validation purposes — PLS_glm_wvc","title":"Light version of PLS_glm for cross validation purposes — PLS_glm_wvc","text":"Light version PLS_glm cross validation purposes either complete incomplete datasets.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_glm_wvc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Light version of PLS_glm for cross validation purposes — PLS_glm_wvc","text":"","code":"PLS_glm_wvc(   dataY,   dataX,   nt = 2,   dataPredictY = dataX,   modele = \"pls\",   family = NULL,   scaleX = TRUE,   scaleY = NULL,   keepcoeffs = FALSE,   keepstd.coeffs = FALSE,   tol_Xi = 10^(-12),   weights,   method = \"logistic\",   verbose = TRUE )"},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_glm_wvc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Light version of PLS_glm for cross validation purposes — PLS_glm_wvc","text":"dataY response (training) dataset dataX predictor(s) (training) dataset nt number components extracted dataPredictY predictor(s) (testing) dataset modele name PLS glm model fitted (\"pls\", \"pls-glm-Gamma\", \"pls-glm-gaussian\", \"pls-glm-inverse.gaussian\", \"pls-glm-logistic\", \"pls-glm-poisson\", \"pls-glm-polr\"). Use \"modele=pls-glm-family\" enable family option. family description error distribution link function used model. can character string naming family function, family function result call family function. (See family details family functions.) use family option, please set modele=\"pls-glm-family\". User defined families can also defined. See details. scaleX scale predictor(s) : must set TRUE modele=\"pls\" glms pls. scaleY scale response : Yes/. Ignored since non always possible glm responses. keepcoeffs whether coefficients linear fit link scale unstandardized eXplanatory variables returned . keepstd.coeffs whether coefficients linear fit link scale standardized eXplanatory variables returned . tol_Xi minimal value Norm2(Xi) \\(\\mathrm{det}(pp' \\times pp)\\) missing value dataX. defaults \\(10^{-12}\\) weights optional vector 'prior weights' used fitting process. NULL numeric vector. method logistic, probit, complementary log-log cauchit (corresponding Cauchy latent variable). verbose info messages displayed ?","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_glm_wvc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Light version of PLS_glm for cross validation purposes — PLS_glm_wvc","text":"valsPredict nrow(dataPredictY) * nt matrix predicted values list(\"coeffs\") coefficients eXplanatory variables requested: .e. keepcoeffs=TRUE.ncol(dataX) * 1 matrix coefficients eXplanatory variables","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_glm_wvc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Light version of PLS_glm for cross validation purposes — PLS_glm_wvc","text":"function called PLS_glm_kfoldcv_formula order perform cross-validation either complete incomplete datasets. seven different predefined models predefined link functions available : list(\"\\\"pls\\\"\") ordinary pls models list(\"\\\"pls-glm-Gamma\\\"\") glm gaussian inverse link pls models list(\"\\\"pls-glm-gaussian\\\"\") glm gaussian identity link pls models list(\"\\\"pls-glm-inverse-gamma\\\"\") glm binomial square inverse link pls models list(\"\\\"pls-glm-logistic\\\"\") glm binomial logit link pls models list(\"\\\"pls-glm-poisson\\\"\") glm poisson log link pls models list(\"\\\"pls-glm-polr\\\"\") glm polr logit link pls models Using \"family=\" option setting \"modele=pls-glm-family\" allows changing family link function way glm function. consequence user-specified families can also used. accepts links (names) identity, log inverse. list(\"gaussian\") accepts links (names) identity, log inverse. family accepts links (names) identity, log inverse. accepts links logit, probit, cauchit, (corresponding logistic, normal Cauchy CDFs respectively) log cloglog (complementary log-log). list(\"binomial\") accepts links logit, probit, cauchit, (corresponding logistic, normal Cauchy CDFs respectively) log cloglog (complementary log-log). family accepts links logit, probit, cauchit, (corresponding logistic, normal Cauchy CDFs respectively) log cloglog (complementary log-log). accepts links inverse, identity log. list(\"Gamma\") accepts links inverse, identity log. family accepts links inverse, identity log. accepts links log, identity, sqrt. list(\"poisson\") accepts links log, identity, sqrt. family accepts links log, identity, sqrt. accepts links 1/mu^2, inverse, identity log. list(\"inverse.gaussian\") accepts links 1/mu^2, inverse, identity log. family accepts links 1/mu^2, inverse, identity log. accepts links logit, probit, cloglog, identity, inverse, log, 1/mu^2 sqrt. list(\"quasi\") accepts links logit, probit, cloglog, identity, inverse, log, 1/mu^2 sqrt. family accepts links logit, probit, cloglog, identity, inverse, log, 1/mu^2 sqrt. function can used create power link function. list(\"power\") can used create power link function. Non-NULL weights can used indicate different observations different dispersions (values weights inversely proportional dispersions); equivalently, elements weights positive integers w_i, response y_i mean w_i unit-weight observations.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_glm_wvc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Light version of PLS_glm for cross validation purposes — PLS_glm_wvc","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_glm_wvc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Light version of PLS_glm for cross validation purposes — PLS_glm_wvc","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_glm_wvc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Light version of PLS_glm for cross validation purposes — PLS_glm_wvc","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] PLS_glm_wvc(dataY=yCornell,dataX=XCornell,nt=3,modele=\"pls-glm-gaussian\", dataPredictY=XCornell[1,]) #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> $valsPredict #>       [,1]     [,2]    [,3] #> 1 95.03164 97.08409 97.4436 #>  PLS_glm_wvc(dataY=yCornell,dataX=XCornell,nt=3,modele=\"pls-glm-family\", family=gaussian(),dataPredictY=XCornell[1,], verbose=FALSE) #> $valsPredict #>       [,1]     [,2]    [,3] #> 1 95.03164 97.08409 97.4436 #>  PLS_glm_wvc(dataY=yCornell[-1],dataX=XCornell[-1,],nt=3,modele=\"pls-glm-gaussian\", dataPredictY=XCornell[1,], verbose=FALSE) #> $valsPredict #>       [,1]     [,2]     [,3] #> 1 93.74777 95.32475 96.08522 #>  PLS_glm_wvc(dataY=yCornell[-1],dataX=XCornell[-1,],nt=3,modele=\"pls-glm-family\", family=gaussian(),dataPredictY=XCornell[1,], verbose=FALSE) #> $valsPredict #>       [,1]     [,2]     [,3] #> 1 93.74777 95.32475 96.08522 #>  rm(\"XCornell\",\"yCornell\")  # \\donttest{ ## With an incomplete dataset (X[1,2] is NA) data(pine) ypine <- pine[,11] data(XpineNAX21) PLS_glm_wvc(dataY=ypine,dataX=XpineNAX21,nt=10,modele=\"pls-glm-gaussian\") #> ____************************************************____ #> Only naive DoF can be used with missing data #>  #> Family: gaussian  #> Link function: identity  #>  #> ____There are some NAs in X but not in Y____ #> ____Predicting X with NA in X and not in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> Warning : reciprocal condition number of t(cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE])%*%cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE] < 10^{-12} #> Warning only 9 components could thus be extracted #> ****________________________________________________**** #>  #> $valsPredict #>             [,1]        [,2]       [,3]        [,4]        [,5]        [,6] #> 1   1.4539431721  2.58686302  2.6090759  2.65655978  3.15883072  3.42926182 #> 2   0.9803000295  1.16058533  1.1833005  1.28488164  1.18517618  1.17351469 #> 3   1.5421433729  1.20822242  1.3853553  1.15999892  1.06119789  0.99352272 #> 4   0.8634757400  0.61153667  0.9598232  0.63676710  0.73217251  0.72439005 #> 5   1.1046967056  0.72056610  0.5615100  0.48002572  0.05031434 -0.02890243 #> 6   1.3430089378  1.44124063  1.2350616  1.35213181  1.07499774  1.00153522 #> 7   0.4653011509 -0.55778608 -0.1345810 -0.40312929 -0.11007833  0.02486483 #> 8   0.7245706631  0.77453614 -0.1329786  0.06547790  0.31942685 -0.06589345 #> 9   1.4768276059  1.51567612  1.6250574  1.59073347  1.97691808  2.06744335 #> 10  1.0240822662  0.87210913  0.6081081  0.51995031  1.25860279  1.17823388 #> 11  0.3376379927  1.17893648  0.7989349  0.59109134  0.67492159  0.66971895 #> 12 -0.1361926285  0.32400051  0.1088808  0.02503985  1.09413721  0.91614621 #> 13  1.7251506342  1.94257097  2.3721225  2.30673885  2.08307096  2.12519360 #> 14  1.2983306330  1.75308300  1.6929078  1.99562658  1.58229858  1.60648610 #> 15  1.2673647925  1.36309370  1.3509504  1.50028142  1.56068200  1.66788433 #> 16 -0.2742212930 -0.54947877 -0.4625418 -0.45217350 -0.43900249 -0.54284805 #> 17  0.0726132592  0.09110250  0.2767850  0.38572317 -0.46094657 -0.37755959 #> 18  1.0119232701  1.24823667  1.0358333  0.93127818  1.04973056  1.07268197 #> 19  1.1712169069  0.45709538  0.7154129  0.69975186  1.04627874  1.12890339 #> 20  0.3380528810 -0.05282248 -0.1359717 -0.17511644  0.01795423 -0.03635962 #> 21 -0.0006184277  0.21271797  1.0933839  1.10740476  0.60193100  0.61977791 #> 22  0.6475528007  0.64676752  0.9677756  0.88988795  0.74500454  0.78221342 #> 23  0.9069905284  0.88140911  0.7681153  1.08147288  0.95938321  1.05823268 #> 24  0.2908076924  0.12961264  0.8282876  0.95768372  0.56951175  0.59933236 #> 25  0.6399372516  0.14296644 -0.4236403 -0.37407716 -0.44329114 -0.69039703 #> 26  0.9183707395  0.90065654  0.8887530  1.09037413  0.98475758  1.18762561 #> 27 -0.0660539634  0.61584030  0.2968035  0.37286685 -0.40233133 -0.23591051 #> 28  1.6294091667  1.01981261  1.4487065  1.30885327  1.04296746  1.02750273 #> 29  1.4527596503  1.39098952  1.6208012  1.60355751  1.81341376  1.91094735 #> 30  0.7455927900  0.74230137  0.7595845  0.45727580  0.79191445  0.79398217 #> 31  0.9251914554  1.22235139  0.9675384  1.27926735  1.60673050  1.62225025 #> 32  0.6030109074  1.10766233  0.9423622  0.97635769  0.97873680  1.07730348 #> 33  0.2463233753  0.05289306 -0.1983792 -0.15328541  0.20920986  0.37188736 #>           [,7]        [,8]        [,9] #> 1   3.41392627  2.96083291  3.23542261 #> 2   1.09536968  0.93205421  0.88650726 #> 3   1.29732525  1.20790868  1.22562598 #> 4   0.93697105  0.96071216  1.00900607 #> 5   0.34395975  0.31660424  0.35664778 #> 6   1.25769379  1.27286284  1.31025110 #> 7   0.10061500  0.20716458  0.22337146 #> 8  -0.06749700 -0.45235173 -0.53735541 #> 9   1.84752454  1.96619927  1.95995370 #> 10  1.07258576  1.25598280  1.30528130 #> 11  0.65182003  0.67547129  0.66502359 #> 12  0.82760907  0.63803800  0.59597012 #> 13  2.25015844  2.33499027  2.34358840 #> 14  1.83700630  1.92773146  2.00021878 #> 15  1.64781018  1.69047876  1.67309741 #> 16 -0.53535935 -0.55349482 -0.58253557 #> 17 -0.09360753 -0.07937692  0.06042429 #> 18  0.73514311  0.39733701  0.23952431 #> 19  1.03072981  1.07397224  1.07267962 #> 20 -0.08754010 -0.20699608 -0.25853347 #> 21  0.58792158  0.61901916  0.60223241 #> 22  0.72354893  0.65192523  0.61620016 #> 23  0.86644827  0.94744835  0.95335224 #> 24  0.38330515  0.46140202  0.44202144 #> 25 -0.43279587 -0.59408406 -0.57013118 #> 26  0.93104122  0.98212754  0.92705304 #> 27  0.20209342  0.32284534  0.38231639 #> 28  1.01171393  1.02783639  0.97721921 #> 29  1.78120212  1.87739994  1.82673047 #> 30  0.47349187  0.52149603  0.52673297 #> 31  1.46531670  1.50285087  1.51032980 #> 32  0.87652870  1.16647296  1.16995441 #> 33  0.28101723  0.47212049  0.52841275 #>  rm(\"XpineNAX21\",\"ypine\") #> Warning: object 'XpineNAX21' not found  data(pine) Xpine<-pine[,1:10] ypine<-pine[,11] PLS_glm_wvc(ypine,Xpine,10,modele=\"pls\", verbose=FALSE) #> $valsPredict #>           [,1]        [,2]        [,3]        [,4]         [,5]        [,6] #> 1   1.57673729  2.00433040  2.00216849  2.01939633  1.937245401  1.88550891 #> 2   1.01203030  1.15199511  1.11571861  1.24570213  1.235802532  1.20179188 #> 3   1.48993594  1.24149458  1.36818432  1.53585542  1.486704711  1.51671911 #> 4   0.82287026  0.63250520  0.93956109  1.04161870  1.007232341  1.04125064 #> 5   1.03843648  0.73560935  0.56129947  0.58902449  0.528441708  0.57134580 #> 6   1.35675180  1.40730081  1.25451432  1.37731103  1.366862539  1.39997555 #> 7   0.32014006 -0.32532009 -0.14347163 -0.17938500 -0.165426534 -0.11535438 #> 8   0.71839021  0.73099520  0.30866945  0.39516648  0.412751496  0.32418945 #> 9   1.48896024  1.52799376  1.67587131  1.60139990  1.652717167  1.65007715 #> 10  0.99804354  0.88959103  0.97569244  0.86352520  0.947912813  0.94847153 #> 11  0.43405362  0.86608054  0.97012047  0.64182858  0.616856901  0.63882421 #> 12 -0.07021385  0.26999887  0.59312200  0.92157715  1.008253831  0.98380367 #> 13  1.76424139  1.90090137  2.11336407  2.19169300  2.166416346  2.19486369 #> 14  1.37638458  1.70611149  1.58504677  1.84688715  1.857927378  1.90455582 #> 15  1.29114690  1.38753932  1.35365960  1.43462512  1.476219895  1.51027552 #> 16 -0.31402446 -0.47052602 -0.50369169 -0.48552205 -0.489472457 -0.51351160 #> 17  0.07868727  0.09889902 -0.01564596  0.15763382  0.083278591  0.10574381 #> 18  1.03444868  1.14007872  1.09595610  0.88458167  0.852892800  0.78377367 #> 19  1.08137124  0.67811651  0.73915351  0.82968208  0.879143668  0.88040097 #> 20  0.27838475  0.03080907 -0.03681897 -0.06160100 -0.054332827 -0.07763891 #> 21  0.04732997  0.24640318  0.51964685  0.71563687  0.653313657  0.61594736 #> 22  0.64993047  0.65252960  0.76864397  0.76705111  0.732874483  0.71165796 #> 23  0.91576469  0.95152885  0.70877390  0.68206508  0.726537887  0.71111241 #> 24  0.28714240  0.25747771  0.32732647  0.36607751  0.340816493  0.27266379 #> 25  0.55621083  0.20897499 -0.13621852 -0.01161858 -0.029168653 -0.04249364 #> 26  0.92489518  0.94649310  0.77909889  0.64060202  0.670826485  0.67364464 #> 27  0.01702572  0.38181268  0.20327363  0.07976920  0.023726459  0.15754257 #> 28  1.54352449  1.13003525  1.14773845  0.98446655  0.935861794  0.90956750 #> 29  1.45181367  1.42783969  1.54487387  1.46033916  1.495705868  1.51049933 #> 30  0.73123225  0.66412607  0.84569291  0.49408354  0.482259156  0.42326984 #> 31  0.98197420  1.24443724  1.14351551  1.31718138  1.406786445  1.39942166 #> 32  0.66850881  0.94811355  0.92220097  0.50456716  0.531183973  0.55048739 #> 33  0.21787107  0.10572384  0.04295933 -0.08122119 -0.008152348  0.04161271 #>           [,7]         [,8]        [,9]       [,10] #> 1   1.95676227  1.948450849  1.93896093  1.94144962 #> 2   1.21592652  1.235442425  1.24794773  1.24303207 #> 3   1.54977163  1.524520187  1.53266664  1.53900851 #> 4   1.05581321  1.021862826  1.03178760  1.03548430 #> 5   0.58624206  0.562391104  0.56933856  0.58993331 #> 6   1.38175170  1.360508864  1.35664763  1.36575593 #> 7  -0.07128741 -0.047428997 -0.05482975 -0.06507565 #> 8   0.35423193  0.306999026  0.28300642  0.26870841 #> 9   1.63319069  1.631509959  1.64240206  1.64555642 #> 10  0.90453538  0.837015730  0.82600711  0.82493397 #> 11  0.66440603  0.619480777  0.61806414  0.61605314 #> 12  1.06477362  1.031255436  1.02700955  1.02592619 #> 13  2.16399005  2.163911302  2.15049944  2.14429918 #> 14  1.84909183  1.845501860  1.84534215  1.84361941 #> 15  1.53220512  1.567310225  1.56848600  1.56902383 #> 16 -0.51165239 -0.500336508 -0.52095379 -0.50662867 #> 17  0.01828375 -0.002607768  0.01667444 -0.02206645 #> 18  0.88281941  0.918670514  0.94195909  0.93284893 #> 19  0.88632519  0.909007733  0.91379654  0.90631555 #> 20 -0.03748213 -0.025963454 -0.03697219 -0.04597628 #> 21  0.56329746  0.606867697  0.60725951  0.63204655 #> 22  0.71534817  0.734795585  0.73328612  0.71985709 #> 23  0.66101344  0.690882417  0.69856666  0.69360847 #> 24  0.17883038  0.221072111  0.21360194  0.22005958 #> 25 -0.02445300 -0.070467998 -0.05897223 -0.03210573 #> 26  0.69268993  0.763387338  0.78043784  0.79028544 #> 27  0.19700010  0.215177839  0.20405047  0.19800511 #> 28  0.87932761  0.893834308  0.86843397  0.85997782 #> 29  1.52036274  1.552065698  1.53445170  1.53023569 #> 30  0.38164488  0.326448839  0.35187384  0.34979385 #> 31  1.37872533  1.385981563  1.39371317  1.39564352 #> 32  0.49904917  0.493233383  0.48196396  0.49873722 #> 33  0.04746533  0.049219132  0.06349274  0.06165365 #>  PLS_glm_wvc(ypine,Xpine,10,modele=\"pls-glm-Gamma\", verbose=FALSE) #> $valsPredict #>         [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7] #> 1  1.7021625 3.3482083 2.7139565 2.4058093 3.2467830 2.2037424 2.5521714 #> 2  0.6639038 0.6387631 0.6121317 0.7600887 0.9482646 0.9294531 0.8653260 #> 3  1.3088626 0.8281449 0.8781982 0.8175537 1.0345037 1.1660944 1.3209167 #> 4  0.5006322 0.4014678 0.4796826 0.4658354 0.4844424 0.4841038 0.5449712 #> 5  0.6854677 0.5251666 0.4284003 0.3615301 0.3586455 0.3703400 0.3739103 #> 6  1.1713845 1.2407194 0.9038012 0.8025733 0.7106149 0.7508921 0.7329991 #> 7  0.3549836 0.2691848 0.2777883 0.2608888 0.2663969 0.2714017 0.2817687 #> 8  0.5120913 0.5899263 0.5143725 0.4952195 0.4492835 0.4160523 0.3486881 #> 9  1.4945619 1.8984358 3.2406348 2.6184777 2.9855578 3.5895484 2.8384646 #> 10 0.6500508 0.7579531 1.0736393 0.7529701 0.5609868 0.5445539 0.4945195 #> 11 0.3849210 0.4622240 0.4980263 0.3569521 0.3024332 0.2995254 0.3421787 #> 12 0.2795105 0.3152286 0.4814740 0.6678051 0.6433927 0.5911492 0.7463694 #> 13 4.2141188 3.0076725 3.4791475 4.2092704 3.2534025 2.9808121 3.3581408 #> 14 1.2733917 1.8325125 1.2115241 1.6556086 1.3004955 1.5582862 1.6386778 #> 15 1.0345150 1.2033342 1.0290148 1.0809521 1.1747941 1.4991592 1.7732216 #> 16 0.2576160 0.2298102 0.2306029 0.2393888 0.2219856 0.2038692 0.1991727 #> 17 0.3181072 0.2641593 0.2394775 0.2465446 0.2434009 0.2454800 0.2454886 #> 18 0.6689827 0.6826523 0.6317041 0.5589350 0.7682575 0.8003709 0.8141919 #> 19 0.7212759 0.5417550 0.5624130 0.6169171 0.7357709 0.7839123 0.6859125 #> 20 0.3544669 0.3125267 0.3071243 0.3004883 0.2983363 0.2888686 0.2809863 #> 21 0.3010344 0.2531795 0.2689006 0.3545433 0.3516489 0.2928523 0.2888406 #> 22 0.4524566 0.3845643 0.3876906 0.4082754 0.4216088 0.3971631 0.3949778 #> 23 0.6507469 0.6608146 0.5157721 0.5355239 0.5223465 0.5289271 0.4564660 #> 24 0.3581027 0.2902701 0.2841434 0.3507472 0.3384621 0.2851532 0.2518528 #> 25 0.4407103 0.3888439 0.3464864 0.3246940 0.3226049 0.3196535 0.2975328 #> 26 0.6435771 0.6370758 0.4976960 0.4812621 0.5249918 0.5591198 0.5489260 #> 27 0.3096927 0.3200657 0.2664525 0.2208262 0.1962616 0.2068674 0.2457191 #> 28 1.7027982 0.7863943 0.6191251 0.5376817 0.5259622 0.4714803 0.3925142 #> 29 1.3624280 1.3395903 1.3437875 1.1678080 1.0829979 1.0899791 1.0607518 #> 30 0.4809691 0.4482798 0.5264782 0.4211320 0.4080366 0.3796394 0.3529260 #> 31 0.6795166 0.9667644 1.0310662 1.5914495 1.4876477 1.6576885 1.4173828 #> 32 0.4867971 0.5929337 0.5403197 0.3962608 0.3103903 0.2955165 0.2975775 #> 33 0.3501638 0.3513783 0.3489678 0.3059872 0.2892922 0.3083446 0.3264570 #>         [,8]      [,9]     [,10] #> 1  2.4848460 2.5383659 2.5386650 #> 2  0.8818512 0.8504103 0.8504414 #> 3  1.3240837 1.3853373 1.3858636 #> 4  0.5790253 0.5768843 0.5769496 #> 5  0.3921145 0.4055536 0.4055933 #> 6  0.7330597 0.7621053 0.7622316 #> 7  0.2660918 0.2660232 0.2660038 #> 8  0.2912579 0.2917354 0.2917732 #> 9  3.2596209 3.2484587 3.2483633 #> 10 0.4443817 0.4485445 0.4486040 #> 11 0.3542984 0.3444401 0.3444444 #> 12 0.6853879 0.6926198 0.6926340 #> 13 3.2365795 3.1305159 3.1301005 #> 14 1.7486322 1.7094242 1.7099539 #> 15 1.6651777 1.7173913 1.7167684 #> 16 0.2027942 0.2069252 0.2069125 #> 17 0.2423289 0.2281793 0.2282071 #> 18 0.7941254 0.7399260 0.7398598 #> 19 0.6071330 0.6085899 0.6085694 #> 20 0.2637502 0.2634246 0.2634166 #> 21 0.3540481 0.3637124 0.3636558 #> 22 0.3923977 0.3816768 0.3816594 #> 23 0.4520624 0.4454465 0.4454376 #> 24 0.2724808 0.2743025 0.2742785 #> 25 0.3016025 0.3133463 0.3133922 #> 26 0.6115410 0.6177281 0.6175658 #> 27 0.2518436 0.2473006 0.2472828 #> 28 0.3629759 0.3659599 0.3659410 #> 29 0.9255826 0.9503453 0.9500157 #> 30 0.3723393 0.3588267 0.3588724 #> 31 1.3702410 1.3900717 1.3901525 #> 32 0.3220191 0.3261020 0.3260694 #> 33 0.3243259 0.3203266 0.3203212 #>  PLS_glm_wvc(ypine,Xpine,10,modele=\"pls-glm-family\",family=Gamma(), verbose=FALSE) #> $valsPredict #>         [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7] #> 1  1.7021625 3.3482083 2.7139565 2.4058093 3.2467830 2.2037424 2.5521714 #> 2  0.6639038 0.6387631 0.6121317 0.7600887 0.9482646 0.9294531 0.8653260 #> 3  1.3088626 0.8281449 0.8781982 0.8175537 1.0345037 1.1660944 1.3209167 #> 4  0.5006322 0.4014678 0.4796826 0.4658354 0.4844424 0.4841038 0.5449712 #> 5  0.6854677 0.5251666 0.4284003 0.3615301 0.3586455 0.3703400 0.3739103 #> 6  1.1713845 1.2407194 0.9038012 0.8025733 0.7106149 0.7508921 0.7329991 #> 7  0.3549836 0.2691848 0.2777883 0.2608888 0.2663969 0.2714017 0.2817687 #> 8  0.5120913 0.5899263 0.5143725 0.4952195 0.4492835 0.4160523 0.3486881 #> 9  1.4945619 1.8984358 3.2406348 2.6184777 2.9855578 3.5895484 2.8384646 #> 10 0.6500508 0.7579531 1.0736393 0.7529701 0.5609868 0.5445539 0.4945195 #> 11 0.3849210 0.4622240 0.4980263 0.3569521 0.3024332 0.2995254 0.3421787 #> 12 0.2795105 0.3152286 0.4814740 0.6678051 0.6433927 0.5911492 0.7463694 #> 13 4.2141188 3.0076725 3.4791475 4.2092704 3.2534025 2.9808121 3.3581408 #> 14 1.2733917 1.8325125 1.2115241 1.6556086 1.3004955 1.5582862 1.6386778 #> 15 1.0345150 1.2033342 1.0290148 1.0809521 1.1747941 1.4991592 1.7732216 #> 16 0.2576160 0.2298102 0.2306029 0.2393888 0.2219856 0.2038692 0.1991727 #> 17 0.3181072 0.2641593 0.2394775 0.2465446 0.2434009 0.2454800 0.2454886 #> 18 0.6689827 0.6826523 0.6317041 0.5589350 0.7682575 0.8003709 0.8141919 #> 19 0.7212759 0.5417550 0.5624130 0.6169171 0.7357709 0.7839123 0.6859125 #> 20 0.3544669 0.3125267 0.3071243 0.3004883 0.2983363 0.2888686 0.2809863 #> 21 0.3010344 0.2531795 0.2689006 0.3545433 0.3516489 0.2928523 0.2888406 #> 22 0.4524566 0.3845643 0.3876906 0.4082754 0.4216088 0.3971631 0.3949778 #> 23 0.6507469 0.6608146 0.5157721 0.5355239 0.5223465 0.5289271 0.4564660 #> 24 0.3581027 0.2902701 0.2841434 0.3507472 0.3384621 0.2851532 0.2518528 #> 25 0.4407103 0.3888439 0.3464864 0.3246940 0.3226049 0.3196535 0.2975328 #> 26 0.6435771 0.6370758 0.4976960 0.4812621 0.5249918 0.5591198 0.5489260 #> 27 0.3096927 0.3200657 0.2664525 0.2208262 0.1962616 0.2068674 0.2457191 #> 28 1.7027982 0.7863943 0.6191251 0.5376817 0.5259622 0.4714803 0.3925142 #> 29 1.3624280 1.3395903 1.3437875 1.1678080 1.0829979 1.0899791 1.0607518 #> 30 0.4809691 0.4482798 0.5264782 0.4211320 0.4080366 0.3796394 0.3529260 #> 31 0.6795166 0.9667644 1.0310662 1.5914495 1.4876477 1.6576885 1.4173828 #> 32 0.4867971 0.5929337 0.5403197 0.3962608 0.3103903 0.2955165 0.2975775 #> 33 0.3501638 0.3513783 0.3489678 0.3059872 0.2892922 0.3083446 0.3264570 #>         [,8]      [,9]     [,10] #> 1  2.4848460 2.5383659 2.5386650 #> 2  0.8818512 0.8504103 0.8504414 #> 3  1.3240837 1.3853373 1.3858636 #> 4  0.5790253 0.5768843 0.5769496 #> 5  0.3921145 0.4055536 0.4055933 #> 6  0.7330597 0.7621053 0.7622316 #> 7  0.2660918 0.2660232 0.2660038 #> 8  0.2912579 0.2917354 0.2917732 #> 9  3.2596209 3.2484587 3.2483633 #> 10 0.4443817 0.4485445 0.4486040 #> 11 0.3542984 0.3444401 0.3444444 #> 12 0.6853879 0.6926198 0.6926340 #> 13 3.2365795 3.1305159 3.1301005 #> 14 1.7486322 1.7094242 1.7099539 #> 15 1.6651777 1.7173913 1.7167684 #> 16 0.2027942 0.2069252 0.2069125 #> 17 0.2423289 0.2281793 0.2282071 #> 18 0.7941254 0.7399260 0.7398598 #> 19 0.6071330 0.6085899 0.6085694 #> 20 0.2637502 0.2634246 0.2634166 #> 21 0.3540481 0.3637124 0.3636558 #> 22 0.3923977 0.3816768 0.3816594 #> 23 0.4520624 0.4454465 0.4454376 #> 24 0.2724808 0.2743025 0.2742785 #> 25 0.3016025 0.3133463 0.3133922 #> 26 0.6115410 0.6177281 0.6175658 #> 27 0.2518436 0.2473006 0.2472828 #> 28 0.3629759 0.3659599 0.3659410 #> 29 0.9255826 0.9503453 0.9500157 #> 30 0.3723393 0.3588267 0.3588724 #> 31 1.3702410 1.3900717 1.3901525 #> 32 0.3220191 0.3261020 0.3260694 #> 33 0.3243259 0.3203266 0.3203212 #>  PLS_glm_wvc(ypine,Xpine,10,modele=\"pls-glm-gaussian\", verbose=FALSE) #> $valsPredict #>           [,1]         [,2]        [,3]         [,4]        [,5]          [,6] #> 1   1.57673729  2.112703071  2.04925275  2.025720690  1.99988877  1.9833376732 #> 2   1.01203030  1.097055838  1.16768196  1.188171412  1.15718087  1.2424038010 #> 3   1.48993594  1.408750619  1.48576816  1.417980819  1.47582762  1.4982947689 #> 4   0.82287026  0.920756079  1.01128635  0.901257566  0.97491134  0.9909505955 #> 5   1.03843648  0.659104154  0.56302369  0.539466433  0.54522439  0.5188201727 #> 6   1.35675180  1.363858458  1.34528931  1.394223504  1.37942281  1.3306250748 #> 7   0.32014006 -0.208936487 -0.12375412 -0.181775915 -0.06686014 -0.0207190905 #> 8   0.71839021  0.466159761  0.40368534  0.513587769  0.48884774  0.3578640505 #> 9   1.48896024  1.577050840  1.58976688  1.576666292  1.60118999  1.6121834444 #> 10  0.99804354  0.955521315  0.91591324  0.915171230  0.97502649  0.8174125637 #> 11  0.43405362  1.004865089  0.70022268  0.636399772  0.65960111  0.6245784031 #> 12 -0.07021385  0.625346725  0.85018705  0.906678742  1.04976341  1.0296261669 #> 13  1.76424139  2.130136647  2.23589140  2.197201851  2.19275527  2.1697925483 #> 14  1.37638458  1.681218703  1.75409814  1.849649772  1.80173880  1.8135307368 #> 15  1.29114690  1.361382091  1.39654708  1.475461977  1.50322338  1.5668160958 #> 16 -0.31402446 -0.467204941 -0.38855760 -0.373068343 -0.38143767 -0.4913222929 #> 17  0.07868727 -0.009485106  0.00923828 -0.036909766 -0.14037506  0.0003648119 #> 18  1.03444868  1.006290938  0.84699467  0.805974957  0.80434945  0.9670404542 #> 19  1.08137124  0.652213314  0.80163323  0.811023094  0.86280576  0.9155210110 #> 20  0.27838475 -0.032388253 -0.02071891 -0.009618538  0.02030676  0.0147427279 #> 21  0.04732997  0.463005953  0.75191452  0.690072944  0.59756638  0.5787557488 #> 22  0.64993047  0.723791521  0.78678336  0.734843252  0.71613035  0.7677772238 #> 23  0.91576469  0.661826559  0.63945101  0.723928013  0.65099726  0.6902564661 #> 24  0.28714240  0.226510895  0.44320269  0.409261632  0.27917608  0.2269039458 #> 25  0.55621083 -0.024808263 -0.08836434 -0.049135741 -0.04935391 -0.1262912840 #> 26  0.92489518  0.696833356  0.61254496  0.676658656  0.64557351  0.7620516870 #> 27  0.01702572  0.383663431  0.09067225  0.142983517  0.15295203  0.2265845367 #> 28  1.54352449  1.118282238  1.14733091  1.067690338  1.02839043  0.9429046207 #> 29  1.45181367  1.511879599  1.55176709  1.566714783  1.60155782  1.5828522058 #> 30  0.73123225  0.675786261  0.50840164  0.348494547  0.32640081  0.3072993447 #> 31  0.98197420  1.138509770  1.22086791  1.348938103  1.34491760  1.3622819484 #> 32  0.66850881  0.900496012  0.64433614  0.644006458  0.60182468  0.4779691553 #> 33  0.21787107 -0.010176189 -0.13235770 -0.087719821 -0.02952413  0.0287906836 #>           [,7]        [,8]        [,9]       [,10] #> 1   1.95998953  1.94645747  1.93186966  1.94144962 #> 2   1.25598752  1.24287885  1.23986128  1.24303207 #> 3   1.49520811  1.51724573  1.53404270  1.53900851 #> 4   0.99891106  1.01599568  1.03395498  1.03548430 #> 5   0.51896770  0.56790205  0.58389496  0.58993331 #> 6   1.32539225  1.34603852  1.36392791  1.36575593 #> 7  -0.06196351 -0.05464413 -0.06141636 -0.06507565 #> 8   0.33392253  0.26216021  0.26205140  0.26870841 #> 9   1.65121630  1.65247099  1.64949308  1.64555642 #> 10  0.84217676  0.81747252  0.83103198  0.82493397 #> 11  0.62520462  0.61633899  0.61661614  0.61605314 #> 12  1.05350867  1.02479904  1.02287949  1.02592619 #> 13  2.13743805  2.13939290  2.14749253  2.14429918 #> 14  1.80845036  1.81864863  1.84537429  1.84361941 #> 15  1.56195461  1.57681740  1.57071745  1.56902383 #> 16 -0.50961890 -0.49310993 -0.50826612 -0.50662867 #> 17 -0.02051672 -0.06780741 -0.01988610 -0.02206645 #> 18  0.98706465  0.95905848  0.92650134  0.93284893 #> 19  0.91934368  0.91222031  0.90916925  0.90631555 #> 20 -0.01218066 -0.03394867 -0.04715924 -0.04597628 #> 21  0.59411953  0.64146282  0.62996595  0.63204655 #> 22  0.74682044  0.72671756  0.72012579  0.71985709 #> 23  0.70899785  0.69938422  0.69733168  0.69360847 #> 24  0.23235605  0.23628193  0.22277700  0.22005958 #> 25 -0.08891154 -0.05778064 -0.04168003 -0.03210573 #> 26  0.78675646  0.81693166  0.79133604  0.79028544 #> 27  0.15249578  0.18906869  0.19908660  0.19800511 #> 28  0.88885380  0.87522045  0.86246092  0.85997782 #> 29  1.55342327  1.55350046  1.53516894  1.53023569 #> 30  0.37656252  0.34741004  0.35160380  0.34979385 #> 31  1.40075691  1.39407660  1.39778420  1.39564352 #> 32  0.49263192  0.51865275  0.50530217  0.49873722 #> 33  0.05468043  0.06268582  0.06658628  0.06165365 #>  PLS_glm_wvc(ypine,Xpine,10,modele=\"pls-glm-family\",family=gaussian(log), verbose=FALSE) #> Warning: glm.fit: algorithm did not converge #> $valsPredict #>          [,1]       [,2]       [,3]       [,4]       [,5]       [,6]       [,7] #> 1  1.94034398 2.71462895 2.43467867 2.34032266 2.49387242 2.52177239 2.36881223 #> 2  0.75808067 0.69121040 0.65620818 0.70721651 1.04029001 0.98040711 0.93783784 #> 3  1.40934523 1.05235219 1.16507753 1.04330692 1.27590261 1.35755324 1.37414207 #> 4  0.37708016 0.35352178 0.46140678 0.36128092 0.61457152 0.56530388 0.62061981 #> 5  0.77818425 0.53104971 0.43760160 0.37373842 0.34144739 0.34208810 0.33370653 #> 6  1.51169791 1.44153372 1.26663946 1.31087294 1.06609858 1.04718818 1.03518591 #> 7  0.16713747 0.08885717 0.09752329 0.06901046 0.10159776 0.10286735 0.11602626 #> 8  0.52169803 0.45181518 0.39494988 0.45271597 0.35170317 0.30990886 0.24700339 #> 9  1.72168458 2.00061811 2.45997527 2.60364609 2.49269049 2.67113548 2.60678716 #> 10 0.69017124 0.87663394 1.23358029 1.21064587 0.88829904 0.83085920 0.79099293 #> 11 0.24761936 0.59543246 0.61011139 0.43755305 0.41628614 0.43157686 0.53045450 #> 12 0.07788296 0.13938476 0.23445656 0.21678007 0.54126772 0.46650102 0.53587964 #> 13 2.54607327 2.73230801 2.90764248 2.80193225 2.88622102 2.71241728 2.82081773 #> 14 1.66719840 1.88972107 1.63632610 1.91063363 1.84158614 1.73408495 1.86193764 #> 15 1.34895761 1.33460645 1.23252238 1.29571895 1.25365525 1.45657367 1.58051773 #> 16 0.06341544 0.04781972 0.04523887 0.03588003 0.06230984 0.03910136 0.03595447 #> 17 0.13804789 0.10480764 0.08384257 0.07535406 0.14547767 0.10826649 0.12411130 #> 18 0.79061549 0.82574247 0.74064232 0.69586410 0.87182540 1.09564836 1.06117605 #> 19 0.78786507 0.45717855 0.51628995 0.52758141 0.65036236 0.66698463 0.63632866 #> 20 0.18952817 0.13436883 0.12758699 0.10907087 0.14319721 0.12855285 0.12477305 #> 21 0.10522301 0.09131829 0.09479376 0.08113521 0.28581761 0.13871715 0.12566135 #> 22 0.34302383 0.29785876 0.29338908 0.25447835 0.42009515 0.35272268 0.35674133 #> 23 0.81820041 0.66972983 0.54855397 0.64001770 0.59570640 0.55276326 0.50977543 #> 24 0.19474253 0.12654062 0.12041800 0.11763698 0.25419417 0.12872552 0.10208317 #> 25 0.35299833 0.22248594 0.19757934 0.19485657 0.19771813 0.17411768 0.14585414 #> 26 0.80124529 0.67773527 0.52264350 0.53603714 0.54379607 0.60854112 0.60682863 #> 27 0.14150887 0.22211358 0.13221850 0.08582109 0.08069217 0.09245398 0.14580144 #> 28 1.81316065 0.97154149 0.87534137 0.78129461 0.64910997 0.54803145 0.45120061 #> 29 1.61509512 1.55735811 1.60106153 1.52704385 1.31898041 1.40585691 1.42994630 #> 30 0.39043233 0.49977789 0.66789433 0.57577267 0.69466570 0.59985551 0.53879331 #> 31 0.83475962 0.99424242 1.05056360 1.31875471 1.42449237 1.39059830 1.37115108 #> 32 0.47025561 0.82350400 0.75180162 0.62855746 0.42921486 0.37592533 0.38664416 #> 33 0.19382221 0.20784671 0.20961391 0.18342774 0.18891735 0.21202125 0.24981935 #>          [,8]       [,9]      [,10] #> 1  2.31091578 2.37167744 2.36198559 #> 2  0.93585220 0.95791298 0.98575560 #> 3  1.41641694 1.50522613 1.47941643 #> 4  0.59950218 0.70071774 0.71423505 #> 5  0.37190673 0.42675025 0.42402377 #> 6  1.09060470 1.11874494 1.08702344 #> 7  0.09571100 0.09647244 0.09630241 #> 8  0.20785619 0.16125305 0.14088436 #> 9  2.71378257 2.69868104 2.70464247 #> 10 0.73029614 0.65922545 0.60326641 #> 11 0.54022679 0.51472598 0.49819043 #> 12 0.35506281 0.45808959 0.46151119 #> 13 2.79802911 2.76063955 2.78066411 #> 14 1.98170008 1.95001758 1.93229013 #> 15 1.53052186 1.51841242 1.52042283 #> 16 0.02766734 0.04128363 0.04540010 #> 17 0.14200686 0.10908344 0.10682024 #> 18 1.11860371 0.97590985 0.97740363 #> 19 0.58502710 0.55929325 0.55484711 #> 20 0.10381511 0.10249376 0.10126389 #> 21 0.10867268 0.22973117 0.29869098 #> 22 0.33080890 0.33655123 0.35050213 #> 23 0.54181217 0.50162257 0.50663290 #> 24 0.09203855 0.13818992 0.16532608 #> 25 0.15063372 0.18519359 0.18156725 #> 26 0.65085067 0.71168397 0.76264933 #> 27 0.14727015 0.14028361 0.13815779 #> 28 0.43710022 0.39895696 0.39737902 #> 29 1.28688769 1.23785532 1.23709320 #> 30 0.62334349 0.59651237 0.59626615 #> 31 1.30383078 1.34676942 1.34563447 #> 32 0.40329953 0.46335753 0.48230863 #> 33 0.24694643 0.23442405 0.22839915 #>  PLS_glm_wvc(round(ypine),Xpine,10,modele=\"pls-glm-poisson\", verbose=FALSE) #> $valsPredict #>         [,1]       [,2]       [,3]       [,4]       [,5]       [,6]       [,7] #> 1  1.6399850 2.60506445 2.11819574 2.41837386 2.53667962 2.20251218 2.06903053 #> 2  0.7290121 0.69629584 0.86286774 0.91041443 1.03494013 1.08047292 1.04940245 #> 3  1.4007318 0.91577118 0.87914923 0.91048321 0.88943352 1.13236954 1.27356987 #> 4  0.5073121 0.58670097 0.49153953 0.47288217 0.47195939 0.58602584 0.68553431 #> 5  0.7167976 0.26869425 0.17547231 0.16659766 0.14906365 0.20126291 0.20750054 #> 6  1.2277121 0.87836123 0.79196664 0.74357948 0.62570190 0.70241020 0.67883278 #> 7  0.2394851 0.11484061 0.10723855 0.09952527 0.09561722 0.09178740 0.10346041 #> 8  0.4486498 0.21249182 0.25417881 0.29270841 0.19704511 0.07643748 0.06392087 #> 9  1.5375425 1.72997866 1.88584119 2.06164431 2.14385483 2.24654776 2.35711461 #> 10 0.7082187 0.70892020 0.65884300 0.68326209 0.48035002 0.29285649 0.30175497 #> 11 0.2936374 0.73061296 0.24263912 0.23403044 0.20470584 0.23168872 0.22840093 #> 12 0.1322042 0.56376787 0.95488027 1.07792637 0.91182710 0.93220801 0.97645652 #> 13 2.3010540 3.38048229 3.41269178 3.09515690 3.11675468 2.83446755 2.94222186 #> 14 1.3291560 1.58321807 1.75503319 1.50912761 1.35057561 1.76448864 1.65562250 #> 15 1.1448439 1.08877131 1.25968183 1.27173335 1.27622471 1.76272105 1.72201423 #> 16 0.0941790 0.08628985 0.09230834 0.08013583 0.07468272 0.04857939 0.04622128 #> 17 0.1757439 0.12211384 0.07899382 0.05819776 0.05831164 0.05675775 0.05570430 #> 18 0.7307741 0.57135156 0.43624010 0.56728509 0.74050220 0.81621686 0.79616814 #> 19 0.8036405 0.39016521 0.60474619 0.63620204 0.64631151 0.57833457 0.61425877 #> 20 0.2296892 0.13681561 0.13816133 0.13921219 0.12832775 0.08814754 0.08562427 #> 21 0.1690309 0.41209378 0.59658496 0.47032464 0.67844078 0.64008147 0.65138413 #> 22 0.4128838 0.44811365 0.42513686 0.40081655 0.45309870 0.36374930 0.36640901 #> 23 0.6719322 0.38499657 0.43763564 0.42067876 0.42831773 0.38428972 0.34730722 #> 24 0.2518950 0.26446399 0.40504213 0.33075720 0.42496338 0.22271054 0.21188843 #> 25 0.3415030 0.09895810 0.09308877 0.09857795 0.07905177 0.08172748 0.07994832 #> 26 0.6718422 0.41760796 0.39983789 0.41407059 0.51103696 0.75685751 0.71134635 #> 27 0.1598578 0.23017899 0.06417506 0.04623807 0.03896774 0.08594351 0.07861887 #> 28 1.6103573 0.64304401 0.62041835 0.58564249 0.58885702 0.26270837 0.26265212 #> 29 1.4503379 1.50168396 1.65079230 1.65474205 1.64013824 1.36785798 1.36596556 #> 30 0.4619784 0.46051634 0.26232493 0.28912455 0.31006305 0.21938924 0.23797224 #> 31 0.7331324 0.89331268 1.39212273 1.45116888 1.34444176 1.50249618 1.40404240 #> 32 0.4547769 0.70774332 0.33469867 0.29588706 0.26928216 0.24247816 0.22480412 #> 33 0.2201032 0.16657890 0.11747299 0.11349275 0.10047155 0.14341775 0.14484710 #>          [,8]       [,9]      [,10] #> 1  2.02482801 2.09337142 2.09445057 #> 2  1.02979098 1.00523770 1.00859344 #> 3  1.24588728 1.28630576 1.28831559 #> 4  0.67844519 0.67808489 0.67912103 #> 5  0.20598501 0.22263909 0.22289776 #> 6  0.67635225 0.70420679 0.70561084 #> 7  0.10133294 0.09847205 0.09737196 #> 8  0.06139630 0.06185310 0.06202701 #> 9  2.43317037 2.42608241 2.43213747 #> 10 0.31175798 0.31302351 0.31392542 #> 11 0.23326785 0.22472545 0.22453972 #> 12 0.96450569 0.96172419 0.95912503 #> 13 2.92826816 2.88041181 2.87784898 #> 14 1.63943166 1.61203045 1.61806746 #> 15 1.72636185 1.72600708 1.71786827 #> 16 0.04614683 0.04911642 0.04884304 #> 17 0.05209752 0.04344071 0.04389911 #> 18 0.78681869 0.75517340 0.75514721 #> 19 0.60876974 0.59789477 0.59656484 #> 20 0.08364279 0.08252597 0.08207915 #> 21 0.65597011 0.69554797 0.69687802 #> 22 0.35829121 0.33954857 0.33920155 #> 23 0.35016186 0.33960578 0.34056020 #> 24 0.21327505 0.21575584 0.21648404 #> 25 0.07937426 0.08865757 0.08919000 #> 26 0.72799199 0.73683412 0.73410737 #> 27 0.07702918 0.07296722 0.07209219 #> 28 0.26006772 0.26199357 0.26110683 #> 29 1.38309722 1.38333502 1.37253094 #> 30 0.24610086 0.23542502 0.23820983 #> 31 1.42270195 1.41766315 1.42184343 #> 32 0.24013435 0.24834876 0.24777468 #> 33 0.14754717 0.14199043 0.14158704 #>  PLS_glm_wvc(round(ypine),Xpine,10,modele=\"pls-glm-family\",family=poisson(log), verbose=FALSE) #> $valsPredict #>         [,1]       [,2]       [,3]       [,4]       [,5]       [,6]       [,7] #> 1  1.6399850 2.60506445 2.11819574 2.41837386 2.53667962 2.20251218 2.06903053 #> 2  0.7290121 0.69629584 0.86286774 0.91041443 1.03494013 1.08047292 1.04940245 #> 3  1.4007318 0.91577118 0.87914923 0.91048321 0.88943352 1.13236954 1.27356987 #> 4  0.5073121 0.58670097 0.49153953 0.47288217 0.47195939 0.58602584 0.68553431 #> 5  0.7167976 0.26869425 0.17547231 0.16659766 0.14906365 0.20126291 0.20750054 #> 6  1.2277121 0.87836123 0.79196664 0.74357948 0.62570190 0.70241020 0.67883278 #> 7  0.2394851 0.11484061 0.10723855 0.09952527 0.09561722 0.09178740 0.10346041 #> 8  0.4486498 0.21249182 0.25417881 0.29270841 0.19704511 0.07643748 0.06392087 #> 9  1.5375425 1.72997866 1.88584119 2.06164431 2.14385483 2.24654776 2.35711461 #> 10 0.7082187 0.70892020 0.65884300 0.68326209 0.48035002 0.29285649 0.30175497 #> 11 0.2936374 0.73061296 0.24263912 0.23403044 0.20470584 0.23168872 0.22840093 #> 12 0.1322042 0.56376787 0.95488027 1.07792637 0.91182710 0.93220801 0.97645652 #> 13 2.3010540 3.38048229 3.41269178 3.09515690 3.11675468 2.83446755 2.94222186 #> 14 1.3291560 1.58321807 1.75503319 1.50912761 1.35057561 1.76448864 1.65562250 #> 15 1.1448439 1.08877131 1.25968183 1.27173335 1.27622471 1.76272105 1.72201423 #> 16 0.0941790 0.08628985 0.09230834 0.08013583 0.07468272 0.04857939 0.04622128 #> 17 0.1757439 0.12211384 0.07899382 0.05819776 0.05831164 0.05675775 0.05570430 #> 18 0.7307741 0.57135156 0.43624010 0.56728509 0.74050220 0.81621686 0.79616814 #> 19 0.8036405 0.39016521 0.60474619 0.63620204 0.64631151 0.57833457 0.61425877 #> 20 0.2296892 0.13681561 0.13816133 0.13921219 0.12832775 0.08814754 0.08562427 #> 21 0.1690309 0.41209378 0.59658496 0.47032464 0.67844078 0.64008147 0.65138413 #> 22 0.4128838 0.44811365 0.42513686 0.40081655 0.45309870 0.36374930 0.36640901 #> 23 0.6719322 0.38499657 0.43763564 0.42067876 0.42831773 0.38428972 0.34730722 #> 24 0.2518950 0.26446399 0.40504213 0.33075720 0.42496338 0.22271054 0.21188843 #> 25 0.3415030 0.09895810 0.09308877 0.09857795 0.07905177 0.08172748 0.07994832 #> 26 0.6718422 0.41760796 0.39983789 0.41407059 0.51103696 0.75685751 0.71134635 #> 27 0.1598578 0.23017899 0.06417506 0.04623807 0.03896774 0.08594351 0.07861887 #> 28 1.6103573 0.64304401 0.62041835 0.58564249 0.58885702 0.26270837 0.26265212 #> 29 1.4503379 1.50168396 1.65079230 1.65474205 1.64013824 1.36785798 1.36596556 #> 30 0.4619784 0.46051634 0.26232493 0.28912455 0.31006305 0.21938924 0.23797224 #> 31 0.7331324 0.89331268 1.39212273 1.45116888 1.34444176 1.50249618 1.40404240 #> 32 0.4547769 0.70774332 0.33469867 0.29588706 0.26928216 0.24247816 0.22480412 #> 33 0.2201032 0.16657890 0.11747299 0.11349275 0.10047155 0.14341775 0.14484710 #>          [,8]       [,9]      [,10] #> 1  2.02482801 2.09337142 2.09445057 #> 2  1.02979098 1.00523770 1.00859344 #> 3  1.24588728 1.28630576 1.28831559 #> 4  0.67844519 0.67808489 0.67912103 #> 5  0.20598501 0.22263909 0.22289776 #> 6  0.67635225 0.70420679 0.70561084 #> 7  0.10133294 0.09847205 0.09737196 #> 8  0.06139630 0.06185310 0.06202701 #> 9  2.43317037 2.42608241 2.43213747 #> 10 0.31175798 0.31302351 0.31392542 #> 11 0.23326785 0.22472545 0.22453972 #> 12 0.96450569 0.96172419 0.95912503 #> 13 2.92826816 2.88041181 2.87784898 #> 14 1.63943166 1.61203045 1.61806746 #> 15 1.72636185 1.72600708 1.71786827 #> 16 0.04614683 0.04911642 0.04884304 #> 17 0.05209752 0.04344071 0.04389911 #> 18 0.78681869 0.75517340 0.75514721 #> 19 0.60876974 0.59789477 0.59656484 #> 20 0.08364279 0.08252597 0.08207915 #> 21 0.65597011 0.69554797 0.69687802 #> 22 0.35829121 0.33954857 0.33920155 #> 23 0.35016186 0.33960578 0.34056020 #> 24 0.21327505 0.21575584 0.21648404 #> 25 0.07937426 0.08865757 0.08919000 #> 26 0.72799199 0.73683412 0.73410737 #> 27 0.07702918 0.07296722 0.07209219 #> 28 0.26006772 0.26199357 0.26110683 #> 29 1.38309722 1.38333502 1.37253094 #> 30 0.24610086 0.23542502 0.23820983 #> 31 1.42270195 1.41766315 1.42184343 #> 32 0.24013435 0.24834876 0.24777468 #> 33 0.14754717 0.14199043 0.14158704 #>  rm(list=c(\"pine\",\"ypine\",\"Xpine\")) #> Warning: object 'pine' not found   data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] PLS_glm_wvc(yCornell,XCornell,10,modele=\"pls-glm-inverse.gaussian\", verbose=FALSE) #> $valsPredict #>        [,1]     [,2]     [,3]     [,4]     [,5]     [,6] #> 1  95.04599 96.84573 97.43211 97.72960 97.67692 97.66926 #> 2  96.68764 98.13364 98.03691 97.94523 98.18530 98.04886 #> 3  96.09893 97.85843 97.65344 97.12746 96.98194 97.11752 #> 4  95.02359 91.98294 91.88913 91.79131 91.91479 91.89828 #> 5  87.87811 86.94625 86.08537 86.10526 86.02670 86.01328 #> 6  93.46390 90.91980 91.39057 91.61375 91.49733 91.58550 #> 7  81.89068 81.77545 81.85201 81.95061 82.04635 82.07739 #> 8  82.40022 82.61020 82.63964 82.58216 82.62615 82.70790 #> 9  82.17002 82.45931 82.55178 82.57494 82.62086 82.69025 #> 10 82.58963 83.07833 83.11779 83.00651 83.01600 83.12446 #> 11 82.15442 81.74862 82.05216 81.73070 81.63852 81.40000 #> 12 87.59686 88.64130 88.29910 88.84247 88.76913 88.66730 #>  PLS_glm_wvc(yCornell,XCornell,10,modele=\"pls-glm-family\", family=inverse.gaussian(), verbose=FALSE) #> $valsPredict #>        [,1]     [,2]     [,3]     [,4]     [,5]     [,6] #> 1  95.04599 96.84573 97.43211 97.72960 97.67692 97.66926 #> 2  96.68764 98.13364 98.03691 97.94523 98.18530 98.04886 #> 3  96.09893 97.85843 97.65344 97.12746 96.98194 97.11752 #> 4  95.02359 91.98294 91.88913 91.79131 91.91479 91.89828 #> 5  87.87811 86.94625 86.08537 86.10526 86.02670 86.01328 #> 6  93.46390 90.91980 91.39057 91.61375 91.49733 91.58550 #> 7  81.89068 81.77545 81.85201 81.95061 82.04635 82.07739 #> 8  82.40022 82.61020 82.63964 82.58216 82.62615 82.70790 #> 9  82.17002 82.45931 82.55178 82.57494 82.62086 82.69025 #> 10 82.58963 83.07833 83.11779 83.00651 83.01600 83.12446 #> 11 82.15442 81.74862 82.05216 81.73070 81.63852 81.40000 #> 12 87.59686 88.64130 88.29910 88.84247 88.76913 88.66730 #>  rm(list=c(\"XCornell\",\"yCornell\"))   data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] PLS_glm_wvc(dataY=yCornell,dataX=XCornell,nt=3,modele=\"pls-glm-gaussian\", dataPredictY=XCornell[1,], verbose=FALSE) #> $valsPredict #>       [,1]     [,2]    [,3] #> 1 95.03164 97.08409 97.4436 #>  PLS_glm_wvc(dataY=yCornell[-1],dataX=XCornell[-1,],nt=3,modele=\"pls-glm-gaussian\", dataPredictY=XCornell[1,], verbose=FALSE) #> $valsPredict #>       [,1]     [,2]     [,3] #> 1 93.74777 95.32475 96.08522 #>  rm(\"XCornell\",\"yCornell\")  data(aze_compl) Xaze_compl<-aze_compl[,2:34] yaze_compl<-aze_compl$y PLS_glm(yaze_compl,Xaze_compl,10,modele=\"pls-glm-logistic\",typeVC=\"none\", verbose=FALSE)$InfCrit #>                 AIC      BIC Missclassed Chi2_Pearson_Y    RSS_Y      R2_Y #> Nb_Comp_0  145.8283 148.4727          49      104.00000 25.91346        NA #> Nb_Comp_1  118.1398 123.4285          28      100.53823 19.32272 0.2543365 #> Nb_Comp_2  109.9553 117.8885          26       99.17955 17.33735 0.3309519 #> Nb_Comp_3  105.1591 115.7366          22      123.37836 15.58198 0.3986915 #> Nb_Comp_4  103.8382 117.0601          21      114.77551 15.14046 0.4157299 #> Nb_Comp_5  104.7338 120.6001          21      105.35382 15.08411 0.4179043 #> Nb_Comp_6  105.6770 124.1878          21       98.87767 14.93200 0.4237744 #> Nb_Comp_7  107.2828 128.4380          20       97.04072 14.87506 0.4259715 #> Nb_Comp_8  109.0172 132.8167          22       98.90110 14.84925 0.4269676 #> Nb_Comp_9  110.9354 137.3793          21      100.35563 14.84317 0.4272022 #> Nb_Comp_10 112.9021 141.9904          20      102.85214 14.79133 0.4292027 #>             R2_residY RSS_residY #> Nb_Comp_0          NA   25.91346 #> Nb_Comp_1   -6.004879  181.52066 #> Nb_Comp_2   -9.617595  275.13865 #> Nb_Comp_3  -12.332217  345.48389 #> Nb_Comp_4  -15.496383  427.47839 #> Nb_Comp_5  -15.937183  438.90105 #> Nb_Comp_6  -16.700929  458.69233 #> Nb_Comp_7  -16.908851  464.08033 #> Nb_Comp_8  -17.555867  480.84675 #> Nb_Comp_9  -17.834439  488.06552 #> Nb_Comp_10 -17.999267  492.33678 PLS_glm_wvc(yaze_compl,Xaze_compl,10,modele=\"pls-glm-logistic\", keepcoeffs=TRUE, verbose=FALSE) #> $valsPredict #>           [,1]        [,2]        [,3]        [,4]        [,5]        [,6] #> 1   0.43119151 0.702047114 0.631858261 0.673867317 0.633105720 0.643502088 #> 2   0.21927519 0.208200622 0.166440274 0.108288423 0.122814698 0.163115357 #> 3   0.04106998 0.029963092 0.006791838 0.002965336 0.003725325 0.003746401 #> 4   0.30929185 0.554282284 0.414180215 0.441249985 0.520547128 0.604562658 #> 5   0.05118382 0.067233546 0.022736369 0.006104612 0.005217977 0.002943517 #> 6   0.05290489 0.111062277 0.030654567 0.012385420 0.011599399 0.007397041 #> 7   0.04770848 0.012461554 0.009969069 0.011387816 0.019758711 0.057213719 #> 8   0.23030599 0.203968184 0.120876571 0.103096864 0.048403176 0.031122482 #> 9   0.79603342 0.646912665 0.498819889 0.545037945 0.543238786 0.423550027 #> 10  0.18420109 0.281904502 0.319927429 0.355711963 0.419764286 0.422912933 #> 11  0.86850308 0.895570974 0.856803244 0.853618586 0.877371706 0.906873854 #> 12  0.81973108 0.742594700 0.819314935 0.772099212 0.770185219 0.741949824 #> 13  0.10378096 0.034374513 0.061664137 0.105513481 0.144646667 0.124182122 #> 14  0.24065500 0.216121428 0.236771150 0.254073363 0.180029130 0.162304231 #> 15  0.25406843 0.189921149 0.122309327 0.046077032 0.051655065 0.046711552 #> 16  0.11742108 0.026636030 0.021144841 0.009932451 0.011928074 0.012867736 #> 17  0.62187722 0.356241370 0.300877326 0.222486735 0.223971302 0.259218578 #> 18  0.63085304 0.495186298 0.710135221 0.596235794 0.529760711 0.488161297 #> 19  0.15384411 0.299159188 0.246846331 0.150702653 0.120019849 0.138670219 #> 20  0.23938183 0.102233996 0.261323652 0.418478866 0.480248654 0.437149596 #> 21  0.31843739 0.359915314 0.702415128 0.553592625 0.486242603 0.471686531 #> 22  0.26948160 0.218115310 0.330039231 0.176032976 0.142744996 0.144657867 #> 23  0.38688875 0.322522571 0.194282977 0.216329749 0.180302487 0.177187916 #> 24  0.25929423 0.113805680 0.125244332 0.065622331 0.055343844 0.053635436 #> 25  0.23956717 0.451995286 0.543962067 0.419106683 0.580554368 0.530330948 #> 26  0.19444922 0.251820723 0.123966447 0.177175557 0.150373132 0.093400279 #> 27  0.70737780 0.733381154 0.462512849 0.414579021 0.345820167 0.355863574 #> 28  0.13829538 0.102635881 0.082813672 0.085265556 0.055242281 0.061020998 #> 29  0.40496093 0.233837866 0.285045914 0.369925740 0.447381566 0.509598027 #> 30  0.12221316 0.186893799 0.059111670 0.048296062 0.062374711 0.061380243 #> 31  0.36560681 0.422607656 0.224275870 0.377066732 0.416945477 0.375434519 #> 32  0.58998317 0.392983408 0.151910276 0.143422224 0.185402553 0.124318557 #> 33  0.72886354 0.793463890 0.580779612 0.545477866 0.603245033 0.464806210 #> 34  0.31934676 0.184466274 0.101014622 0.077194233 0.075925319 0.066154173 #> 35  0.23746345 0.058469811 0.031578958 0.024285467 0.016659570 0.009334068 #> 36  0.35013391 0.355313187 0.415796281 0.521253111 0.426498990 0.456656482 #> 37  0.64850050 0.375923248 0.304390434 0.224221121 0.215331147 0.211685762 #> 38  0.38755032 0.137284188 0.101796277 0.084379325 0.091286905 0.115888877 #> 39  0.27424019 0.226697218 0.139175059 0.183685469 0.193530386 0.216586409 #> 40  0.65388494 0.519887626 0.478567247 0.400516903 0.394105599 0.554735843 #> 41  0.12946450 0.097012345 0.102677452 0.045309845 0.068832652 0.045887603 #> 42  0.66689831 0.490170524 0.514407085 0.617870569 0.618113005 0.602192147 #> 43  0.34774313 0.607127514 0.681870162 0.723512977 0.612203171 0.599031952 #> 44  0.20534214 0.060514691 0.034936078 0.023923047 0.022811279 0.030127494 #> 45  0.10787137 0.110762018 0.078045740 0.062754149 0.056126233 0.054466980 #> 46  0.66116234 0.725582784 0.700422712 0.842037688 0.798801727 0.748214349 #> 47  0.17500187 0.181257265 0.147033836 0.075688012 0.052217574 0.054286615 #> 48  0.27826924 0.312332943 0.156648719 0.138061479 0.102556222 0.094175338 #> 49  0.67906352 0.518547155 0.484272837 0.608913994 0.596609568 0.610163418 #> 50  0.40298084 0.482554614 0.223122702 0.198767758 0.288197158 0.261541091 #> 51  0.28408032 0.163890090 0.188384267 0.161186131 0.189991487 0.226812553 #> 52  0.02120634 0.007494379 0.010418897 0.005706003 0.004028951 0.003211954 #> 53  0.53874100 0.450203729 0.614709704 0.386004761 0.328383647 0.295044939 #> 54  0.67152137 0.406158600 0.409417001 0.411703449 0.449462796 0.485883982 #> 55  0.08777970 0.075522741 0.132824654 0.178966392 0.124633556 0.141516794 #> 56  0.61855060 0.721686274 0.584022743 0.783926814 0.737841421 0.696846758 #> 57  0.52725323 0.671536671 0.902964122 0.912756588 0.928084614 0.938575849 #> 58  0.67512847 0.587075631 0.694863898 0.715487331 0.707353396 0.646163105 #> 59  0.39617134 0.436010575 0.346619901 0.369125532 0.274518456 0.240623252 #> 60  0.20362696 0.227843791 0.394195242 0.515590659 0.637767577 0.535068332 #> 61  0.67200417 0.660036839 0.747335781 0.662234187 0.679349829 0.720216240 #> 62  0.50396071 0.635184174 0.695678303 0.564600033 0.608155992 0.607249320 #> 63  0.53548611 0.537052534 0.518321788 0.506052818 0.560106390 0.705117054 #> 64  0.81456207 0.923746901 0.940505447 0.946852982 0.937110807 0.963914099 #> 65  0.76930107 0.652078773 0.779696124 0.750240414 0.759297145 0.774107137 #> 66  0.74081281 0.538838825 0.490449388 0.561092475 0.628698596 0.645415477 #> 67  0.91280565 0.985524499 0.987385270 0.995952381 0.995809795 0.994173319 #> 68  0.27025468 0.642218762 0.881003868 0.892387298 0.893777605 0.913554112 #> 69  0.72400506 0.847099614 0.763912533 0.755718333 0.751986129 0.842526567 #> 70  0.75276334 0.922407667 0.915955573 0.924372638 0.952274824 0.956119967 #> 71  0.50141585 0.318030343 0.310744148 0.218311644 0.212515092 0.174944911 #> 72  0.12927414 0.099124892 0.030697353 0.026288318 0.034633861 0.054380083 #> 73  0.48132481 0.465376787 0.500862912 0.742159597 0.688353402 0.689246028 #> 74  0.68772032 0.778090832 0.874976023 0.935754083 0.949673750 0.969407185 #> 75  0.72031937 0.606769993 0.622494495 0.572143218 0.579477288 0.627568141 #> 76  0.55793917 0.494421342 0.437434284 0.460400091 0.460542480 0.494890446 #> 77  0.79943991 0.855257753 0.935928508 0.978005670 0.981273972 0.984309678 #> 78  0.85745937 0.830618813 0.865134636 0.898312327 0.913928051 0.928170413 #> 79  0.83345117 0.919224715 0.856369203 0.791325587 0.745470889 0.766729075 #> 80  0.57235513 0.414039021 0.351476404 0.311958419 0.290518135 0.263925112 #> 81  0.86879852 0.898679681 0.879900894 0.773949255 0.704553708 0.671359206 #> 82  0.45535619 0.764274615 0.797532046 0.744461196 0.824764221 0.811884622 #> 83  0.82827167 0.900830434 0.938275422 0.933835357 0.951546879 0.956093466 #> 84  0.70805640 0.903075834 0.967809228 0.979031867 0.972328032 0.963104641 #> 85  0.58750948 0.270646003 0.275457584 0.262474288 0.265058291 0.259707331 #> 86  0.85501392 0.950653792 0.950972848 0.957421636 0.940415633 0.911863862 #> 87  0.59350862 0.367675846 0.541557780 0.623191067 0.628609893 0.603566405 #> 88  0.78701299 0.779778499 0.528980639 0.595241939 0.624596722 0.612263975 #> 89  0.53053475 0.463363952 0.357941654 0.342680704 0.325066419 0.411465198 #> 90  0.78742155 0.970653016 0.964721638 0.978839943 0.985003070 0.987145933 #> 91  0.35243467 0.320053491 0.479839722 0.640766735 0.611879896 0.666491216 #> 92  0.89720093 0.966418149 0.960220418 0.963882817 0.955612296 0.958551535 #> 93  0.68862173 0.907543424 0.913645809 0.913758045 0.951448175 0.959000320 #> 94  0.28015169 0.404075368 0.545346353 0.760763289 0.680088744 0.672242170 #> 95  0.47946796 0.826642022 0.699988396 0.535143591 0.588217592 0.502063440 #> 96  0.29303531 0.260466286 0.575477371 0.479152176 0.513734415 0.428690041 #> 97  0.57134153 0.493862376 0.662480104 0.534413997 0.483990436 0.485013225 #> 98  0.80738973 0.800712471 0.861510658 0.899175983 0.915135265 0.882660615 #> 99  0.17424886 0.084872199 0.039330110 0.089167782 0.089911231 0.075436072 #> 100 0.69464297 0.849056789 0.901977691 0.852790391 0.855378024 0.837083296 #> 101 0.42957598 0.523749819 0.697708069 0.781939401 0.831423860 0.869246953 #> 102 0.77532567 0.726430234 0.850516228 0.849288906 0.876686813 0.866961583 #> 103 0.30244539 0.633632746 0.580168854 0.600867278 0.516381330 0.595553649 #> 104 0.72830077 0.856329971 0.822297122 0.839564063 0.843377821 0.894234435 #>            [,7]        [,8]         [,9]        [,10] #> 1   0.638787122 0.659736147 0.6929134622 0.6943989562 #> 2   0.183028361 0.177705421 0.1926067471 0.1927561148 #> 3   0.003376060 0.003152591 0.0032092459 0.0031900703 #> 4   0.637363116 0.601345955 0.6315525475 0.6128454701 #> 5   0.001804324 0.001087005 0.0009059437 0.0008702787 #> 6   0.007558967 0.008124069 0.0075922059 0.0072190675 #> 7   0.075010051 0.090577306 0.0904145007 0.0948080986 #> 8   0.037693727 0.036957495 0.0385194884 0.0366579947 #> 9   0.425135095 0.416115302 0.4234960049 0.4324032991 #> 10  0.343557178 0.355791649 0.3338844672 0.3416736098 #> 11  0.886266198 0.869985302 0.8690005512 0.8662229884 #> 12  0.710054194 0.673535568 0.6614385720 0.6495800417 #> 13  0.113655657 0.099642192 0.0950823806 0.0871083484 #> 14  0.162253329 0.157798411 0.1528392913 0.1395625569 #> 15  0.052536503 0.054898188 0.0458127882 0.0418375835 #> 16  0.014844229 0.016856869 0.0175371209 0.0173133552 #> 17  0.265167590 0.277072182 0.2975291066 0.3102814947 #> 18  0.471171553 0.456928590 0.4615499112 0.4590135395 #> 19  0.124799505 0.110005858 0.0939806189 0.0901182975 #> 20  0.390670737 0.441849813 0.4361859267 0.4353931743 #> 21  0.476731092 0.500960968 0.5071133610 0.5064639572 #> 22  0.122666126 0.121059180 0.1160295322 0.1176406817 #> 23  0.157621354 0.130954478 0.1380573789 0.1433585464 #> 24  0.060662413 0.064337031 0.0732478070 0.0788979344 #> 25  0.578979810 0.545258742 0.5619282569 0.5595832463 #> 26  0.108427152 0.149040860 0.1378520800 0.1466056822 #> 27  0.395406681 0.355201942 0.3518622723 0.3491848585 #> 28  0.063474701 0.061968018 0.0571164691 0.0556497892 #> 29  0.437293949 0.440015737 0.4520380190 0.4550505243 #> 30  0.090222972 0.106807614 0.1110660966 0.1078204935 #> 31  0.352227836 0.338481138 0.3335947194 0.3461925622 #> 32  0.137231222 0.139858851 0.1304182629 0.1232302292 #> 33  0.429294436 0.474754408 0.4757750462 0.4534418743 #> 34  0.075702396 0.089288097 0.0976117186 0.1002116059 #> 35  0.008228014 0.007198486 0.0075462359 0.0077113361 #> 36  0.416343698 0.433478675 0.4314919966 0.4291386780 #> 37  0.214184092 0.233031978 0.2466886171 0.2451334330 #> 38  0.131467992 0.133488355 0.1335614164 0.1313510107 #> 39  0.155762668 0.148717710 0.1567326194 0.1594062043 #> 40  0.577240742 0.554673059 0.5497730900 0.5509835451 #> 41  0.048124309 0.050731059 0.0500083553 0.0448639866 #> 42  0.557924005 0.621291699 0.6152093088 0.6041143234 #> 43  0.634717435 0.625848315 0.6179020932 0.6180509570 #> 44  0.030924644 0.034659867 0.0306744277 0.0329719302 #> 45  0.044139143 0.041342057 0.0370482993 0.0355143768 #> 46  0.765226062 0.719351450 0.7165147398 0.7371329957 #> 47  0.057359793 0.045401532 0.0448929095 0.0487307228 #> 48  0.078230361 0.075182597 0.0721409234 0.0707122052 #> 49  0.694411530 0.720080600 0.7210842527 0.7183599426 #> 50  0.235732262 0.220747630 0.2261186866 0.2145370126 #> 51  0.234065793 0.220978475 0.1869430913 0.1995610601 #> 52  0.003437084 0.003779608 0.0035686761 0.0033152141 #> 53  0.303245796 0.306092227 0.3003119432 0.3125280275 #> 54  0.523115204 0.502477841 0.4860084012 0.4799221158 #> 55  0.159531646 0.148936794 0.1471387050 0.1461051611 #> 56  0.704311058 0.670809998 0.6863833984 0.6954430065 #> 57  0.943204808 0.926497752 0.9285111732 0.9189983080 #> 58  0.654185441 0.637253621 0.6339188721 0.6237031375 #> 59  0.211731291 0.194702818 0.2153012812 0.2224698451 #> 60  0.578481709 0.553430985 0.5498083458 0.5552296673 #> 61  0.717399252 0.688899651 0.6833342733 0.6938073689 #> 62  0.580236946 0.561386908 0.5344644041 0.5476964614 #> 63  0.651909358 0.666423048 0.6518698084 0.6663502131 #> 64  0.966570975 0.967919914 0.9629859429 0.9607163779 #> 65  0.769033500 0.771933407 0.7688031852 0.7654739625 #> 66  0.618660601 0.605251254 0.6147034915 0.6115411360 #> 67  0.992233615 0.992370008 0.9912205187 0.9908677967 #> 68  0.926820425 0.940010587 0.9433622300 0.9472604786 #> 69  0.820022341 0.828019425 0.8345071602 0.8307300622 #> 70  0.952446809 0.942761722 0.9464573655 0.9474262795 #> 71  0.177146497 0.202296797 0.2065928146 0.2148691609 #> 72  0.059294591 0.044850251 0.0396625181 0.0359318012 #> 73  0.764615989 0.774200149 0.7720125792 0.7645581755 #> 74  0.977761403 0.984747935 0.9840257594 0.9833411230 #> 75  0.691909459 0.682556639 0.6572532436 0.6429766278 #> 76  0.532574707 0.494727136 0.4906445050 0.5066664293 #> 77  0.987637116 0.991228314 0.9916479530 0.9915530258 #> 78  0.945274182 0.949158918 0.9500366289 0.9503794757 #> 79  0.754986019 0.776998067 0.7816242563 0.7871699651 #> 80  0.228016301 0.223396570 0.2186964646 0.2082883519 #> 81  0.666420005 0.684833773 0.6766117373 0.6632488136 #> 82  0.801528750 0.829859317 0.8267776343 0.8261734713 #> 83  0.959791502 0.967581315 0.9699116096 0.9732698475 #> 84  0.956332714 0.964097103 0.9633606742 0.9650418710 #> 85  0.265579761 0.306826150 0.3330031055 0.3383605790 #> 86  0.891734459 0.888000574 0.8923024430 0.8958113953 #> 87  0.634861265 0.637836802 0.6497185838 0.6508400647 #> 88  0.592698628 0.583637434 0.5435709244 0.5588191361 #> 89  0.424076781 0.404623342 0.4313744898 0.4218769380 #> 90  0.989332252 0.992616886 0.9943134281 0.9946703862 #> 91  0.675576650 0.734303755 0.7206461704 0.7140897952 #> 92  0.953076020 0.959646001 0.9545742998 0.9480225668 #> 93  0.970105937 0.974883444 0.9754998983 0.9782804092 #> 94  0.680953582 0.649567373 0.6240201397 0.6168279359 #> 95  0.561170807 0.599211294 0.5856984481 0.5961543896 #> 96  0.396894305 0.339334143 0.3662679214 0.3640990048 #> 97  0.484857170 0.487769044 0.4938813223 0.4960597646 #> 98  0.881013093 0.859741343 0.8710430696 0.8736903224 #> 99  0.072463010 0.082375646 0.0886148007 0.0861258464 #> 100 0.853833336 0.877254170 0.8697760323 0.8733522761 #> 101 0.873059397 0.868378502 0.8660074209 0.8659618513 #> 102 0.877121140 0.890714101 0.8995141757 0.9033306611 #> 103 0.555036219 0.587526765 0.6104774849 0.6020532420 #> 104 0.871930923 0.882906865 0.8840853461 0.8836606796 #>  #> $coeffs #>                       [,1] #> tempConstante -2.276982302 #>               -1.068275295 #>                3.509231595 #>               -1.651869135 #>                2.207538418 #>                0.568523938 #>               -0.059691869 #>               -0.214529856 #>               -1.405223273 #>                0.396973880 #>               -0.782167532 #>                0.677591817 #>               -0.972259676 #>                0.650745841 #>                0.723667343 #>                0.477540145 #>                0.638755948 #>                1.666070158 #>               -0.005938234 #>                0.482766293 #>               -0.904425334 #>                0.300460249 #>                1.367992779 #>               -1.201977825 #>               -1.536120691 #>               -1.983144986 #>                1.544435411 #>                1.410302156 #>               -0.495400138 #>                0.454129717 #>                1.240250301 #>               -0.222933455 #>               -2.822712745 #>                0.026369914 #>  rm(\"Xaze_compl\",\"yaze_compl\") # }"},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_lm_wvc.html","id":null,"dir":"Reference","previous_headings":"","what":"Light version of PLS_lm for cross validation purposes — PLS_lm_wvc","title":"Light version of PLS_lm for cross validation purposes — PLS_lm_wvc","text":"Light version PLS_lm cross validation purposes either complete incomplete datasets.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_lm_wvc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Light version of PLS_lm for cross validation purposes — PLS_lm_wvc","text":"","code":"PLS_lm_wvc(   dataY,   dataX,   nt = 2,   dataPredictY = dataX,   modele = \"pls\",   scaleX = TRUE,   scaleY = NULL,   keepcoeffs = FALSE,   keepstd.coeffs = FALSE,   tol_Xi = 10^(-12),   weights,   verbose = TRUE )"},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_lm_wvc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Light version of PLS_lm for cross validation purposes — PLS_lm_wvc","text":"dataY response (training) dataset dataX predictor(s) (training) dataset nt number components extracted dataPredictY predictor(s) (testing) dataset modele name PLS model fitted, (\"pls\" available fonction. scaleX scale predictor(s) : must set TRUE modele=\"pls\" glms pls. scaleY scale response : Yes/. Ignored since non always possible glm responses. keepcoeffs whether coefficients unstandardized eXplanatory variables returned . keepstd.coeffs whether coefficients standardized eXplanatory variables returned . tol_Xi minimal value Norm2(Xi) \\(\\mathrm{det}(pp' \\times pp)\\) missing value dataX. defaults \\(10^{-12}\\) weights optional vector 'prior weights' used fitting process. NULL numeric vector. verbose info messages displayed ?","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_lm_wvc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Light version of PLS_lm for cross validation purposes — PLS_lm_wvc","text":"valsPredict nrow(dataPredictY) * nt matrix predicted values list(\"coeffs\") coefficients eXplanatory variables requested: .e. keepcoeffs=TRUE.ncol(dataX) * 1 matrix coefficients eXplanatory variables","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_lm_wvc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Light version of PLS_lm for cross validation purposes — PLS_lm_wvc","text":"function called PLS_lm_kfoldcv order perform cross-validation either complete incomplete datasets. Non-NULL weights can used indicate different observations different dispersions (values weights inversely proportional dispersions); equivalently, elements weights positive integers w_i, response y_i mean w_i unit-weight observations.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_lm_wvc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Light version of PLS_lm for cross validation purposes — PLS_lm_wvc","text":"Use PLS_lm_kfoldcv wrapper view cross-validation.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_lm_wvc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Light version of PLS_lm for cross validation purposes — PLS_lm_wvc","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_lm_wvc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Light version of PLS_lm for cross validation purposes — PLS_lm_wvc","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/PLS_lm_wvc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Light version of PLS_lm for cross validation purposes — PLS_lm_wvc","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] PLS_lm_wvc(dataY=yCornell,dataX=XCornell,nt=3,dataPredictY=XCornell[1,]) #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> $valsPredict #>       [,1]     [,2]     [,3] #> 1 95.03164 96.49529 97.55864 #>  PLS_lm_wvc(dataY=yCornell[-c(1,2)],dataX=XCornell[-c(1,2),],nt=3,dataPredictY=XCornell[c(1,2),], verbose=FALSE) #> $valsPredict #>       [,1]     [,2]     [,3] #> 1 93.21260 93.91414 95.73889 #> 2 94.71773 95.68684 96.79566 #>  PLS_lm_wvc(dataY=yCornell[-c(1,2)],dataX=XCornell[-c(1,2),],nt=3,dataPredictY=XCornell[c(1,2),], keepcoeffs=TRUE, verbose=FALSE) #> $valsPredict #>       [,1]     [,2]     [,3] #> 1 93.21260 93.91414 95.73889 #> 2 94.71773 95.68684 96.79566 #>  #> $coeffs #>                     [,1] #> tempConstante  90.036430 #> X1             -8.146409 #> X2             -4.000226 #> X3            -13.728783 #> X4             -5.883018 #> X5              6.937067 #> X6             10.148166 #> X7            -29.571048 #>  rm(\"XCornell\",\"yCornell\")  ## With an incomplete dataset (X[1,2] is NA) data(pine) ypine <- pine[,11] data(XpineNAX21) PLS_lm_wvc(dataY=ypine[-1],dataX=XpineNAX21[-1,],nt=3, verbose=FALSE) #> $valsPredict #>           [,1]        [,2]          [,3] #> 2   0.94076404  1.05174832  1.0374616113 #> 3   1.39047885  1.13453980  1.3242356673 #> 4   0.79354603  0.61363359  0.9634719738 #> 5   0.97860870  0.65429731  0.5150093803 #> 6   1.27787513  1.34466033  1.2141683374 #> 7   0.38074833 -0.19960869 -0.0297875729 #> 8   0.63365198  0.54155986  0.2091351671 #> 9   1.43295859  1.55738575  1.6867033620 #> 10  0.99298825  0.98045144  1.0732360517 #> 11  0.39646989  0.77799528  0.8878866176 #> 12 -0.06668771  0.22196126  0.6489885307 #> 13  1.66741434  1.86115065  2.0625005103 #> 14  1.30880185  1.68986944  1.5677761570 #> 15  1.23730000  1.38593444  1.3409666162 #> 16 -0.25157291 -0.43528542 -0.4743325478 #> 17  0.11040475  0.12039192  0.0007238673 #> 18  0.92497736  0.93090871  0.9139450905 #> 19  1.07369519  0.75362958  0.8101882969 #> 20  0.28649448  0.01372797 -0.0381486634 #> 21  0.07611695  0.25760359  0.4947474762 #> 22  0.62440377  0.61179280  0.7213780672 #> 23  0.90767675  1.00727900  0.7150222566 #> 24  0.32767392  0.33311540  0.3319260445 #> 25  0.52077680  0.11553149 -0.1540043757 #> 26  0.90533669  0.96712444  0.7408564424 #> 27  0.03199415  0.35664666  0.1497469324 #> 28  1.47696322  1.10783727  1.0880798820 #> 29  1.39868360  1.45100576  1.5321709218 #> 30  0.71071212  0.65722183  0.8296817343 #> 31  0.95366454  1.27340221  1.1747095867 #> 32  0.67802770  1.02264538  0.9118337341 #> 33  0.27905267  0.23984263  0.1497228439 #>  PLS_lm_wvc(dataY=ypine[-1],dataX=XpineNAX21[-1,],nt=3,dataPredictY=XpineNAX21[1,], verbose=FALSE) #> list() PLS_lm_wvc(dataY=ypine[-2],dataX=XpineNAX21[-2,],nt=3,dataPredictY=XpineNAX21[2,], verbose=FALSE) #> $valsPredict #>        [,1]     [,2]     [,3] #> 2 0.9914237 1.127694 1.076871 #>  PLS_lm_wvc(dataY=ypine,dataX=XpineNAX21,nt=3, verbose=FALSE) #> $valsPredict #>                [,1]        [,2]        [,3] #>  [1,]  1.4589428372  2.11593441  2.26945463 #>  [2,]  0.9829728848  1.18076301  1.03620773 #>  [3,]  1.5465793485  1.18650144  1.27588027 #>  [4,]  0.8655200475  0.46560150  0.87695905 #>  [5,]  1.1072893206  0.85251283  0.57894070 #>  [6,]  1.3475354913  1.50304781  1.20343678 #>  [7,]  0.4642031730 -0.42135911 -0.09955758 #>  [8,]  0.7227037635  0.98797643  0.21698630 #>  [9,]  1.4817373396  1.44514851  1.73358055 #> [10,]  1.0254800667  0.83934144  1.03617380 #> [11,]  0.3387272475  0.80689483  1.16252267 #> [12,] -0.1404993319  0.07995556  0.28848700 #> [13,]  1.7330197324  1.78515568  2.09996156 #> [14,]  1.3042461768  1.77459300  1.45332343 #> [15,]  1.2715747058  1.40954157  1.32075175 #> [16,] -0.2777168878 -0.44870259 -0.51434295 #> [17,]  0.0732828651  0.16650220 -0.07993936 #> [18,]  1.0136353777  1.18186572  1.21367764 #> [19,]  1.1731943384  0.65036199  0.69946245 #> [20,]  0.3361806444  0.07862672 -0.02520022 #> [21,]  0.0005399781  0.08838604  0.42008495 #> [22,]  0.6493952920  0.59285401  0.78398392 #> [23,]  0.9096512309  1.09049865  0.76180402 #> [24,]  0.2922013348  0.21706236  0.34621654 #> [25,]  0.6382767422  0.42340484 -0.21649161 #> [26,]  0.9211966658  1.04536567  0.90202594 #> [27,] -0.0650662222  0.48221488  0.31920563 #> [28,]  1.6349387353  1.13681799  1.30914490 #> [29,]  1.4578617140  1.36487443  1.62299471 #> [30,]  0.7469063021  0.56602059  1.06652525 #> [31,]  0.9273242679  1.29767879  1.02671404 #> [32,]  0.6059700763  0.95665914  1.21783413 #> [33,]  0.2450768211  0.13732755  0.12831479 #>  rm(\"ypine\")"},{"path":"https://fbertran.github.io/plsRglm/reference/XbordeauxNA.html","id":null,"dir":"Reference","previous_headings":"","what":"Incomplete dataset for the quality of wine dataset — XbordeauxNA","title":"Incomplete dataset for the quality of wine dataset — XbordeauxNA","text":"Quality Bordeaux wines (Quality) four potentially predictive variables (Temperature, Sunshine, Heat Rain). value Temperature first observation remove matrix predictors purpose.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/XbordeauxNA.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Incomplete dataset for the quality of wine dataset — XbordeauxNA","text":"data frame 34 observations following 4 variables. Temperature numeric vector Sunshine numeric vector Heat numeric vector Rain numeric vector","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/XbordeauxNA.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Incomplete dataset for the quality of wine dataset — XbordeauxNA","text":"P. Bastien, V. Esposito-Vinzi, M. Tenenhaus. (2005). PLS generalised linear regression. Computational Statistics & Data Analysis, 48(1):17-46.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/XbordeauxNA.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Incomplete dataset for the quality of wine dataset — XbordeauxNA","text":"M. Tenenhaus. (2005). La regression logistique PLS. J.-J. Droesbeke, M. Lejeune, G. Saporta, editors, Modeles statistiques pour donnees qualitatives. Editions Technip, Paris.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/XbordeauxNA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Incomplete dataset for the quality of wine dataset — XbordeauxNA","text":"","code":"data(XbordeauxNA) str(XbordeauxNA) #> 'data.frame':\t34 obs. of  4 variables: #>  $ Temperature: int  NA 3000 3155 3085 3245 3267 3080 2974 3038 3318 ... #>  $ Sunshine   : int  1201 1053 1133 970 1258 1386 966 1189 1103 1310 ... #>  $ Heat       : int  10 11 19 4 36 35 13 12 14 29 ... #>  $ Rain       : int  361 338 393 467 294 225 417 488 677 427 ..."},{"path":"https://fbertran.github.io/plsRglm/reference/XpineNAX21.html","id":null,"dir":"Reference","previous_headings":"","what":"Incomplete dataset from the pine caterpillars example — XpineNAX21","title":"Incomplete dataset from the pine caterpillars example — XpineNAX21","text":"caterpillar dataset extracted 1973 study pine processionary caterpillars. assesses influence forest settlement characteristics development caterpillar colonies. k=10 potentially explanatory variables defined n=33 areas. value x2 first observation remove matrix predictors purpose.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/XpineNAX21.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Incomplete dataset from the pine caterpillars example — XpineNAX21","text":"data frame 33 observations following 10 variables one missing value. x1 altitude (meters) x2 slope (en degrees) x3 number pines area x4 height (meters) tree sampled center area x5 diameter (meters) tree sampled center area x6 index settlement density x7 orientation area (1 southbound 2 otherwise) x8 height (meters) dominant tree x9 number vegetation strata x10 mix settlement index (1 mixed 2 mixed)","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/XpineNAX21.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Incomplete dataset from the pine caterpillars example — XpineNAX21","text":"Tomassone R., Audrain S., Lesquoy-de Turckeim E., Millier C. (1992). “La régression, nouveaux regards sur une ancienne méthode statistique”, INRA, Actualités Scientifiques et Agronomiques, Masson, Paris.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/XpineNAX21.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Incomplete dataset from the pine caterpillars example — XpineNAX21","text":"caterpillars got names habit moving ground incredibly long head--tail processions leaving nest create new colony. XpineNAX21 dataset missing value testing purpose.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/XpineNAX21.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Incomplete dataset from the pine caterpillars example — XpineNAX21","text":"","code":"data(XpineNAX21) str(XpineNAX21) #> 'data.frame':\t33 obs. of  10 variables: #>  $ x1 : int  1200 1342 1231 1254 1357 1250 1422 1309 1127 1075 ... #>  $ x2 : int  NA 28 28 28 32 27 37 46 24 34 ... #>  $ x3 : int  1 8 5 18 7 1 22 7 2 9 ... #>  $ x4 : num  4 4.4 2.4 3 3.7 4.4 3 5.7 3.5 4.3 ... #>  $ x5 : num  14.8 18 7.8 9.2 10.7 14.8 8.1 19.6 12.6 12 ... #>  $ x6 : num  1 1.5 1.3 2.3 1.4 1 2.7 1.5 1 1.6 ... #>  $ x7 : num  1.1 1.5 1.6 1.7 1.7 1.7 1.9 1.3 1.7 1.8 ... #>  $ x8 : num  5.9 6.4 4.3 6.9 6.6 5.8 8.3 7.8 4.9 6.8 ... #>  $ x9 : num  1.4 1.7 1.5 2.3 1.8 1.3 2.5 1.8 1.5 2 ... #>  $ x10: num  1.4 1.7 1.4 1.6 1.3 1.4 2 1.6 2 2 ..."},{"path":"https://fbertran.github.io/plsRglm/reference/aic.dof.html","id":null,"dir":"Reference","previous_headings":"","what":"Akaike and Bayesian Information Criteria and Generalized minimum description length — aic.dof","title":"Akaike and Bayesian Information Criteria and Generalized minimum description length — aic.dof","text":"function computes Akaike Bayesian Information Criteria Generalized minimum description length.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/aic.dof.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Akaike and Bayesian Information Criteria and Generalized minimum description length — aic.dof","text":"","code":"aic.dof(RSS, n, DoF, sigmahat)  bic.dof(RSS, n, DoF, sigmahat)  gmdl.dof(sigmahat, n, DoF, yhat)"},{"path":"https://fbertran.github.io/plsRglm/reference/aic.dof.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Akaike and Bayesian Information Criteria and Generalized minimum description length — aic.dof","text":"RSS vector residual sum squares. n number observations. DoF vector Degrees Freedom. length DoF length RSS. sigmahat Estimated model error. length sigmahat length RSS. yhat vector squared norm Yhat. length yhat length sigmahat.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/aic.dof.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Akaike and Bayesian Information Criteria and Generalized minimum description length — aic.dof","text":"vector numerical values requested AIC, BIC GMDL.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/aic.dof.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Akaike and Bayesian Information Criteria and Generalized minimum description length — aic.dof","text":"gmdl criterion defined $$gmdl=\\frac{n}{2}log(S)+\\frac{DoF}{2}log(F)+\\frac{1}{2}log(n)$$ $$S=\\hat\\sigma^2$$","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/aic.dof.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Akaike and Bayesian Information Criteria and Generalized minimum description length — aic.dof","text":"M. Hansen, B. Yu. (2001). Model Selection Minimum Descripion Length Principle, Journal American Statistical Association, 96, 746-774. N. Kraemer, M. Sugiyama. (2011). Degrees Freedom Partial Least Squares Regression. Journal American Statistical Association, 106(494), 697-705. N. Kraemer, M.L. Braun, Kernelizing PLS, Degrees Freedom, Efficient Model Selection, Proceedings 24th International Conference Machine Learning, Omni Press, (2007) 441-448.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/aic.dof.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Akaike and Bayesian Information Criteria and Generalized minimum description length — aic.dof","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/aic.dof.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Akaike and Bayesian Information Criteria and Generalized minimum description length — aic.dof","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] modpls <- plsR(yCornell,XCornell,4) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  dof.object <- plsR.dof(modpls) aic.dof(modpls$RSS,modpls$nr,dof.object$DoF,dof.object$sigmahat) #>          [,1]     [,2]     [,3]      [,4]      [,5] #> [1,] 46.07088 4.569969 2.107546 0.8467795 0.8232505 bic.dof(modpls$RSS,modpls$nr,dof.object$DoF,dof.object$sigmahat) #>          [,1]     [,2]     [,3]      [,4]      [,5] #> [1,] 47.78935 4.955816 2.394933 0.9628191 0.9357846 gmdl.dof(dof.object$sigmahat,modpls$nr,dof.object$DoF,dof.object$yhat) #> [1] 27.59461 21.34020 27.40202 24.40842 24.23105 naive.object <- plsR.dof(modpls,naive=TRUE) aic.dof(modpls$RSS,modpls$nr,naive.object$DoF,naive.object$sigmahat) #>          [,1]     [,2]     [,3]      [,4]      [,5] #> [1,] 46.07088 4.169957 1.537029 0.7363469 0.8721072 bic.dof(modpls$RSS,modpls$nr,naive.object$DoF,naive.object$sigmahat) #>          [,1]    [,2]     [,3]      [,4]      [,5] #> [1,] 47.78935 4.45882 1.686092 0.8256118 0.9964867 gmdl.dof(naive.object$sigmahat,modpls$nr,naive.object$DoF,naive.object$yhat) #> [1] 27.59461 18.37545 17.71117 19.01033 24.16510"},{"path":"https://fbertran.github.io/plsRglm/reference/aze.html","id":null,"dir":"Reference","previous_headings":"","what":"Microsatellites Dataset — aze","title":"Microsatellites Dataset — aze","text":"database collected patients carrying colon adenocarcinoma. 104 observations 33 binary qualitative explanatory variables one response variable y representing cancer stage according Astler-Coller classification (Astler Coller, 1954). dataset missing data due technical limits. microsattelite non-coding DNA sequence.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/aze.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Microsatellites Dataset — aze","text":"data frame 104 observations following 34 variables. y response: binary vector (Astler-Coller score). D2S138 binary vector indicates whether microsatellite altered . D18S61 binary vector indicates whether microsatellite altered . D16S422 binary vector indicates whether microsatellite altered . D17S794 binary vector indicates whether microsatellite altered . D6S264 binary vector indicates whether microsatellite altered . D14S65 binary vector indicates whether microsatellite altered . D18S53 binary vector indicates whether microsatellite altered . D17S790 binary vector indicates whether microsatellite altered . D1S225 binary vector indicates whether microsatellite altered . D3S1282 binary vector indicates whether microsatellite altered . D9S179 binary vector indicates whether microsatellite altered . D5S430 binary vector indicates whether microsatellite altered . D8S283 binary vector indicates whether microsatellite altered . D11S916 binary vector indicates whether microsatellite altered . D2S159 binary vector indicates whether microsatellite altered . D16S408 binary vector indicates whether microsatellite altered . D5S346 binary vector indicates whether microsatellite altered . D10S191 binary vector indicates whether microsatellite altered . D13S173 binary vector indicates whether microsatellite altered . D6S275 binary vector indicates whether microsatellite altered . D15S127 binary vector indicates whether microsatellite altered . D1S305 binary vector indicates whether microsatellite altered . D4S394 binary vector indicates whether microsatellite altered . D20S107 binary vector indicates whether microsatellite altered . D1S197 binary vector indicates whether microsatellite altered . D1S207 binary vector indicates whether microsatellite altered . D10S192 binary vector indicates whether microsatellite altered . D3S1283 binary vector indicates whether microsatellite altered . D4S414 binary vector indicates whether microsatellite altered . D8S264 binary vector indicates whether microsatellite altered . D22S928 binary vector indicates whether microsatellite altered . TP53 binary vector indicates whether microsatellite altered . D9S171 binary vector indicates whether microsatellite altered .","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/aze.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Microsatellites Dataset — aze","text":"Weber et al. (2007). Allelotyping analyzes synchronous primary metastasis CIN colon cancers identified different subtypes. Int J Cancer, 120(3), pages 524-32.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/aze.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Microsatellites Dataset — aze","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Société Française de Statistique, 151(2), pages 1-18.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/aze.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Microsatellites Dataset — aze","text":"","code":"data(aze) str(aze) #> 'data.frame':\t104 obs. of  34 variables: #>  $ y      : int  0 0 0 0 0 0 0 0 0 0 ... #>  $ D2S138 : int  0 0 NA NA 0 0 0 0 1 0 ... #>  $ D18S61 : int  1 0 0 0 0 0 1 NA 1 1 ... #>  $ D16S422: int  1 1 0 0 NA 0 0 1 1 0 ... #>  $ D17S794: int  NA 1 NA NA 1 0 NA 0 0 NA ... #>  $ D6S264 : int  0 NA 0 0 NA 0 NA NA 0 0 ... #>  $ D14S65 : int  1 1 1 NA 0 NA NA NA 0 0 ... #>  $ D18S53 : int  1 0 NA NA 0 0 1 1 NA 0 ... #>  $ D17S790: int  0 NA 0 0 NA 0 1 0 0 1 ... #>  $ D1S225 : int  0 NA 0 0 0 0 1 0 1 0 ... #>  $ D3S1282: int  0 0 NA 0 0 0 NA NA 0 0 ... #>  $ D9S179 : int  NA 1 NA 0 0 0 0 0 NA NA ... #>  $ D5S430 : int  NA 1 0 NA NA 0 NA 0 NA 0 ... #>  $ D8S283 : int  1 NA 0 1 0 0 0 1 NA 0 ... #>  $ D11S916: int  0 0 0 0 0 0 0 0 1 1 ... #>  $ D2S159 : int  NA 0 0 0 0 0 0 0 1 0 ... #>  $ D16S408: int  1 1 0 NA 0 0 NA 1 1 0 ... #>  $ D5S346 : int  0 1 0 1 0 0 0 1 1 0 ... #>  $ D10S191: int  0 0 0 0 0 0 0 1 1 0 ... #>  $ D13S173: int  1 1 NA NA NA 0 0 1 0 1 ... #>  $ D6S275 : int  0 1 NA 0 0 NA NA 0 1 NA ... #>  $ D15S127: int  NA 0 0 0 0 NA 1 0 NA 0 ... #>  $ D1S305 : int  0 0 0 0 0 0 NA 0 1 0 ... #>  $ D4S394 : int  0 0 NA 0 NA 0 NA 0 1 1 ... #>  $ D20S107: int  1 1 NA NA 0 0 1 NA 1 1 ... #>  $ D1S197 : int  0 0 NA 0 0 1 NA NA 1 0 ... #>  $ D1S207 : int  0 0 0 0 0 0 1 0 1 0 ... #>  $ D10S192: int  NA NA NA 1 0 0 1 0 1 NA ... #>  $ D3S1283: int  0 0 NA NA 0 0 NA 1 1 0 ... #>  $ D4S414 : int  0 1 0 0 0 0 NA 0 1 1 ... #>  $ D8S264 : int  0 NA 0 0 0 0 0 1 1 0 ... #>  $ D22S928: int  0 NA 0 0 0 0 0 1 1 0 ... #>  $ TP53   : int  1 1 0 0 1 0 NA 1 1 1 ... #>  $ D9S171 : int  0 1 0 NA NA 0 0 NA 1 NA ..."},{"path":"https://fbertran.github.io/plsRglm/reference/aze_compl.html","id":null,"dir":"Reference","previous_headings":"","what":"As aze without missing values — aze_compl","title":"As aze without missing values — aze_compl","text":"single imputation aze dataset collected patients carrying colon adenocarcinoma. 104 observations 33 binary qualitative explanatory variables one response variable y representing cancer stage according Astler-Coller classification (Astler Coller, 1954). microsattelite non-coding DNA sequence.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/aze_compl.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"As aze without missing values — aze_compl","text":"data frame 104 observations following 34 variables. y response: binary vector (Astler-Coller score). D2S138 binary vector indicates whether microsatellite altered . D18S61 binary vector indicates whether microsatellite altered . D16S422 binary vector indicates whether microsatellite altered . D17S794 binary vector indicates whether microsatellite altered . D6S264 binary vector indicates whether microsatellite altered . D14S65 binary vector indicates whether microsatellite altered . D18S53 binary vector indicates whether microsatellite altered . D17S790 binary vector indicates whether microsatellite altered . D1S225 binary vector indicates whether microsatellite altered . D3S1282 binary vector indicates whether microsatellite altered . D9S179 binary vector indicates whether microsatellite altered . D5S430 binary vector indicates whether microsatellite altered . D8S283 binary vector indicates whether microsatellite altered . D11S916 binary vector indicates whether microsatellite altered . D2S159 binary vector indicates whether microsatellite altered . D16S408 binary vector indicates whether microsatellite altered . D5S346 binary vector indicates whether microsatellite altered . D10S191 binary vector indicates whether microsatellite altered . D13S173 binary vector indicates whether microsatellite altered . D6S275 binary vector indicates whether microsatellite altered . D15S127 binary vector indicates whether microsatellite altered . D1S305 binary vector indicates whether microsatellite altered . D4S394 binary vector indicates whether microsatellite altered . D20S107 binary vector indicates whether microsatellite altered . D1S197 binary vector indicates whether microsatellite altered . D1S207 binary vector indicates whether microsatellite altered . D10S192 binary vector indicates whether microsatellite altered . D3S1283 binary vector indicates whether microsatellite altered . D4S414 binary vector indicates whether microsatellite altered . D8S264 binary vector indicates whether microsatellite altered . D22S928 binary vector indicates whether microsatellite altered . TP53 binary vector indicates whether microsatellite altered . D9S171 binary vector indicates whether microsatellite altered .","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/aze_compl.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"As aze without missing values — aze_compl","text":"Weber et al. (2007). Allelotyping analyzes synchronous primary metastasis CIN colon cancers identified different subtypes. Int J Cancer, 120(3), pages 524-32.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/aze_compl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"As aze without missing values — aze_compl","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Société Française de Statistique, 151(2), pages 1-18.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/aze_compl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"As aze without missing values — aze_compl","text":"","code":"data(aze_compl) str(aze_compl) #> 'data.frame':\t104 obs. of  34 variables: #>  $ y      : int  0 0 0 0 0 0 0 0 0 0 ... #>  $ D2S138 : int  0 0 1 1 0 0 0 0 1 0 ... #>  $ D18S61 : int  1 0 0 0 0 0 1 1 1 1 ... #>  $ D16S422: int  1 1 0 0 1 0 0 1 1 0 ... #>  $ D17S794: int  1 1 1 1 1 0 1 0 0 1 ... #>  $ D6S264 : int  0 1 0 0 1 0 1 1 0 0 ... #>  $ D14S65 : int  1 1 1 1 0 1 1 1 0 0 ... #>  $ D18S53 : int  1 0 1 1 0 0 1 1 1 0 ... #>  $ D17S790: int  0 1 0 0 1 0 1 0 0 1 ... #>  $ D1S225 : int  0 1 0 0 0 0 1 0 1 0 ... #>  $ D3S1282: int  0 0 1 0 0 0 1 1 0 0 ... #>  $ D9S179 : int  1 1 1 0 0 0 0 0 1 1 ... #>  $ D5S430 : int  1 1 0 1 1 0 1 0 1 0 ... #>  $ D8S283 : int  1 1 0 1 0 0 0 1 1 0 ... #>  $ D11S916: int  0 0 0 0 0 0 0 0 1 1 ... #>  $ D2S159 : int  1 0 0 0 0 0 0 0 1 0 ... #>  $ D16S408: int  1 1 0 1 0 0 1 1 1 0 ... #>  $ D5S346 : int  0 1 0 1 0 0 0 1 1 0 ... #>  $ D10S191: int  0 0 0 0 0 0 0 1 1 0 ... #>  $ D13S173: int  1 1 1 1 1 0 0 1 0 1 ... #>  $ D6S275 : int  0 1 1 0 0 1 1 0 1 1 ... #>  $ D15S127: int  1 0 0 0 0 1 1 0 1 0 ... #>  $ D1S305 : int  0 0 0 0 0 0 1 0 1 0 ... #>  $ D4S394 : int  0 0 1 0 1 0 1 0 1 1 ... #>  $ D20S107: int  1 1 1 1 0 0 1 1 1 1 ... #>  $ D1S197 : int  0 0 1 0 0 1 1 1 1 0 ... #>  $ D1S207 : int  0 0 0 0 0 0 1 0 1 0 ... #>  $ D10S192: int  1 1 1 1 0 0 1 0 1 1 ... #>  $ D3S1283: int  0 0 1 1 0 0 1 1 1 0 ... #>  $ D4S414 : int  0 1 0 0 0 0 1 0 1 1 ... #>  $ D8S264 : int  0 1 0 0 0 0 0 1 1 0 ... #>  $ D22S928: int  0 1 0 0 0 0 0 1 1 0 ... #>  $ TP53   : int  1 1 0 0 1 0 1 1 1 1 ... #>  $ D9S171 : int  0 1 0 1 1 0 0 1 1 1 ..."},{"path":"https://fbertran.github.io/plsRglm/reference/bootpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Non-parametric Bootstrap for PLS models — bootpls","title":"Non-parametric Bootstrap for PLS models — bootpls","text":"Provides wrapper bootstrap function boot boot R package. Implements non-parametric bootstraps PLS Regression models either (Y,X) (Y,T) resampling.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bootpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Non-parametric Bootstrap for PLS models — bootpls","text":"","code":"bootpls(   object,   typeboot = \"plsmodel\",   R = 250,   statistic = NULL,   sim = \"ordinary\",   stype = \"i\",   stabvalue = 1e+06,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/plsRglm/reference/bootpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Non-parametric Bootstrap for PLS models — bootpls","text":"object object class plsRmodel bootstrap typeboot type bootstrap. Either (Y,X) boostrap (typeboot=\"plsmodel\") (Y,T) bootstrap (typeboot=\"fmodel_np\"). Defaults (Y,X) resampling. R number bootstrap replicates. Usually single positive integer. importance resampling, resamples may use one set weights others use different set weights. case R vector integers component gives number resamples rows weights. statistic function applied data returns vector containing statistic(s) interest. statistic must take least two arguments. first argument passed always original data. second vector indices, frequencies weights define bootstrap sample. , predictions required, third argument required vector random indices used generate bootstrap predictions. arguments can passed statistic ... argument. sim character string indicating type simulation required. Possible values \"ordinary\" (default), \"balanced\", \"permutation\", \"antithetic\". stype character string indicating second argument statistic represents. Possible values stype \"\" (indices - default), \"f\" (frequencies), \"w\" (weights). stabvalue value hard threshold bootstrap estimates computed atypical resamplings. Especially useful Generalized Linear Models. verbose info messages displayed ? ... named arguments statistic passed unchanged time called. arguments statistic follow arguments statistic required simulation. Beware partial matching arguments boot listed .","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bootpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Non-parametric Bootstrap for PLS models — bootpls","text":"object class \"boot\". See Value part help function boot.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bootpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Non-parametric Bootstrap for PLS models — bootpls","text":"details bootstrap techniques available help boot function.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bootpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Non-parametric Bootstrap for PLS models — bootpls","text":". Lazraq, R. Cleroux, J.-P. Gauchi. (2003). Selecting latent explanatory variables PLS1 regression model. Chemometrics Intelligent Laboratory Systems, 66(2):117-126. P. Bastien, V. Esposito-Vinzi, M. Tenenhaus. (2005). PLS generalised linear regression. Computational Statistics & Data Analysis, 48(1):17-46. . C. Davison D. V. Hinkley. (1997). Bootstrap Methods Applications. Cambridge University Press, Cambridge.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/bootpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Non-parametric Bootstrap for PLS models — bootpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bootpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Non-parametric Bootstrap for PLS models — bootpls","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8]  # Lazraq-Cleroux PLS ordinary bootstrap set.seed(250) modpls <- plsR(yCornell,XCornell,3) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>   #(Y,X) resampling Cornell.bootYX <- bootpls(modpls, R=250, verbose=FALSE)  #(Y,T) resampling Cornell.bootYT <- bootpls(modpls, typeboot=\"fmodel_np\", R=250, verbose=FALSE)  # Using the boxplots.bootpls function boxplots.bootpls(Cornell.bootYX,indices=2:8)  # Confidence intervals plotting confints.bootpls(Cornell.bootYX,indices=2:8) #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints #>                                                                          #> X1 -0.2305299 -0.03654653 -0.2146155 -0.01243502 -0.2657483 -0.063567788 #> X2 -0.3824730 -0.12056633 -0.4240731 -0.16474400 -0.2526435  0.006685662 #> X3 -0.2262325 -0.03807142 -0.2115428 -0.01464437 -0.2604663 -0.063567788 #> X4 -0.4336032 -0.19861671 -0.4793055 -0.22524165 -0.3610949 -0.107030999 #> X5 -0.2895056  0.13307318 -0.3083408  0.07915147 -0.1560125  0.231479782 #> X6  0.3197348  0.65767612  0.3256605  0.67125328  0.2415264  0.587119147 #> X7 -0.2387634 -0.03963758 -0.2590735 -0.03271142 -0.2540574 -0.027695351 #>                           #> X1 -0.2867282 -0.07494113 #> X2 -0.2795110 -0.11744873 #> X3 -0.2795040 -0.07955903 #> X4 -0.4109452 -0.17018880 #> X5 -0.1803183  0.17569760 #> X6  0.3172633  0.64752609 #> X7 -0.2222602  0.03146667 #> attr(,\"typeBCa\") #> [1] TRUE plots.confints.bootpls(confints.bootpls(Cornell.bootYX,indices=2:8)) #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints  # Graph similar to the one of Bastien et al. in CSDA 2005 boxplot(as.vector(Cornell.bootYX$t[,-1])~factor(rep(1:7,rep(250,7))),  main=\"Bootstrap distributions of standardised bj (j = 1, ..., 7).\") points(c(1:7),Cornell.bootYX$t0[-1],col=\"red\",pch=19)    # \\donttest{ library(boot) boot.ci(Cornell.bootYX, conf = c(0.90,0.95), type = c(\"norm\",\"basic\",\"perc\",\"bca\"), index=2) #> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS #> Based on 250 bootstrap replicates #>  #> CALL :  #> boot.ci(boot.out = Cornell.bootYX, conf = c(0.9, 0.95), type = c(\"norm\",  #>     \"basic\", \"perc\", \"bca\"), index = 2) #>  #> Intervals :  #> Level      Normal              Basic          #> 90%   (-0.2149, -0.0521 )   (-0.1971, -0.0401 )    #> 95%   (-0.2305, -0.0365 )   (-0.2146, -0.0124 )   #>  #> Level     Percentile            BCa           #> 90%   (-0.2380, -0.0811 )   (-0.2573, -0.0857 )    #> 95%   (-0.2657, -0.0636 )   (-0.2867, -0.0749 )   #> Calculations and Intervals on Original Scale #> Some basic intervals may be unstable #> Some percentile intervals may be unstable #> Some BCa intervals may be unstable plot(Cornell.bootYX,index=2)  jack.after.boot(Cornell.bootYX, index=2, useJ=TRUE, nt=3)  plot(Cornell.bootYX,index=2,jack=TRUE)   car::dataEllipse(Cornell.bootYX$t[,2], Cornell.bootYX$t[,3], cex=.3,  levels=c(.5, .95, .99), robust=TRUE)  rm(Cornell.bootYX)   # PLS balanced bootstrap  set.seed(225) Cornell.bootYX <- bootpls(modpls, sim=\"balanced\", R=250, verbose=FALSE) boot.array(Cornell.bootYX, indices=TRUE) #>        [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] #>   [1,]    5    4    9    2    4   11    5    3    1     5     9     6 #>   [2,]    1   10    4    1    8    3    7    2   11     8     5    11 #>   [3,]    2    6    1    8    4    1   10    5    1    10     5     7 #>   [4,]    7    9    2   12    5    7    6    9    7     7     6     8 #>   [5,]    5   11    3    8    4    4    6    2    7     1     5     5 #>   [6,]    2    6    4   10    9   11    7    8    5    12    12     4 #>   [7,]    6    6   11    2    7    7    9    2    4     8     2    12 #>   [8,]    5    9    9   11   10   10    7    2    3    10     2     6 #>   [9,]    6    2    3    8    2    9    8   10    6     9    11     7 #>  [10,]    5    8    4    4    2   12    4    1   10    12     8    12 #>  [11,]    2    1    4    6   11   10    9   10    7     6     4     6 #>  [12,]    1    1    1    1   10    2    9    1   12     7    10     1 #>  [13,]    1    2   11    9   10    4    1   10    1     7    12     3 #>  [14,]   11    3    1    7    5   12    6    6    9     8     1     7 #>  [15,]    3   11    8    7    1    9    6    1    4     1     4     5 #>  [16,]   10   12   12    8    9    6    3    5    1     2     8    12 #>  [17,]    1    8    7    8    1    3   10    3    7     9     8     9 #>  [18,]    5    1    1    1    5    4    4   11    8     7     3     9 #>  [19,]    2    5    3    2   12    7    4    7   10    11     4    10 #>  [20,]    2    4    2   11   10   10   10    5    7     7     4    12 #>  [21,]    7   10    8    1   12    4   11    7    9    12     2     7 #>  [22,]    5    5   11    6    8    6   12    9    7     9     4     5 #>  [23,]    8   12    6   12    9    8    1    5    1     2    11     4 #>  [24,]    2    2    3    6   10    1    9   11   11     8     2     2 #>  [25,]    4    7   11    7    7    7    1    6    1     5     3    11 #>  [26,]    4   11    8    8    1    2    6    9   10    11     6    10 #>  [27,]    3    4   12    8   11    8    1   10    9     1     3    12 #>  [28,]    6    8    6    6    4    7   10    9    3     7    10     8 #>  [29,]    5    1    2   12   10    9    4    9    8     6    11     8 #>  [30,]   11   12    4    8    8   10    3   10    8     2     2     7 #>  [31,]    6   11    3    7    5   11    3   12    6     5     4    10 #>  [32,]    8    7    8    4    1    7    3    7    1    11     4     6 #>  [33,]    2   11    5    3    2    8   11    9    2     2     6     9 #>  [34,]    6    1    6    4    8    6    6    3    8     2     3     5 #>  [35,]    6    4   10    5   11    7   10   11    4     5     7     4 #>  [36,]    4    8    1   10    4    4    6    7    6     7     2    10 #>  [37,]    9    1    6    4   10    6    8   11   12     2     4     7 #>  [38,]   11    9    6    7    6    3    3   11    7     6     3    11 #>  [39,]    7    4    1    7    3    3    9   12    2     3    10     3 #>  [40,]    6    2    5    1    9    8   10   12    2     3     5     1 #>  [41,]    8   12    1    9    9    8    6    6   12    12     2     9 #>  [42,]    1    3    7   11   10   10   11   11    9     1     2    11 #>  [43,]   11    2   10    9    6    9    1    9    7    10     1     5 #>  [44,]   11    2   12    7   11    1   12    6    9    10     6     5 #>  [45,]    5    4    9    4    9   10    3    6    9    12     9    12 #>  [46,]    8    2    1   11    6    8   10   11   11    12     9     4 #>  [47,]    6    9    5    1    1    6    9    7    1    10     8     5 #>  [48,]    6    5    3    3   12   10   11   12   11     4    11    11 #>  [49,]    1    1    6    1    6   10    5    6   12     6     4     4 #>  [50,]    2    2    1   12   11    2   12    7    5     5     3     9 #>  [51,]    8    8    9    5   10    3    6   12    3     1     5     6 #>  [52,]    4   12    9    9    5   10    9    6    8     8     5    11 #>  [53,]    3    5    1    4    7   12    8    9   12    10    10     6 #>  [54,]    3    5   11    3   11   12    7   11   10     4     9     2 #>  [55,]    5    7    7    6    2    1    9   11    2     9     7    11 #>  [56,]    8    4    2    7    8    1    6    6   11     3     8     2 #>  [57,]   12    5    9    2    6   10    1   12   11     7     5    12 #>  [58,]    1   12    6   12    7    5    2    6    9     1     6    12 #>  [59,]    7    7    6    2    5    3    9    8    5    10     5     5 #>  [60,]    7    5    2    5    4    7    2    8    4     8     6     2 #>  [61,]    8    8    8   12   10    1   10    8   12    11     1     5 #>  [62,]    1    9    9    4    3    4    7    1    1    11     7     6 #>  [63,]    4    7    5    3    6    7    8    8   10    11    10     8 #>  [64,]    2   10   11    6    6    9   11    6   11     3     8     8 #>  [65,]   12    5    6   10   10   12    1    9    6     5     6     7 #>  [66,]   11    9    2   12    5    2    9   11    5     2     6     7 #>  [67,]   10    1    8   12    6   12    9   10   12     7     4     2 #>  [68,]    7    5    8    3    6   12   12    8    3     6    12     1 #>  [69,]    4    4    3    5    4    2    5   12    8     4     1    10 #>  [70,]   10   11   11    8    8    6    1    9    7     8    11    11 #>  [71,]    3    3    1    1   11    1    1    2    4     6     2     8 #>  [72,]   12   12    8    8    8   12    2   10    3    11     5    11 #>  [73,]    7    9    6    5    1   11    8    5    2    11    12     3 #>  [74,]    6    9    1   10    9    3    1    3    1     4     5     4 #>  [75,]    5    5    8    2    8    2    8    4   11     5     3     4 #>  [76,]    8    2    4    9    8   12   10    6    3     4    11     9 #>  [77,]    5    7    9   10    8    9    4    7   12    12    12     8 #>  [78,]    6    9    9    3    7    3    4   12    4     7     3    11 #>  [79,]   12    2   12    3    5   12    8   12    3     8     8    12 #>  [80,]   12    4    7    6    8    5    7    3    8     9    11     3 #>  [81,]    4    5    6    8   10   12   12    7    6    11     1     4 #>  [82,]    8    3   10   11    5    5    4   12   10     2     8     4 #>  [83,]    9    2    2    9   12    9   12   11    5    11     4     8 #>  [84,]    4    7    9    9    1    2   12    7    9     3    11    12 #>  [85,]    9    3   12    2   11    3    3    4    4     7     8     2 #>  [86,]    6    2    2    7   12    3    8   10    2     5    10    10 #>  [87,]    7    5    6    4    8    4    8    8   12     5     1     7 #>  [88,]    5    4   11    4    2    4    4    9    3     1     8    12 #>  [89,]    1    7    5   10    1   11   12    5    8    10     3     3 #>  [90,]    9    2    6    8    4    8    1    1    9     6     2     3 #>  [91,]   12    5    4   12    7    4    8    3    3    11     5     1 #>  [92,]    5   12   10    4    3   11    9   11    3    12     9     1 #>  [93,]    2    9    4    2    7    8    5    1    6    11     4     5 #>  [94,]   10    1    2    7    7    2    9    2    5    12     6    11 #>  [95,]    3    1    9    4    6   11    2   12   12     4     6     4 #>  [96,]    8    9    3    1    1   11    9    3   12    12    11     5 #>  [97,]    9    1    1    5   11    2   11   11    6    11     7     1 #>  [98,]    8   11    4    1    3    5    9    1   10     8     8     2 #>  [99,]    8    6    3    4    7    1    6    6    7     7     2     9 #> [100,]   10    9   10    2   11    7    1    5    9     5     4     6 #> [101,]    5    6    2    3    6    8   10    1   11     4     2     5 #> [102,]    7    6    1    9    1    1   10    8    9    12    11    11 #> [103,]    2    1    7    3   10    5    3    6    8    10     8     6 #> [104,]    1    9    5    4    4   11   10    2    5     2     2     2 #> [105,]    2    1    2    8    7   12    7   10    9     3     9     5 #> [106,]    1    1   12    8    3    6    8    6    3     3     9    10 #> [107,]    3    5   10   10   11    5    8   10   11     1    12     7 #> [108,]    4   12    7   10    1   10   11    1   10    12     3     8 #> [109,]   11   10    3    7   12    4   12   11    6     7     4    10 #> [110,]   11    4    5    2   12    8    7    7   12     8     3     2 #> [111,]    5   11    3   12    9    3    5    6    6    11    10     4 #> [112,]   11    6    6    5    4    1    6   11   11    12    10     9 #> [113,]    9   12    3    9    9    8    3   10   12     5    11    10 #> [114,]   12    8    6    3    2    4    1    1   12     7     7    12 #> [115,]    9    4    3    9   10    7    4    5    2     9     9     8 #> [116,]    4    7    3    4    6    5    4    6   10     5     3    12 #> [117,]    1    8    2   10   11   10   11    1   12    12     1     2 #> [118,]    6    7    3    7    7    8    9   11   12     9    12     5 #> [119,]    3    9    6    5    8    8    2    8   10     4     1     2 #> [120,]    5    9   11    2   10   10    2   10   12     4    11     6 #> [121,]    9    6    9    4    8    2   12   11   12     3     2     4 #> [122,]    9   11    7   11    2    4   12    4    2     4     9     9 #> [123,]    3    1    4    5    9    7   10    3    7     9     7    10 #> [124,]    5    6    9    3    3    4   11   11    8     1     6     6 #> [125,]    6    8    9    7    2    4    7   10    3     5     2     7 #> [126,]    3    7    2    2   11    7   12    6   10    10     7     1 #> [127,]   10    5    8    3   10    1   11    5   10     4     3    11 #> [128,]    9    6    3    4    2    2   10    2    1     2    11     1 #> [129,]    4    9    1    4    3    9   10    3   12     9     2     6 #> [130,]   11   10    9   10    3    6    8   11   12     6     3     5 #> [131,]    4    3   11    9    7   10    5    8    1    12     9     4 #> [132,]   11    1    9    6   10   10    6    5    2     2    11     4 #> [133,]   10    7    9    9   10    6    6    3    8     3     5     6 #> [134,]    3    8    6   10   12    3    4   11    7    10     4    11 #> [135,]    4    1    6    5    2    8   10    5    9    11     2    11 #> [136,]   11    4   11    2   11    8   10    7    7     9     2    12 #> [137,]    5    2   10    4   12    6    7    5    1     1     9     4 #> [138,]    7    7    1    8    3    4    3    2    6     5     7     1 #> [139,]   12    2    8    3    2    2    7   11   11     4     6    10 #> [140,]    3    3    7    6    8    9    4    6    8     4     7     1 #> [141,]    4    2    3   12    9   10   10   10    5     6    12    10 #> [142,]    4    9    8    8    3    3    4   10   10     1     7     7 #> [143,]   12    3   10    9    2    8    8    6   10     7     9    10 #> [144,]    7    3    4    5   11    2   12   12    7    12     6    10 #> [145,]    1    3    6    9   12   12   10   12    8    11     7     4 #> [146,]    7    3   11    3   12    4   10    4   10     2     5     6 #> [147,]   12    3    8    3    5   11    2    6    7     5     3    10 #> [148,]    3   12    6    4    7   12    6   11    4     2     5     3 #> [149,]    8    5   12    2   10    2    7    4    2     8    11     2 #> [150,]   12    6    7    6   12    4   12    9    3    12     4     3 #> [151,]   11    5    5    4    7   10    2   12    9    10     6     2 #> [152,]    9    3    8    2    7    7    1    6    9     3     8     3 #> [153,]    4    2    7    1    5    3    6    6    7     8    11     4 #> [154,]    1    5    7    5    8   12    4    6    6     9     6     9 #> [155,]    4    8    4    1    8    2    6    4    6    10     9     6 #> [156,]    4   11    3   10    3    2    5    2   12    11     1     5 #> [157,]   12    7    1   11    2    6    3    8    3     8    11     7 #> [158,]    2    2    3   11   11   11    3    6    7     9    11     6 #> [159,]    8   11    2   10    1   11   12   11    3     4     2     5 #> [160,]    4   10    1    5   10    1    6   11    1     6     5     2 #> [161,]   11    9    3   11    6   10    2   11    6     7     9     8 #> [162,]   10   11    1    7    2    6   12    8    6     3    10    11 #> [163,]   11   10    7    1    2    3    4    9    8     6     7     7 #> [164,]    9    2   10    8    1    8    3   10    5     4     9     5 #> [165,]    5    1    4    6   10    7    5    6    2     3     2     2 #> [166,]    8   12   10    3    7    7    3    3   11    12     9    12 #> [167,]    4    9    4   11    8    9    4    6    8     4     3    10 #> [168,]    9    5    3    5    2   10   12    7   12    10     4    11 #> [169,]    2    3    2   10    5    8    7    5   12     7     2    10 #> [170,]   10    6   10    8    6   12    6    3    9     6     6     3 #> [171,]    6    5    6    7    7   12    1    9    4     4    12     3 #> [172,]    5   12    5   12    1    8    5    7    7     1     8     8 #> [173,]    9    7    2    2    1    9    8    5    3     5     5     2 #> [174,]   12    2   10    4   10    5   10    7    5    10     1     6 #> [175,]    1    5    1   11   11   12   10    1    3    12     5     1 #> [176,]    4    8   12    4    9    7    4   12    8     4     1     9 #> [177,]    1   10    2    4   11    4    9    4    2     5     9     8 #> [178,]   10    6    6    2    4    6    5    2    1    10     9     8 #> [179,]    9    8    7    7    8    3    1    5   11     9    11     5 #> [180,]    1    9   11    6    2   10    1   11   11     6    12     3 #> [181,]    9    9   10    6    9    6    6    7    2    12     3     5 #> [182,]   12    2    2    9    7    3    7    4   11    10     3     8 #> [183,]    8    2    9    8   12    1    8    9   10     2    10     5 #> [184,]   11    5   12   10   12    9    1   10    2    12    12     5 #> [185,]   10    1   11    4    8    9    5    6    1     8    10     1 #> [186,]    4   12    5    9   12    1    5   12    9     8     4     9 #> [187,]    3    9    9    9    6    5    7    5    8     4     6    10 #> [188,]    1    5    1    1    2    6   11    8   10     1     5     6 #> [189,]    4    6    5    6    4   12    9    8    2     1    12     9 #> [190,]    3    5    2    4   11   10   12    6   10    11     3    12 #> [191,]    7    9    5    4    8   12    3    4   12     3     8    12 #> [192,]    5    3    7    5    2   11    8    9   11     6     6     7 #> [193,]    3   10   10    8    9    5   10    3    6     9     7     4 #> [194,]    8    7    4    2    7    3    9    3    4     9     2     2 #> [195,]    7   12    8    5    4   10    7    1   10     7     1     7 #> [196,]    4   10    3   12   10   12    7    7    9     8     6     2 #> [197,]    9    2    1    7   11    5    2   10    6     5    12     8 #> [198,]    6    2   11   12    2    8   11    1    9     1     8    11 #> [199,]    4    3    1    3   12    2   11    7    6     4     5     7 #> [200,]    9    2    5    5    9    7    2    2    7     3     5     4 #> [201,]    2    1   10   10    8    5    1    2    6    11     9     4 #> [202,]    5    1   12   11    1    8    5    3    4     9     9     2 #> [203,]    6   12    2    6    8    4    3   12    2    12     1     3 #> [204,]   12    8    3    1   10    4    3    3    8     3     3    10 #> [205,]    1    6   12    5   10    2    7    6    3     9     2     2 #> [206,]    7    8    5    7   12    3    4    6    7     3    11    12 #> [207,]    1   10   12    3   12    3   12    4    3    10     9     6 #> [208,]    2   12    9   10   11    7    8   10    7     9     4     7 #> [209,]    6   11    4    7    9   11   11    1    8    11     8     7 #> [210,]    8    1    9    3    7    7    4    4    3     1     8     1 #> [211,]    5    3    1    9   12    6   10    4    5    12     3    11 #> [212,]    2    2    9    8    7    7   10    9    1     5     4     7 #> [213,]   10    1    4    5    1    9    8    6    9     8     3    11 #> [214,]    4    2    6    3   11    3    5    9    4     1     8    12 #> [215,]    4   10    5    4    9    3    8   12    5     1     6     4 #> [216,]    2    3    5    3    1   11    7    5    1    12     2     9 #> [217,]    3   12   11    7   12    9    6   11   10     6     4     8 #> [218,]    8    6    3    2    9    5    8    9    9     2     7     3 #> [219,]    1    7    6   11    3    4    1   11   12    10     2     9 #> [220,]   11   11    3    8   10    9    8    9    9    10     8     6 #> [221,]    7    8    1    7    4    8   10    5    7     2     3     4 #> [222,]   12    2    6    8   11    3    2    2    3     4    10     3 #> [223,]   10    1    4   11    4   12   10    2    9    11    10     3 #> [224,]    3    8    4    5    8    4    1    8   11     9    12     3 #> [225,]    1   12    7    5   12    5    1    8    2    11     7    11 #> [226,]    9    1   11   12   11    1    3   10    1     4     8     8 #> [227,]    1   11    5    4    1   10    5   12    3    10     5    12 #> [228,]   12    1   10   12    9    5   11    4    2     6    11     5 #> [229,]   10    6    2    1   12   11    8   11   11     9     2     5 #> [230,]    5    4    2   11    1   10   11    7    6     3     2     9 #> [231,]    1    1    8    2    6    7    1   12   12    10     4     3 #> [232,]    3    8   10    3    8   10    3    5   10     7     6     6 #> [233,]    7    5    6    2    2    2   12    6    3     4     2     1 #> [234,]    4    3   10   11    8    7    7    6    5     4     4     1 #> [235,]    6    4    2    6    3   11    6    5    4     5    11     7 #> [236,]    5    4    5   11    2    9    7    5   12     5     7    12 #> [237,]    9    4    3   12    3   12    6    1   10     3    11     1 #> [238,]    7    3    5   11    8    5   11    1    5     7     1    10 #> [239,]    1    7    6    3    7    2    7    1    5     2     4     5 #> [240,]   10   11    1    2   12    8   12    4    7     5     1     3 #> [241,]    8    5    9   11   11    1    6    3    4    11     2     2 #> [242,]    5   11   10   10   12   10   12    4    1     9     4     1 #> [243,]   12    3    7    5    5   10    3    6    8    12     1    10 #> [244,]    5    1    6    2   10    9    8    5    9    12     5     9 #> [245,]   10    4    3    6   12   11   11   12    1    12     2     6 #> [246,]    1    3    2   11    7    9    1    5    5     8    12     5 #> [247,]   10    4    8    9   12    7   10   10    1     9     8     2 #> [248,]    5   12    1    7    5   12   10    8    1     7     8     7 #> [249,]    9    7    3    8    8    5    9    7   10     7     1    11 #> [250,]    7    7    6   11   11    2    9    7    9     3     7    10  # Using the boxplots.bootpls function boxplots.bootpls(Cornell.bootYX,indices=2:8)  # Confidence intervals plotting confints.bootpls(Cornell.bootYX,indices=2:8) #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints #>                                                                          #> X1 -0.2192145 -0.03502591 -0.2119416 -0.02617619 -0.2520071 -0.066241725 #> X2 -0.3828012 -0.11801756 -0.4193349 -0.15286851 -0.2645190  0.001947385 #> X3 -0.2154695 -0.03582192 -0.2088689 -0.02820433 -0.2469063 -0.066241725 #> X4 -0.4379789 -0.21238307 -0.4660525 -0.22425891 -0.3620776 -0.120283989 #> X5 -0.2967356  0.13546366 -0.2921161  0.09312255 -0.1699835  0.215255066 #> X6  0.3276202  0.67729268  0.3397828  0.68421162  0.2285681  0.572996919 #> X7 -0.2394465 -0.03754892 -0.2166742 -0.03032279 -0.2564461 -0.070094620 #>                           #> X1 -0.2459524 -0.04831319 #> X2 -0.2918411 -0.11466891 #> X3 -0.2394376 -0.04850420 #> X4 -0.4645601 -0.20487969 #> X5 -0.2196585  0.18011275 #> X6  0.3325666  0.69760910 #> X7 -0.2561586 -0.06959096 #> attr(,\"typeBCa\") #> [1] TRUE plots.confints.bootpls(confints.bootpls(Cornell.bootYX,indices=2:8)) #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints  # Graph similar to the one of Bastien et al. in CSDA 2005 boxplot(as.vector(Cornell.bootYX$t[,-1])~factor(rep(1:7,rep(250,7))),  main=\"Bootstrap distributions of standardised bj (j = 1, ..., 7).\") points(c(1:7),Cornell.bootYX$t0[-1],col=\"red\",pch=19)    library(boot) boot.ci(Cornell.bootYX, conf = c(0.90,0.95), type = c(\"norm\",\"basic\",\"perc\",\"bca\"),  index=2, verbose=FALSE) #> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS #> Based on 250 bootstrap replicates #>  #> CALL :  #> boot.ci(boot.out = Cornell.bootYX, conf = c(0.9, 0.95), type = c(\"norm\",  #>     \"basic\", \"perc\", \"bca\"), index = 2, verbose = FALSE) #>  #> Intervals :  #> Level      Normal              Basic          #> 90%   (-0.2044, -0.0498 )   (-0.1967, -0.0406 )    #> 95%   (-0.2192, -0.0350 )   (-0.2119, -0.0262 )   #>  #> Level     Percentile            BCa           #> 90%   (-0.2376, -0.0815 )   (-0.2216, -0.0718 )    #> 95%   (-0.2520, -0.0662 )   (-0.2460, -0.0483 )   #> Calculations and Intervals on Original Scale #> Some basic intervals may be unstable #> Some percentile intervals may be unstable #> Some BCa intervals may be unstable plot(Cornell.bootYX,index=2)  jack.after.boot(Cornell.bootYX, index=2, useJ=TRUE, nt=3)  plot(Cornell.bootYX,index=2,jack=TRUE)   rm(Cornell.bootYX)  # PLS permutation bootstrap  set.seed(500) Cornell.bootYX <- bootpls(modpls, sim=\"permutation\", R=1000, verbose=FALSE) boot.array(Cornell.bootYX, indices=TRUE) #>         [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] #>    [1,]    7   11    5    2    1   12    4    9   10     6     3     8 #>    [2,]   10    6   12    9    8    2   11    4    7     1     5     3 #>    [3,]    6   12    1    5    2   10   11    3    4     9     8     7 #>    [4,]    5    7    9    4   11    2    6    8   12     1    10     3 #>    [5,]    5    9    7    6   12   10    4   11    8     2     1     3 #>    [6,]    8   12    7   10    1    4    3    2    5     6     9    11 #>    [7,]    1    2    5    6    4    7   12   10    8    11     9     3 #>    [8,]    9    1   12    7    2   11    8    3    5     6    10     4 #>    [9,]    2   10    5    6   11   12    8    1    4     3     7     9 #>   [10,]   10    1    9    7   12    3    4   11    5     8     2     6 #>   [11,]    8    3    6   12   10    7    1    9   11     4     2     5 #>   [12,]    9    2    4    1    3   10    6   12   11     7     5     8 #>   [13,]    5   10    1    3    2   11   12    4    7     8     6     9 #>   [14,]    7    4    3    2    9   12   10   11    8     5     1     6 #>   [15,]    9    5   11    3    4    6    8    2    1     7    10    12 #>   [16,]    3    9    1   12    4    5    6    7   11     2     8    10 #>   [17,]    1    3    8    2    5    6   11   10    4     7    12     9 #>   [18,]    5   12    2   10    4   11    9    3    1     6     7     8 #>   [19,]   12    1    5    4    3    2    6   10    9     7    11     8 #>   [20,]   12   11    6    8    2    5    1    3    7     9     4    10 #>   [21,]    3    4   12    9    7    8   11    6    1     2     5    10 #>   [22,]    4    2    1    5    6   10    7   11    3     8     9    12 #>   [23,]    2    9    5    1   12    3    8   10   11     6     4     7 #>   [24,]    9    5    7    4   12    2    6    1   10    11     3     8 #>   [25,]    5    8    4    1    6   12   10    9   11     2     3     7 #>   [26,]    5    7    8   12    3    2    4   10    6     9    11     1 #>   [27,]    5    8    1   11    6    9    3    2   12     4    10     7 #>   [28,]    3    8   12    4   11   10    2    5    7     6     1     9 #>   [29,]    9    5    7    1    2    4    6   12   10    11     3     8 #>   [30,]    7    3   11    6    2    1    8   12    9     5    10     4 #>   [31,]    9    1    6    2    8    3   12   11    4     5     7    10 #>   [32,]    3    8    7    9    4    6    2   10    1     5    12    11 #>   [33,]    3    4    6    8   12    1    7   10   11     2     9     5 #>   [34,]    9   10   12    8    3    4    6    5    2     1    11     7 #>   [35,]    7    8    6    3   12    4    9    5    2    10    11     1 #>   [36,]    5    9    6   11    7    4   12    8    3     1     2    10 #>   [37,]    9    6    8    3   12   10    4    5   11     1     7     2 #>   [38,]    7    9   12   10    5    6    2    3    1     8    11     4 #>   [39,]    6    1    2   10   11    4    7   12    9     8     5     3 #>   [40,]    6    1    5    9    3    7   10   11    4     2     8    12 #>   [41,]   11    1    4    8    5    9   10   12    7     6     3     2 #>   [42,]    2    3    1   12    8    4    9    6   11     5     7    10 #>   [43,]    4    3    6    5    8   11    2   12   10     7     9     1 #>   [44,]    4    7   11    3   10    5    2    1    6     8     9    12 #>   [45,]    2    1   10    9    3    6    5   12    4     8     7    11 #>   [46,]   12    8   10    7    3   11    4    1    9     6     5     2 #>   [47,]   11    3    7    5    8    4    9    2    1     6    12    10 #>   [48,]   11    5    1    3    2    8    7    4   12     6    10     9 #>   [49,]    2    3    4    8    7    1   11    5   10     9     6    12 #>   [50,]   12   10    5    2    6    3    1    7   11     8     9     4 #>   [51,]    1   10    4    6    5    7    3    8    9     2    12    11 #>   [52,]    6    9    7    2   11    8   12    3    4     1    10     5 #>   [53,]   11    9    8    4    6   12    5    1    7     2    10     3 #>   [54,]   12    9    8    3    4    1   11    6    7     2    10     5 #>   [55,]    4    7    6    3   10   12    2    9    1    11     8     5 #>   [56,]   10    8    4    5    9    7   12    6   11     2     1     3 #>   [57,]    8    5   12    7    9    2    6    1   11     3    10     4 #>   [58,]    9    1    6    5   12   11    7    3   10     4     8     2 #>   [59,]    3    7    4    9    6    2    1   12    5    10     8    11 #>   [60,]   12    7   11    4    8    9   10    6    5     2     1     3 #>   [61,]    9    1    3    7    4    5    8    6   10    11    12     2 #>   [62,]    8    5    2   11   10    1    7    4    6     3     9    12 #>   [63,]    1    7   10    3    4    6   12    8    9     2     5    11 #>   [64,]    6   11    8    7    3    4    5    1    2     9    10    12 #>   [65,]   10    5    4    3    7    6    8   12    1    11     9     2 #>   [66,]   11    7    6   12    3    2    9   10    4     8     1     5 #>   [67,]    5    7    9    2    6    3   12   11    1     8    10     4 #>   [68,]   11    3    8    6   10    4    7    2    1     9    12     5 #>   [69,]    5    7    4   12    2    3   11   10    9     1     8     6 #>   [70,]    1    4    3   12   10    6    5   11    2     8     9     7 #>   [71,]   11    2   12    7    8    1    6   10    4     3     9     5 #>   [72,]    4    5    9    8    7   10   12    2    3    11     6     1 #>   [73,]    8   10   11    5    7    4    9    1    2     6    12     3 #>   [74,]    9    3    5    2    8    4    1    6   12    10    11     7 #>   [75,]   12    2    8    9    7    4    3   10    6     1     5    11 #>   [76,]    4    6    3    1   10    2    8   12    5     9     7    11 #>   [77,]    1    5   11    4    2    6   10    3   12     8     9     7 #>   [78,]    2    3    8   10    7   12    1    6    5     9    11     4 #>   [79,]   11    4    8   10    6   12    5    7    3     1     9     2 #>   [80,]    4    8    3    6    9    1   11    7    2    12     5    10 #>   [81,]    6    9    7   10    3   11    1    8    5     4    12     2 #>   [82,]    4    9   11    1   12    5    7    8    3    10     2     6 #>   [83,]    9    3    1   11    4    6    8    5   12    10     7     2 #>   [84,]    1    2   11    5    9    4    6    8   10     7     3    12 #>   [85,]   12    7    9    5   10    2    4    1   11     8     6     3 #>   [86,]    7   12    3    5    2   11    1    4    6     8    10     9 #>   [87,]    8    1   11   12    2    4    9    6    5    10     7     3 #>   [88,]   10    2    5   12    6    1    3   11    4     9     7     8 #>   [89,]   12    1    4    2    8    5    9    7   11     6    10     3 #>   [90,]    1   12   11    9    6    5    4    2    8    10     7     3 #>   [91,]   11    2    1    7   12    8    3    4   10     5     6     9 #>   [92,]    5    1    8    2    4    6   12   10    9     3     7    11 #>   [93,]    2    3    1    5   10   12    4    9    7     8     6    11 #>   [94,]    6    1    2    5   12   10   11    8    4     7     9     3 #>   [95,]    7    6   12    5   10    4    3    2    1    11     8     9 #>   [96,]    2    3    9   10    7    1    5    6    4    12     8    11 #>   [97,]    8   12    3    4   10    9    2    1   11     7     5     6 #>   [98,]    8    6    2    1    7   10   11    5    9     3    12     4 #>   [99,]   10    8    1    9   11    5    3    7   12     2     6     4 #>  [100,]    4    7    1   10    6   11    3   12    2     5     8     9 #>  [101,]    6    7    9    2   10    8    3   12    1     4     5    11 #>  [102,]    9   12    6    7    3    4   11    1    5     2     8    10 #>  [103,]    2    3   12    1   11    6    5    7   10     8     9     4 #>  [104,]    6    8    7    1   11    4    2   12    3     5    10     9 #>  [105,]   11    9    4    3    8    6    7   10   12     2     1     5 #>  [106,]    5    6   11    2   12    8   10    9    7     4     3     1 #>  [107,]    3    8    4    1   12    2    9    6   11     7     5    10 #>  [108,]    2    8    1   10   12    4    9   11    5     7     6     3 #>  [109,]    7    4    6    2   11    9    1   10    3     8    12     5 #>  [110,]    2   11    1   12    7    4    8    3   10     9     6     5 #>  [111,]    5    7   12    6    2    1    9    3    4     8    10    11 #>  [112,]   10   12    4    9    3    8    1    6   11     5     2     7 #>  [113,]    5    9    7    1   10   11    8   12    3     6     4     2 #>  [114,]    4    2    3    6   10   11    7    8    1    12     5     9 #>  [115,]   12    1    9   11    3    8    6    4    5     7     2    10 #>  [116,]    9    6    4    3   11    5    2    1   12     8    10     7 #>  [117,]    8    9    5    7    1   10   11    3    6     2    12     4 #>  [118,]    3   12    9    2   10    1    5    8    7     4    11     6 #>  [119,]   10    1   12    3    5    8    6    4    9     2    11     7 #>  [120,]    1   11   10    2   12    3    7    5    4     8     9     6 #>  [121,]    8    5    3    7    2    9    4   12   10    11     6     1 #>  [122,]    7    9   10    5   12    6    3   11    8     4     1     2 #>  [123,]    2    8    5    1    3   11   10    7    9     4    12     6 #>  [124,]    8    9    2   11    5    7    6    4    3     1    10    12 #>  [125,]    8   10    1    2    5    7    6    4   12     9    11     3 #>  [126,]    3    5    6    7    2    1   10   12    9    11     4     8 #>  [127,]    4   10    3    1    7   12    5    2    8     9    11     6 #>  [128,]    7    3   10    2    5    8    4   12    9     1    11     6 #>  [129,]    7   10   11    3    1    4    9    2    6    12     8     5 #>  [130,]   12    6    1    2    3    7   11    5    8    10     9     4 #>  [131,]    8    1   11    9    5    7    2   10    3    12     6     4 #>  [132,]    9    5   11    8    3    6   10    2    1    12     7     4 #>  [133,]    8    5    9    7   11    1   10   12    6     2     3     4 #>  [134,]   11    6    9   10    3    8    5    7    2     1     4    12 #>  [135,]    8   11   12    9    3    2   10    1    7     5     4     6 #>  [136,]    9    2   10    4   12    8    6    1    5     3     7    11 #>  [137,]   10    7    9    8    4    3    1   11    6    12     2     5 #>  [138,]   12    2    7   10    5   11    8    6    1     4     3     9 #>  [139,]   11   10    8    3    9    4    2    5    6     7    12     1 #>  [140,]   11    9    4    5    3    6    1    8   12     2     7    10 #>  [141,]    2    6   12    1    3    7    4    5    8     9    10    11 #>  [142,]   12    1    3    8   10   11    5    4    9     7     2     6 #>  [143,]    6    8    1   12    3    7    2    9    5    10     4    11 #>  [144,]   11    1    8   12    5    2    3    9    6    10     7     4 #>  [145,]   10    6    7    9    1    5   11   12    4     8     2     3 #>  [146,]    6    5    8    9    1    4    3   11    7    10     2    12 #>  [147,]    6    2    1    7    8    9   10    5   11     4     3    12 #>  [148,]   10   12    9    3    5    2    8    6    4    11     7     1 #>  [149,]   10    3    4    7    9    8   11    2    6     5     1    12 #>  [150,]    1    9    2    4   10   12   11    8    6     7     5     3 #>  [151,]    4    1    6   11   10    3    8    5    9    12     2     7 #>  [152,]    8    3    2    7    6    4   10    5    1    12    11     9 #>  [153,]    1    2   11   12    6    8    3    4    5    10     9     7 #>  [154,]    1    9    6    5    3    4   10   11    8     2     7    12 #>  [155,]    9    7    5    3    2   12    8    4   11     1    10     6 #>  [156,]   11    8    3    2   10    6    5   12    7     4     1     9 #>  [157,]    4    2   10    5   11    3    7   12    8     6     9     1 #>  [158,]    2   12    4    6   11    1   10    9    8     5     3     7 #>  [159,]    7    8    5    9    4    3    6    1   11    12    10     2 #>  [160,]    2    1    8   11    5    9    7    4   12    10     6     3 #>  [161,]    7    1   12    6    8    9   10    5   11     4     2     3 #>  [162,]   10   11    6    7    2    5    1    3   12     4     9     8 #>  [163,]   12    8    6    1    7    2   11    3    5     4    10     9 #>  [164,]    6    2   12    8    1    5   10    3    7     4     9    11 #>  [165,]    1    3   11   12   10    9    5    4    2     6     8     7 #>  [166,]   12    5    1    2    8    4    9    3    7    10     6    11 #>  [167,]    1    8    5   11    3   12    7    9    2     4    10     6 #>  [168,]   10   11    3    4   12    5    2    7    9     6     1     8 #>  [169,]   11    9    5    1    4   10   12    3    6     2     7     8 #>  [170,]    8   10   12    4    3    2    1    7   11     9     5     6 #>  [171,]    2    5    3    8   10    7    9    4   12    11     6     1 #>  [172,]    8    6    5   11    9   10    1    2    7    12     3     4 #>  [173,]    4   10   12    8    2    9    7    1    5    11     6     3 #>  [174,]   11   10    6    5    3    2    4    7   12     9     1     8 #>  [175,]   12    3   10    5    1   11    8    9    4     7     6     2 #>  [176,]    9    6    7    8   11    3    5   10    2    12     4     1 #>  [177,]    5    8    2    3    6   11   10    9    1     7     4    12 #>  [178,]    5   12    8    3    9    4    1   10   11     6     2     7 #>  [179,]    3   12    6   10    9    8    1   11    2     4     7     5 #>  [180,]    4   12    1    3    8   10   11    5    7     2     9     6 #>  [181,]   11    4    5    6    3    2    1    8   12     9    10     7 #>  [182,]    7   12    3    1    6    2    5   11    8    10     9     4 #>  [183,]    1    4    9    3    5   10   11    7   12     8     6     2 #>  [184,]   12    9    3    5   11    6    8    4    1     7    10     2 #>  [185,]    7    4    6    8    9    5    1   10   11    12     2     3 #>  [186,]    2    9    8   12    1   11    5    3   10     4     7     6 #>  [187,]    2    4   11    5   10    8    7    1    3     9     6    12 #>  [188,]    4    2    9    7    1    8   11    3    5    12     6    10 #>  [189,]    6   11    1    8   10    7    5   12    3     2     9     4 #>  [190,]   12    7   10   11    8    3    4    6    5     9     1     2 #>  [191,]    5    4   11    2   10    1   12    3    9     7     6     8 #>  [192,]    1    8    2    7   10    5    6   11    4     3     9    12 #>  [193,]   10    2    7    5    6   12   11    3    4     9     1     8 #>  [194,]    4    8    5   10   11    6    3   12    7     1     9     2 #>  [195,]    3   12    9   11    2    8   10    6    5     7     1     4 #>  [196,]    8    4   12    2    3    9   10    7    5     6     1    11 #>  [197,]   10    3    5    2    9    4    7   12    6     1     8    11 #>  [198,]    1    6    2   10    9    8    7    4    5    11     3    12 #>  [199,]    3    1   10   11    7    6    2   12    8     5     4     9 #>  [200,]   11    4    3    5    9   10   12    1    6     7     8     2 #>  [201,]    4    8    6   11    2    3    1    9    7    12    10     5 #>  [202,]    7   11    2    5   12    3   10    6    1     4     9     8 #>  [203,]    4    8    6    5   11    9    3    1    2    12    10     7 #>  [204,]    5   10    7    3    9    2    4    8   11     1    12     6 #>  [205,]    8    9   10    5    4   12   11    2    3     6     1     7 #>  [206,]    3   10    9    5    6    8    4    1   11     2    12     7 #>  [207,]    2    7    5    3    9   12    6    1   11    10     8     4 #>  [208,]    1    4   12    2    9    7    8    6    3     5    10    11 #>  [209,]   10    9    6    7   12    1    8    2    3     5    11     4 #>  [210,]    1    9    8   12   11    2    7    6    4    10     3     5 #>  [211,]    1   10    5    7    4    8    2    3    6    12     9    11 #>  [212,]    3    1    4    7   12    2   11   10    6     5     8     9 #>  [213,]    3    9    2   10   12    5    6    8   11     1     4     7 #>  [214,]    4    2    3   12   10   11    1    9    8     6     7     5 #>  [215,]    2    5    3    4    1    6   10    8    9     7    12    11 #>  [216,]    1    2    4   10    9    6    3    5    7    12    11     8 #>  [217,]   11    7    6    1    2    4    9    3    8    10    12     5 #>  [218,]    5    2    3   11    6    1    8   12   10     7     4     9 #>  [219,]    8    2   11    3    6    4   10   12    5     9     7     1 #>  [220,]   12    1   10    2   11    4    7    8    6     9     5     3 #>  [221,]    3    4    9    2    5   11   12    1   10     8     7     6 #>  [222,]    9    5    6    4    2    7    8   11   10     3    12     1 #>  [223,]   11    2    5    9    1    8    3   10    6     7     4    12 #>  [224,]    4    7    9    5   10   12    2    8    1    11     3     6 #>  [225,]   10    3   12    1   11    2    8    7    9     5     4     6 #>  [226,]    7    3    9    1   10    6    5    2    8     4    11    12 #>  [227,]    8    3    2    5    4   11    1    9   12     6    10     7 #>  [228,]    8    3    5    9    4   11    2   12    1     6    10     7 #>  [229,]   10    4    5    2    8    1    3   12    6    11     9     7 #>  [230,]    2   11    6    1    4   12    3    8   10     7     9     5 #>  [231,]    2    9    4    8    1    3    6   12    5     7    10    11 #>  [232,]   12    2    3    7    1   10    8    4    6     5    11     9 #>  [233,]    5   11    6    4    7   12   10    1    8     9     2     3 #>  [234,]   10    1    6    4    3    8   11    7    5     2    12     9 #>  [235,]    6    3    7    8   12    2    5    4    1    10     9    11 #>  [236,]   11    5    4    6    7    1    9    2   12     8     3    10 #>  [237,]    6    5    4    2    7   12    8    1   11     9     3    10 #>  [238,]   10    4    6   12    7    1    3   11    5     8     9     2 #>  [239,]   12    2    7    3    8    9    6    5    4    11    10     1 #>  [240,]    2    3    9    5    4   10   12    6    1     8     7    11 #>  [241,]    7    1    4    8   11    6    5    9   12     3    10     2 #>  [242,]    1   11   10    4    5   12    2    3    8     7     6     9 #>  [243,]    3    6    7    2    1    9   12    5   11    10     8     4 #>  [244,]    8    2    4    9    5    3    6   12   11    10     7     1 #>  [245,]    9   10    1    5    8    4   12    6    3     2     7    11 #>  [246,]   11   12    3   10    6    9    1    2    5     4     8     7 #>  [247,]    9    1    6    8   11    7    2    5   12    10     4     3 #>  [248,]   12    9   11    2    7   10    1    4    3     5     8     6 #>  [249,]    5    6    8   12    1    3   10    9   11     7     4     2 #>  [250,]    7    5    4    1   11    6   10    2    9     8    12     3 #>  [251,]   11   12    6    8    7    3    9    1    2     4     5    10 #>  [252,]    9    1    4    2    8    5    3   10    7     6    11    12 #>  [253,]   11    1    3    7   10    8    9    6   12     4     2     5 #>  [254,]    3    8    5   12    6    1    2   11    9    10     4     7 #>  [255,]    3    8   10   11    9    4    2    6   12     7     1     5 #>  [256,]    4    1   12   10   11    5    7    2    9     3     6     8 #>  [257,]    6    9    1    2    7    8   11    3    4     5    12    10 #>  [258,]   10    4    7    2   12    5    1    8   11     3     6     9 #>  [259,]   12    1    9   10    8    3    7    4    6     2    11     5 #>  [260,]   10    9    1    7    5    4    8    3    6     2    12    11 #>  [261,]    2    3   12    9    5    1    4    7   10     6     8    11 #>  [262,]    6    5    9   10   12    2    7    3    8    11     4     1 #>  [263,]    8   12   10   11    1    2    5    6    4     3     7     9 #>  [264,]    9    1    6    7    3    8    2    4    5    10    12    11 #>  [265,]    8    4   10   12    5   11    3    6    2     7     1     9 #>  [266,]    4   11    9   10    3    2    5    8    7     6    12     1 #>  [267,]    3   12    8   10    9    2    6    1    4     5    11     7 #>  [268,]    4   10   11    7    1    2   12    9    3     5     6     8 #>  [269,]   10    3    1    6   11    2   12    9    8     4     7     5 #>  [270,]    4   12    6    1   11    2    8    7   10     3     5     9 #>  [271,]    2    6    1   12    9   10   11    3    8     4     7     5 #>  [272,]    6    4   10    2   12    1    7    3    8    11     5     9 #>  [273,]    4   11    5    1   12    6    9    8    2     3     7    10 #>  [274,]    8   12    6    5    3    7   11    2    1    10     9     4 #>  [275,]    1    8    7   12    9    4    6    2   10     5     3    11 #>  [276,]   12    5    7   11    2   10    4    8    3     9     1     6 #>  [277,]    4    5    1    9    7    2   11   10   12     3     6     8 #>  [278,]    1   10    3    2    6   12    8    9    4    11     5     7 #>  [279,]   10    1    9    5    3   11    6   12    2     8     7     4 #>  [280,]    6   10   12    4    2    9   11    5    1     3     8     7 #>  [281,]    9    4    3   12    5    1    8    6    2     7    10    11 #>  [282,]    2   11   10   12    9    8    7    1    5     6     4     3 #>  [283,]    8    3    6    1    4    5    2    9   11    10     7    12 #>  [284,]    1   11    4    2   12    5   10    8    7     3     9     6 #>  [285,]   12    1   10    6    2    8    4    3    7    11     9     5 #>  [286,]   10    1    6    2    7    3   12    9    5    11     8     4 #>  [287,]    5    1   11    4   12    8    9    2    6     7    10     3 #>  [288,]    2    4    5   10    9    3    1   11    8     6     7    12 #>  [289,]    2   10    3    6    5    7    1    9   11     8    12     4 #>  [290,]   11    6    3    8   10    7    4    9    2    12     5     1 #>  [291,]   10   11    3    7    1    4    2   12    5     6     8     9 #>  [292,]    8    7    4    1    3   11    5    9   10     6    12     2 #>  [293,]    6   10    3   11    9    2    8    7    1     4    12     5 #>  [294,]   10   12    3    2    9    4   11    7    8     1     6     5 #>  [295,]    2    3    1   12    6   10    7   11    9     8     5     4 #>  [296,]    5    2    6    7   10    4   11    9    8    12     1     3 #>  [297,]    4    6    3   11    9    8    7    1   12     2     5    10 #>  [298,]    5   10    8   12    2    7    1    3    6    11     4     9 #>  [299,]    9    7    2    6   10   11    1    3    5     8     4    12 #>  [300,]    2    9   12    5    4    6    8    3    7    11    10     1 #>  [301,]    4    5    9   10    2   12    1    8    6    11     3     7 #>  [302,]    5    7   10   12   11    3    4    9    6     8     2     1 #>  [303,]    8   12   10    4    5    9    6    1    7     3     2    11 #>  [304,]    7    3    2   11    9   12    5    6   10     4     8     1 #>  [305,]    1   12    6    8    4    5   11    9    3     7     2    10 #>  [306,]   12    3    8    4    9    1    5    6   10     2     7    11 #>  [307,]   10    1    7    6    3    4    9    2   12     8     5    11 #>  [308,]    6    7    2   11   10    4    3    5    1    12     9     8 #>  [309,]    1    8   12    7    9    5    6    3    4    10     2    11 #>  [310,]    1    2   10    7    8    4   12    3    5    11     9     6 #>  [311,]    6   12   11    5    8    3    1    4    7     2     9    10 #>  [312,]    5   11    7    4   12    2    8    9    1     6    10     3 #>  [313,]    6   10   11   12    9    7    4    5    3     1     2     8 #>  [314,]    3    6    8   10   11    9    2    5    4    12     1     7 #>  [315,]    8    6   11   10    3    7    4    9    2     5    12     1 #>  [316,]    2    3    1    5   10    8    6    7    9    11     4    12 #>  [317,]   11    7    6   12    2    5    1    8    9     3    10     4 #>  [318,]    5   12    8   10    6    4   11    7    3     1     9     2 #>  [319,]    6    5    9    4    2   10    8    7    3     1    12    11 #>  [320,]    2   11    6    4    7    5   12    8    1    10     3     9 #>  [321,]    2    6   10    8    3    5    9   11    1     4    12     7 #>  [322,]    9    1   11    2    6    4    8    3   12    10     7     5 #>  [323,]    2    6    3    1    5    8   11   12    4    10     7     9 #>  [324,]    3    2    6    9    5   11   10    8    4     7    12     1 #>  [325,]    3    6    1   11    7    8    5    4   12     9    10     2 #>  [326,]    1    2    6   12    4    5    8   10   11     9     3     7 #>  [327,]   12   10    4    3    2    7    5    6   11     9     8     1 #>  [328,]    9    2    3    5    7    6    4   11   10     1     8    12 #>  [329,]    2    8    1    7    3    9    5   12   10     4     6    11 #>  [330,]    3    6    1   12    2    4    7    8    5    11     9    10 #>  [331,]    9    2   11   10    6    1    4   12    7     3     8     5 #>  [332,]   11    2    8   12    7    5    1   10    6     9     3     4 #>  [333,]   10    2    6    3   12    8    5    4    1    11     7     9 #>  [334,]    7   10    5   11    4   12    1    8    6     3     2     9 #>  [335,]    6   12    3    1    8    4   11   10    2     5     9     7 #>  [336,]   11    4    7    8   12    6   10    9    5     3     1     2 #>  [337,]   10   12    6    5   11    7    4    8    2     3     9     1 #>  [338,]    4    5   10    2    8   11   12    7    9     1     6     3 #>  [339,]    4    1    5    8    7    9    6   12    2    10     3    11 #>  [340,]    4   10    5   11    3    1    2    7    6     9     8    12 #>  [341,]    5   10   12    1   11    6    9    4    2     7     3     8 #>  [342,]    6    8    3    5    1    4   12   10    9     2    11     7 #>  [343,]    7    8    9    4    6    2   11    1   12     5    10     3 #>  [344,]    7    9   10    6    8    2   11    4    5    12     1     3 #>  [345,]    6    7    3    9    2   12   10   11    1     5     4     8 #>  [346,]    6    1    4    5    3    2    8   10    7    12     9    11 #>  [347,]    4    6    2    7    8    9   10   12    1    11     3     5 #>  [348,]    3    8    6    4    5    9    7   11    2    10    12     1 #>  [349,]    5    2    4   12    9    7    3    8    1    11    10     6 #>  [350,]    7    9   12   11    3    2    6    8    5     4     1    10 #>  [351,]    9    4   10    1    6    8    5    3    7     2    12    11 #>  [352,]    7   11    4    8    3    5    1    9    6    10    12     2 #>  [353,]   12    5    3   10    1   11    9    7    2     4     8     6 #>  [354,]    3    1    5    9    8    6    4   12   11     2    10     7 #>  [355,]    8    4    5    3   11   12    7    2    1    10     9     6 #>  [356,]    6    4   10   11    7    5    1    2    9     8     3    12 #>  [357,]    2   10   11    6    8    5    1    9   12     7     4     3 #>  [358,]    5   12    2   10    7    4    8    6    9     1     3    11 #>  [359,]    7    9    6    3   10    4    1    8    5    12     2    11 #>  [360,]   11    9   12   10    4    3    5    6    7     8     1     2 #>  [361,]   11    9    8   12    5    4    1    2   10     3     7     6 #>  [362,]    7    3   11    9    4   10    2    5    8     6     1    12 #>  [363,]   11    6   10    1    4    2    9    3    5     7     8    12 #>  [364,]    9    7    2    4    5   12   10    8   11     3     6     1 #>  [365,]    2    9   11    5    8    3    6    4    1    12     7    10 #>  [366,]    5    7    9    4   12    3    1   11   10     8     6     2 #>  [367,]    7    6    1   11    4    8    9    5   12     2    10     3 #>  [368,]    7    2    9    6    8   11    3   10    5    12     1     4 #>  [369,]    7    1    8    2   12    4    6   11    5    10     3     9 #>  [370,]    9    7    6    8   12   10    2    5    3    11     1     4 #>  [371,]    4    6    2    7   10   11   12    3    9     5     1     8 #>  [372,]   11    4    3    1    5    7    2   12   10     8     6     9 #>  [373,]    2    7    1   11   10   12    8    6    5     4     3     9 #>  [374,]    9    2    1   12    4    3    7   11    5     6    10     8 #>  [375,]    7    8    5    9    2   10   12    3   11     1     4     6 #>  [376,]    8    3    4    1    6    2   10    7    5    11     9    12 #>  [377,]   10    3    4    6   11    2    8    7    1     5    12     9 #>  [378,]   10    3    8    2    5    4    9   12    6     7    11     1 #>  [379,]    8    4   12    2    5    3    6    1    9     7    10    11 #>  [380,]    4    6   11    7    8    2   10    5    1     3     9    12 #>  [381,]    6   11    2    5    3   12    4    8   10     7     1     9 #>  [382,]   12   11    5    3    8    6    2    9    4     1    10     7 #>  [383,]    5    8    9   11    3   12    6    1    7     2    10     4 #>  [384,]    3    4   11    7    9   12    6    1    8    10     5     2 #>  [385,]   10   11    3    7    2    4    6    5    8     1     9    12 #>  [386,]    3    2   11    1    6    5   12    7    9     4    10     8 #>  [387,]   12   11    4    9    2    6    5    3    8    10     1     7 #>  [388,]    6    7    3    9    2    4    1    8   12     5    11    10 #>  [389,]    9    8    2    3    5   11    4    7   10     6     1    12 #>  [390,]   10    7    4    9    2    1    6    8    3    11    12     5 #>  [391,]    6    4   10    9   11    5    3    2    1     7    12     8 #>  [392,]    6   12    9    1   10    7    4    5    3    11     8     2 #>  [393,]    3    8    9    5    6   10    2    1   12     7     4    11 #>  [394,]    7    2   12    5   11   10    9    1    4     8     3     6 #>  [395,]   11    4    8   12    9   10    1    3    6     5     2     7 #>  [396,]    6    1    4   10   12    2    5   11    7     8     3     9 #>  [397,]    8    4    2    5    9    3   10    6    1    11    12     7 #>  [398,]   12    1   11   10    6    4    2    8    5     3     9     7 #>  [399,]    1    3    7    4    6   10    9    2   11     5     8    12 #>  [400,]    4   12    7    6    2   11    5    9    1    10     8     3 #>  [401,]   12    6    4    5    3    1    2    7   11    10     8     9 #>  [402,]    8    4    3   12    5    1   11    7   10     2     6     9 #>  [403,]    6    2    5   10   11    8    3    7    1     9     4    12 #>  [404,]    4    3    1   10    6    7    9    5    8    11     2    12 #>  [405,]   12    6    8    3    9    7   11    1   10     4     2     5 #>  [406,]    6   12    8    2   11    7    5    9    1    10     3     4 #>  [407,]   11    8    2    9   10    1    6   12    7     3     5     4 #>  [408,]    3   10   11    1    4    6    7    2    8     5    12     9 #>  [409,]    1   12    3    8   11   10    2    9    4     6     7     5 #>  [410,]   11    9    1    7    2    5    8    3    6    10     4    12 #>  [411,]   11    5    2    3    8   10    7    6   12     1     4     9 #>  [412,]   12    5    3    9    8   10    1    4    2    11     6     7 #>  [413,]    6   12    1    5   10    7    3    8    4    11     2     9 #>  [414,]    3   11    7    8    2    5    9    1   10     6    12     4 #>  [415,]    6   11    1    2    7   10    5    8    9     3    12     4 #>  [416,]   11    9    3    2   10    1    8    7    4    12     6     5 #>  [417,]    6    4   12    1    9    7    2    5    3    10    11     8 #>  [418,]    5    8    2    7   11   12    3   10    6     9     1     4 #>  [419,]    9    5    8    7   12   11    6    1    2     4     3    10 #>  [420,]   12    9   10    3    1    6    4    7   11     8     5     2 #>  [421,]   11    8   12    6    3    1    7    5    4     9     2    10 #>  [422,]    3   10    8   12    4    2    6    5    9     1     7    11 #>  [423,]    2    6   12    3    5   11   10    9    7     8     1     4 #>  [424,]    7    1   10   11    3    5    2    9    6     4    12     8 #>  [425,]    5   12    9   11    4    3   10    2    8     7     6     1 #>  [426,]    4    7   12    3    8    1    5    6   10     9    11     2 #>  [427,]    1   12   11    5    4    7   10    8    6     2     9     3 #>  [428,]    3    2    5   11    4   12    8    9    7     1    10     6 #>  [429,]    2   11    5    4    1    3    7    8   12    10     6     9 #>  [430,]    8    6    5    4    2    7   11   10   12     3     1     9 #>  [431,]   10    6    5    4   11    9    3    7    2     1    12     8 #>  [432,]    9    4    7   10    1    5    2    8    3    11     6    12 #>  [433,]    3    1    2    6   12    8   10    7   11     5     4     9 #>  [434,]    3   12   10    7    8    6    2    9   11     5     1     4 #>  [435,]    1    8    2   12    7   11    5   10    6     9     4     3 #>  [436,]   12    1    4    3    5   11    2    7    8    10     6     9 #>  [437,]    4    1    7    9   12    2    3    8    5    11     6    10 #>  [438,]    3    6   12    2    9    1    5    7    4     8    11    10 #>  [439,]   12   10    9    6    3    1    4    7    5     2     8    11 #>  [440,]    9    1    5    2    4    7    8   10   12     3    11     6 #>  [441,]    9    8    3   10    4    5    2    7    6    11    12     1 #>  [442,]    9    4    3    1    8   12   10    6    2     5     7    11 #>  [443,]    2   11    3    4    8    9    6   10    5     1     7    12 #>  [444,]    9    7   11   12    5    3    1    8    6     4    10     2 #>  [445,]    3    4   12   11    9    6    7   10    5     1     8     2 #>  [446,]    5   10    8    7    1    3   12    4    9     2    11     6 #>  [447,]    8    6    9   10    3    7    1    2    4    12     5    11 #>  [448,]    7    1    3   10    8    9    4    6    5    12    11     2 #>  [449,]    7    5    6    2   10   12   11    4    9     1     8     3 #>  [450,]    5    8    6    7    4    9    2   12   11    10     3     1 #>  [451,]    8    5    3    1    6    9    7   10    4    12    11     2 #>  [452,]    6    4   10   12    1    9    8   11    5     7     3     2 #>  [453,]    2   10    9    3   11    4    7    5   12     1     8     6 #>  [454,]    5    6    7    4   10    8    2    3   12    11     1     9 #>  [455,]   12    9   10    8    5    6    7    4    1     3    11     2 #>  [456,]    1    8   10    9   12    5    4   11    2     3     7     6 #>  [457,]    5   10   11    1   12    9    2    4    8     7     3     6 #>  [458,]    6    1    8   12    9    2   11    7    3     4     5    10 #>  [459,]    7   12    9    4    3    5    1    6   11    10     2     8 #>  [460,]    1    9    7   12    5    3    8    2    6    10    11     4 #>  [461,]    2    3   10    9    5    8   12    1    6     7    11     4 #>  [462,]   11    7    9   10    5    4    1   12    3     8     2     6 #>  [463,]    5    1   11   10   12    9    6    2    4     8     7     3 #>  [464,]   10    1    5    3    6    9   12    2   11     7     4     8 #>  [465,]   10    2    8    4    9    3    1    5    6    11    12     7 #>  [466,]    7    5    3    6    2   10   12    1    8    11     4     9 #>  [467,]    9   11    4    1    5   12    2    7    3    10     8     6 #>  [468,]    6    9    4    3   12    7    1    8    5     2    10    11 #>  [469,]    9    1   10    6    8    5   12    7    3     2    11     4 #>  [470,]    3   11   12    6    1    4   10    9    5     2     7     8 #>  [471,]    4   10    5    6   11    1    8    3    9     7     2    12 #>  [472,]   12    5    4    6   10    8    9    7    1     2     3    11 #>  [473,]    1    2    5    7    9   10    6    3   12     8    11     4 #>  [474,]    2   12    3   11    1    5    8    4    6     7     9    10 #>  [475,]    4    5    6    1    9    2   10    7   12    11     8     3 #>  [476,]    7   12    2    8    9    6    1    5    4    10    11     3 #>  [477,]    9    5    1   12    7   10   11    4    2     8     6     3 #>  [478,]    8    7    6   12    4    5    2    3   10    11     9     1 #>  [479,]    4    6    3    1   12   10   11    8    7     2     9     5 #>  [480,]    8    1   11   12    7    3    6    5   10     4     2     9 #>  [481,]   10   12    8    4    5    3   11    2    7     6     1     9 #>  [482,]    6   10    9    2   12    7   11    4    3     1     8     5 #>  [483,]    7    5   11    3    8    1   12    4    6    10     9     2 #>  [484,]    4    5    3    2   10    7    9    6   11    12     1     8 #>  [485,]   11   10    1    6    2    5    7    3    8     4    12     9 #>  [486,]    5    6    3   11   10    8    4    7    2     9    12     1 #>  [487,]   10   12    3    6    1    5    7    9   11     4     8     2 #>  [488,]    1    4   10    2    6    5    8   12    7     3     9    11 #>  [489,]    2    6   11    3   12    7    5    9    8     4    10     1 #>  [490,]    8    6    1    7   12    9    2    3   11     4    10     5 #>  [491,]    5    9    6    8   11    7    1   10    3    12     2     4 #>  [492,]    2    8    5    4    3    6    9    1   11    10     7    12 #>  [493,]    5   11    2    7    9    3    6   12   10     4     8     1 #>  [494,]    4    1    7   11    8    3    5    9   10     6    12     2 #>  [495,]    1   10    9    3    7    8    5   11    6     4    12     2 #>  [496,]    8    7    2    6    3    9    4   10    1    11     5    12 #>  [497,]    7   10    9    6    1    8   11    3   12     4     2     5 #>  [498,]    6   11    4    1    7    3   10    9    2    12     8     5 #>  [499,]   12    9   10    5    4    2    3   11    7     6     1     8 #>  [500,]    4    1    8   11    5    3    9    7   12     2    10     6 #>  [501,]    2   11    8   12    3    5    6    4    1    10     7     9 #>  [502,]    9   12    5    2    6    1   10    4    8     7     3    11 #>  [503,]    6    1    3    4   10    8   11    9   12     2     5     7 #>  [504,]    1   11    2   12    3    5    4    8   10     9     7     6 #>  [505,]    3    5    6    2    1   12   10    7   11     9     8     4 #>  [506,]    8    6    9    4   10   11    2    5    3    12     7     1 #>  [507,]    8    9    7    4   11    5   12    2    1    10     6     3 #>  [508,]   10    1    3    2    9   12    5    7   11     4     8     6 #>  [509,]    2    6    3   11    8    5   10    7   12     4     9     1 #>  [510,]   11    4   12    2    5    8    9    3    6     1    10     7 #>  [511,]    2    8    6    7   12    4   10    5    3     9     1    11 #>  [512,]    7   11    4    6    5   10    3    2    8     9     1    12 #>  [513,]    8    9    1    5    4    6    7   10    3     2    12    11 #>  [514,]    7   11    5    1    8    6   10   12    2     4     9     3 #>  [515,]    3    2    7    1    4    8   11    5    9    12     6    10 #>  [516,]   10    9    2    7    5    1   12    3    4    11     6     8 #>  [517,]    4    8    9   10   12    1    6   11    3     2     5     7 #>  [518,]    2    9   12    3   10    4    6   11    5     8     1     7 #>  [519,]    9    5   10   11    1    7    3    2   12     8     6     4 #>  [520,]    8    6    7   10   11    2    5    4    3     1    12     9 #>  [521,]    1    9   11   12    7    4    5    2   10     3     6     8 #>  [522,]    9    7    4   11    8    3    5    2   12     6    10     1 #>  [523,]   11    4    2    5   10    9    6   12    1     7     3     8 #>  [524,]    4   11   10    6    7    2    8    9    5     3     1    12 #>  [525,]   10    9   12    4    7    6    1    2    8     3    11     5 #>  [526,]    2   11    7    8    3    5    4    1   10     9    12     6 #>  [527,]   11    9    5    2    7    8   12    4    3     1     6    10 #>  [528,]    9    4    3    7    1   10   12    8    2    11     6     5 #>  [529,]    7    3    1   11    2    8   12    4    9     5    10     6 #>  [530,]    8    5    9   12    3   11    4    7    1     2     6    10 #>  [531,]    7    2   11    6    3    4    5   10    9     1    12     8 #>  [532,]    1   10    7    2    6   12   11    8    3     5     9     4 #>  [533,]    9   12    3   11    7    5    8    2    6     1     4    10 #>  [534,]    3    5    7    1    9    4    8   12   10     6     2    11 #>  [535,]   10    5    8    1    2    7    6    4    9     3    12    11 #>  [536,]    8    5   10    7   11    4    1   12    9     6     2     3 #>  [537,]    5    9    8    7   12    4   11   10    3     2     1     6 #>  [538,]    6    7   12    5   11    3    9    4    2    10     1     8 #>  [539,]    7    6   10    5   11    1    4    3    2     9    12     8 #>  [540,]   11   12    8    2    1    5    9    3    4     6    10     7 #>  [541,]   12    6    7   11    4    5    1    2   10     9     8     3 #>  [542,]    2   10   11    9    6    1    5    4    8    12     7     3 #>  [543,]    2    3    6   11    4   12    5    8    7     1    10     9 #>  [544,]   10    4    6    8    2    9    3    5    1    12     7    11 #>  [545,]    2    5    9    7    4    3   12    1    8    11     6    10 #>  [546,]    6    8    1    7   10    2   12   11    5     3     4     9 #>  [547,]    5   11    1    8    3    6    9    7   10     4    12     2 #>  [548,]   11    4    2    8   10    9    7   12    5     1     6     3 #>  [549,]   12    4    2    8   10    6    1    3    9     5     7    11 #>  [550,]    3   10    6    9    1   12   11    4    5     2     7     8 #>  [551,]    5    4   10    2    1   12    3    7    8     6     9    11 #>  [552,]    9    1    6   10    7    3    8    4    5    12     2    11 #>  [553,]    5    4   10    1    6    7   11    8    9    12     3     2 #>  [554,]    2    6    5    8    7   11    4    1    9     3    12    10 #>  [555,]    3   12    5    7    1    8    9   10    2    11     6     4 #>  [556,]    6    3   11    9    5    1   12   10    4     2     7     8 #>  [557,]    3   11   10    2    6   12    4    5    7     8     9     1 #>  [558,]    8   11    1    2    3   10    6    7    9    12     4     5 #>  [559,]   11    5    7    9    6   12    1   10    8     4     3     2 #>  [560,]    2   11    3   12    5    4    7    6    8     9     1    10 #>  [561,]    2    4   11   10    1    5    6   12    8     3     7     9 #>  [562,]   12    6   10    9    8   11    2    1    5     7     4     3 #>  [563,]   10    4    3   11    5    1    7    2    6     8    12     9 #>  [564,]    7   12    6    2    9    1    4    8    3    11    10     5 #>  [565,]    6   12    9    3    8    5    4   10    1    11     7     2 #>  [566,]    3    9    8    1   10    4    5    7   11     6    12     2 #>  [567,]    8    1    2    9    7    3    6    5   11    12     4    10 #>  [568,]    6   11    4    9    7    2   12    8    1     3    10     5 #>  [569,]    2    9   12    4   11    5    7    3    1     8     6    10 #>  [570,]    4    6   10    8    9    5   12    7    3     2     1    11 #>  [571,]    9   11   10    5    3    2    1    8   12     4     6     7 #>  [572,]    7    9   10   11   12    6    5    1    4     3     2     8 #>  [573,]   10    8   12    9    6    5   11    2    4     3     1     7 #>  [574,]   11    8    1    3    6    9    5    2   12    10     4     7 #>  [575,]   12    9    3    6   11    4    8    1    5     7     2    10 #>  [576,]    1    6   12    7    8    9    2    4    5    10    11     3 #>  [577,]    8    9    5   11    6    2    7    4    3    12     1    10 #>  [578,]    1    3    5    9    6   10    8    2   11    12     7     4 #>  [579,]    7    4    8    5   10    2   12   11    1     3     9     6 #>  [580,]   10    1    8   11    4    3    7   12    2     6     5     9 #>  [581,]    8    5    1    4    6   12    3    2   10    11     7     9 #>  [582,]    9    1    4   12    7    3    2    5   11    10     6     8 #>  [583,]    8    2    4   12    7    6    9    3   10    11     5     1 #>  [584,]    5    8    7    1    9    6    4    3   12    11     2    10 #>  [585,]    6   10   12   11    4    9    7    8    2     5     3     1 #>  [586,]    1    3   12    2    5   11    6    8    7     9    10     4 #>  [587,]    1    2    3    5    6    8   10   12    4     7    11     9 #>  [588,]    3    4    7    9   12    8    2   11    1    10     6     5 #>  [589,]    7    8   12   10   11    5    3    6    2     1     9     4 #>  [590,]   11   10    1    2    8    3    5    4   12     7     6     9 #>  [591,]    4    6   12    3    9    8    1    7   10    11     5     2 #>  [592,]    7    8    6    9    4    2   11   12    1     5     3    10 #>  [593,]    3   11    7    4    1    6    2   10    9    12     8     5 #>  [594,]    4   11    3    8    2    5    6    7    9    10     1    12 #>  [595,]   11    5    8   10    6    7   12    4    2     9     3     1 #>  [596,]   11    9    6   10    3   12    4    7    5     8     1     2 #>  [597,]    5   12    1    8   10   11    2    7    6     9     4     3 #>  [598,]   12    7    9   10    4    5    2    3   11     6     1     8 #>  [599,]    9    1    2    6   10    8   11   12    3     4     7     5 #>  [600,]   10    4    3    6    5    9    1    7    2    12    11     8 #>  [601,]    5    8   11    4    1   10    9    2   12     7     3     6 #>  [602,]    5   12   11    3    2    7    1    9    8    10     4     6 #>  [603,]   12    3    1    6   11    2    5    4    8    10     7     9 #>  [604,]    2   12   11    8    7    6    1    5    4     3    10     9 #>  [605,]    2    3    8    5   11    6    9   10    7    12     1     4 #>  [606,]    9    2   10   12    3    6    5    8    4     7    11     1 #>  [607,]   12    2    3    8    5    7   11   10    4     1     9     6 #>  [608,]   10   11    8    3    7    9    2    4    1    12     5     6 #>  [609,]   12   10    4    8    5    9   11    6    7     1     2     3 #>  [610,]   12    5    6    7    4   11    1   10    3     9     8     2 #>  [611,]    1   11    4    7    3   10    2   12    5     9     8     6 #>  [612,]    1    5   11    4   12   10    8    3    2     9     6     7 #>  [613,]    4    6   11    5    9    8    7   12    1    10     2     3 #>  [614,]    8    5   12   11   10    2    9    6    3     1     7     4 #>  [615,]    4    3   11    7    2   12    6    5    1    10     9     8 #>  [616,]   10    9    4   11    6    3    8    2    1    12     5     7 #>  [617,]    9   11   12    8    2    1    5   10    6     3     7     4 #>  [618,]    6    5    9    3    4    1    7   11   10    12     8     2 #>  [619,]    2   10   11    5    4    6    7    8   12     9     1     3 #>  [620,]    5    6   11    9    2   12   10    7    1     3     8     4 #>  [621,]    1    6    3   10   12    9   11    8    7     2     4     5 #>  [622,]    5    9    4   11   12    2    8    6    7     3     1    10 #>  [623,]    4    6    5    8    2   12    9    1    3     7    11    10 #>  [624,]    1    5    3    6   10   11    7    8   12     2     4     9 #>  [625,]    3    4   10    1    2    8    7    6    5    12     9    11 #>  [626,]    5   12    3    9   10    2    1    7    8    11     6     4 #>  [627,]   10    6   12   11    7    3    2    5    8     9     4     1 #>  [628,]    3    1    6   10    8    9   11   12    7     2     5     4 #>  [629,]    1    5    2    7    3   10    6   11    9     8    12     4 #>  [630,]   10    3    4   12    5    2    8    1    7    11     6     9 #>  [631,]    2   11   12    3    8    9   10    6    4     5     1     7 #>  [632,]   12   11    1   10    5    7    3    2    6     9     4     8 #>  [633,]   10    2   12    8   11    7    6    9    1     4     5     3 #>  [634,]    8    1    3    2    9   12    4   10   11     7     6     5 #>  [635,]    8    3    2   10    5    9   12    4    1     6    11     7 #>  [636,]    2   10    1    4   11    9   12    3    5     8     6     7 #>  [637,]    7   10    2    3    5   12    8    9    4     6     1    11 #>  [638,]    7   12    5   10    8    2    4    1    6     3     9    11 #>  [639,]    5    6   10    1    8   12   11    4    9     7     2     3 #>  [640,]    9    2    6   12    1    8   10   11    7     4     5     3 #>  [641,]    6    4    7    5   10   11    2    1   12     8     3     9 #>  [642,]    4    2    8    6    1   10    5   12   11     3     7     9 #>  [643,]    6    3   12   11    8    4    7    5   10     9     2     1 #>  [644,]    8   10   11    3    6    5    7    2    9    12     1     4 #>  [645,]    2   12    7   11    1    8   10    5    3     9     6     4 #>  [646,]    5    8   12    4   10    9    7    1    6    11     2     3 #>  [647,]    7   11   12    9    2    1    8    4    6     3    10     5 #>  [648,]   11    6    4    9    5    7    3    1   12     8    10     2 #>  [649,]    1    8    9   11    7   10    3    5   12     6     2     4 #>  [650,]    9    1   11    6   12    3   10    8    7     2     5     4 #>  [651,]    1   12    5    4   11    2    8    3   10     6     7     9 #>  [652,]    4    6    9    2    8    7    5   11   10     1    12     3 #>  [653,]   10    1    6    5    9    7    3    4   11     2    12     8 #>  [654,]    1    7   11   10    6    8    5    9    3     2    12     4 #>  [655,]   11    1    8    4    2   12   10    9    6     7     3     5 #>  [656,]   10    1    5    7    3    8    4    9   12     6    11     2 #>  [657,]    5    3   12   11    7    8    6    1   10     4     2     9 #>  [658,]   10    7    9    6   12    5    1    4    8     2    11     3 #>  [659,]    2   11    9    7    5    1    8   12    6    10     4     3 #>  [660,]    9    4   11    5   12   10    2    6    1     8     7     3 #>  [661,]   11    8    5    7    2   12    4    1   10     9     3     6 #>  [662,]   11    8    4    7    9   10    3    5    6     1    12     2 #>  [663,]    5    2   10    3    1   12   11    6    4     7     8     9 #>  [664,]    1    7    2   10    9   12    3   11    5     8     4     6 #>  [665,]    4    1    2    8   10    9    5    6   11    12     7     3 #>  [666,]    1    3    4    2   10    5   12    8    6     9    11     7 #>  [667,]    8    4    9    1   11    7   10    2   12     5     3     6 #>  [668,]    3    8   11    7   12    2    6    9    5     4    10     1 #>  [669,]   10   11    2    5    3   12    8    4    7     9     6     1 #>  [670,]   11   12    3    7    8    6    2   10    5     9     4     1 #>  [671,]    4   10   12    2    7   11    6    8    1     3     5     9 #>  [672,]    5    4    2    6   10   12    8    3   11     1     7     9 #>  [673,]   10   12    3   11    1    7    9    6    5     4     8     2 #>  [674,]   12    3    4    6    7   11    2    1    8    10     5     9 #>  [675,]    7    9   11   12    1    3    2    6    8    10     4     5 #>  [676,]   11   12    4   10    2    7    3    1    6     5     9     8 #>  [677,]   12    5    8    7    9    4    2    3   10     1    11     6 #>  [678,]    5   12    6   11   10    2    1    9    3     7     8     4 #>  [679,]    6   10    9   11    8    2    1    7    4     3     5    12 #>  [680,]   12    9    7    4    8    5    2   10   11     1     6     3 #>  [681,]    8    7   12    2    1   10    9   11    4     5     3     6 #>  [682,]    2    8   10   12    5    9   11    1    4     6     7     3 #>  [683,]   10    8    7    3    9    6    5    1    4    12     2    11 #>  [684,]    3    9   12    5    6   10    7    4    8     1    11     2 #>  [685,]    4   12    5    3    9    7    8   10    1     6    11     2 #>  [686,]    1    3   11    4    5    7   12    2    8    10     9     6 #>  [687,]   11    8   10    3   12    5    9    4    7     1     6     2 #>  [688,]    3    5    1    7   12    9    8    4    2    10    11     6 #>  [689,]    9    7   12    4    1    8   11    2   10     3     6     5 #>  [690,]    7    1    6   11    8   12    3   10    2     9     4     5 #>  [691,]    9   10    6   12    2    1   11    8    7     3     4     5 #>  [692,]    6    8    3    5    7   11    1    2    4    12     9    10 #>  [693,]   10    3    8    6    9   11    5    7    1    12     2     4 #>  [694,]   10    7    2   12    5    9    6    8    1    11     3     4 #>  [695,]    9    4    7    5    2    6    1   12    8     3    10    11 #>  [696,]    3    7   10    8    5    6    1   11    2     4    12     9 #>  [697,]   12    9    1   11    4    5    6    3    8     7    10     2 #>  [698,]   10    2    1    9    3    5    8    4    7    12     6    11 #>  [699,]   11   10   12    7    2    9    5    6    3     8     1     4 #>  [700,]    3    7    8   12   11    9    2    4    5    10     6     1 #>  [701,]   11    7    6    9    1    2    3    8   12    10     5     4 #>  [702,]    9   11    6    4    1   12    7    8    5    10     3     2 #>  [703,]    7    8   10    3    6   12   11    5    2     4     9     1 #>  [704,]    9    6    5   10   12    1    7    8    3     2     4    11 #>  [705,]    7   10    1    5    9   12   11    4    6     3     2     8 #>  [706,]    3   11    7    1    8    2   12    5    9     4    10     6 #>  [707,]    4    2    3   12    5    6    9   10   11     1     8     7 #>  [708,]    4    5    1    7    3   10    9    8    2    11    12     6 #>  [709,]    1   11    2    5    7    8   12    6    9    10     3     4 #>  [710,]    4    2    9    5   10    7    3   11    8    12     6     1 #>  [711,]    6    1   10    3    2    8    7    9   12     5     4    11 #>  [712,]    2    3   11    6    9   10    4    5    7     1    12     8 #>  [713,]    2   10    9    5   12    7    3    6    4     1    11     8 #>  [714,]    2   10    7   11    8    4    9    3   12     5     1     6 #>  [715,]    8    5    1   12    9    4    3    6   11     7    10     2 #>  [716,]    8    5   10    4    9    2    1    6   11     3    12     7 #>  [717,]   11    5    7   12    3    2    1    8    9     6    10     4 #>  [718,]   11    4    6    2   10   12    9    8    1     5     7     3 #>  [719,]    4    9   11    7    3   12    1    2   10     8     6     5 #>  [720,]    5   10    6    9    1    2    3   12    7    11     8     4 #>  [721,]   10    1    9    2    3    5    8    4    7    12    11     6 #>  [722,]    5   11   12    6    7    8    2    3   10     9     1     4 #>  [723,]    1   12    5    6    7    2   11    4    8     3    10     9 #>  [724,]    9    6   12    5   11    8    3    7    2    10     1     4 #>  [725,]    8    9    4   11   10    6    7   12    1     5     3     2 #>  [726,]    6    9    8    7    1    2   12   11    3     4    10     5 #>  [727,]    3    2   12   10    7    9    4   11    6     5     8     1 #>  [728,]   11    1   10    6   12    9    7    8    2     3     4     5 #>  [729,]   12    6    4    2    5    8    7    3    9    11    10     1 #>  [730,]    8    9    3    4    2    7    6   12   10     1     5    11 #>  [731,]   12   10    6    7    9    1    2    5    3    11     4     8 #>  [732,]    8    1    6   12   11    4    7    9    2    10     3     5 #>  [733,]    8    6    7   10    5    1    4    3    2    11    12     9 #>  [734,]   10    6    2    8    5    1    4    7   12     9    11     3 #>  [735,]    3    7    1    6   10   11    8   12    2     9     4     5 #>  [736,]    3    9   11    7    1    5    2   10    8     4    12     6 #>  [737,]   10    9    5    6   11    4    3    1    2    12     7     8 #>  [738,]   10    4    9    3    1   11    5    2    8     7    12     6 #>  [739,]    8    2   10    3    9   12    5    7    1     6     4    11 #>  [740,]    2    6    8   11    1    3    9    5   10     4     7    12 #>  [741,]    9    5    4    2   12   11    6    3    7    10     1     8 #>  [742,]    9    8   11   12    5    1   10    3    7     6     4     2 #>  [743,]    5   12    6    2    3    8    7    9   11     1     4    10 #>  [744,]    8    5    6    2    9    4    1   10   11     3     7    12 #>  [745,]    3   11    2    1   10    7   12    8    6     4     9     5 #>  [746,]    2   12    8    9    7   10    5    4    3    11     1     6 #>  [747,]    3    9    7   10    6   12    8    1   11     4     2     5 #>  [748,]   11    8    3   12    2    9    6    5    7     1     4    10 #>  [749,]   11    8    6    4    5    7   10    2    3     9     1    12 #>  [750,]    6    1    3   11    7    4    9    2    5     8    10    12 #>  [751,]    7    5   11    4   12    9    6    8    1     3    10     2 #>  [752,]    2   12    7    8    9    6    1    3   11    10     4     5 #>  [753,]    3    4   10    2    8   12    7   11    6     1     5     9 #>  [754,]    9    1    8    6    5   12    7    4   10     3     2    11 #>  [755,]    6    3    7    2   11    5    4    8    1    12    10     9 #>  [756,]    9    4    8    5   12   11    6    1    2     3    10     7 #>  [757,]    7    9    8    3   12    5    2   11    4     6    10     1 #>  [758,]   11    5    8    3    7    1   12    6    2    10     9     4 #>  [759,]    7    2    3    9    1    5   10   12    6    11     8     4 #>  [760,]    2    9   11    5    7    1    3    6   10     4     8    12 #>  [761,]    6    9   12   10    7    5    1    3    2     4     8    11 #>  [762,]    2    7    6    4    8    5   11   10    3    12     1     9 #>  [763,]    6    3    1    9    2   12    4    7    8    11    10     5 #>  [764,]   12    4    5   11    3    7    8   10    2     9     1     6 #>  [765,]    5   10    7    8   11    6    9    2    4     3     1    12 #>  [766,]    4    7   11    5    2    6   12    9    3    10     1     8 #>  [767,]    1   10    2    8    4   12   11    3    9     6     7     5 #>  [768,]    4    3    5    1    2   11    8   12   10     7     6     9 #>  [769,]   10    6   11    1    9   12    2    4    8     3     5     7 #>  [770,]    7    5    4    1    9   12    3    2   11     8    10     6 #>  [771,]    4   12    7    5    9    8   11    2   10     1     6     3 #>  [772,]    9    8    1    4    6    3    5   11    2    10    12     7 #>  [773,]    1   11   12    6   10    5    4    9    2     8     7     3 #>  [774,]   12   11    5    8    2    7    9    6   10     4     1     3 #>  [775,]    8    9   11    2    6    3   12    1   10     4     5     7 #>  [776,]   10    7    5   12    1   11    9    8    2     6     4     3 #>  [777,]    4   10    7    1    8    9    5   12   11     2     3     6 #>  [778,]    2    6    7    5    1   11   12   10    9     4     8     3 #>  [779,]   11    4    2    7    5   12   10    6    8     3     1     9 #>  [780,]    6    5    9    2    3    4   11    8    1    12     7    10 #>  [781,]    4    7    3   10    5   11    2    9   12     8     1     6 #>  [782,]    8    9    7    3    6    5    4   11    2    10     1    12 #>  [783,]    4    8    1    2    3    5   12   10    7     9    11     6 #>  [784,]    8    7    5   10    3    1    4   11    6    12     2     9 #>  [785,]    1   11    5   12    4    7    9    6   10     2     8     3 #>  [786,]    8   10    4    3    1    9    2    7    5    12    11     6 #>  [787,]   11    3    5    9    8    4   12    6   10     2     1     7 #>  [788,]    2    7   12    1    8    5    4   10    6    11     3     9 #>  [789,]    3    6    7    4    9   11    2    8    1    10     5    12 #>  [790,]    8    7   10    9    4    5   11    6    3     2     1    12 #>  [791,]    7    8    1    4   10    2    3   12    5     6     9    11 #>  [792,]   12    4    8    2    5    6    9   10    3    11     7     1 #>  [793,]   10    6    8    3   12   11    7    4    2     5     9     1 #>  [794,]    5   12    8   11    4    9    3   10    7     2     6     1 #>  [795,]    2   11    6    4   12    3    8    9    7     1    10     5 #>  [796,]   11    9   10    6    1    3    4    7    5     8     2    12 #>  [797,]    3    9    2   11    7    5   12    4   10     1     6     8 #>  [798,]   11    8    4   10   12    3    2    1    6     9     7     5 #>  [799,]    8   10    2   11    1    3   12    9    5     4     6     7 #>  [800,]    5    8   11   10    9    1    4    3   12     6     7     2 #>  [801,]   12   10    7    2    9    5    3    8    1    11     6     4 #>  [802,]    4    2   12    7    5    3   10    8   11     6     9     1 #>  [803,]   10    8   12    4    7    9   11    3    2     1     5     6 #>  [804,]    5    2    7    8   12    1    3    9   10     6    11     4 #>  [805,]   11    2    1    6   10    9    4    5    7     3    12     8 #>  [806,]    9   11   10    3    8    4    7    5    6     1     2    12 #>  [807,]    4   12    5    3    8    6   10    9    1     7    11     2 #>  [808,]    3    7    8   12    5   10   11    2    1     4     6     9 #>  [809,]    7   10   12    9    1    3   11    2    4     8     6     5 #>  [810,]   11    9    4    5   12    6    7    3    1     2     8    10 #>  [811,]    3    1   12    2    8   11   10    9    5     6     4     7 #>  [812,]    5    9    8   10   12    1    4    3   11     2     6     7 #>  [813,]   10   11    2    9    1    7    8   12    6     4     5     3 #>  [814,]    2    4    7    1    3    8    9   10    5    12    11     6 #>  [815,]    2   12    9    1    4    5    6    3   10    11     8     7 #>  [816,]    9    5   11    1    3    4    6    2    7    10    12     8 #>  [817,]    8   10   12    7    5    3    9    2    4     6     1    11 #>  [818,]    9    6   11    1    2    4    8    5   10     7    12     3 #>  [819,]    3    9    2    4    5   11   10   12    6     7     8     1 #>  [820,]    3    8   12   10   11    6    4    1    7     5     2     9 #>  [821,]    3   10   11    4    1    8    6    5    7     2    12     9 #>  [822,]    8    6    2    7   11    4   10    3    1    12     5     9 #>  [823,]    3    5    6   10    8    2   11   12    7     4     9     1 #>  [824,]   11    9    7    6    2    5   12    3   10     4     8     1 #>  [825,]    8    6    5    9   11    1   12    7   10     4     2     3 #>  [826,]   11    2   12    3    1   10    5    8    9     7     6     4 #>  [827,]    8    3   11   12    6   10    2    4    5     7     9     1 #>  [828,]    1    9   12   11    5    8    6   10    4     2     3     7 #>  [829,]    6    1    7   12    8   10    3    2    4     5    11     9 #>  [830,]    8    2    9    3    6    5    4   11    7    10     1    12 #>  [831,]   11   12    9    4    6    8    3    7    1    10     2     5 #>  [832,]    7   12    6    5    1    4    3    8    9    11     2    10 #>  [833,]    7    1    5    9    3    2   10   12   11     6     8     4 #>  [834,]   12    5    4    3    8    6   10    1    2     9    11     7 #>  [835,]    4    1    3    9    6    5    7   12   10    11     8     2 #>  [836,]    9   11    1    5    7    8   10    6    3    12     2     4 #>  [837,]    8   11    7   12   10    2    5    6    4     1     3     9 #>  [838,]    8   11    2    7    5    3    9    1   12    10     6     4 #>  [839,]    9    2   12    3    6    8    4   10    5    11     7     1 #>  [840,]    2    1    8   11    5    3    7    6    9    12     4    10 #>  [841,]    6   10    4    3   11    1    2    5    8     7    12     9 #>  [842,]   12   11    2    6    9    1    3   10    4     5     8     7 #>  [843,]    8   11    4    3    1    2    5   12    9    10     7     6 #>  [844,]    7    6    5    3    8    4    1   11    2     9    10    12 #>  [845,]   10    9    8   12    2    1    4    7    5     6    11     3 #>  [846,]   10    7   12    3    5    9    8    6    1     4     2    11 #>  [847,]    3   10    4   11    5    8    1   12    6     2     7     9 #>  [848,]    1    2    7    5    8   12    3    6    4    10     9    11 #>  [849,]   10    6    9    7    5    2    1    3    4     8    12    11 #>  [850,]    1    6   12    5    3   10   11    2    9     8     4     7 #>  [851,]    9    8    5    7    3   12    2    6    4     1    11    10 #>  [852,]    8   12    9   10    3    5    4    6   11     7     1     2 #>  [853,]    2    7    8    3    9   12   10    6    5     4     1    11 #>  [854,]    9   10    5    6    2   11    3    8    7     1     4    12 #>  [855,]    2   11   12    3    5   10    4    7    8     6     1     9 #>  [856,]   11    5    6    9    3    2    4   12    8     1     7    10 #>  [857,]    3    1   11   10    7   12    5    9    8     6     4     2 #>  [858,]   10    8    5    2    1   12    4    7    9     3    11     6 #>  [859,]    3    8    4    9   10   11    7    2    1    12     5     6 #>  [860,]    3    9   10    7    5   11    8    4    6    12     2     1 #>  [861,]    5    1   10    7    3    6    8    2   11     4    12     9 #>  [862,]    3    9    6   12   11    8    2   10    7     4     1     5 #>  [863,]   11    4    7    3    1   12    9    8   10     2     5     6 #>  [864,]    9   12    3    4    1    5   10    8    7     2     6    11 #>  [865,]    2    1    4    5   10    7    3   11    8    12     6     9 #>  [866,]   11    3    8    2   10    9    7    4    1     6     5    12 #>  [867,]    2    7    4    8    9   10    3    6    5     1    12    11 #>  [868,]   11    6    2    9   12    1    7   10    5     3     4     8 #>  [869,]    1    9    6   10    8   11    7    2    5     4    12     3 #>  [870,]   11   10    5    2    3    9    6    4    7     8    12     1 #>  [871,]    8   12    9    5    1    7   11   10    4     2     6     3 #>  [872,]    6   10    1    9   12    3    8    5    2     7     4    11 #>  [873,]   11    2    6    3   12    4    5    7    8     1    10     9 #>  [874,]    4    9   11    8    5    6    2    1    7     3    12    10 #>  [875,]    2   11    7    4    8   12    1    9    5    10     3     6 #>  [876,]    1   12   10    8    5    4    6    9   11     7     3     2 #>  [877,]    8   12    5    4    7    9    1    2    6    10     3    11 #>  [878,]    9    7    6   11   12    5   10    4    2     1     8     3 #>  [879,]   10    4   12    7    6    8    5    3   11     2     1     9 #>  [880,]    5    4    9    8   11    6    1    2   12     3     7    10 #>  [881,]    9    4    2    6   12    7   11    5    8    10     3     1 #>  [882,]    1    9   10    3    7    5    6    4   11     2    12     8 #>  [883,]   10    2    8    3    6    7    1   11   12     9     4     5 #>  [884,]    7    9   10    3    6    4    2    8   11    12     1     5 #>  [885,]    3    8   10    9    4    5   12    1    6     7     2    11 #>  [886,]    7   11    1    2    9   12    6    5    4    10     8     3 #>  [887,]    2   12   11    3    4    9   10    7    1     5     8     6 #>  [888,]    3    7    1    4    6   10   11    5   12     8     9     2 #>  [889,]    3   11   10    5    7    9   12    8    2     4     6     1 #>  [890,]    2   11    9   12    4   10    1    3    6     5     7     8 #>  [891,]    9   12    5   11    7    2    6   10    8     4     1     3 #>  [892,]    9    5   11   12    6   10    2    7    4     8     1     3 #>  [893,]   12    2    8    7    9   10    6    4   11     5     1     3 #>  [894,]   10    6   11    2    4    8    3    1    7     9     5    12 #>  [895,]    3    4    8    9   11    1   10   12    2     6     7     5 #>  [896,]    9    6   11   10   12    8    4    3    1     2     7     5 #>  [897,]    7    4    9    1    2   11   10   12    5     8     6     3 #>  [898,]    4    6    2    7    9    1   12    8    3     5    11    10 #>  [899,]    9    2    7   12    6    5   11   10    3     4     8     1 #>  [900,]    7    9    8    3   12    1    4   10    5     2    11     6 #>  [901,]    2    9    3   11    5    1    7    6   12     4     8    10 #>  [902,]    5    1    6    2    8    4    3    7   11    10     9    12 #>  [903,]    5    8   12    2   11    6    1    3    4     7     9    10 #>  [904,]   12    8    7   10    3    4    5   11    9     2     6     1 #>  [905,]   10    9    8    6    7    2   12   11    3     1     5     4 #>  [906,]    5    2   11    1    4    3   12    6   10     7     9     8 #>  [907,]    8    5   10    2   12    3   11    9    1     6     4     7 #>  [908,]    4    9   12    3    6   11    8    7    5     2     1    10 #>  [909,]    9    1    4    2   11    7   12    8    5     3     6    10 #>  [910,]    8    1   12    9    5    3   11    6   10     2     4     7 #>  [911,]    1   11    7    9    3   10   12    2    8     6     5     4 #>  [912,]    6    2    4    9    8   10    7    1    3     5    11    12 #>  [913,]    7    5    8    4   10    9    2   12    3     6     1    11 #>  [914,]    6   12    1    8    9    3    4   11    2     5     7    10 #>  [915,]    1   11    8   12    9    7    2    6    5     4     3    10 #>  [916,]    6    8    3    9    2    1    4   10   12    11     7     5 #>  [917,]    7    8    1   10   11    6   12    9    4     5     2     3 #>  [918,]    4    3    5   11   12    7    9    6    2    10     1     8 #>  [919,]    7    1   12    3   10    8   11    9    6     2     4     5 #>  [920,]    4   10    6    7    3    8    1    2   11     5    12     9 #>  [921,]    5    7   10    8    1    6    2    3   11    12     9     4 #>  [922,]    9    6   10    7    4    3    8    2    5    11     1    12 #>  [923,]    8    9   10    1    3    6   12    2    4     5    11     7 #>  [924,]    9    8    7    6    4   12    5    2    3    11    10     1 #>  [925,]    9   11    8    7    6    3   12    1    2     5    10     4 #>  [926,]    1    6    3   10    9    8   11    5   12     4     2     7 #>  [927,]    4    6   10    7    1   11    5    8    2     9    12     3 #>  [928,]    5    7    3    8   11    9   10    6   12     4     2     1 #>  [929,]    1    3   10    6    4   12    2    8    9     5    11     7 #>  [930,]   10    8    1    9    4   11    7    6    2    12     5     3 #>  [931,]    5   10    1    3    7    2    4   11    6     9    12     8 #>  [932,]    9    7    4    6    3   10    2    8    5    11     1    12 #>  [933,]   10    2    4    3    8    9    6    7    1    11    12     5 #>  [934,]   11    1    4   10    5    2    8    6    9    12     7     3 #>  [935,]    1    6    9    5    2   12    4    8   11     7     3    10 #>  [936,]    7    3    8    5    9   12    1    2    4    10    11     6 #>  [937,]   12    3    2    5    6   10    4    7   11     8     1     9 #>  [938,]    6    2    9    1    4    3   11    5    8    10     7    12 #>  [939,]    5   10    4    9    8    7    3   11    6     1    12     2 #>  [940,]    8    5    6    3   11    2    4    9    1     7    12    10 #>  [941,]    8   12    1    7    3    2    6    4   10     5    11     9 #>  [942,]    5    4   10    1    2    3    8   11    6     7    12     9 #>  [943,]    8   10    4    2    1    7   11    6    5     3    12     9 #>  [944,]    4   11    6    5   10    9    7    3    2    12     8     1 #>  [945,]   11    9    1    4   10   12    6    5    8     3     2     7 #>  [946,]    3    5   11    8    9    2    4    1    6    12     7    10 #>  [947,]    4    3    5    9    1    7    2    6    8    10    12    11 #>  [948,]    8    9    2    3   11    6    1    5    4     7    12    10 #>  [949,]    3   12    5   10    6    8    2   11    9     4     7     1 #>  [950,]    2    5    8    6   12    4    7    9   11     1    10     3 #>  [951,]    2   11    3   12    6    1   10    4    5     7     9     8 #>  [952,]    7    4    1    9    6    3    8   12   10     5    11     2 #>  [953,]    7   10   12    9    6    2   11    5    1     3     8     4 #>  [954,]    6    7   10    8    4    3   11    1   12     9     5     2 #>  [955,]   12    1   11    9    4    6    5    7    8     2    10     3 #>  [956,]    4    8    6    3    5    1   10    9   11     2    12     7 #>  [957,]    5    2    7    6    8    3    1   10   12     4     9    11 #>  [958,]    4    3    5    7   12   11    1    8    6    10     9     2 #>  [959,]   10    6    9   11    4    5    7    1    3     2     8    12 #>  [960,]   12    4    6   11    3    8    7    5   10     2     1     9 #>  [961,]   10    1    5    2    4    9    8   11    3     6    12     7 #>  [962,]    7    5    6    1    4    2   12   11    9     3    10     8 #>  [963,]   12    7    4    9   10    1    2   11    8     3     5     6 #>  [964,]    7    9   11    4    2   12    1    5   10     6     3     8 #>  [965,]   10    7    2   12    5    3    6   11    9     4     1     8 #>  [966,]    3   11   10    9    5    8    4    6    2     1     7    12 #>  [967,]    3    4    8    5   10    9    6   11   12     1     2     7 #>  [968,]    8    9    3   12    6    1   10    5    4     2     7    11 #>  [969,]    6    9    8    1    5    2   12   10    4    11     3     7 #>  [970,]    1    9    2    4    7    5   12    3    6    11     8    10 #>  [971,]    8    6    4    9   12    7    2    1    5     3    11    10 #>  [972,]    5    7    9    6   11   12    3   10    4     2     8     1 #>  [973,]    3    7    6   12    9    5    8   10    2     1     4    11 #>  [974,]    2   10    4    8   11    5   12    1    9     3     7     6 #>  [975,]   12    3   11   10    9    7    4    5    8     2     1     6 #>  [976,]    8    9    4   12    2    3    6   10    1     5     7    11 #>  [977,]    9    1    5    2    8   12    3   10   11     6     4     7 #>  [978,]    4    2    5    1    9   10   12   11    6     7     3     8 #>  [979,]    9   11    2    1    6    4   12    5    7    10     8     3 #>  [980,]    8    3   10    7   11    9    6    2   12     1     5     4 #>  [981,]    6   10    1    3    4   12   11    7    2     8     9     5 #>  [982,]    4   10    7    5    9    1    6    8   12    11     2     3 #>  [983,]   10    1    2    5    9    6    7    3    8    12    11     4 #>  [984,]   10   12    8    5    6   11    1    9    7     4     3     2 #>  [985,]   10    4   12    6   11    5    9    8    3     1     7     2 #>  [986,]    7    3   12    4   11    9   10    8    5     1     6     2 #>  [987,]    8    1    6    7    9   12    5   10    3    11     4     2 #>  [988,]    2    5   11    8    3   12    4    7    1     6    10     9 #>  [989,]   12   11    5    3    1    2    8    9    7     6    10     4 #>  [990,]    4    1    3    2   11   10    5    7   12     8     6     9 #>  [991,]   12    4    5    6    1    2   11   10    9     3     8     7 #>  [992,]    3    1    6    9    7   12   10    5    4    11     8     2 #>  [993,]    6    4   11    2    3    5    7    8    9    12     1    10 #>  [994,]    8    2    9    4    6   12    5    3   10     1    11     7 #>  [995,]    4    8    7    3   12   11   10    9    1     6     2     5 #>  [996,]    5    8    2    3    7   10   12   11    4     6     9     1 #>  [997,]    3   12    9   10    8    4    7    2    1    11     5     6 #>  [998,]   11   12    1   10    9    5    7    4    8     3     2     6 #>  [999,]   10    8    4    3    2   12    9    5    7     1    11     6 #> [1000,]    4   10    9    8    2   11    6    5    3     7     1    12   # Graph of bootstrap distributions boxplot(as.vector(Cornell.bootYX$t[,-1])~factor(rep(1:7,rep(1000,7))), main=\"Bootstrap distributions of standardised bj (j = 1, ..., 7).\") points(c(1:7),Cornell.bootYX$t0[-1],col=\"red\",pch=19)  # Using the boxplots.bootpls function boxplots.bootpls(Cornell.bootYX,indices=2:8)    library(boot) plot(Cornell.bootYX,index=2)   qqnorm(Cornell.bootYX$t[,2],ylim=c(-1,1)) abline(h=Cornell.bootYX$t0[2],lty=2)  (sum(abs(Cornell.bootYX$t[,2])>=abs(Cornell.bootYX$t0[2]))+1)/(length(Cornell.bootYX$t[,2])+1) #> [1] 0.5584416  rm(Cornell.bootYX) # }"},{"path":"https://fbertran.github.io/plsRglm/reference/bootplsglm.html","id":null,"dir":"Reference","previous_headings":"","what":"Non-parametric Bootstrap for PLS generalized linear models — bootplsglm","title":"Non-parametric Bootstrap for PLS generalized linear models — bootplsglm","text":"Provides wrapper bootstrap function boot boot R package. Implements non-parametric bootstraps PLS Generalized Linear Regression models either (Y,X) (Y,T) resampling.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bootplsglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Non-parametric Bootstrap for PLS generalized linear models — bootplsglm","text":"","code":"bootplsglm(   object,   typeboot = \"fmodel_np\",   R = 250,   statistic = NULL,   sim = \"ordinary\",   stype = \"i\",   stabvalue = 1e+06,   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/plsRglm/reference/bootplsglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Non-parametric Bootstrap for PLS generalized linear models — bootplsglm","text":"object object class plsRglmmodel bootstrap typeboot type bootstrap. Either (Y,X) boostrap (typeboot=\"plsmodel\") (Y,T) bootstrap (typeboot=\"fmodel_np\"). Defaults (Y,T) resampling. R number bootstrap replicates. Usually single positive integer. importance resampling, resamples may use one set weights others use different set weights. case R vector integers component gives number resamples rows weights. statistic function applied data returns vector containing statistic(s) interest. statistic must take least two arguments. first argument passed always original data. second vector indices, frequencies weights define bootstrap sample. , predictions required, third argument required vector random indices used generate bootstrap predictions. arguments can passed statistic ... argument. sim character string indicating type simulation required. Possible values \"ordinary\" (default), \"balanced\", \"permutation\", \"antithetic\". stype character string indicating second argument statistic represents. Possible values stype \"\" (indices - default), \"f\" (frequencies), \"w\" (weights). stabvalue value hard threshold bootstrap estimates computed atypical resamplings. Especially useful Generalized Linear Models. verbose info messages displayed ? ... named arguments statistic passed unchanged time called. arguments statistic follow arguments statistic required simulation. Beware partial matching arguments boot listed .","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bootplsglm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Non-parametric Bootstrap for PLS generalized linear models — bootplsglm","text":"object class \"boot\". See Value part help function boot.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bootplsglm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Non-parametric Bootstrap for PLS generalized linear models — bootplsglm","text":"details bootstrap techniques available help boot function.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bootplsglm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Non-parametric Bootstrap for PLS generalized linear models — bootplsglm","text":". Lazraq, R. Cleroux, J.-P. Gauchi. (2003). Selecting latent explanatory variables PLS1 regression model. Chemometrics Intelligent Laboratory Systems, 66(2):117-126. P. Bastien, V. Esposito-Vinzi, M. Tenenhaus. (2005). PLS generalised linear regression. Computational Statistics & Data Analysis, 48(1):17-46. . C. Davison D. V. Hinkley. (1997). Bootstrap Methods Applications. Cambridge University Press, Cambridge.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/bootplsglm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Non-parametric Bootstrap for PLS generalized linear models — bootplsglm","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bootplsglm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Non-parametric Bootstrap for PLS generalized linear models — bootplsglm","text":"","code":"#Imputed aze dataset data(aze_compl) Xaze_compl<-aze_compl[,2:34] yaze_compl<-aze_compl$y  dataset <- cbind(y=yaze_compl,Xaze_compl) modplsglm <- plsRglm(y~.,data=dataset,3,modele=\"pls-glm-logistic\") #> ____************************************************____ #> Error in eval(mf, parent.frame(n = sys.nframe())): object 'dataset' not found  library(boot) # Bastien (Y,T) PLS bootstrap aze_compl.bootYT <- bootplsglm(modplsglm, R=250, verbose=FALSE) #> Error: object 'modplsglm' not found boxplots.bootpls(aze_compl.bootYT) #> Error: object 'aze_compl.bootYT' not found confints.bootpls(aze_compl.bootYT) #> Error: object 'aze_compl.bootYT' not found plots.confints.bootpls(confints.bootpls(aze_compl.bootYT)) #> Error: object 'aze_compl.bootYT' not found  # \\donttest{ # (Y,X) PLS bootstrap aze_compl.bootYX <- bootplsglm(modplsglm, R=250, verbose=FALSE,  typeboot = \"plsmodel\") #> Error: object 'modplsglm' not found boxplots.bootpls(aze_compl.bootYX) #> Error: object 'aze_compl.bootYX' not found confints.bootpls(aze_compl.bootYX) #> Error: object 'aze_compl.bootYX' not found plots.confints.bootpls(confints.bootpls(aze_compl.bootYX)) #> Error: object 'aze_compl.bootYX' not found  # (Y,X) PLS bootstrap raw coefficients aze_compl.bootYX.raw <- bootplsglm(modplsglm, R=250, verbose=FALSE,  typeboot = \"plsmodel\", statistic=coefs.plsRglm.raw) #> Error: object 'modplsglm' not found boxplots.bootpls(aze_compl.bootYX.raw) #> Error: object 'aze_compl.bootYX.raw' not found confints.bootpls(aze_compl.bootYX.raw) #> Error: object 'aze_compl.bootYX.raw' not found plots.confints.bootpls(confints.bootpls(aze_compl.bootYX.raw)) #> Error: object 'aze_compl.bootYX.raw' not found  plot(aze_compl.bootYT,index=2) #> Error: object 'aze_compl.bootYT' not found jack.after.boot(aze_compl.bootYT, index=2, useJ=TRUE, nt=3) #> Error: object 'aze_compl.bootYT' not found plot(aze_compl.bootYT, index=2,jack=TRUE) #> Error: object 'aze_compl.bootYT' not found aze_compl.tilt.boot <- tilt.bootplsglm(modplsglm, statistic=coefs.plsRglm,  R=c(499, 100, 100), alpha=c(0.025, 0.975), sim=\"ordinary\", stype=\"i\", index=1) #> Error: object 'modplsglm' not found  # PLS bootstrap balanced aze_compl.bootYT <- bootplsglm(modplsglm, sim=\"balanced\", R=250, verbose=FALSE) #> Error: object 'modplsglm' not found boxplots.bootpls(aze_compl.bootYT) #> Error: object 'aze_compl.bootYT' not found confints.bootpls(aze_compl.bootYT) #> Error: object 'aze_compl.bootYT' not found plots.confints.bootpls(confints.bootpls(aze_compl.bootYT)) #> Error: object 'aze_compl.bootYT' not found   plot(aze_compl.bootYT) #> Error: object 'aze_compl.bootYT' not found jack.after.boot(aze_compl.bootYT, index=1, useJ=TRUE, nt=3) #> Error: object 'aze_compl.bootYT' not found plot(aze_compl.bootYT,jack=TRUE) #> Error: object 'aze_compl.bootYT' not found aze_compl.tilt.boot <- tilt.bootplsglm(modplsglm, statistic=coefs.plsR, R=c(499, 100, 100), alpha=c(0.025, 0.975), sim=\"balanced\", stype=\"i\", index=1) #> Error: object 'modplsglm' not found   # PLS permutation bootstrap  aze_compl.bootYT <- bootplsglm(modplsglm, sim=\"permutation\", R=250, verbose=FALSE) #> Error: object 'modplsglm' not found boxplots.bootpls(aze_compl.bootYT) #> Error: object 'aze_compl.bootYT' not found plot(aze_compl.bootYT) #> Error: object 'aze_compl.bootYT' not found   #Original aze dataset with missing values data(aze) Xaze<-aze[,2:34] yaze<-aze$y  library(boot) modplsglm2 <- plsRglm(yaze,Xaze,3,modele=\"pls-glm-logistic\") #> ____************************************************____ #> Only naive DoF can be used with missing data #>  #> Family: binomial  #> Link function: logit  #>  #> ____There are some NAs in X but not in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  aze.bootYT <- bootplsglm(modplsglm2, R=250, verbose=FALSE) boxplots.bootpls(aze.bootYT)  confints.bootpls(aze.bootYT) #>                                                                            #> D2S138  -0.0430836553 -0.015340921 -0.043771063 -0.015915414 -0.0441844214 #> D18S61   0.0703346712  0.162336180  0.071935484  0.165361254  0.0722574935 #> D16S422 -0.0561136431 -0.005347258 -0.059676408 -0.005351559 -0.0567101732 #> D17S794  0.0404155966  0.108741234  0.040233047  0.110770927  0.0408701197 #> D6S264  -0.0680962185 -0.028577392 -0.069099553 -0.029722687 -0.0692416158 #> D14S65   0.0151209602  0.037919094  0.014885696  0.037835120  0.0165886795 #> D18S53  -0.0529741202 -0.012714380 -0.052792663 -0.012743960 -0.0544408234 #> D17S790 -0.0664210755 -0.020405306 -0.066978791 -0.017771732 -0.0721055081 #> D1S225  -0.0052321704  0.006903596 -0.005848025  0.006656162 -0.0052618808 #> D3S1282 -0.0215190769  0.029216212 -0.020660109  0.030001668 -0.0238002947 #> D9S179   0.0307514177  0.073789897  0.030024037  0.075966850  0.0304696746 #> D5S430  -0.1600803249 -0.060188776 -0.160960833 -0.061242429 -0.1638597019 #> D8S283  -0.0077997369  0.040815231 -0.009419890  0.038801333 -0.0043766160 #> D11S916  0.0543333696  0.129008238  0.052515691  0.131501660  0.0557582337 #> D2S159   0.0008913442  0.056595181  0.001222099  0.057318612 -0.0001957766 #> D16S408  0.0214997486  0.049967624  0.021864280  0.050791733  0.0221326483 #> D5S346   0.0324918549  0.120035882  0.026536220  0.118409217  0.0389396103 #> D10S191 -0.0260498302 -0.001849705 -0.025555131 -0.002426571 -0.0266428318 #> D13S173  0.0487962093  0.112221487  0.050937074  0.114705594  0.0499823616 #> D6S275  -0.1217425047 -0.050761661 -0.123803040 -0.052968251 -0.1242459020 #> D15S127 -0.0167795889  0.002720454 -0.017198824  0.002686720 -0.0170748538 #> D1S305   0.0523651314  0.124929667  0.051790245  0.129158702  0.0513609110 #> D4S394  -0.0677457113 -0.024550754 -0.068279579 -0.025700358 -0.0693585009 #> D20S107 -0.0931339901 -0.027553803 -0.094408687 -0.024102508 -0.1009376191 #> D1S197  -0.0792352128 -0.022228397 -0.078992924 -0.023114482 -0.0803608213 #> D1S207  -0.0110540044  0.005098099 -0.011232542  0.004724430 -0.0109319960 #> D10S192  0.0510075345  0.117768568  0.051111694  0.120177155  0.0523369378 #> D3S1283 -0.0518113997  0.009568615 -0.050095200  0.012528410 -0.0578427865 #> D4S414   0.0167537293  0.052187501  0.016255411  0.053599865  0.0161042221 #> D8S264   0.0098750699  0.088319094  0.004673021  0.086606529  0.0151475916 #> D22S928 -0.0090243311  0.031195079 -0.010445549  0.029430211 -0.0062160652 #> TP53    -0.1562103856 -0.063107294 -0.157693133 -0.067116796 -0.1585481284 #> D9S171   0.0118482350  0.053605259  0.011508865  0.052591819  0.0130947554 #>                                                  #> D2S138  -0.016328772 -0.0418841999 -1.512330e-02 #> D18S61   0.165683264  0.0654056966  1.574272e-01 #> D16S422 -0.002385324 -0.0547943467 -6.250634e-05 #> D17S794  0.111407999  0.0399341623  1.091797e-01 #> D6S264  -0.029864749 -0.0667002622 -2.529991e-02 #> D14S65   0.039538103  0.0146820695  3.706730e-02 #> D18S53  -0.014392120 -0.0525625573 -1.434752e-02 #> D17S790 -0.022898448 -0.0651740801 -2.109078e-02 #> D1S225   0.007242307 -0.0050933601  7.679490e-03 #> D3S1282  0.026861482 -0.0235184949  2.687434e-02 #> D9S179   0.076412487  0.0297923155  7.313882e-02 #> D5S430  -0.064141298 -0.1619354568 -5.565190e-02 #> D8S283   0.043844606 -0.0001397147  4.732440e-02 #> D11S916  0.134744202  0.0508036923  1.271264e-01 #> D2S159   0.055900736 -0.0004940934  5.563520e-02 #> D16S408  0.051060101  0.0205076146  4.915675e-02 #> D5S346   0.130812607  0.0372828145  1.201410e-01 #> D10S191 -0.003514272 -0.0252945910 -5.309125e-04 #> D13S173  0.113750882  0.0418838726  1.088635e-01 #> D6S275  -0.053411113 -0.1202950936 -4.727772e-02 #> D15S127  0.002810690 -0.0169041296  3.220130e-03 #> D1S305   0.128729368  0.0488549040  1.237695e-01 #> D4S394  -0.026779280 -0.0662829853 -2.375609e-02 #> D20S107 -0.030631441 -0.0909686262 -2.761123e-02 #> D1S197  -0.024482379 -0.0790658141 -2.365270e-02 #> D1S207   0.005024976 -0.0107419547  5.079784e-03 #> D10S192  0.121402399  0.0461171988  1.150375e-01 #> D3S1283  0.004780823 -0.0536085037  1.185818e-02 #> D4S414   0.053448676  0.0150836678  5.329205e-02 #> D8S264   0.097081099  0.0159201759  9.835832e-02 #> D22S928  0.033659695 -0.0027651887  3.635174e-02 #> TP53    -0.067971792 -0.1548235948 -6.044448e-02 #> D9S171   0.054177710  0.0077360617  5.363401e-02 #> attr(,\"typeBCa\") #> [1] TRUE plots.confints.bootpls(confints.bootpls(aze.bootYT))      #Ordinal logistic regression data(bordeaux) Xbordeaux<-bordeaux[,1:4] ybordeaux<-factor(bordeaux$Quality,ordered=TRUE) dataset <- cbind(y=ybordeaux,Xbordeaux) options(contrasts = c(\"contr.treatment\", \"contr.poly\")) modplsglm3 <- plsRglm(ybordeaux,Xbordeaux,1,modele=\"pls-glm-polr\") #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Component____ 1 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  bordeaux.bootYT<- bootplsglm(modplsglm3, sim=\"permutation\", R=250, verbose=FALSE) boxplots.bootpls(bordeaux.bootYT)  boxplots.bootpls(bordeaux.bootYT,ranget0=TRUE)   bordeaux.bootYT2<- bootplsglm(modplsglm3, sim=\"permutation\", R=250,  strata=unclass(ybordeaux), verbose=FALSE) boxplots.bootpls(bordeaux.bootYT2,ranget0=TRUE)    if(require(chemometrics)){ data(hyptis) hyptis yhyptis <- factor(hyptis$Group,ordered=TRUE) Xhyptis <- as.data.frame(hyptis[,c(1:6)]) dataset <- cbind(y=yhyptis,Xhyptis) options(contrasts = c(\"contr.treatment\", \"contr.poly\")) modplsglm4 <- plsRglm(yhyptis,Xhyptis,3,modele=\"pls-glm-polr\") hyptis.bootYT3<- bootplsglm(modplsglm4, sim=\"permutation\", R=250, verbose=FALSE) rownames(hyptis.bootYT3$t0)<-c(\"Sabi\\nnene\",\"Pin\\nene\", \"Cine\\nole\",\"Terpi\\nnene\",\"Fenc\\nhone\",\"Terpi\\nnolene\") boxplots.bootpls(hyptis.bootYT3) boxplots.bootpls(hyptis.bootYT3,xaxisticks=FALSE) boxplots.bootpls(hyptis.bootYT3,ranget0=TRUE) boxplots.bootpls(hyptis.bootYT3,ranget0=TRUE,xaxisticks=FALSE) } #> Loading required package: chemometrics #> Warning: there is no package called ‘chemometrics’ # }"},{"path":"https://fbertran.github.io/plsRglm/reference/bordeaux.html","id":null,"dir":"Reference","previous_headings":"","what":"Quality of wine dataset — bordeaux","title":"Quality of wine dataset — bordeaux","text":"Quality Bordeaux wines (Quality) four potentially predictive variables (Temperature, Sunshine, Heat Rain).","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bordeaux.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Quality of wine dataset — bordeaux","text":"data frame 34 observations following 5 variables. Temperature numeric vector Sunshine numeric vector Heat numeric vector Rain numeric vector Quality ordered factor levels 1 < 2 < 3","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bordeaux.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Quality of wine dataset — bordeaux","text":"P. Bastien, V. Esposito-Vinzi, M. Tenenhaus. (2005). PLS generalised linear regression. Computational Statistics & Data Analysis, 48(1):17-46.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bordeaux.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quality of wine dataset — bordeaux","text":"M. Tenenhaus. (2005). La regression logistique PLS. J.-J. Droesbeke, M. Lejeune, G. Saporta, editors, Modeles statistiques pour donnees qualitatives. Editions Technip, Paris.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bordeaux.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quality of wine dataset — bordeaux","text":"","code":"data(bordeaux) str(bordeaux) #> 'data.frame':\t34 obs. of  5 variables: #>  $ Temperature: int  3064 3000 3155 3085 3245 3267 3080 2974 3038 3318 ... #>  $ Sunshine   : int  1201 1053 1133 970 1258 1386 966 1189 1103 1310 ... #>  $ Heat       : int  10 11 19 4 36 35 13 12 14 29 ... #>  $ Rain       : int  361 338 393 467 294 225 417 488 677 427 ... #>  $ Quality    : Ord.factor w/ 3 levels \"1\"<\"2\"<\"3\": 2 3 2 3 1 1 3 3 3 2 ..."},{"path":"https://fbertran.github.io/plsRglm/reference/bordeauxNA.html","id":null,"dir":"Reference","previous_headings":"","what":"Quality of wine dataset — bordeauxNA","title":"Quality of wine dataset — bordeauxNA","text":"Quality Bordeaux wines (Quality) four potentially predictive variables (Temperature, Sunshine, Heat Rain).","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bordeauxNA.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Quality of wine dataset — bordeauxNA","text":"data frame 34 observations following 5 variables. Temperature numeric vector Sunshine numeric vector Heat numeric vector Rain numeric vector Quality ordered factor levels 1 < 2 < 3","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bordeauxNA.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Quality of wine dataset — bordeauxNA","text":"P. Bastien, V. Esposito-Vinzi, M. Tenenhaus. (2005). PLS generalised linear regression. Computational Statistics & Data Analysis, 48(1):17-46.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bordeauxNA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quality of wine dataset — bordeauxNA","text":"value x1 first observation removed matrix predictors purpose. bordeauxNA dataset missing value testing purpose.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bordeauxNA.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quality of wine dataset — bordeauxNA","text":"M. Tenenhaus. (2005). La regression logistique PLS. J.-J. Droesbeke, M. Lejeune, G. Saporta, editors, Modeles statistiques pour donnees qualitatives. Editions Technip, Paris.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/bordeauxNA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quality of wine dataset — bordeauxNA","text":"","code":"data(bordeauxNA) str(bordeauxNA) #> 'data.frame':\t34 obs. of  5 variables: #>  $ Temperature: int  NA 3000 3155 3085 3245 3267 3080 2974 3038 3318 ... #>  $ Sunshine   : int  1201 1053 1133 970 1258 1386 966 1189 1103 1310 ... #>  $ Heat       : int  10 11 19 4 36 35 13 12 14 29 ... #>  $ Rain       : int  361 338 393 467 294 225 417 488 677 427 ... #>  $ Quality    : Ord.factor w/ 3 levels \"1\"<\"2\"<\"3\": 2 3 2 3 1 1 3 3 3 2 ..."},{"path":"https://fbertran.github.io/plsRglm/reference/boxplots.bootpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Boxplot bootstrap distributions — boxplots.bootpls","title":"Boxplot bootstrap distributions — boxplots.bootpls","text":"Boxplots bootstrap distributions.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/boxplots.bootpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Boxplot bootstrap distributions — boxplots.bootpls","text":"","code":"boxplots.bootpls(   bootobject,   indices = NULL,   prednames = TRUE,   articlestyle = TRUE,   xaxisticks = TRUE,   ranget0 = FALSE,   las = par(\"las\"),   mar,   mgp,   ... )"},{"path":"https://fbertran.github.io/plsRglm/reference/boxplots.bootpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Boxplot bootstrap distributions — boxplots.bootpls","text":"bootobject object class \"boot\" indices vector indices variables plot. Defaults NULL: predictors used. prednames original names predictors shall plotted ? Defaults TRUE: names plotted. articlestyle extra blank zones margin shall removed plot ? Defaults TRUE: margins removed. xaxisticks ticks x axis shall plotted ? Defaults TRUE: ticks plotted. ranget0 vertival range plot shall computed include initial estimates coefficients ? Defaults FALSE: vertical range calculated using bootstrapped values statistics. Especially using permutation bootstrap. las numeric 0,1,2,3; style axis labels. 0: always parallel axis [default], 1: always horizontal, 2: always perpendicular axis, 3: always vertical. mar numerical vector form c(bottom, left, top, right) gives number lines margin specified four sides plot. default c(5, 4, 4, 2) + 0.1. mgp margin line (mex units) axis title, axis labels axis line. Note mgp[1] affects title whereas mgp[2:3] affect axis. default c(3, 1, 0). ... options pass boxplot function.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/boxplots.bootpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Boxplot bootstrap distributions — boxplots.bootpls","text":"NULL","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/boxplots.bootpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Boxplot bootstrap distributions — boxplots.bootpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/boxplots.bootpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Boxplot bootstrap distributions — boxplots.bootpls","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8]  # Lazraq-Cleroux PLS ordinary bootstrap set.seed(250) modpls <- plsR(yCornell,XCornell,3) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  Cornell.bootYX <- bootpls(modpls, R=250) #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>   # Graph similar to the one of Bastien et al. in CSDA 2005 boxplots.bootpls(Cornell.bootYX,indices=2:8)   # \\donttest{ data(aze_compl) modplsglm<-plsRglm(y~.,data=aze_compl,3,modele=\"pls-glm-logistic\") #> ____************************************************____ #>  #> Family: binomial  #> Link function: logit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  aze_compl.boot3 <- bootplsglm(modplsglm, R=250, verbose=FALSE) boxplots.bootpls(aze_compl.boot3)  boxplots.bootpls(aze_compl.boot3,las=3,mar=c(5,2,1,1))  boxplots.bootpls(aze_compl.boot3,indices=c(2,4,6),prednames=FALSE)  # }"},{"path":"https://fbertran.github.io/plsRglm/reference/coef.plsRglmmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"coef method for plsR models — coef.plsRglmmodel","title":"coef method for plsR models — coef.plsRglmmodel","text":"function provides coef method class \"plsRglmmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coef.plsRglmmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"coef method for plsR models — coef.plsRglmmodel","text":"","code":"# S3 method for class 'plsRglmmodel' coef(object, type = c(\"scaled\", \"original\"), ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/coef.plsRglmmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"coef method for plsR models — coef.plsRglmmodel","text":"object object class \"plsRglmmodel\" type scaled, coefficients predictors given scaled predictors, original coefficients used predictors original scale. ... used","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coef.plsRglmmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"coef method for plsR models — coef.plsRglmmodel","text":"object class coef.plsRglmmodel. CoeffC Coefficients components. Std.Coeffs Coefficients scaled predictors regression function. Coeffs Coefficients untransformed predictors (original scale).","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/coef.plsRglmmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"coef method for plsR models — coef.plsRglmmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coef.plsRglmmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"coef method for plsR models — coef.plsRglmmodel","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] modpls <- plsRglm(yCornell,XCornell,3,modele=\"pls-glm-family\",family=gaussian()) #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  class(modpls) #> [1] \"plsRglmmodel\" coef(modpls) #> Coefficients of the components #> Coeff_Comp_Reg 1 Coeff_Comp_Reg 2 Coeff_Comp_Reg 3  #>        3.1434906        2.8745210        0.9766999  #> Coefficients of the predictors (original scale) #>                 [,1] #> Intercept  87.652763 #> X1         -5.930456 #> X2         -2.069198 #> X3         -9.607722 #> X4         -4.994568 #> X5          2.603934 #> X6         14.721801 #> X7        -20.912671 coef(modpls,type=\"scaled\") #> Coefficients of the components #> Coeff_Comp_Reg 1 Coeff_Comp_Reg 2 Coeff_Comp_Reg 3  #>        3.1434906        2.8745210        0.9766999  #> Coefficients of the predictors (scaled scale) #>                 [,1] #> Intercept 88.5833333 #> X1        -0.5473211 #> X2        -0.4045974 #> X3        -0.5171213 #> X4        -1.1338145 #> X5         0.1486891 #> X6         4.3120090 #> X7        -0.5663178 rm(list=c(\"XCornell\",\"yCornell\",\"modpls\"))"},{"path":"https://fbertran.github.io/plsRglm/reference/coef.plsRmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"coef method for plsR models — coef.plsRmodel","title":"coef method for plsR models — coef.plsRmodel","text":"function provides coef method class \"plsRmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coef.plsRmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"coef method for plsR models — coef.plsRmodel","text":"","code":"# S3 method for class 'plsRmodel' coef(object, type = c(\"scaled\", \"original\"), ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/coef.plsRmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"coef method for plsR models — coef.plsRmodel","text":"object object class \"plsRmodel\" type scaled, coefficients predictors given scaled predictors, original coefficients used predictors original scale. ... used","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coef.plsRmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"coef method for plsR models — coef.plsRmodel","text":"object class coef.plsRmodel. CoeffC Coefficients components. Std.Coeffs Coefficients scaled predictors. Coeffs Coefficients untransformed predictors (original scale).","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/coef.plsRmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"coef method for plsR models — coef.plsRmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coef.plsRmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"coef method for plsR models — coef.plsRmodel","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] modpls <- plsRglm(yCornell,XCornell,3,modele=\"pls\") #> ____************************************************____ #>  #> Model: pls  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  class(modpls) #> [1] \"plsRglmmodel\" coef(modpls) #> Coefficients of the components #> Coeff_Comp_Reg 1 Coeff_Comp_Reg 2 Coeff_Comp_Reg 3  #>        0.4820365        0.2731127        0.1030689  #> Coefficients of the predictors (original scale) #>                 [,1] #> Intercept  92.675989 #> X1         -9.828318 #> X2         -6.960181 #> X3        -16.666239 #> X4         -8.421802 #> X5         -4.388934 #> X6         10.161304 #> X7        -34.528959 coef(modpls,type=\"scaled\") #> Coefficients of the components #> Coeff_Comp_Reg 1 Coeff_Comp_Reg 2 Coeff_Comp_Reg 3  #>        0.4820365        0.2731127        0.1030689  #> Coefficients of the predictors (scaled scale) #>                  [,1] #> Intercept  0.00000000 #> X1        -0.13909167 #> X2        -0.20869374 #> X3        -0.13755531 #> X4        -0.29316826 #> X5        -0.03843049 #> X6         0.45638984 #> X7        -0.14338442 rm(list=c(\"XCornell\",\"yCornell\",\"modpls\"))"},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsR.html","id":null,"dir":"Reference","previous_headings":"","what":"Coefficients for bootstrap computations of PLSR models — coefs.plsR","title":"Coefficients for bootstrap computations of PLSR models — coefs.plsR","text":"function passed boot perform bootstrap.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coefficients for bootstrap computations of PLSR models — coefs.plsR","text":"","code":"coefs.plsR(dataset, ind, nt, modele, maxcoefvalues, ifbootfail, verbose)"},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coefficients for bootstrap computations of PLSR models — coefs.plsR","text":"dataset dataset resample ind indices resampling nt number components use modele type modele use, see plsR maxcoefvalues maximum values allowed estimates coefficients discard coming singular bootstrap samples ifbootfail value return estimation fails bootstrap sample verbose info messages displayed ?","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coefficients for bootstrap computations of PLSR models — coefs.plsR","text":"estimates bootstrap sample ifbootfail value bootstrap computation fails.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Coefficients for bootstrap computations of PLSR models — coefs.plsR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coefficients for bootstrap computations of PLSR models — coefs.plsR","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8]  # Lazraq-Cleroux PLS (Y,X) bootstrap # statistic=coefs.plsR is the default for (Y,X) resampling of PLSR models. set.seed(250) modpls <- plsR(yCornell,XCornell,1) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  Cornell.bootYX <- bootpls(modpls, R=250, statistic=coefs.plsR, verbose=FALSE)"},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsR.raw.html","id":null,"dir":"Reference","previous_headings":"","what":"Raw coefficients for bootstrap computations of PLSR models — coefs.plsR.raw","title":"Raw coefficients for bootstrap computations of PLSR models — coefs.plsR.raw","text":"function passed boot perform bootstrap.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsR.raw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Raw coefficients for bootstrap computations of PLSR models — coefs.plsR.raw","text":"","code":"coefs.plsR.raw(dataset, ind, nt, modele, maxcoefvalues, ifbootfail, verbose)"},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsR.raw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Raw coefficients for bootstrap computations of PLSR models — coefs.plsR.raw","text":"dataset dataset resample ind indices resampling nt number components use modele type modele use, see plsR maxcoefvalues maximum values allowed estimates coefficients discard coming singular bootstrap samples ifbootfail value return estimation fails bootstrap sample verbose info messages displayed ?","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsR.raw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Raw coefficients for bootstrap computations of PLSR models — coefs.plsR.raw","text":"estimates bootstrap sample ifbootfail value bootstrap computation fails.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsR.raw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Raw coefficients for bootstrap computations of PLSR models — coefs.plsR.raw","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsR.raw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Raw coefficients for bootstrap computations of PLSR models — coefs.plsR.raw","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8]  # Lazraq-Cleroux PLS (Y,X) bootstrap set.seed(250) modpls <- coefs.plsR.raw(Cornell[,-8],1:nrow(Cornell),nt=3, maxcoefvalues=1e5,ifbootfail=rep(0,3),verbose=FALSE)"},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglm.html","id":null,"dir":"Reference","previous_headings":"","what":"Coefficients for bootstrap computations of PLSGLR models — coefs.plsRglm","title":"Coefficients for bootstrap computations of PLSGLR models — coefs.plsRglm","text":"function passed boot perform bootstrap.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coefficients for bootstrap computations of PLSGLR models — coefs.plsRglm","text":"","code":"coefs.plsRglm(   dataset,   ind,   nt,   modele,   family = NULL,   maxcoefvalues,   ifbootfail,   verbose )"},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coefficients for bootstrap computations of PLSGLR models — coefs.plsRglm","text":"dataset dataset resample ind indices resampling nt number components use modele type modele use, see plsRglm family glm family use, see plsRglm maxcoefvalues maximum values allowed estimates coefficients discard coming singular bootstrap samples ifbootfail value return estimation fails bootstrap sample verbose info messages displayed ?","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coefficients for bootstrap computations of PLSGLR models — coefs.plsRglm","text":"estimates bootstrap sample ifbootfail value bootstrap computation fails.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Coefficients for bootstrap computations of PLSGLR models — coefs.plsRglm","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coefficients for bootstrap computations of PLSGLR models — coefs.plsRglm","text":"","code":"data(Cornell)  # (Y,X) bootstrap of a PLSGLR model # statistic=coefs.plsRglm is the default for (Y,X) bootstrap of a PLSGLR models. set.seed(250) modplsglm <- plsRglm(Y~.,data=Cornell,1,modele=\"pls-glm-family\",family=gaussian) #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  Cornell.bootYX <- bootplsglm(modplsglm, R=250, typeboot=\"plsmodel\",  statistic=coefs.plsRglm, verbose=FALSE)"},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglm.raw.html","id":null,"dir":"Reference","previous_headings":"","what":"Raw coefficients for bootstrap computations of PLSGLR models — coefs.plsRglm.raw","title":"Raw coefficients for bootstrap computations of PLSGLR models — coefs.plsRglm.raw","text":"function passed boot perform bootstrap.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglm.raw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Raw coefficients for bootstrap computations of PLSGLR models — coefs.plsRglm.raw","text":"","code":"coefs.plsRglm.raw(   dataset,   ind,   nt,   modele,   family = NULL,   maxcoefvalues,   ifbootfail,   verbose )"},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglm.raw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Raw coefficients for bootstrap computations of PLSGLR models — coefs.plsRglm.raw","text":"dataset dataset resample ind indices resampling nt number components use modele type modele use, see plsRglm family glm family use, see plsRglm maxcoefvalues maximum values allowed estimates coefficients discard coming singular bootstrap samples ifbootfail value return estimation fails bootstrap sample verbose info messages displayed ?","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglm.raw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Raw coefficients for bootstrap computations of PLSGLR models — coefs.plsRglm.raw","text":"estimates bootstrap sample ifbootfail value bootstrap computation fails.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglm.raw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Raw coefficients for bootstrap computations of PLSGLR models — coefs.plsRglm.raw","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglm.raw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Raw coefficients for bootstrap computations of PLSGLR models — coefs.plsRglm.raw","text":"","code":"data(Cornell)  # (Y,X) bootstrap of a PLSGLR model set.seed(250) modplsglm <- coefs.plsRglm.raw(Cornell[,-8],1:nrow(Cornell),nt=3, modele=\"pls-glm-family\",family=gaussian,maxcoefvalues=1e5, ifbootfail=rep(0,3),verbose=FALSE)"},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglmnp.html","id":null,"dir":"Reference","previous_headings":"","what":"Coefficients for bootstrap computations of PLSGLR models — coefs.plsRglmnp","title":"Coefficients for bootstrap computations of PLSGLR models — coefs.plsRglmnp","text":"function passed boot perform bootstrap.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglmnp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coefficients for bootstrap computations of PLSGLR models — coefs.plsRglmnp","text":"","code":"coefs.plsRglmnp(   dataRepYtt,   ind,   nt,   modele,   family = NULL,   maxcoefvalues,   wwetoile,   ifbootfail )"},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglmnp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coefficients for bootstrap computations of PLSGLR models — coefs.plsRglmnp","text":"dataRepYtt components' coordinates bootstrap ind indices resampling nt number components use modele type modele use, see plsRglm family glm family use, see plsRglm maxcoefvalues maximum values allowed estimates coefficients discard coming singular bootstrap samples wwetoile values Wstar matrix original fit ifbootfail value return estimation fails bootstrap sample","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglmnp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coefficients for bootstrap computations of PLSGLR models — coefs.plsRglmnp","text":"estimates bootstrap sample ifbootfail value bootstrap computation fails.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglmnp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Coefficients for bootstrap computations of PLSGLR models — coefs.plsRglmnp","text":"~~notes~~","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglmnp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Coefficients for bootstrap computations of PLSGLR models — coefs.plsRglmnp","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRglmnp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coefficients for bootstrap computations of PLSGLR models — coefs.plsRglmnp","text":"","code":"data(Cornell)  # (Y,X) bootstrap of a PLSGLR model # statistic=coefs.plsRglm is the default for (Y,X) bootstrap of a PLSGLR models. set.seed(250) modplsglm <- plsRglm(Y~.,data=Cornell,1,modele=\"pls-glm-family\",family=gaussian) #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  Cornell.bootYT <- bootplsglm(modplsglm, R=250, statistic=coefs.plsRglmnp, verbose=FALSE)"},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRnp.html","id":null,"dir":"Reference","previous_headings":"","what":"Coefficients for bootstrap computations of PLSR models — coefs.plsRnp","title":"Coefficients for bootstrap computations of PLSR models — coefs.plsRnp","text":"function passed boot perform bootstrap.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRnp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coefficients for bootstrap computations of PLSR models — coefs.plsRnp","text":"","code":"coefs.plsRnp(dataRepYtt, ind, nt, modele, maxcoefvalues, wwetoile, ifbootfail)"},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRnp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coefficients for bootstrap computations of PLSR models — coefs.plsRnp","text":"dataRepYtt components' coordinates bootstrap ind indices resampling nt number components use modele type modele use, see plsRglm maxcoefvalues maximum values allowed estimates coefficients discard coming singular bootstrap samples wwetoile values Wstar matrix original fit ifbootfail value return estimation fails bootstrap sample","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRnp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coefficients for bootstrap computations of PLSR models — coefs.plsRnp","text":"estimates bootstrap sample ifbootfail value bootstrap computation fails.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRnp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Coefficients for bootstrap computations of PLSR models — coefs.plsRnp","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/coefs.plsRnp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coefficients for bootstrap computations of PLSR models — coefs.plsRnp","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8]  # Lazraq-Cleroux PLS (Y,X) bootstrap # statistic=coefs.plsR is the default for (Y,X) resampling of PLSR models. set.seed(250) modpls <- plsR(yCornell,XCornell,1) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  Cornell.bootYT <- bootpls(modpls, R=250, typeboot=\"fmodel_np\", statistic=coefs.plsRnp, verbose=FALSE)"},{"path":"https://fbertran.github.io/plsRglm/reference/confints.bootpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Bootstrap confidence intervals — confints.bootpls","title":"Bootstrap confidence intervals — confints.bootpls","text":"function wrapper boot.ci derive bootstrap-based confidence intervals \"boot\" object.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/confints.bootpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bootstrap confidence intervals — confints.bootpls","text":"","code":"confints.bootpls(bootobject, indices = NULL, typeBCa = TRUE)"},{"path":"https://fbertran.github.io/plsRglm/reference/confints.bootpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bootstrap confidence intervals — confints.bootpls","text":"bootobject object class \"boot\" indices indices predictor CIs calculated. Defaults NULL: predictors used. typeBCa shall BCa bootstrap based CI derived ? Defaults TRUE. safety option since sometimes computing BCa bootstrap based CI fails whereas types CI can still derived.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/confints.bootpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bootstrap confidence intervals — confints.bootpls","text":"Matrix limits bootstrap based CI (defaults) selected predictors (indices option). limits given order: Normal Lower Upper Limit, Basic Lower Upper Limit, Percentile Lower Upper Limit, BCa Lower Upper Limit.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/confints.bootpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bootstrap confidence intervals — confints.bootpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/confints.bootpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bootstrap confidence intervals — confints.bootpls","text":"","code":"# \\donttest{ data(Cornell)  #Lazraq-Cleroux PLS (Y,X) bootstrap set.seed(250) modpls <- plsR(Y~.,data=Cornell,3) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  Cornell.bootYX <- bootpls(modpls, R=250, verbose=FALSE) confints.bootpls(Cornell.bootYX,2:8) #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints #>                                                                          #> X1 -0.2305299 -0.03654653 -0.2146155 -0.01243502 -0.2657483 -0.063567788 #> X2 -0.3824730 -0.12056633 -0.4240731 -0.16474400 -0.2526435  0.006685662 #> X3 -0.2262325 -0.03807142 -0.2115428 -0.01464437 -0.2604663 -0.063567788 #> X4 -0.4336032 -0.19861671 -0.4793055 -0.22524165 -0.3610949 -0.107030999 #> X5 -0.2895056  0.13307318 -0.3083408  0.07915147 -0.1560125  0.231479782 #> X6  0.3197348  0.65767612  0.3256605  0.67125328  0.2415264  0.587119147 #> X7 -0.2387634 -0.03963758 -0.2590735 -0.03271142 -0.2540574 -0.027695351 #>                           #> X1 -0.2867282 -0.07494113 #> X2 -0.2795110 -0.11744873 #> X3 -0.2795040 -0.07955903 #> X4 -0.4109452 -0.17018880 #> X5 -0.1803183  0.17569760 #> X6  0.3172633  0.64752609 #> X7 -0.2222602  0.03146667 #> attr(,\"typeBCa\") #> [1] TRUE confints.bootpls(Cornell.bootYX,2:8,typeBCa=FALSE) #>                                                                          #> X1 -0.2305299 -0.03654653 -0.2146155 -0.01243502 -0.2657483 -0.063567788 #> X2 -0.3824730 -0.12056633 -0.4240731 -0.16474400 -0.2526435  0.006685662 #> X3 -0.2262325 -0.03807142 -0.2115428 -0.01464437 -0.2604663 -0.063567788 #> X4 -0.4336032 -0.19861671 -0.4793055 -0.22524165 -0.3610949 -0.107030999 #> X5 -0.2895056  0.13307318 -0.3083408  0.07915147 -0.1560125  0.231479782 #> X6  0.3197348  0.65767612  0.3256605  0.67125328  0.2415264  0.587119147 #> X7 -0.2387634 -0.03963758 -0.2590735 -0.03271142 -0.2540574 -0.027695351 #> attr(,\"typeBCa\") #> [1] FALSE # }"},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsR.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial least squares regression models with k-fold cross-validation — cv.plsR","title":"Partial least squares regression models with k-fold cross-validation — cv.plsR","text":"function implements k-fold cross-validation complete incomplete datasets partial least squares regression models","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial least squares regression models with k-fold cross-validation — cv.plsR","text":"","code":"cv.plsR(object, ...) # Default S3 method cv.plsRmodel(object,dataX,nt=2,limQ2set=.0975,modele=\"pls\",  K=5, NK=1, grouplist=NULL, random=TRUE, scaleX=TRUE,  scaleY=NULL, keepcoeffs=FALSE, keepfolds=FALSE, keepdataY=TRUE,  keepMclassed=FALSE, tol_Xi=10^(-12), weights, verbose=TRUE,...) # S3 method for class 'formula' cv.plsRmodel(object,data=NULL,nt=2,limQ2set=.0975,modele=\"pls\",  K=5, NK=1, grouplist=NULL, random=TRUE, scaleX=TRUE,  scaleY=NULL, keepcoeffs=FALSE, keepfolds=FALSE, keepdataY=TRUE,  keepMclassed=FALSE, tol_Xi=10^(-12), weights,subset,contrasts=NULL, verbose=TRUE,...) PLS_lm_kfoldcv(dataY, dataX, nt = 2, limQ2set = 0.0975, modele = \"pls\",  K = 5, NK = 1, grouplist = NULL, random = TRUE, scaleX = TRUE,  scaleY = NULL, keepcoeffs = FALSE, keepfolds = FALSE, keepdataY = TRUE,  keepMclassed=FALSE, tol_Xi = 10^(-12), weights, verbose=TRUE) PLS_lm_kfoldcv_formula(formula,data=NULL,nt=2,limQ2set=.0975,modele=\"pls\",  K=5, NK=1, grouplist=NULL, random=TRUE, scaleX=TRUE,  scaleY=NULL, keepcoeffs=FALSE, keepfolds=FALSE, keepdataY=TRUE,  keepMclassed=FALSE, tol_Xi=10^(-12), weights,subset,contrasts=NULL,verbose=TRUE)"},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial least squares regression models with k-fold cross-validation — cv.plsR","text":"object response (training) dataset object class \"formula\" (one can coerced class): symbolic description model fitted. details model specification given 'Details'. dataY response (training) dataset dataX predictor(s) (training) dataset formula object class \"formula\" (one can coerced class): symbolic description model fitted. details model specification given 'Details'. data optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found data, variables taken environment(formula), typically environment plsRglm called. nt number components extracted limQ2set limit value Q2 modele name PLS model fitted, (\"pls\" available fonction. K number groups. Defaults 5. NK number times group division made grouplist specify members K groups random K groups made randomly. Defaults TRUE scaleX scale predictor(s) : must set TRUE modele=\"pls\" glms pls. scaleY scale response : Yes/. Ignored since non always possible glm responses. keepcoeffs shall coefficients model returned keepfolds shall groups' composition returned keepdataY shall observed value response one predicted value returned keepMclassed shall number miss classed returned tol_Xi minimal value Norm2(Xi) \\(\\mathrm{det}(pp' \\times pp)\\) missing value dataX. defaults \\(10^{-12}\\) weights optional vector 'prior weights' used fitting process. NULL numeric vector. subset optional vector specifying subset observations used fitting process. contrasts optional list. See contrasts.arg model.matrix.default. verbose info messages displayed ? ... arguments pass cv.plsRmodel.default cv.plsRmodel.formula","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial least squares regression models with k-fold cross-validation — cv.plsR","text":"Predicts 1 group K-1 groups. Leave one cross validation thus obtained K==nrow(dataX). typical predictor form response ~ terms response (numeric) response vector terms series terms specifies linear predictor response. terms specification form first + second indicates terms first together terms second duplicates removed. specification form first:second indicates set terms obtained taking interactions terms first terms second. specification first*second indicates cross first second. first + second + first:second. terms formula re-ordered main effects come first, followed interactions, second-order, third-order : avoid pass terms object formula. Non-NULL weights can used indicate different observations different dispersions (values weights inversely proportional dispersions); equivalently, elements weights positive integers w_i, response y_i mean w_i unit-weight observations.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial least squares regression models with k-fold cross-validation — cv.plsR","text":"object class \"cv.plsRmodel\". results_kfolds list NK. element list sums results group division: list K matrices size nrow(dataX)/K * nt predicted values growing number components ... ... list K matrices size nrow(dataX)/K * nt predicted values growing number components  folds list NK. element list sums results group division: list K vectors length nrow(dataX) numbers rows dataX used training set ... ... list K vectors length nrow(dataX) numbers rows dataX used training set  dataY_kfolds list NK. element list sums results group division: list K matrices size nrow(dataX)/K * 1 observed values response ... ... list K matrices size nrow(dataX)/K * 1 observed values response  call call function","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partial least squares regression models with k-fold cross-validation — cv.plsR","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frederic Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Partial least squares regression models with k-fold cross-validation — cv.plsR","text":"Frederic Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsR.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Partial least squares regression models with k-fold cross-validation — cv.plsR","text":"Work complete incomplete datasets.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial least squares regression models with k-fold cross-validation — cv.plsR","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8]  #Leave one out CV (K=nrow(Cornell)) one time (NK=1) bbb <- cv.plsR(object=yCornell,dataX=XCornell,nt=6,K=nrow(Cornell),NK=1) #> NK: 1  #> Leave One Out #> Number of groups : 12  #> 1  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 6  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 7  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 8  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 9  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 10  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 11  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 5 components could thus be extracted #> ****________________________________________________**** #>  #> 12  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  bbb2 <- cv.plsR(Y~.,data=Cornell,nt=6,K=12,NK=1,verbose=FALSE) (sum1<-summary(bbb2)) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC    Q2cum_Y LimQ2_Y       Q2_Y  PRESS_Y      RSS_Y      R2_Y #> Nb_Comp_0 82.01205         NA      NA         NA       NA 467.796667        NA #> Nb_Comp_1 53.15173  0.8809146  0.0975  0.8809146 55.70774  35.742486 0.9235940 #> Nb_Comp_2 41.08283  0.8619560  0.0975 -0.1592015 41.43274  11.066606 0.9763431 #> Nb_Comp_3 32.06411  0.7471041  0.0975 -0.8319956 20.27397   4.418081 0.9905556 #> Nb_Comp_4 33.76477 -0.2159389  0.0975 -3.8080607 21.24240   4.309235 0.9907882 #> Nb_Comp_5 33.34373 -5.9182568  0.0975 -4.6896417 24.51801   3.521924 0.9924713 #> Nb_Comp_6 35.25533         NA  0.0975         NA       NA   3.496074 0.9925265 #>              AIC.std  DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof #> Nb_Comp_0  37.010388 1.000000    6.5212706 46.0708838 47.7893514 27.59461 #> Nb_Comp_1   8.150064 2.740749    1.8665281  4.5699686  4.9558156 21.34020 #> Nb_Comp_2  -3.918831 5.085967    1.1825195  2.1075461  2.3949331 27.40202 #> Nb_Comp_3 -12.937550 5.121086    0.7488308  0.8467795  0.9628191 24.40842 #> Nb_Comp_4 -11.236891 5.103312    0.7387162  0.8232505  0.9357846 24.23105 #> Nb_Comp_5 -11.657929 6.006316    0.7096382  0.7976101  0.9198348 28.21184 #> Nb_Comp_6  -9.746328 7.000002    0.7633343  0.9711322  1.1359502 33.18348 #>           DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0         1      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1         2      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2         3      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3         4      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4         5      0.7846050  0.8721072  0.9964867   24.16510 #> Nb_Comp_5         6      0.7661509  0.8804809  1.0227979   28.64206 #> Nb_Comp_6         7      0.8361907  1.1070902  1.3048716   33.63927 #> attr(,\"computed_nt\") #> [1] 6 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\"  #6-fold CV (K=6) two times (NK=2) #use random=TRUE to randomly create folds for repeated CV bbb3 <- cv.plsR(object=yCornell,dataX=XCornell,nt=6,K=6,NK=2) #> NK: 1  #> Number of groups : 6  #> 1  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 5 components could thus be extracted #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 6  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> NK: 2  #> Number of groups : 6  #> 1  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 5 components could thus be extracted #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 6  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  bbb4 <- cv.plsR(Y~.,data=Cornell,nt=6,K=6,NK=2,verbose=FALSE) (sum3<-summary(bbb4)) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1,  2 #> [[1]] #>                AIC    Q2cum_Y LimQ2_Y        Q2_Y  PRESS_Y      RSS_Y      R2_Y #> Nb_Comp_0 82.01205         NA      NA          NA       NA 467.796667        NA #> Nb_Comp_1 53.15173  0.8856252  0.0975  0.88562522 53.50414  35.742486 0.9235940 #> Nb_Comp_2 41.08283  0.8838671  0.0975 -0.01537155 36.29190  11.066606 0.9763431 #> Nb_Comp_3 32.06411  0.7763726  0.0975 -0.92561654 21.31004   4.418081 0.9905556 #> Nb_Comp_4 33.76477  0.2710856  0.0975 -2.25950371 14.40075   4.309235 0.9907882 #> Nb_Comp_5 33.34373 -2.4910745  0.0975 -3.78941633 20.63872   3.521924 0.9924713 #> Nb_Comp_6 35.25533         NA  0.0975          NA       NA   3.496074 0.9925265 #>              AIC.std  DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof #> Nb_Comp_0  37.010388 1.000000    6.5212706 46.0708838 47.7893514 27.59461 #> Nb_Comp_1   8.150064 2.740749    1.8665281  4.5699686  4.9558156 21.34020 #> Nb_Comp_2  -3.918831 5.085967    1.1825195  2.1075461  2.3949331 27.40202 #> Nb_Comp_3 -12.937550 5.121086    0.7488308  0.8467795  0.9628191 24.40842 #> Nb_Comp_4 -11.236891 5.103312    0.7387162  0.8232505  0.9357846 24.23105 #> Nb_Comp_5 -11.657929 6.006316    0.7096382  0.7976101  0.9198348 28.21184 #> Nb_Comp_6  -9.746328 7.000002    0.7633343  0.9711322  1.1359502 33.18348 #>           DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0         1      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1         2      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2         3      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3         4      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4         5      0.7846050  0.8721072  0.9964867   24.16510 #> Nb_Comp_5         6      0.7661509  0.8804809  1.0227979   28.64206 #> Nb_Comp_6         7      0.8361907  1.1070902  1.3048716   33.63927 #> attr(,\"computed_nt\") #> [1] 6 #>  #> [[2]] #>                AIC     Q2cum_Y LimQ2_Y       Q2_Y  PRESS_Y      RSS_Y      R2_Y #> Nb_Comp_0 82.01205          NA      NA         NA       NA 467.796667        NA #> Nb_Comp_1 53.15173   0.8557983  0.0975  0.8557983 67.45709  35.742486 0.9235940 #> Nb_Comp_2 41.08283   0.8000384  0.0975 -0.3866793 49.56337  11.066606 0.9763431 #> Nb_Comp_3 32.06411   0.4610525  0.0975 -1.6952557 29.82733   4.418081 0.9905556 #> Nb_Comp_4 33.76477  -3.1852578  0.0975 -6.7656125 34.30911   4.309235 0.9907882 #> Nb_Comp_5 33.34373 -32.0034334  0.0975 -6.8856394 33.98108   3.521924 0.9924713 #> Nb_Comp_6 35.25533          NA  0.0975         NA       NA   3.496074 0.9925265 #>              AIC.std  DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof #> Nb_Comp_0  37.010388 1.000000    6.5212706 46.0708838 47.7893514 27.59461 #> Nb_Comp_1   8.150064 2.740749    1.8665281  4.5699686  4.9558156 21.34020 #> Nb_Comp_2  -3.918831 5.085967    1.1825195  2.1075461  2.3949331 27.40202 #> Nb_Comp_3 -12.937550 5.121086    0.7488308  0.8467795  0.9628191 24.40842 #> Nb_Comp_4 -11.236891 5.103312    0.7387162  0.8232505  0.9357846 24.23105 #> Nb_Comp_5 -11.657929 6.006316    0.7096382  0.7976101  0.9198348 28.21184 #> Nb_Comp_6  -9.746328 7.000002    0.7633343  0.9711322  1.1359502 33.18348 #>           DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0         1      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1         2      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2         3      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3         4      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4         5      0.7846050  0.8721072  0.9964867   24.16510 #> Nb_Comp_5         6      0.7661509  0.8804809  1.0227979   28.64206 #> Nb_Comp_6         7      0.8361907  1.1070902  1.3048716   33.63927 #> attr(,\"computed_nt\") #> [1] 6 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\"  cvtable(sum1) #>  #> CV Q2 criterion: #> 0 1  #> 0 1  #>  #> CV Press criterion: #> 1 2 3  #> 0 0 1  cvtable(sum3) #>  #> CV Q2 criterion: #> 0 1  #> 0 2  #>  #> CV Press criterion: #> 1 2 3 4  #> 0 0 1 1  rm(list=c(\"XCornell\",\"yCornell\",\"bbb\",\"bbb2\",\"bbb3\",\"bbb4\"))"},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsRglm.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial least squares regression glm models with k-fold cross validation — cv.plsRglm","title":"Partial least squares regression glm models with k-fold cross validation — cv.plsRglm","text":"function implements k-fold cross-validation complete incomplete datasets partial least squares regression generalized linear models","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsRglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial least squares regression glm models with k-fold cross validation — cv.plsRglm","text":"","code":"cv.plsRglm(object, ...) # Default S3 method cv.plsRglmmodel(object,dataX,nt=2,limQ2set=.0975, modele=\"pls\", family=NULL, K=5, NK=1, grouplist=NULL, random=TRUE,  scaleX=TRUE, scaleY=NULL, keepcoeffs=FALSE, keepfolds=FALSE,  keepdataY=TRUE, keepMclassed=FALSE, tol_Xi=10^(-12), weights, method, verbose=TRUE,...) # S3 method for class 'formula' cv.plsRglmmodel(object,data=NULL,nt=2,limQ2set=.0975, modele=\"pls\", family=NULL, K=5, NK=1, grouplist=NULL, random=TRUE,  scaleX=TRUE, scaleY=NULL, keepcoeffs=FALSE, keepfolds=FALSE,  keepdataY=TRUE, keepMclassed=FALSE, tol_Xi=10^(-12),weights,subset, start=NULL,etastart,mustart,offset,method,control= list(),contrasts=NULL, verbose=TRUE,...) PLS_glm_kfoldcv(dataY, dataX, nt = 2, limQ2set = 0.0975, modele = \"pls\",  family = NULL, K = 5, NK = 1, grouplist = NULL, random = TRUE,  scaleX = TRUE, scaleY = NULL, keepcoeffs = FALSE, keepfolds = FALSE,  keepdataY = TRUE, keepMclassed=FALSE, tol_Xi = 10^(-12), weights, method, verbose=TRUE) PLS_glm_kfoldcv_formula(formula,data=NULL,nt=2,limQ2set=.0975,modele=\"pls\", family=NULL, K=5, NK=1, grouplist=NULL, random=TRUE,  scaleX=TRUE, scaleY=NULL, keepcoeffs=FALSE, keepfolds=FALSE, keepdataY=TRUE,  keepMclassed=FALSE, tol_Xi=10^(-12),weights,subset,start=NULL,etastart, mustart,offset,method,control= list(),contrasts=NULL, verbose=TRUE)"},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsRglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial least squares regression glm models with k-fold cross validation — cv.plsRglm","text":"object response (training) dataset object class \"formula\" (one can coerced class): symbolic description model fitted. details model specification given 'Details'. dataY response (training) dataset dataX predictor(s) (training) dataset formula object class \"formula\" (one can coerced class): symbolic description model fitted. details model specification given 'Details'. data optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found data, variables taken environment(formula), typically environment plsRglm called. nt number components extracted limQ2set limit value Q2 modele name PLS glm model fitted (\"pls\", \"pls-glm-Gamma\", \"pls-glm-gaussian\", \"pls-glm-inverse.gaussian\", \"pls-glm-logistic\", \"pls-glm-poisson\", \"pls-glm-polr\"). Use \"modele=pls-glm-family\" enable family option. family description error distribution link function used model. can character string naming family function, family function result call family function. (See family details family functions.) use family option, please set modele=\"pls-glm-family\". User defined families can also defined. See details. K number groups. Defaults 5. NK number times group division made grouplist specify members K groups random K groups made randomly. Defaults TRUE scaleX scale predictor(s) : must set TRUE modele=\"pls\" glms pls. scaleY scale response : Yes/. Ignored since non always possible glm responses. keepcoeffs shall coefficients model returned keepfolds shall groups' composition returned keepdataY shall observed value response one predicted value returned keepMclassed shall number miss classed returned (unavailable) tol_Xi minimal value Norm2(Xi) \\(\\mathrm{det}(pp' \\times pp)\\) missing value dataX. defaults \\(10^{-12}\\) weights optional vector 'prior weights' used fitting process. NULL numeric vector. subset optional vector specifying subset observations used fitting process. start starting values parameters linear predictor. etastart starting values linear predictor. mustart starting values vector means. offset can used specify priori known component included linear predictor fitting. NULL numeric vector length equal number cases. One offset terms can included formula instead well, one specified sum used. See model.offset. method fitting glms glm (\"pls-glm-Gamma\", \"pls-glm-gaussian\", \"pls-glm-inverse.gaussian\", \"pls-glm-logistic\", \"pls-glm-poisson\", \"modele=pls-glm-family\") method used fitting model. default method \"glm.fit\" uses iteratively reweighted least squares (IWLS). User-supplied fitting functions can supplied either function character string naming function, function takes arguments glm.fit. \"model.frame\", model frame returned. pls-glm-polr logistic, probit, complementary log-log cauchit (corresponding Cauchy latent variable). control list parameters controlling fitting process. glm.fit passed glm.control. contrasts optional list. See contrasts.arg model.matrix.default. verbose info messages displayed ? ... arguments pass cv.plsRglmmodel.default cv.plsRglmmodel.formula","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsRglm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial least squares regression glm models with k-fold cross validation — cv.plsRglm","text":"Predicts 1 group K-1 groups. Leave one cross validation thus obtained K==nrow(dataX). seven different predefined models predefined link functions available : \"pls\" ordinary pls models \"pls-glm-Gamma\" glm gaussian inverse link pls models \"pls-glm-gaussian\" glm gaussian identity link pls models \"pls-glm-inverse-gamma\" glm binomial square inverse link pls models \"pls-glm-logistic\" glm binomial logit link pls models \"pls-glm-poisson\" glm poisson log link pls models \"pls-glm-polr\" glm polr logit link pls models Using \"family=\" option setting \"modele=pls-glm-family\" allows changing family link function way glm function. consequence user-specified families can also used. gaussian family accepts links (names) identity, log inverse. binomial family accepts links logit, probit, cauchit, (corresponding logistic, normal Cauchy CDFs respectively) log cloglog (complementary log-log). Gamma family accepts links inverse, identity log. poisson family accepts links log, identity, sqrt. inverse.gaussian family accepts links 1/mu^2, inverse, identity log. quasi family accepts links logit, probit, cloglog, identity, inverse, log, 1/mu^2 sqrt. function power can used create power link function. ... arguments pass cv.plsRglmmodel.default cv.plsRglmmodel.formula typical predictor form response ~ terms response (numeric) response vector terms series terms specifies linear predictor response. terms specification form first + second indicates terms first together terms second duplicates removed. specification form first:second indicates set terms obtained taking interactions terms first terms second. specification first*second indicates cross first second. first + second + first:second. terms formula re-ordered main effects come first, followed interactions, second-order, third-order : avoid pass terms object formula. Non-NULL weights can used indicate different observations different dispersions (values weights inversely proportional dispersions); equivalently, elements weights positive integers w_i, response y_i mean w_i unit-weight observations.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsRglm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial least squares regression glm models with k-fold cross validation — cv.plsRglm","text":"object class \"cv.plsRglmmodel\". results_kfolds list NK. element list sums results group division: list K matrices size nrow(dataX)/K * nt predicted values growing number components ... ... list K matrices size nrow(dataX)/K * nt predicted values growing number components folds list NK. element list sums informations group division: list K vectors length nrow(dataX) numbers rows dataX used training set ... ... list K vectors length nrow(dataX) numbers rows dataX used training set  dataY_kfolds list NK. element list sums results group division: list K matrices size nrow(dataX)/K * 1 observed values response ... ... list K matrices size nrow(dataX)/K * 1 observed values response  call call function","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsRglm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partial least squares regression glm models with k-fold cross validation — cv.plsRglm","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frederic Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsRglm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Partial least squares regression glm models with k-fold cross validation — cv.plsRglm","text":"Frederic Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsRglm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Partial least squares regression glm models with k-fold cross validation — cv.plsRglm","text":"Work complete incomplete datasets.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/cv.plsRglm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial least squares regression glm models with k-fold cross validation — cv.plsRglm","text":"","code":"data(Cornell) bbb <- cv.plsRglm(Y~.,data=Cornell,nt=10) #>  #> Model: pls  #>  #> NK: 1  #> Number of groups : 5  #> 1  #> ____************************************************____ #>  #> Model: pls  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #>  #> Model: pls  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #>  #> Model: pls  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 5 components could thus be extracted #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #>  #> Model: pls  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #>  #> Model: pls  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ****________________________________________________**** #>  (sum1<-summary(bbb)) #> ____************************************************____ #>  #> Model: pls  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC     Q2cum_Y LimQ2_Y       Q2_Y  PRESS_Y      RSS_Y      R2_Y #> Nb_Comp_0 82.01205          NA      NA         NA       NA 467.796667        NA #> Nb_Comp_1 53.15173   0.8625059  0.0975  0.8625059 64.31930  35.742486 0.9235940 #> Nb_Comp_2 41.08283   0.8328694  0.0975 -0.2155470 43.44667  11.066606 0.9763431 #> Nb_Comp_3 32.06411   0.5549232  0.0975 -1.6630483 29.47091   4.418081 0.9905556 #> Nb_Comp_4 33.76477  -2.9860985  0.0975 -7.9559789 39.56824   4.309235 0.9907882 #> Nb_Comp_5 33.34373 -33.2216598  0.0975 -7.5852520 36.99587   3.521924 0.9924713 #> Nb_Comp_6 35.25533          NA  0.0975         NA       NA   3.496074 0.9925265 #>              AIC.std  DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof #> Nb_Comp_0  37.010388 1.000000    6.5212706 46.0708838 47.7893514 27.59461 #> Nb_Comp_1   8.150064 2.740749    1.8665281  4.5699686  4.9558156 21.34020 #> Nb_Comp_2  -3.918831 5.085967    1.1825195  2.1075461  2.3949331 27.40202 #> Nb_Comp_3 -12.937550 5.121086    0.7488308  0.8467795  0.9628191 24.40842 #> Nb_Comp_4 -11.236891 5.103312    0.7387162  0.8232505  0.9357846 24.23105 #> Nb_Comp_5 -11.657929 6.006316    0.7096382  0.7976101  0.9198348 28.21184 #> Nb_Comp_6  -9.746328 7.000002    0.7633343  0.9711322  1.1359502 33.18348 #>           DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0         1      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1         2      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2         3      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3         4      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4         5      0.7846050  0.8721072  0.9964867   24.16510 #> Nb_Comp_5         6      0.7661509  0.8804809  1.0227979   28.64206 #> Nb_Comp_6         7      0.8361907  1.1070902  1.3048716   33.63927 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\" cvtable(sum1) #>  #> CV Q2 criterion: #> 0 1  #> 0 1  #>  #> CV Press criterion: #> 1 2 3  #> 0 0 1   bbb2 <- cv.plsRglm(Y~.,data=Cornell,nt=3, modele=\"pls-glm-family\",family=gaussian(),K=12,verbose=FALSE) (sum2<-summary(bbb2)) #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 82.01205 82.98186           NA     NA         NA                NA #> Nb_Comp_1 53.15173 54.60645    0.8809146 0.0975  0.8809146          55.70774 #> Nb_Comp_2 31.46903 33.40866    0.9182731 0.0975  0.3137113          24.52966 #> Nb_Comp_3 31.54404 33.96857    0.6570253 0.0975 -3.1965930          20.84377 #>           Chi2_Pearson_Y      RSS_Y      R2_Y #> Nb_Comp_0     467.796667 467.796667        NA #> Nb_Comp_1      35.742486  35.742486 0.9235940 #> Nb_Comp_2       4.966831   4.966831 0.9893825 #> Nb_Comp_3       4.230693   4.230693 0.9909561 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" cvtable(sum2) #>  #> CV Q2Chi2 criterion: #> 0 1 2  #> 0 0 1  #>  #> CV PreChi2 criterion: #> 1 2 3  #> 0 0 1   # \\donttest{ #random=TRUE is the default to randomly create folds for repeated CV bbb3 <- cv.plsRglm(Y~.,data=Cornell,nt=3, modele=\"pls-glm-family\",family=gaussian(),K=6,NK=10, verbose=FALSE) (sum3<-summary(bbb3)) #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1,  2,  3,  4,  5,  6,  7,  8,  9,  10 #> [[1]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 82.01205 82.98186           NA     NA         NA                NA #> Nb_Comp_1 53.15173 54.60645    0.8909831 0.0975  0.8909831          50.99774 #> Nb_Comp_2 31.46903 33.40866    0.9186718 0.0975  0.2539856          26.66441 #> Nb_Comp_3 31.54404 33.96857    0.7075171 0.0975 -2.5963292          17.86236 #>           Chi2_Pearson_Y      RSS_Y      R2_Y #> Nb_Comp_0     467.796667 467.796667        NA #> Nb_Comp_1      35.742486  35.742486 0.9235940 #> Nb_Comp_2       4.966831   4.966831 0.9893825 #> Nb_Comp_3       4.230693   4.230693 0.9909561 #>  #> [[2]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 82.01205 82.98186           NA     NA         NA                NA #> Nb_Comp_1 53.15173 54.60645    0.8941767 0.0975  0.8941767          49.50377 #> Nb_Comp_2 31.46903 33.40866    0.8696415 0.0975 -0.2318510          44.02942 #> Nb_Comp_3 31.54404 33.96857    0.2809944 0.0975 -4.5156021          27.39506 #>           Chi2_Pearson_Y      RSS_Y      R2_Y #> Nb_Comp_0     467.796667 467.796667        NA #> Nb_Comp_1      35.742486  35.742486 0.9235940 #> Nb_Comp_2       4.966831   4.966831 0.9893825 #> Nb_Comp_3       4.230693   4.230693 0.9909561 #>  #> [[3]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 82.01205 82.98186           NA     NA         NA                NA #> Nb_Comp_1 53.15173 54.60645    0.8920096 0.0975  0.8920096          50.51753 #> Nb_Comp_2 31.46903 33.40866    0.9224725 0.0975  0.2820887          25.65994 #> Nb_Comp_3 31.54404 33.96857    0.7961141 0.0975 -1.6298534          13.06204 #>           Chi2_Pearson_Y      RSS_Y      R2_Y #> Nb_Comp_0     467.796667 467.796667        NA #> Nb_Comp_1      35.742486  35.742486 0.9235940 #> Nb_Comp_2       4.966831   4.966831 0.9893825 #> Nb_Comp_3       4.230693   4.230693 0.9909561 #>  #> [[4]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 82.01205 82.98186           NA     NA         NA                NA #> Nb_Comp_1 53.15173 54.60645    0.8650559 0.0975  0.8650559          63.12640 #> Nb_Comp_2 31.46903 33.40866    0.9351616 0.0975  0.5195166          17.17367 #> Nb_Comp_3 31.54404 33.96857    0.8063984 0.0975 -1.9859086          14.83050 #>           Chi2_Pearson_Y      RSS_Y      R2_Y #> Nb_Comp_0     467.796667 467.796667        NA #> Nb_Comp_1      35.742486  35.742486 0.9235940 #> Nb_Comp_2       4.966831   4.966831 0.9893825 #> Nb_Comp_3       4.230693   4.230693 0.9909561 #>  #> [[5]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 82.01205 82.98186           NA     NA         NA                NA #> Nb_Comp_1 53.15173 54.60645    0.8767872 0.0975  0.8767872          57.63854 #> Nb_Comp_2 31.46903 33.40866    0.8506422 0.0975 -0.2121934          43.32681 #> Nb_Comp_3 31.54404 33.96857    0.5192922 0.0975 -2.2184994          15.98574 #>           Chi2_Pearson_Y      RSS_Y      R2_Y #> Nb_Comp_0     467.796667 467.796667        NA #> Nb_Comp_1      35.742486  35.742486 0.9235940 #> Nb_Comp_2       4.966831   4.966831 0.9893825 #> Nb_Comp_3       4.230693   4.230693 0.9909561 #>  #> [[6]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 82.01205 82.98186           NA     NA         NA                NA #> Nb_Comp_1 53.15173 54.60645    0.8943815 0.0975  0.8943815          49.40800 #> Nb_Comp_2 31.46903 33.40866    0.8694290 0.0975 -0.2362506          44.18667 #> Nb_Comp_3 31.54404 33.96857    0.2786060 0.0975 -4.5249187          27.44134 #>           Chi2_Pearson_Y      RSS_Y      R2_Y #> Nb_Comp_0     467.796667 467.796667        NA #> Nb_Comp_1      35.742486  35.742486 0.9235940 #> Nb_Comp_2       4.966831   4.966831 0.9893825 #> Nb_Comp_3       4.230693   4.230693 0.9909561 #>  #> [[7]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 82.01205 82.98186           NA     NA         NA                NA #> Nb_Comp_1 53.15173 54.60645    0.8786200 0.0975  0.8786200          56.78115 #> Nb_Comp_2 31.46903 33.40866    0.8966674 0.0975  0.1486847          30.42813 #> Nb_Comp_3 31.54404 33.96857    0.7057117 0.0975 -1.8479707          14.14539 #>           Chi2_Pearson_Y      RSS_Y      R2_Y #> Nb_Comp_0     467.796667 467.796667        NA #> Nb_Comp_1      35.742486  35.742486 0.9235940 #> Nb_Comp_2       4.966831   4.966831 0.9893825 #> Nb_Comp_3       4.230693   4.230693 0.9909561 #>  #> [[8]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 82.01205 82.98186           NA     NA         NA                NA #> Nb_Comp_1 53.15173 54.60645   0.89262850 0.0975  0.8926285          50.22803 #> Nb_Comp_2 31.46903 33.40866   0.82478362 0.0975 -0.6318705          58.32711 #> Nb_Comp_3 31.54404 33.96857   0.05193796 0.0975 -4.4108070          26.87456 #>           Chi2_Pearson_Y      RSS_Y      R2_Y #> Nb_Comp_0     467.796667 467.796667        NA #> Nb_Comp_1      35.742486  35.742486 0.9235940 #> Nb_Comp_2       4.966831   4.966831 0.9893825 #> Nb_Comp_3       4.230693   4.230693 0.9909561 #>  #> [[9]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 82.01205 82.98186           NA     NA         NA                NA #> Nb_Comp_1 53.15173 54.60645    0.8935639 0.0975  0.8935639          49.79045 #> Nb_Comp_2 31.46903 33.40866    0.9164468 0.0975  0.2149922          28.05813 #> Nb_Comp_3 31.54404 33.96857    0.6378345 0.0975 -3.3345511          21.52898 #>           Chi2_Pearson_Y      RSS_Y      R2_Y #> Nb_Comp_0     467.796667 467.796667        NA #> Nb_Comp_1      35.742486  35.742486 0.9235940 #> Nb_Comp_2       4.966831   4.966831 0.9893825 #> Nb_Comp_3       4.230693   4.230693 0.9909561 #>  #> [[10]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 82.01205 82.98186           NA     NA         NA                NA #> Nb_Comp_1 53.15173 54.60645   0.83094829 0.0975  0.8309483          79.08183 #> Nb_Comp_2 31.46903 33.40866   0.86100399 0.0975  0.1777900          29.38783 #> Nb_Comp_3 31.54404 33.96857   0.04531766 0.0975 -5.8684157          34.11426 #>           Chi2_Pearson_Y      RSS_Y      R2_Y #> Nb_Comp_0     467.796667 467.796667        NA #> Nb_Comp_1      35.742486  35.742486 0.9235940 #> Nb_Comp_2       4.966831   4.966831 0.9893825 #> Nb_Comp_3       4.230693   4.230693 0.9909561 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" plot(cvtable(sum3)) #>  #> CV Q2Chi2 criterion: #> 0 1 2  #> 0 4 6  #>  #> CV PreChi2 criterion: #> 1 2 3  #> 0 1 9    data(aze_compl) bbb <- cv.plsRglm(y~.,data=aze_compl,nt=10,K=10,modele=\"pls\",keepcoeffs=TRUE, verbose=FALSE)  #For Jackknife computations kfolds2coeff(bbb) #>              [,1]        [,2]      [,3]       [,4]      [,5]       [,6] #>  [1,]  0.17952318 -0.18358069 0.5161098 -0.1970097 0.3432269 0.14406722 #>  [2,]  0.35486763 -0.13637388 0.3957869 -0.2173580 0.3219187 0.03170179 #>  [3,]  0.33521485 -0.11313171 0.3619222 -0.2489085 0.2235826 0.14783733 #>  [4,]  0.36137537 -0.13489880 0.4751676 -0.1456797 0.3143053 0.07825339 #>  [5,]  0.39892318 -0.14974277 0.4912091 -0.1333353 0.2465573 0.04141418 #>  [6,]  0.35575963 -0.15979357 0.4360585 -0.1439848 0.1418600 0.09004068 #>  [7,]  0.36192756 -0.16936160 0.3541551 -0.1643634 0.2103803 0.17025162 #>  [8,]  0.37423079 -0.11674480 0.4160774 -0.1919962 0.2852640 0.13706961 #>  [9,] -0.02132443 -0.10957065 0.5659451 -0.2705819 0.3429421 0.11972351 #> [10,]  0.22012069 -0.06492909 0.5845200 -0.1663546 0.3168039 0.04866365 #>               [,7]         [,8]       [,9]        [,10]        [,11] #>  [1,]  0.005055119 -0.038703832 -0.2571432  0.146789151 -0.168382704 #>  [2,] -0.019036273 -0.003253334 -0.2559151  0.118744491 -0.075399509 #>  [3,] -0.121191704  0.107641274 -0.1411623  0.093327808 -0.059216708 #>  [4,] -0.152479468  0.023338255 -0.1098179  0.008658965 -0.141339811 #>  [5,] -0.111047521 -0.023397267 -0.2485575 -0.065852638 -0.038422674 #>  [6,] -0.015909361  0.007412513 -0.1291427  0.063113505 -0.057988769 #>  [7,] -0.093195865  0.042269770 -0.1805481 -0.003189911 -0.125462227 #>  [8,] -0.116861565 -0.002197013 -0.2515660  0.032865891  0.017641030 #>  [9,] -0.012303380 -0.046829189 -0.2522609  0.041513610 -0.007180318 #> [10,]  0.060093993  0.065599396 -0.2409495  0.037350847 -0.204718238 #>               [,12]       [,13]      [,14]       [,15]       [,16]        [,17] #>  [1,]  0.1249068075 -0.17751959 0.10265542 0.007837119  0.10071757  0.118916503 #>  [2,] -0.0022470110 -0.12354564 0.12454837 0.039703445  0.01694103  0.022199126 #>  [3,]  0.0752765026 -0.04104846 0.07988420 0.066697127  0.07220045  0.009193862 #>  [4,]  0.0243577425 -0.08327565 0.14772026 0.089837980  0.12111513  0.004168097 #>  [5,]  0.0706978339 -0.16541495 0.15677722 0.183976063 -0.05341081  0.060792750 #>  [6,]  0.0200666191 -0.06576887 0.06466309 0.117137444  0.03326864 -0.029718013 #>  [7,]  0.0754839409 -0.10527587 0.12421903 0.184423100  0.04300596 -0.105705980 #>  [8,]  0.0055059576 -0.09703297 0.14873490 0.080873461  0.08790355 -0.050843806 #>  [9,]  0.1244068338 -0.24806077 0.10833856 0.118967892  0.06089489  0.002948510 #> [10,] -0.0002526879 -0.18986208 0.08533294 0.187802532  0.08557121  0.053980146 #>           [,18]        [,19]       [,20]       [,21]       [,22]      [,23] #>  [1,] 0.2350007 -0.042572440  0.11002000 -0.17439453  0.11034362 0.27575858 #>  [2,] 0.2924087  0.010195821  0.06649023 -0.11157999  0.08148841 0.20909839 #>  [3,] 0.1810613  0.049828840 -0.01354591 -0.22894350  0.13780002 0.19368056 #>  [4,] 0.2280875 -0.007786965 -0.01794921 -0.10961352  0.13152759 0.05164439 #>  [5,] 0.1814771  0.044180255  0.11897818 -0.09146756 -0.02083331 0.26713912 #>  [6,] 0.2114864 -0.073119375  0.07654015 -0.18757912  0.07562632 0.16732477 #>  [7,] 0.2884797  0.061275351  0.08129355 -0.06677417  0.07334575 0.11644107 #>  [8,] 0.2495068  0.048902989  0.10683997 -0.06861327  0.06705986 0.15148672 #>  [9,] 0.3647231 -0.021627249  0.05201960 -0.05902643  0.08953918 0.18270856 #> [10,] 0.1907015  0.064084386  0.18049238 -0.10081597 -0.07573383 0.27895839 #>             [,24]      [,25]      [,26]      [,27]     [,28]       [,29] #>  [1,] -0.21923953 -0.2446405 -0.3733561 0.19518539 0.2252522 -0.18334833 #>  [2,] -0.19784877 -0.1763453 -0.3101657 0.20005392 0.1613447 -0.04828271 #>  [3,] -0.10504568 -0.1764676 -0.2070636 0.09461131 0.2380637 -0.07371022 #>  [4,] -0.15396328 -0.2432382 -0.2015450 0.21816483 0.1523498 -0.12841479 #>  [5,] -0.14435273 -0.1305746 -0.3134875 0.12506679 0.1454776 -0.10287116 #>  [6,] -0.08353783 -0.1654616 -0.2942352 0.23180525 0.2992130 -0.07559580 #>  [7,] -0.07799205 -0.1208744 -0.3483218 0.17504792 0.1808582 -0.08645249 #>  [8,] -0.14895954 -0.1674702 -0.3162844 0.23426714 0.2464161 -0.18714513 #>  [9,] -0.19616815 -0.0310772 -0.2753396 0.20505455 0.1873829 -0.11823695 #> [10,] -0.15493743 -0.3530348 -0.2561731 0.15461451 0.1007065 -0.02512739 #>              [,30]        [,31]         [,32]      [,33]        [,34] #>  [1,]  0.065690072  0.088159481 -0.0322657267 -0.2784938  0.042173811 #>  [2,]  0.009509667  0.182200256 -0.0863661964 -0.3992084  0.043228795 #>  [3,] -0.031892160  0.148228132 -0.0687252063 -0.4172826 -0.081560209 #>  [4,]  0.023731318  0.126998699 -0.0359740247 -0.4201255  0.037335195 #>  [5,]  0.061829943 -0.028519777  0.0004144259 -0.3579925  0.040781211 #>  [6,] -0.051164051  0.115084495  0.0446461823 -0.5016755 -0.003751708 #>  [7,] -0.019958880  0.177658366 -0.0183375618 -0.4407841 -0.091256937 #>  [8,]  0.021704477  0.111346123 -0.0931150117 -0.4516393 -0.010121379 #>  [9,]  0.054898697  0.206397884 -0.1818664097 -0.3522866 -0.029160853 #> [10,]  0.032878376  0.006803997  0.0331389178 -0.3266800 -0.038402853 bbb2 <- cv.plsRglm(y~.,data=aze_compl,nt=10,K=10,modele=\"pls-glm-family\", family=binomial(probit),keepcoeffs=TRUE, verbose=FALSE) bbb2 <- cv.plsRglm(y~.,data=aze_compl,nt=10,K=10, modele=\"pls-glm-logistic\",keepcoeffs=TRUE, verbose=FALSE) summary(bbb,MClassed=TRUE) #> ____************************************************____ #>  #> Model: pls  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                 AIC MissClassed CV_MissClassed       Q2cum_Y LimQ2_Y       Q2_Y #> Nb_Comp_0  154.6179          49             NA            NA      NA         NA #> Nb_Comp_1  126.4083          27             49    -0.1768169  0.0975 -0.1768169 #> Nb_Comp_2  119.3375          25             48    -0.8158860  0.0975 -0.5430488 #> Nb_Comp_3  114.2313          27             49    -2.4018547  0.0975 -0.8733856 #> Nb_Comp_4  112.3463          23             50    -6.5321615  0.0975 -1.2141338 #> Nb_Comp_5  113.2362          22             50   -16.2613341  0.0975 -1.2916840 #> Nb_Comp_6  114.7620          21             50   -39.7178594  0.0975 -1.3589057 #> Nb_Comp_7  116.5264          20             50   -95.8630906  0.0975 -1.3788846 #> Nb_Comp_8  118.4601          20             51  -231.0774120  0.0975 -1.3959323 #> Nb_Comp_9  120.4452          19             51  -556.5611537  0.0975 -1.4024792 #> Nb_Comp_10 122.4395          19             51 -1338.2107374  0.0975 -1.4019083 #>             PRESS_Y    RSS_Y      R2_Y  AIC.std  DoF.dof sigmahat.dof   AIC.dof #> Nb_Comp_0        NA 25.91346        NA 298.1344  1.00000    0.5015845 0.2540061 #> Nb_Comp_1  30.49540 19.38086 0.2520929 269.9248 22.55372    0.4848429 0.2883114 #> Nb_Comp_2  29.90562 17.76209 0.3145613 262.8540 27.31542    0.4781670 0.2908950 #> Nb_Comp_3  33.27524 16.58896 0.3598323 257.7478 30.52370    0.4719550 0.2902572 #> Nb_Comp_4  36.73018 15.98071 0.3833049 255.8628 34.00000    0.4744263 0.3008285 #> Nb_Comp_5  36.62273 15.81104 0.3898523 256.7527 34.00000    0.4719012 0.2976347 #> Nb_Comp_6  37.29675 15.73910 0.3926285 258.2785 34.00000    0.4708264 0.2962804 #> Nb_Comp_7  37.44150 15.70350 0.3940024 260.0429 33.71066    0.4693382 0.2937976 #> Nb_Comp_8  37.62451 15.69348 0.3943888 261.9766 34.00000    0.4701436 0.2954217 #> Nb_Comp_9  37.70326 15.69123 0.3944758 263.9617 33.87284    0.4696894 0.2945815 #> Nb_Comp_10 37.68889 15.69037 0.3945088 265.9560 34.00000    0.4700970 0.2953632 #>              BIC.dof  GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive #> Nb_Comp_0  0.2604032 -67.17645         1      0.5015845 0.2540061 0.2604032 #> Nb_Comp_1  0.4231184 -53.56607         2      0.4358996 0.1936625 0.2033251 #> Nb_Comp_2  0.4496983 -52.42272         3      0.4193593 0.1809352 0.1943501 #> Nb_Comp_3  0.4631316 -51.93343         4      0.4072955 0.1722700 0.1891422 #> Nb_Comp_4  0.4954133 -50.37079         5      0.4017727 0.1691819 0.1897041 #> Nb_Comp_5  0.4901536 -50.65724         6      0.4016679 0.1706451 0.1952588 #> Nb_Comp_6  0.4879234 -50.78005         7      0.4028135 0.1731800 0.2020601 #> Nb_Comp_7  0.4826103 -51.05525         8      0.4044479 0.1761610 0.2094352 #> Nb_Comp_8  0.4865092 -50.85833         9      0.4064413 0.1794902 0.2172936 #> Nb_Comp_9  0.4845867 -50.95616        10      0.4085682 0.1829787 0.2254232 #> Nb_Comp_10 0.4864128 -50.86368        11      0.4107477 0.1865584 0.2337468 #>            GMDL.naive #> Nb_Comp_0   -67.17645 #> Nb_Comp_1   -79.67755 #> Nb_Comp_2   -81.93501 #> Nb_Comp_3   -83.31503 #> Nb_Comp_4   -83.23369 #> Nb_Comp_5   -81.93513 #> Nb_Comp_6   -80.42345 #> Nb_Comp_7   -78.87607 #> Nb_Comp_8   -77.31942 #> Nb_Comp_9   -75.80069 #> Nb_Comp_10  -74.33325 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\" summary(bbb2,MClassed=TRUE) #> ____************************************************____ #>  #> Family: binomial  #> Link function: logit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                 AIC      BIC MissClassed CV_MissClassed  Q2Chisqcum_Y  limQ2 #> Nb_Comp_0  145.8283 148.4727          49             NA            NA     NA #> Nb_Comp_1  118.1398 123.4285          28             44 -1.137905e+00 0.0975 #> Nb_Comp_2  109.9553 117.8885          26             45 -7.911290e+00 0.0975 #> Nb_Comp_3  105.1591 115.7366          22             49 -2.196646e+02 0.0975 #> Nb_Comp_4  103.8382 117.0601          21             48 -9.534571e+03 0.0975 #> Nb_Comp_5  104.7338 120.6001          21             50 -4.735207e+05 0.0975 #> Nb_Comp_6  105.6770 124.1878          21             48 -3.105521e+07 0.0975 #> Nb_Comp_7  107.2828 128.4380          20             48 -2.872864e+09 0.0975 #> Nb_Comp_8  109.0172 132.8167          22             50 -3.179467e+11 0.0975 #> Nb_Comp_9  110.9354 137.3793          21             49 -3.493236e+13 0.0975 #> Nb_Comp_10 112.9021 141.9904          20             48 -3.755538e+15 0.0975 #>              Q2Chisq_Y PREChi2_Pearson_Y Chi2_Pearson_Y    RSS_Y      R2_Y #> Nb_Comp_0           NA                NA      104.00000 25.91346        NA #> Nb_Comp_1    -1.137905          222.3421      100.53823 19.32272 0.2543365 #> Nb_Comp_2    -3.168234          419.0669       99.17955 17.33735 0.3309519 #> Nb_Comp_3   -23.762360         2455.9199      123.37836 15.58198 0.3986915 #> Nb_Comp_4   -42.212970         5331.5453      114.77551 15.14046 0.4157299 #> Nb_Comp_5   -48.658454         5699.5744      105.35382 15.08411 0.4179043 #> Nb_Comp_6   -64.583493         6909.4714       98.87767 14.93200 0.4237744 #> Nb_Comp_7   -91.508279         9147.0030       97.04072 14.87506 0.4259715 #> Nb_Comp_8  -109.672382        10739.7273       98.90110 14.84925 0.4269676 #> Nb_Comp_9  -108.868593        10866.1246      100.35563 14.84317 0.4272022 #> Nb_Comp_10 -106.508863        10789.1196      102.85214 14.79133 0.4292027 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" kfolds2coeff(bbb2) #>            [,1]       [,2]     [,3]      [,4]     [,5]       [,6]        [,7] #>  [1,] -1.965799 -1.0199331 3.648911 -1.827265 2.662801  0.8363928 -0.20691823 #>  [2,] -1.830537 -0.7563970 2.471137 -1.328305 1.373733  0.2233750 -0.01177607 #>  [3,] -2.407847 -2.0298046 3.945164 -1.373957 1.150147  0.5031490 -0.28988306 #>  [4,] -3.203007 -2.8372141 5.033710 -2.342386 2.849491  0.5291630 -0.35109681 #>  [5,] -3.921451 -2.3715250 4.589552 -2.449563 3.207610  1.0504067 -0.28974803 #>  [6,] -3.282263 -1.0293596 3.976786 -1.858869 2.238536  0.1722852 -0.05050652 #>  [7,] -2.812126 -0.6713289 5.375383 -1.346515 3.262103 -0.3730782  0.54959518 #>  [8,] -1.927544 -1.1442212 3.731474 -3.196959 3.488297  0.9931449 -0.44058243 #>  [9,] -1.531716 -0.8715758 3.034173 -1.404271 1.773505  0.6354226  0.11996263 #> [10,] -2.414664 -0.3558774 3.794280 -1.785590 1.969097  1.6414859 -0.25026263 #>              [,8]       [,9]      [,10]       [,11]       [,12]      [,13] #>  [1,] -0.49557050 -2.2071901  0.3144860 -0.54202797  0.89228175 -1.3974488 #>  [2,]  0.08175729 -0.8963582  0.3744940 -0.82162989  0.95615239 -0.9206204 #>  [3,]  0.43607504 -0.3824681  0.3625755 -1.45131465  0.84913838 -0.3492717 #>  [4,] -0.58858681 -1.2308754  1.7161346 -1.43443870  0.69995889 -1.4772216 #>  [5,] -0.35619065 -1.8369971 -0.5525098 -0.89540254  1.90236001 -1.0874626 #>  [6,] -0.37069014 -1.1498791 -0.0109854 -0.54891131  0.37492146 -0.5548299 #>  [7,] -0.30273554 -2.3051430  0.6134508 -1.03987768  0.29071503 -1.0123951 #>  [8,]  0.72584141 -1.4468813  0.6799241 -1.48397492  0.74533508 -0.3907250 #>  [9,] -0.92881692 -1.4740544  0.2470470 -0.78119954  0.46362094 -1.2201283 #> [10,] -0.50050095 -1.6644052  0.9803552 -0.05002341 -0.02921065 -1.8217372 #>            [,14]     [,15]      [,16]      [,17]    [,18]        [,19] #>  [1,]  0.4358246 0.6140765  0.4353961 1.03774234 1.831834 -0.196193746 #>  [2,]  0.4477398 0.9288757  0.3006236 0.13455052 1.987615 -0.100381114 #>  [3,]  0.3238327 1.3386612 -0.1676638 1.05782999 1.098517  0.615658509 #>  [4,]  1.8742007 0.5617816  3.9698098 1.75700382 1.849360 -1.337655891 #>  [5,] -0.1440952 1.5457708 -0.2065585 0.42532822 3.712537  0.334844801 #>  [6,]  0.6290360 0.2229422  0.6668117 0.67706931 1.594161  0.001342479 #>  [7,]  0.2792567 1.0277483  0.6998584 0.71725754 1.622390  0.400745609 #>  [8,]  0.4989434 0.3625643  0.6576075 0.05803996 2.996122 -0.013229745 #>  [9,]  0.8207341 0.8339903  0.5055199 0.60297127 1.527743 -0.430524781 #> [10,]  2.6738156 0.8785213  0.2864730 0.12896572 1.034729  0.113203504 #>              [,20]      [,21]      [,22]      [,23]       [,24]     [,25] #>  [1,]  0.972378415 -0.4871654  0.5628326  1.8361471 -1.28128703 -1.988099 #>  [2,]  0.627611896 -0.6617926  0.7704099  1.5821050 -1.33485590 -1.477002 #>  [3,]  1.174386144 -1.2668516  0.2016689  0.8706718 -0.07905719 -2.052309 #>  [4,]  1.595173575 -2.4129503  1.3251517 -0.5706750 -0.93031259 -2.544465 #>  [5,]  1.116156919 -1.5859034  0.1183023  1.8599384 -1.50675883 -1.298512 #>  [6,]  0.303664715 -0.3820341  0.1644571  1.4632345 -1.39241213 -1.340381 #>  [7,]  0.183816922 -1.4149841 -0.4554074  2.0560514 -1.35446911 -1.867863 #>  [8,] -0.098670036 -1.1387885  0.4048529  1.1567518 -2.55717510 -1.480850 #>  [9,]  0.739530460 -1.0162033  0.1812029  1.7540139 -0.88453664 -1.599275 #> [10,]  0.007075075 -0.9902770  0.6096433  1.2025498 -1.56825066 -1.090705 #>           [,26]    [,27]     [,28]      [,29]      [,30]     [,31]      [,32] #>  [1,] -2.337064 1.388788 1.5932181 -0.5114985  0.7249617 1.0289371 -0.4060729 #>  [2,] -1.787068 1.183226 1.3537645 -0.3917539  0.5019871 0.7369473 -0.4116624 #>  [3,] -2.629235 2.833334 2.1034713 -0.2423233 -0.5243678 1.6754232 -0.3921395 #>  [4,] -1.430462 0.695463 1.5404238 -0.4989249  0.4161941 1.3803824 -0.3206621 #>  [5,] -2.792315 2.118639 1.5949681 -0.7218437  0.3504715 1.8499016  0.4807796 #>  [6,] -1.558588 1.458914 1.4431533 -0.5113983  0.5674723 1.9399099 -0.4903038 #>  [7,] -2.215763 1.773044 0.9484737 -0.6892981  0.6376707 1.1413413  0.2866099 #>  [8,] -3.023586 1.985707 2.0889874  0.4568915  0.8408701 1.5481679 -0.9643611 #>  [9,] -1.775669 1.827119 1.3916357 -0.3777829  0.2414968 0.9526591 -0.2185785 #> [10,] -2.488184 1.647320 2.1733116 -1.3909588  0.7063196 1.5892143 -0.4530108 #>           [,33]       [,34] #>  [1,] -2.785066 -0.30193814 #>  [2,] -2.818961  0.16363750 #>  [3,] -3.901225 -0.03908195 #>  [4,] -3.593725 -0.14883634 #>  [5,] -3.359821 -0.30516790 #>  [6,] -2.883337  0.30333766 #>  [7,] -3.519127  0.05782243 #>  [8,] -4.382122  0.53328853 #>  [9,] -2.264007 -0.09067303 #> [10,] -3.599580  0.15623576  kfolds2Chisqind(bbb2) #> [[1]] #> [[1]][[1]] #>  [1]  9.138129  9.940345 10.656152 11.792951 23.539081 22.980702 24.630842 #>  [8] 27.656301 28.953563 28.656831 #>  #> [[1]][[2]] #>  [1] 26.77943 22.18569 24.18229 21.06303 20.68927 17.84010 17.56275 17.49662 #>  [9] 17.17441 16.08457 #>  #> [[1]][[3]] #>  [1]  35.93140  72.26203 117.09286 213.96365 270.39345 396.41635 399.80898 #>  [8] 451.63438 456.65919 404.48063 #>  #> [[1]][[4]] #>  [1]   36.45611   80.40065  307.30286  575.34925 1090.85333 1385.55853 #>  [7] 1814.76025 1972.87463 2142.48155 2243.37735 #>  #> [[1]][[5]] #>  [1]   20.71883   87.51129  567.42311  903.21928  806.57769 1228.45450 #>  [7] 2701.43600 3171.17408 3046.45690 2499.28901 #>  #> [[1]][[6]] #>  [1] 14.646120  7.531857  6.426014  9.173460 13.174570 19.394117 17.950400 #>  [8] 15.465632 15.597041 15.517834 #>  #> [[1]][[7]] #>  [1]   34.23608   92.06347 1343.75103 3500.00729 3369.49587 3663.63618 #>  [7] 3875.15003 4678.94455 4743.05595 5166.47579 #>  #> [[1]][[8]] #>  [1]  11.68854  12.97723  19.08495  27.39190  33.33952  95.69299 201.37583 #>  [8] 294.72375 293.31858 292.47884 #>  #> [[1]][[9]] #>  [1] 13.727902 13.720644  9.302802 10.677076 11.456733 12.552194 11.100323 #>  [8]  9.024091  8.672000  8.607707 #>  #> [[1]][[10]] #>  [1]  19.01959  20.47371  50.69779  58.90737  60.05489  66.94569  83.22761 #>  [8] 100.73331 113.75541 114.15105 #>  #>  kfolds2Chisq(bbb2) #> [[1]] #>  [1]   222.3421   419.0669  2455.9199  5331.5453  5699.5744  6909.4714 #>  [7]  9147.0030 10739.7273 10866.1246 10789.1196 #>  summary(bbb2) #> ____************************************************____ #>  #> Family: binomial  #> Link function: logit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                 AIC      BIC  Q2Chisqcum_Y  limQ2   Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0  145.8283 148.4727            NA     NA          NA                NA #> Nb_Comp_1  118.1398 123.4285 -1.137905e+00 0.0975   -1.137905          222.3421 #> Nb_Comp_2  109.9553 117.8885 -7.911290e+00 0.0975   -3.168234          419.0669 #> Nb_Comp_3  105.1591 115.7366 -2.196646e+02 0.0975  -23.762360         2455.9199 #> Nb_Comp_4  103.8382 117.0601 -9.534571e+03 0.0975  -42.212970         5331.5453 #> Nb_Comp_5  104.7338 120.6001 -4.735207e+05 0.0975  -48.658454         5699.5744 #> Nb_Comp_6  105.6770 124.1878 -3.105521e+07 0.0975  -64.583493         6909.4714 #> Nb_Comp_7  107.2828 128.4380 -2.872864e+09 0.0975  -91.508279         9147.0030 #> Nb_Comp_8  109.0172 132.8167 -3.179467e+11 0.0975 -109.672382        10739.7273 #> Nb_Comp_9  110.9354 137.3793 -3.493236e+13 0.0975 -108.868593        10866.1246 #> Nb_Comp_10 112.9021 141.9904 -3.755538e+15 0.0975 -106.508863        10789.1196 #>            Chi2_Pearson_Y    RSS_Y      R2_Y #> Nb_Comp_0       104.00000 25.91346        NA #> Nb_Comp_1       100.53823 19.32272 0.2543365 #> Nb_Comp_2        99.17955 17.33735 0.3309519 #> Nb_Comp_3       123.37836 15.58198 0.3986915 #> Nb_Comp_4       114.77551 15.14046 0.4157299 #> Nb_Comp_5       105.35382 15.08411 0.4179043 #> Nb_Comp_6        98.87767 14.93200 0.4237744 #> Nb_Comp_7        97.04072 14.87506 0.4259715 #> Nb_Comp_8        98.90110 14.84925 0.4269676 #> Nb_Comp_9       100.35563 14.84317 0.4272022 #> Nb_Comp_10      102.85214 14.79133 0.4292027 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" rm(list=c(\"bbb\",\"bbb2\"))    data(pine) Xpine<-pine[,1:10] ypine<-pine[,11] bbb <- cv.plsRglm(round(x11)~.,data=pine,nt=10,modele=\"pls-glm-family\", family=poisson(log),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE) bbb <- cv.plsRglm(round(x11)~.,data=pine,nt=10, modele=\"pls-glm-poisson\",K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)  #For Jackknife computations kfolds2coeff(bbb) #>           [,1]         [,2]        [,3]        [,4]      [,5]      [,6] #>  [1,] 12.23228 -0.005536853 -0.06035313  0.21075559 -1.509566 0.3891260 #>  [2,] 14.32616 -0.005472639 -0.07659818  0.25653307 -1.496063 0.2455091 #>  [3,] 12.40342 -0.004631656 -0.10646369  0.16293855 -2.485515 0.4488413 #>  [4,] 10.97834 -0.004237452 -0.05073310  0.17068724 -1.595761 0.3037007 #>  [5,] 11.99869 -0.004589766 -0.07217495  0.19467679 -1.301550 0.2616567 #>  [6,] 11.21735 -0.004246082 -0.07199980  0.15406592 -1.438080 0.2934104 #>  [7,] 16.85425 -0.006536052 -0.09856612  0.34244991 -2.109424 0.4062731 #>  [8,] 10.92865 -0.005912708 -0.03022862 -0.02194749 -1.316067 0.2801402 #>  [9,] 11.28964 -0.004643210 -0.07253036  0.15351588 -1.612797 0.3242276 #> [10,] 14.59362 -0.005455122 -0.05837141  0.25584500 -1.779435 0.3188999 #>             [,7]         [,8]       [,9]      [,10]        [,11] #>  [1,] -2.2221164  0.154839413 -0.0148678 -0.9159189 -0.043456849 #>  [2,] -2.9221081  0.036086621  0.3780611 -1.5914109 -0.201445332 #>  [3,] -2.0592645  0.663714218  0.5454282 -1.1510459 -0.627219682 #>  [4,] -1.6471132  0.142996046  0.1627417 -1.3784248 -0.006574006 #>  [5,] -1.8966704 -0.224268493  0.1396611 -1.3784609  0.164126510 #>  [6,] -1.6236813  0.002402134  0.1512606 -0.9878680 -0.307230536 #>  [7,] -4.3402151  0.359188340  0.3560064 -1.1404673 -0.372509115 #>  [8,]  0.4838324 -0.522774677  0.1006362 -1.0965444 -0.011750707 #>  [9,] -1.5812611  0.141304409  0.1891793 -1.0272417 -0.132808486 #> [10,] -2.9669311  0.479145437  0.2613261 -1.1668214 -0.921124035 boxplot(kfolds2coeff(bbb)[,1])   kfolds2Chisqind(bbb) #> [[1]] #> [[1]][[1]] #>  [1] 1.142498 1.441775 1.980300 2.598358 2.669610 3.049673 3.012338 2.985366 #>  [9] 2.880423 2.889056 #>  #> [[1]][[2]] #>  [1] 2.591149 2.778573 2.027467 2.142058 2.098839 2.008267 2.413857 2.517996 #>  [9] 2.590328 2.609335 #>  #> [[1]][[3]] #>  [1] 0.7392703 2.0734013 2.1311453 1.8991696 1.0721471 3.4101252 5.4459136 #>  [8] 6.3284543 6.2193184 5.9980376 #>  #> [[1]][[4]] #>  [1] 1.6837200 0.7466781 1.1656998 1.2825498 1.3679960 1.1822751 1.2835441 #>  [8] 1.2558035 1.2396572 1.2334661 #>  #> [[1]][[5]] #>  [1] 1.0715319 1.5693955 1.1456871 1.3559922 0.9495254 0.7828828 0.7282813 #>  [8] 0.6074119 0.6128180 0.6063229 #>  #> [[1]][[6]] #>  [1] 10.9521509  5.9784679  2.9987869  2.2389311  1.7708144  1.8583071 #>  [7]  1.2022792  0.8668432  0.8383545  0.8111822 #>  #> [[1]][[7]] #>  [1]  5.245962 11.124279 11.218884 12.827187 12.727385 19.304297 23.763276 #>  [8] 26.981549 28.312951 28.275528 #>  #> [[1]][[8]] #>  [1]  7.056454 11.983755  9.739079 10.606415 10.719232  7.373670  9.422256 #>  [8] 10.136700 10.645665 10.566862 #>  #> [[1]][[9]] #>  [1] 1.2404751 0.7736069 0.7740438 0.8537660 0.5927995 0.6294607 0.6640181 #>  [8] 0.6412462 0.5899091 0.5879259 #>  #> [[1]][[10]] #>  [1] 1.1265687 1.8549784 1.5645359 1.8487013 1.0962112 0.8740828 0.7308147 #>  [8] 1.1825454 1.1297039 1.1396595 #>  #>  kfolds2Chisq(bbb) #> [[1]] #>  [1] 32.84978 40.32491 34.74563 37.65313 35.06456 40.47304 48.66658 53.50391 #>  [9] 55.05913 54.71737 #>  summary(bbb) #> ____************************************************____ #>  #> Family: poisson  #> Link function: log  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                 AIC      BIC  Q2Chisqcum_Y  limQ2   Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0  76.61170 78.10821            NA     NA          NA                NA #> Nb_Comp_1  65.70029 68.69331  2.667317e-02 0.0975  0.02667317          32.84978 #> Nb_Comp_2  62.49440 66.98392 -6.450590e-01 0.0975 -0.69014040          40.32491 #> Nb_Comp_3  62.47987 68.46590 -2.303982e+00 0.0975 -1.00842742          34.74563 #> Nb_Comp_4  64.21704 71.69958 -7.021296e+00 0.0975 -1.42776669          37.65313 #> Nb_Comp_5  65.81654 74.79559 -1.745640e+01 0.0975 -1.30092438          35.06456 #> Nb_Comp_6  66.48888 76.96443 -4.794182e+01 0.0975 -1.65175367          40.47304 #> Nb_Comp_7  68.40234 80.37440 -1.332157e+02 0.0975 -1.74235150          48.66658 #> Nb_Comp_8  70.39399 83.86256 -3.969620e+02 0.0975 -1.96509348          53.50391 #> Nb_Comp_9  72.37642 87.34149 -1.204328e+03 0.0975 -2.02875247          55.05913 #> Nb_Comp_10 74.37612 90.83770 -3.593284e+03 0.0975 -1.98199539          54.71737 #>            Chi2_Pearson_Y     RSS_Y      R2_Y #> Nb_Comp_0        33.75000 24.545455        NA #> Nb_Comp_1        23.85891 12.599337 0.4866937 #> Nb_Comp_2        17.29992  9.056074 0.6310488 #> Nb_Comp_3        15.50937  8.232069 0.6646194 #> Nb_Comp_4        15.23934  8.125808 0.6689485 #> Nb_Comp_5        15.26275  7.862134 0.6796909 #> Nb_Comp_6        17.74629  6.203270 0.7472742 #> Nb_Comp_7        18.04460  5.879880 0.7604493 #> Nb_Comp_8        18.17881  5.827065 0.7626011 #> Nb_Comp_9        18.34925  5.837300 0.7621841 #> Nb_Comp_10       18.39332  5.832437 0.7623822 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" PLS_lm(ypine,Xpine,10,typeVC=\"standard\")$InfCrit #> ____************************************************____ #> ____TypeVC____ standard ____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>                 AIC     Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y     RSS_Y #> Nb_Comp_0  82.41888          NA      NA          NA        NA 20.800152 #> Nb_Comp_1  63.61896  0.38248575  0.0975  0.38248575 12.844390 11.074659 #> Nb_Comp_2  58.47638  0.34836456  0.0975 -0.05525570 11.686597  8.919303 #> Nb_Comp_3  56.55421  0.23688359  0.0975 -0.17107874 10.445206  7.919786 #> Nb_Comp_4  54.35053  0.06999681  0.0975 -0.21869112  9.651773  6.972542 #> Nb_Comp_5  55.99834 -0.07691053  0.0975 -0.15796434  8.073955  6.898523 #> Nb_Comp_6  57.69592 -0.19968885  0.0975 -0.11400977  7.685022  6.835594 #> Nb_Comp_7  59.37953 -0.27722139  0.0975 -0.06462721  7.277359  6.770369 #> Nb_Comp_8  61.21213 -0.30602578  0.0975 -0.02255238  6.923057  6.736112 #> Nb_Comp_9  63.18426 -0.39920228  0.0975 -0.07134354  7.216690  6.730426 #> Nb_Comp_10 65.15982 -0.43743644  0.0975 -0.02732569  6.914340  6.725443 #>                 R2_Y R2_residY RSS_residY PRESS_residY   Q2_residY  LimQ2 #> Nb_Comp_0         NA        NA   32.00000           NA          NA     NA #> Nb_Comp_1  0.4675684 0.4675684   17.03781     19.76046  0.38248575 0.0975 #> Nb_Comp_2  0.5711905 0.5711905   13.72190     17.97925 -0.05525570 0.0975 #> Nb_Comp_3  0.6192438 0.6192438   12.18420     16.06943 -0.17107874 0.0975 #> Nb_Comp_4  0.6647841 0.6647841   10.72691     14.84877 -0.21869112 0.0975 #> Nb_Comp_5  0.6683426 0.6683426   10.61304     12.42138 -0.15796434 0.0975 #> Nb_Comp_6  0.6713681 0.6713681   10.51622     11.82303 -0.11400977 0.0975 #> Nb_Comp_7  0.6745039 0.6745039   10.41588     11.19586 -0.06462721 0.0975 #> Nb_Comp_8  0.6761508 0.6761508   10.36317     10.65078 -0.02255238 0.0975 #> Nb_Comp_9  0.6764242 0.6764242   10.35443     11.10252 -0.07134354 0.0975 #> Nb_Comp_10 0.6766638 0.6766638   10.34676     10.63737 -0.02732569 0.0975 #>            Q2cum_residY  AIC.std   DoF.dof sigmahat.dof   AIC.dof   BIC.dof #> Nb_Comp_0            NA 96.63448  1.000000    0.8062287 0.6697018 0.6991787 #> Nb_Comp_1    0.38248575 77.83455  3.176360    0.5994089 0.4047616 0.4565153 #> Nb_Comp_2    0.34836456 72.69198  7.133559    0.5761829 0.4138120 0.5212090 #> Nb_Comp_3    0.23688359 70.76981  8.778329    0.5603634 0.4070516 0.5320535 #> Nb_Comp_4    0.06999681 68.56612  8.427874    0.5221703 0.3505594 0.4547689 #> Nb_Comp_5   -0.07691053 70.21393  9.308247    0.5285695 0.3666578 0.4845912 #> Nb_Comp_6   -0.19968885 71.91152  9.291931    0.5259794 0.3629363 0.4795121 #> Nb_Comp_7   -0.27722139 73.59512  9.756305    0.5284535 0.3702885 0.4938445 #> Nb_Comp_8   -0.30602578 75.42772 10.363948    0.5338475 0.3831339 0.5170783 #> Nb_Comp_9   -0.39920228 77.39986 10.732148    0.5378277 0.3920957 0.5328747 #> Nb_Comp_10  -0.43743644 79.37542 11.000000    0.5407500 0.3987417 0.5446065 #>             GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0  -3.605128         1      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1  -9.875081         2      0.5977015 0.3788984 0.4112998 -11.451340 #> Nb_Comp_2  -6.985517         3      0.5452615 0.3243383 0.3647862 -12.822703 #> Nb_Comp_3  -6.260610         4      0.5225859 0.3061986 0.3557368 -12.756838 #> Nb_Comp_4  -8.152986         5      0.4990184 0.2867496 0.3432131 -12.811575 #> Nb_Comp_5  -7.111583         6      0.5054709 0.3019556 0.3714754 -11.329638 #> Nb_Comp_6  -7.233043         7      0.5127450 0.3186757 0.4021333  -9.918688 #> Nb_Comp_7  -6.742195         8      0.5203986 0.3364668 0.4347156  -8.592770 #> Nb_Comp_8  -6.038372         9      0.5297842 0.3572181 0.4717708  -7.287834 #> Nb_Comp_9  -5.600235        10      0.5409503 0.3813021 0.5140048  -6.008747 #> Nb_Comp_10 -5.288422        11      0.5529032 0.4076026 0.5600977  -4.799453  data(pineNAX21) bbb2 <- cv.plsRglm(round(x11)~.,data=pineNAX21,nt=10, modele=\"pls-glm-family\",family=poisson(log),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE) bbb2 <- cv.plsRglm(round(x11)~.,data=pineNAX21,nt=10, modele=\"pls-glm-poisson\",K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)  #For Jackknife computations kfolds2coeff(bbb2) #>           [,1]         [,2]        [,3]       [,4]      [,5]      [,6] #>  [1,] 11.51811 -0.005952386 -0.04705644 0.01579405 -1.519639 0.3274029 #>  [2,] 13.48966 -0.004981385 -0.06984414 0.19631381 -1.560965 0.3040376 #>  [3,] 12.63692 -0.004543425 -0.05466002 0.15527180 -1.371838 0.2951140 #>  [4,] 12.81233 -0.005251442 -0.05779519 0.19878499 -1.341721 0.3182705 #>  [5,] 13.30235 -0.004022254 -0.09036926 0.20118035 -2.168910 0.4199286 #>  [6,] 15.62810 -0.006164254 -0.08473175 0.22820188 -1.902573 0.3330847 #>  [7,] 13.61742 -0.005004306 -0.06550345 0.19769215 -1.506993 0.2906218 #>  [8,] 13.82062 -0.005346061 -0.06939079 0.25433075 -1.570217 0.2798791 #>  [9,] 19.74373 -0.007589103 -0.10421749 0.37990696 -2.120497 0.4017688 #> [10,] 14.84834 -0.004928453 -0.04972723 0.24531299 -1.503833 0.2712783 #>             [,7]        [,8]       [,9]      [,10]       [,11] #>  [1,] -0.2014834  0.10523208 0.06110290 -0.4074067 -0.12976644 #>  [2,] -2.2805101  0.04360632 0.24608496 -1.0725974 -0.29707532 #>  [3,] -1.2419615 -0.34704147 0.02554851 -1.3843230  0.11912524 #>  [4,] -1.9245434  0.01273538 0.08933275 -1.5051381  0.26169495 #>  [5,] -2.2112053  0.18672331 0.30611669 -1.3219579 -0.32977787 #>  [6,] -2.6356030  0.42081192 0.41712124 -1.3295615 -0.48652744 #>  [7,] -2.0755348 -0.06300028 0.22280792 -1.3888067 -0.16197199 #>  [8,] -2.7872614  0.05704597 0.28563651 -1.5290880 -0.09594567 #>  [9,] -5.0683254  0.81985345 0.45414536 -1.0032677 -0.83199603 #> [10,] -2.6971167  0.03780900 0.20135091 -1.4205660 -0.61724236 boxplot(kfolds2coeff(bbb2)[,1])   kfolds2Chisqind(bbb2) #> [[1]] #> [[1]][[1]] #> [1] 7.213648 8.752262 5.572425 4.818952 3.028990 6.217531 4.122426 6.855565 #> [9] 6.499983 #>  #> [[1]][[2]] #> [1] 2.0849314 1.4360473 0.8946700 0.9929068 0.7545875 0.6423280 0.2974474 #> [8] 0.3367926 0.3605493 #>  #> [[1]][[3]] #> [1] 1.631623 2.180784 2.543712 2.620713 2.486795 1.941632 1.545911 1.377616 #> [9] 1.291857 #>  #> [[1]][[4]] #> [1] 1.463748 2.075750 3.379147 3.695561 3.477909 3.489421 3.374752 3.056892 #> [9] 3.052002 #>  #> [[1]][[5]] #> [1] 0.4531292 0.5589994 1.1387310 1.2324005 1.2403710 4.5318536 5.6961986 #> [8] 5.5266582 5.3318349 #>  #> [[1]][[6]] #> [1] 0.6869926 2.9909089 1.7537878 1.7477216 2.0374322 1.9382188 2.4194387 #> [8] 2.4847905 2.6806979 #>  #> [[1]][[7]] #> [1] 9.0634896 3.8153296 0.8093908 0.3964339 0.6056960 0.2921411 0.2268577 #> [8] 0.1989748 0.1924728 #>  #> [[1]][[8]] #> [1]    2.002490    4.357975    7.375590   16.235660   75.062697 2544.879428 #> [7] 1892.216705  373.635078  641.649673 #>  #> [[1]][[9]] #> [1]  5.703873  9.951464  9.445938  9.009311  9.552172 16.060253 21.770003 #> [8] 27.592524 31.304674 #>  #> [[1]][[10]] #> [1] 2.8335216 1.7839647 0.8467397 0.9960074 0.8965102 0.8109255 0.9058031 #> [8] 0.9511547 1.0797027 #>  #>  kfolds2Chisq(bbb2) #> [[1]] #> [1]   33.13745   37.90349   33.76013   41.74567   99.14316 2580.80373 1932.57554 #> [8]  422.01605  693.44345 #>  summary(bbb2) #> ____************************************************____ #> Only naive DoF can be used with missing data #>  #> Family: poisson  #> Link function: log  #>  #> ____There are some NAs in X but not in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> Warning : reciprocal condition number of t(cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE])%*%cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE] < 10^{-12} #> Warning only 9 components could thus be extracted #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC  Q2Chisqcum_Y  limQ2     Q2Chisq_Y #> Nb_Comp_0 76.61170 78.10821            NA     NA            NA #> Nb_Comp_1 65.74449 68.73751  1.814974e-02 0.0975    0.01814974 #> Nb_Comp_2 62.35674 66.84626 -5.577194e-01 0.0975   -0.58651419 #> Nb_Comp_3 62.39804 68.38407 -2.037757e+00 0.0975   -0.95013098 #> Nb_Comp_4 64.08113 71.56366 -7.172691e+00 0.0975   -1.69037050 #> Nb_Comp_5 65.63784 74.61689 -5.191654e+01 0.0975   -5.47479973 #> Nb_Comp_6 67.18468 77.66024 -8.803205e+03 0.0975 -165.37908247 #> Nb_Comp_7 68.61004 80.58210 -1.043500e+06 0.0975 -117.52302582 #> Nb_Comp_8 70.54487 84.01344 -2.513541e+07 0.0975  -23.08757731 #> Nb_Comp_9 72.37296 87.33803 -9.815474e+08 0.0975  -38.05037858 #>           PREChi2_Pearson_Y Chi2_Pearson_Y     RSS_Y      R2_Y #> Nb_Comp_0                NA       33.75000 24.545455        NA #> Nb_Comp_1          33.13745       23.89105 12.654950 0.4844280 #> Nb_Comp_2          37.90349       17.31172  8.871122 0.6385839 #> Nb_Comp_3          33.76013       15.51670  8.203709 0.6657748 #> Nb_Comp_4          41.74567       15.31216  7.959332 0.6757309 #> Nb_Comp_5          99.14316       15.51159  7.724832 0.6852846 #> Nb_Comp_6        2580.80373       16.30549  6.814620 0.7223673 #> Nb_Comp_7        1932.57554       17.52007  6.284737 0.7439552 #> Nb_Comp_8         422.01605       17.75766  6.160827 0.7490034 #> Nb_Comp_9         693.44345       18.30206  5.831059 0.7624383 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\"  data(XpineNAX21) PLS_lm(ypine,XpineNAX21,10,typeVC=\"standard\")$InfCrit #> ____************************************************____ #> Only naive DoF can be used with missing data #> ____There are some NAs in X but not in Y____ #> ____TypeVC____ standard ____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> Warning : reciprocal condition number of t(cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE])%*%cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE] < 10^{-12} #> Warning only 9 components could thus be extracted #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  #>                AIC     Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y     RSS_Y #> Nb_Comp_0 82.41888          NA      NA          NA        NA 20.800152 #> Nb_Comp_1 63.69250  0.35639805  0.0975  0.35639805 13.387018 11.099368 #> Nb_Comp_2 58.35228  0.28395028  0.0975 -0.11256611 12.348781  8.885823 #> Nb_Comp_3 56.36553  0.07664889  0.0975 -0.28950699 11.458331  7.874634 #> Nb_Comp_4 54.02416 -0.70355579  0.0975 -0.84497074 14.528469  6.903925 #> Nb_Comp_5 55.80450 -0.94905654  0.0975 -0.14411078  7.898855  6.858120 #> Nb_Comp_6 57.45753 -1.27568315  0.0975 -0.16758190  8.007417  6.786392 #> Nb_Comp_7 58.73951 -1.63309014  0.0975 -0.15705481  7.852227  6.640327 #> Nb_Comp_8 60.61227 -1.67907859  0.0975 -0.01746558  6.756304  6.614773 #> Nb_Comp_9 62.25948 -2.15165796  0.0975 -0.17639623  7.781594  6.544432 #>                R2_Y R2_residY RSS_residY PRESS_residY   Q2_residY  LimQ2 #> Nb_Comp_0        NA        NA   32.00000           NA          NA     NA #> Nb_Comp_1 0.4663804 0.4663804   17.07583     20.59526  0.35639805 0.0975 #> Nb_Comp_2 0.5728001 0.5728001   13.67040     18.99799 -0.11256611 0.0975 #> Nb_Comp_3 0.6214146 0.6214146   12.11473     17.62807 -0.28950699 0.0975 #> Nb_Comp_4 0.6680830 0.6680830   10.62135     22.35133 -0.84497074 0.0975 #> Nb_Comp_5 0.6702851 0.6702851   10.55088     12.15200 -0.14411078 0.0975 #> Nb_Comp_6 0.6737336 0.6737336   10.44053     12.31901 -0.16758190 0.0975 #> Nb_Comp_7 0.6807558 0.6807558   10.21581     12.08026 -0.15705481 0.0975 #> Nb_Comp_8 0.6819844 0.6819844   10.17650     10.39424 -0.01746558 0.0975 #> Nb_Comp_9 0.6853661 0.6853661   10.06828     11.97160 -0.17639623 0.0975 #>           Q2cum_residY  AIC.std DoF.dof sigmahat.dof AIC.dof BIC.dof GMDL.dof #> Nb_Comp_0           NA 96.63448      NA           NA      NA      NA       NA #> Nb_Comp_1   0.35639805 77.90810      NA           NA      NA      NA       NA #> Nb_Comp_2   0.28395028 72.56787      NA           NA      NA      NA       NA #> Nb_Comp_3   0.07664889 70.58113      NA           NA      NA      NA       NA #> Nb_Comp_4  -0.70355579 68.23976      NA           NA      NA      NA       NA #> Nb_Comp_5  -0.94905654 70.02009      NA           NA      NA      NA       NA #> Nb_Comp_6  -1.27568315 71.67313      NA           NA      NA      NA       NA #> Nb_Comp_7  -1.63309014 72.95511      NA           NA      NA      NA       NA #> Nb_Comp_8  -1.67907859 74.82787      NA           NA      NA      NA       NA #> Nb_Comp_9  -2.15165796 76.47507      NA           NA      NA      NA       NA #>           DoF.naive sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0         1      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1         2      0.5983679 0.3797438 0.4122175 -11.413749 #> Nb_Comp_2         3      0.5442372 0.3231208 0.3634169 -12.847656 #> Nb_Comp_3         4      0.5210941 0.3044529 0.3537087 -12.776843 #> Nb_Comp_4         5      0.4965569 0.2839276 0.3398355 -12.891035 #> Nb_Comp_5         6      0.5039885 0.3001871 0.3692997 -11.349498 #> Nb_Comp_6         7      0.5108963 0.3163819 0.3992388  -9.922119 #> Nb_Comp_7         8      0.5153766 0.3300041 0.4263658  -8.696873 #> Nb_Comp_8         9      0.5249910 0.3507834 0.4632727  -7.337679 #> Nb_Comp_9        10      0.5334234 0.3707649 0.4998004  -6.033403 rm(list=c(\"Xpine\",\"XpineNAX21\",\"ypine\",\"bbb\",\"bbb2\")) #> Warning: object 'XpineNAX21' not found    data(pine) Xpine<-pine[,1:10] ypine<-pine[,11] bbb <- cv.plsRglm(x11~.,data=pine,nt=10,modele=\"pls-glm-family\", family=Gamma,K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE) #> Warning: NaNs produced bbb <- cv.plsRglm(x11~.,data=pine,nt=10,modele=\"pls-glm-Gamma\", K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)  #For Jackknife computations kfolds2coeff(bbb) #>             [,1]        [,2]         [,3]        [,4]      [,5]       [,6] #>  [1,] -12.538587 0.006081631  0.051485268 -0.17200406 1.9564449 -0.4121492 #>  [2,] -12.361937 0.009237988  0.039134946 -0.32515811 2.0576931 -0.3290479 #>  [3,]  -9.057436 0.004677511  0.007988804 -0.07922100 0.9813196 -0.2186069 #>  [4,] -10.586646 0.005689529  0.032376860 -0.09035462 1.9699193 -0.3928204 #>  [5,] -10.927667 0.004506554  0.030789213 -0.21565214 1.3977266 -0.2934423 #>  [6,] -11.501775 0.005522298  0.051836980 -0.13536601 1.5245202 -0.3109914 #>  [7,] -16.494083 0.005806689  0.095088328 -0.32343382 3.6142443 -0.6056931 #>  [8,]  -9.210819 0.007641321 -0.008129801  0.13439933 1.6843999 -0.3819648 #>  [9,] -13.596107 0.007307016  0.062945208 -0.25963003 1.7436597 -0.3738348 #> [10,] -11.656738 0.005533928  0.040602824 -0.16403631 1.7953572 -0.3669673 #>             [,7]       [,8]         [,9]      [,10]     [,11] #>  [1,]  2.3545656 -0.4281201 -0.197686771  0.7935866 0.7913407 #>  [2,]  3.3769636 -4.2565134 -0.553253701  2.5194587 0.8576111 #>  [3,]  0.9108687  0.2556929  0.004448834  1.0393063 0.2458766 #>  [4,]  1.3923929 -0.7220402 -0.193888178  0.4000389 1.0641619 #>  [5,]  2.6197499 -0.1320216 -0.081918997  1.0256996 0.5635740 #>  [6,]  1.3504613 -0.1576628 -0.130366130  1.2050842 0.4686387 #>  [7,]  4.3052478 -0.6259748 -0.740700803  1.5778828 0.8433978 #>  [8,] -1.4808742 -0.1824521 -0.090878056  0.7290671 0.4302643 #>  [9,]  4.2000986 -0.9848552 -0.134796298 -0.5740824 0.8225901 #> [10,]  2.2218202 -0.3694189 -0.189664822  0.8733890 0.7222851 boxplot(kfolds2coeff(bbb)[,1])   kfolds2Chisqind(bbb) #> [[1]] #> [[1]][[1]] #>  [1] 2.540288 4.844394 4.351359 4.702662 4.571178 4.326014 4.525768 4.806861 #>  [9] 4.914484 4.930287 #>  #> [[1]][[2]] #>  [1]  4.668016  8.396943 12.484710 14.500103 15.711237 25.102374 35.372325 #>  [8] 53.624929 52.047930 50.024451 #>  #> [[1]][[3]] #>  [1] 2.133621 2.053730 1.892977 1.637721 1.669219 1.536641 1.413236 1.369726 #>  [9] 1.328652 1.328094 #>  #> [[1]][[4]] #>  [1] 1.262670 1.288643 1.209826 1.329300 1.176611 1.123009 1.196177 1.403819 #>  [9] 1.364180 1.366575 #>  #> [[1]][[5]] #>  [1] 1.524722 1.302587 1.294947 1.456490 1.580015 1.357941 1.381343 1.381842 #>  [9] 1.390103 1.390346 #>  #> [[1]][[6]] #>  [1] 1.400649 2.825090 3.668589 3.790930 4.147190 2.384792 2.692231 1.891024 #>  [9] 1.361738 1.346266 #>  #> [[1]][[7]] #>  [1]  2.177392  1.747842  5.055109  4.816448 13.184320 13.122975 18.657676 #>  [8] 18.310017 21.463970 20.825055 #>  #> [[1]][[8]] #>  [1] 2.303359 5.066905 5.164362 3.046195 3.183245 7.164604 6.825827 6.591949 #>  [9] 8.059339 8.090565 #>  #> [[1]][[9]] #>  [1] 2.2108761 1.9416990 0.9562836 0.7962834 0.7057318 1.4156486 1.0268659 #>  [8] 1.8523938 5.2462466 4.7963261 #>  #> [[1]][[10]] #>  [1] 3.15634606 3.47171099 0.87925308 0.13423429 0.62522908 0.03142367 #>  [7] 0.02830618 0.04542298 0.07141477 0.07561845 #>  #>  kfolds2Chisq(bbb) #> [[1]] #>  [1] 23.37794 32.93954 36.95741 36.21037 46.55398 57.56542 73.11976 91.27798 #>  [9] 97.24806 94.17358 #>  summary(bbb) #> ____************************************************____ #>  #> Family: Gamma  #> Link function: inverse  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                 AIC      BIC  Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0  56.60919 59.60220            NA     NA         NA                NA #> Nb_Comp_1  39.01090 43.50042  2.603800e-01 0.0975  0.2603800          23.37794 #> Nb_Comp_2  37.30801 43.29404 -4.070876e-01 0.0975 -0.9024467          32.93954 #> Nb_Comp_3  36.87524 44.35777 -2.057095e+00 0.0975 -1.1726405          36.95741 #> Nb_Comp_4  36.55795 45.53700 -5.991094e+00 0.0975 -1.2868420          36.21037 #> Nb_Comp_5  37.13611 47.61167 -2.306070e+01 0.0975 -2.4416214          46.55398 #> Nb_Comp_6  38.27656 50.24862 -1.007710e+02 0.0975 -3.2297587          57.56542 #> Nb_Comp_7  39.39377 52.86234 -5.339127e+02 0.0975 -4.2560451          73.11976 #> Nb_Comp_8  40.96122 55.92630 -3.266271e+03 0.0975 -5.1080446          91.27798 #> Nb_Comp_9  42.90816 59.36974 -2.082680e+04 0.0975 -5.3746790          97.24806 #> Nb_Comp_10 44.90815 62.86625 -1.294169e+05 0.0975 -5.2137104          94.17358 #>            Chi2_Pearson_Y     RSS_Y      R2_Y #> Nb_Comp_0        31.60805 20.800152        NA #> Nb_Comp_1        17.31431 11.804594 0.4324756 #> Nb_Comp_2        17.01037  6.357437 0.6943562 #> Nb_Comp_3        15.83422  5.699662 0.7259798 #> Nb_Comp_4        13.52676  7.679741 0.6307844 #> Nb_Comp_5        13.60962  6.099077 0.7067773 #> Nb_Comp_6        13.91155  5.205052 0.7497590 #> Nb_Comp_7        14.94390  4.650377 0.7764258 #> Nb_Comp_8        15.25537  4.321314 0.7922461 #> Nb_Comp_9        15.15577  4.307757 0.7928978 #> Nb_Comp_10       15.15490  4.307391 0.7929154 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" PLS_lm(ypine,Xpine,10,typeVC=\"standard\")$InfCrit #> ____************************************************____ #> ____TypeVC____ standard ____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>                 AIC     Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y     RSS_Y #> Nb_Comp_0  82.41888          NA      NA          NA        NA 20.800152 #> Nb_Comp_1  63.61896  0.38248575  0.0975  0.38248575 12.844390 11.074659 #> Nb_Comp_2  58.47638  0.34836456  0.0975 -0.05525570 11.686597  8.919303 #> Nb_Comp_3  56.55421  0.23688359  0.0975 -0.17107874 10.445206  7.919786 #> Nb_Comp_4  54.35053  0.06999681  0.0975 -0.21869112  9.651773  6.972542 #> Nb_Comp_5  55.99834 -0.07691053  0.0975 -0.15796434  8.073955  6.898523 #> Nb_Comp_6  57.69592 -0.19968885  0.0975 -0.11400977  7.685022  6.835594 #> Nb_Comp_7  59.37953 -0.27722139  0.0975 -0.06462721  7.277359  6.770369 #> Nb_Comp_8  61.21213 -0.30602578  0.0975 -0.02255238  6.923057  6.736112 #> Nb_Comp_9  63.18426 -0.39920228  0.0975 -0.07134354  7.216690  6.730426 #> Nb_Comp_10 65.15982 -0.43743644  0.0975 -0.02732569  6.914340  6.725443 #>                 R2_Y R2_residY RSS_residY PRESS_residY   Q2_residY  LimQ2 #> Nb_Comp_0         NA        NA   32.00000           NA          NA     NA #> Nb_Comp_1  0.4675684 0.4675684   17.03781     19.76046  0.38248575 0.0975 #> Nb_Comp_2  0.5711905 0.5711905   13.72190     17.97925 -0.05525570 0.0975 #> Nb_Comp_3  0.6192438 0.6192438   12.18420     16.06943 -0.17107874 0.0975 #> Nb_Comp_4  0.6647841 0.6647841   10.72691     14.84877 -0.21869112 0.0975 #> Nb_Comp_5  0.6683426 0.6683426   10.61304     12.42138 -0.15796434 0.0975 #> Nb_Comp_6  0.6713681 0.6713681   10.51622     11.82303 -0.11400977 0.0975 #> Nb_Comp_7  0.6745039 0.6745039   10.41588     11.19586 -0.06462721 0.0975 #> Nb_Comp_8  0.6761508 0.6761508   10.36317     10.65078 -0.02255238 0.0975 #> Nb_Comp_9  0.6764242 0.6764242   10.35443     11.10252 -0.07134354 0.0975 #> Nb_Comp_10 0.6766638 0.6766638   10.34676     10.63737 -0.02732569 0.0975 #>            Q2cum_residY  AIC.std   DoF.dof sigmahat.dof   AIC.dof   BIC.dof #> Nb_Comp_0            NA 96.63448  1.000000    0.8062287 0.6697018 0.6991787 #> Nb_Comp_1    0.38248575 77.83455  3.176360    0.5994089 0.4047616 0.4565153 #> Nb_Comp_2    0.34836456 72.69198  7.133559    0.5761829 0.4138120 0.5212090 #> Nb_Comp_3    0.23688359 70.76981  8.778329    0.5603634 0.4070516 0.5320535 #> Nb_Comp_4    0.06999681 68.56612  8.427874    0.5221703 0.3505594 0.4547689 #> Nb_Comp_5   -0.07691053 70.21393  9.308247    0.5285695 0.3666578 0.4845912 #> Nb_Comp_6   -0.19968885 71.91152  9.291931    0.5259794 0.3629363 0.4795121 #> Nb_Comp_7   -0.27722139 73.59512  9.756305    0.5284535 0.3702885 0.4938445 #> Nb_Comp_8   -0.30602578 75.42772 10.363948    0.5338475 0.3831339 0.5170783 #> Nb_Comp_9   -0.39920228 77.39986 10.732148    0.5378277 0.3920957 0.5328747 #> Nb_Comp_10  -0.43743644 79.37542 11.000000    0.5407500 0.3987417 0.5446065 #>             GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0  -3.605128         1      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1  -9.875081         2      0.5977015 0.3788984 0.4112998 -11.451340 #> Nb_Comp_2  -6.985517         3      0.5452615 0.3243383 0.3647862 -12.822703 #> Nb_Comp_3  -6.260610         4      0.5225859 0.3061986 0.3557368 -12.756838 #> Nb_Comp_4  -8.152986         5      0.4990184 0.2867496 0.3432131 -12.811575 #> Nb_Comp_5  -7.111583         6      0.5054709 0.3019556 0.3714754 -11.329638 #> Nb_Comp_6  -7.233043         7      0.5127450 0.3186757 0.4021333  -9.918688 #> Nb_Comp_7  -6.742195         8      0.5203986 0.3364668 0.4347156  -8.592770 #> Nb_Comp_8  -6.038372         9      0.5297842 0.3572181 0.4717708  -7.287834 #> Nb_Comp_9  -5.600235        10      0.5409503 0.3813021 0.5140048  -6.008747 #> Nb_Comp_10 -5.288422        11      0.5529032 0.4076026 0.5600977  -4.799453  data(pineNAX21) bbb2 <- cv.plsRglm(x11~.,data=pineNAX21,nt=10, modele=\"pls-glm-family\",family=Gamma(),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE) #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced bbb2 <- cv.plsRglm(x11~.,data=pineNAX21,nt=10, modele=\"pls-glm-Gamma\",K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)  #For Jackknife computations kfolds2coeff(bbb2) #>            [,1]        [,2]        [,3]        [,4]     [,5]       [,6] #>  [1,] -15.25147 0.006490479  0.04204947 -0.19442714 1.781305 -0.2952820 #>  [2,] -15.16986 0.005474605  0.03527656 -0.27648100 1.257921 -0.2420263 #>  [3,] -13.97006 0.010594537 -0.02927609  0.30604636 2.061606 -0.3365954 #>  [4,] -12.03743 0.005373534  0.01951001 -0.08011735 1.311064 -0.2972826 #>  [5,] -13.61994 0.005054427  0.01112295 -0.14897854 1.789084 -0.3465339 #>  [6,] -14.86458 0.006538230  0.05144328 -0.19171348 1.762460 -0.3669618 #>  [7,] -13.85270 0.006060799  0.06967588 -0.02328877 1.870853 -0.4052438 #>  [8,] -14.36499 0.005602741  0.03767463 -0.16984964 1.754658 -0.3354075 #>  [9,] -14.67958 0.006164958  0.05589650 -0.17300465 1.964310 -0.4224304 #> [10,] -15.30241 0.004702082  0.06265784 -0.28441615 2.354652 -0.5135518 #>             [,7]         [,8]        [,9]     [,10]     [,11] #>  [1,]  2.5339085 -0.869322794 -0.50052940 1.5016832 1.1335442 #>  [2,]  3.6679546  0.949554915 -0.27881465 1.4859881 0.7737842 #>  [3,] -2.4661214 -0.929662624 -0.49572148 0.7713872 0.9698994 #>  [4,]  1.1018507 -0.007227048 -0.02295972 0.5747632 0.6669312 #>  [5,]  1.8359211 -0.272589375 -0.10305410 0.9830253 0.8989810 #>  [6,]  2.8883524 -0.608454563 -0.18145293 0.2719423 0.7192753 #>  [7,] -0.4468633  0.251324140 -0.03449214 1.2065942 0.0875273 #>  [8,]  2.0699983  0.023096103 -0.21486194 1.1778879 0.3679135 #>  [9,]  2.4902882 -0.580864643 -0.14887012 0.2397186 1.0540600 #> [10,]  3.5201888 -0.311832092 -0.18456971 1.1482720 0.6852035 boxplot(kfolds2coeff(bbb2)[,1])   kfolds2Chisqind(bbb2) #> [[1]] #> [[1]][[1]] #> [1] 1.463179 1.531142 1.608290 1.829257 1.162081 1.191037 1.238357 1.296691 #> [9] 1.843372 #>  #> [[1]][[2]] #> [1]   2.477326   3.570153   5.299694  13.232160   6.846131  42.482041   2.192721 #> [8]  19.699755 533.685869 #>  #> [[1]][[3]] #> [1] 12.43755 21.55714 21.77690 18.34100 23.44719 31.95209 35.89362 37.58604 #> [9] 38.03269 #>  #> [[1]][[4]] #> [1] 1.642436 1.522085 1.331390 1.276175 1.251882 1.196762 1.164422 1.168649 #> [9] 1.142255 #>  #> [[1]][[5]] #> [1] 1.1726192 0.8839238 0.7895764 0.7055315 0.9398147 0.7111289 0.7615644 #> [8] 1.2020841 1.1560004 #>  #> [[1]][[6]] #> [1] 2.9105254 3.1114201 1.9082122 1.2488792 0.7675007 0.1535418 0.2796247 #> [8] 0.3177351 1.1315258 #>  #> [[1]][[7]] #> [1] 0.693484 2.084585 4.506156 5.289879 5.498737 3.627927 5.417774 5.270269 #> [9] 4.780969 #>  #> [[1]][[8]] #> [1] 0.6566677 0.3051880 2.1918274 1.0515080 1.1735817 2.0113381 1.0441987 #> [8] 0.7190080 0.6158175 #>  #> [[1]][[9]] #> [1] 1.953828 2.719823 2.828047 3.078667 3.120304 3.325169 3.628322 4.480910 #> [9] 4.546886 #>  #> [[1]][[10]] #> [1] 1.504998 1.513776 1.333460 2.381695 5.714160 6.536569 8.279555 9.419846 #> [9] 9.466334 #>  #>  kfolds2Chisq(bbb2) #> [[1]] #> [1]  26.91261  38.79924  43.57356  48.43475  49.92138  93.18760  59.90016 #> [8]  81.16099 596.40172 #>  summary(bbb2) #> ____************************************************____ #> Only naive DoF can be used with missing data #>  #> Family: Gamma  #> Link function: inverse  #>  #> ____There are some NAs in X but not in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> Warning : reciprocal condition number of t(cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE])%*%cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE] < 10^{-12} #> Warning only 9 components could thus be extracted #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC  Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 56.60919 59.60220            NA     NA         NA                NA #> Nb_Comp_1 39.08940 43.57892  1.485520e-01 0.0975   0.148552          26.91261 #> Nb_Comp_2 37.36154 43.34757 -9.085873e-01 0.0975  -1.241578          38.79924 #> Nb_Comp_3 36.81173 44.29427 -3.862364e+00 0.0975  -1.547625          43.57356 #> Nb_Comp_4 36.53654 45.51559 -1.391895e+01 0.0975  -2.068251          48.43475 #> Nb_Comp_5 37.24312 47.71867 -5.420887e+01 0.0975  -2.700587          49.92138 #> Nb_Comp_6 38.18649 50.15855 -3.781519e+02 0.0975  -5.867590          93.18760 #> Nb_Comp_7 39.35575 52.82432 -1.618578e+03 0.0975  -3.271581          59.90016 #> Nb_Comp_8 40.86209 55.82716 -8.727793e+03 0.0975  -4.389547          81.16099 #> Nb_Comp_9 42.80511 59.26669 -3.406856e+05 0.0975 -38.030202         596.40172 #>           Chi2_Pearson_Y     RSS_Y      R2_Y #> Nb_Comp_0       31.60805 20.800152        NA #> Nb_Comp_1       17.30890 12.031518 0.4215659 #> Nb_Comp_2       17.10360  6.183372 0.7027247 #> Nb_Comp_3       15.78579  5.756462 0.7232490 #> Nb_Comp_4       13.49013  7.630460 0.6331536 #> Nb_Comp_5       13.56918  6.303455 0.6969515 #> Nb_Comp_6       14.02295  5.274716 0.7464097 #> Nb_Comp_7       15.05896  4.867806 0.7659726 #> Nb_Comp_8       15.28052  4.317488 0.7924300 #> Nb_Comp_9       15.19429  4.298593 0.7933384 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" XpineNAX21 <- Xpine XpineNAX21[1,2] <- NA PLS_lm(ypine,XpineNAX21,10,typeVC=\"standard\")$InfCrit #> ____************************************************____ #> Only naive DoF can be used with missing data #> ____There are some NAs in X but not in Y____ #> ____TypeVC____ standard ____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> Warning : reciprocal condition number of t(cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE])%*%cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE] < 10^{-12} #> Warning only 9 components could thus be extracted #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  #>                AIC     Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y     RSS_Y #> Nb_Comp_0 82.41888          NA      NA          NA        NA 20.800152 #> Nb_Comp_1 63.69250  0.35639805  0.0975  0.35639805 13.387018 11.099368 #> Nb_Comp_2 58.35228  0.28395028  0.0975 -0.11256611 12.348781  8.885823 #> Nb_Comp_3 56.36553  0.07664889  0.0975 -0.28950699 11.458331  7.874634 #> Nb_Comp_4 54.02416 -0.70355579  0.0975 -0.84497074 14.528469  6.903925 #> Nb_Comp_5 55.80450 -0.94905654  0.0975 -0.14411078  7.898855  6.858120 #> Nb_Comp_6 57.45753 -1.27568315  0.0975 -0.16758190  8.007417  6.786392 #> Nb_Comp_7 58.73951 -1.63309014  0.0975 -0.15705481  7.852227  6.640327 #> Nb_Comp_8 60.61227 -1.67907859  0.0975 -0.01746558  6.756304  6.614773 #> Nb_Comp_9 62.25948 -2.15165796  0.0975 -0.17639623  7.781594  6.544432 #>                R2_Y R2_residY RSS_residY PRESS_residY   Q2_residY  LimQ2 #> Nb_Comp_0        NA        NA   32.00000           NA          NA     NA #> Nb_Comp_1 0.4663804 0.4663804   17.07583     20.59526  0.35639805 0.0975 #> Nb_Comp_2 0.5728001 0.5728001   13.67040     18.99799 -0.11256611 0.0975 #> Nb_Comp_3 0.6214146 0.6214146   12.11473     17.62807 -0.28950699 0.0975 #> Nb_Comp_4 0.6680830 0.6680830   10.62135     22.35133 -0.84497074 0.0975 #> Nb_Comp_5 0.6702851 0.6702851   10.55088     12.15200 -0.14411078 0.0975 #> Nb_Comp_6 0.6737336 0.6737336   10.44053     12.31901 -0.16758190 0.0975 #> Nb_Comp_7 0.6807558 0.6807558   10.21581     12.08026 -0.15705481 0.0975 #> Nb_Comp_8 0.6819844 0.6819844   10.17650     10.39424 -0.01746558 0.0975 #> Nb_Comp_9 0.6853661 0.6853661   10.06828     11.97160 -0.17639623 0.0975 #>           Q2cum_residY  AIC.std DoF.dof sigmahat.dof AIC.dof BIC.dof GMDL.dof #> Nb_Comp_0           NA 96.63448      NA           NA      NA      NA       NA #> Nb_Comp_1   0.35639805 77.90810      NA           NA      NA      NA       NA #> Nb_Comp_2   0.28395028 72.56787      NA           NA      NA      NA       NA #> Nb_Comp_3   0.07664889 70.58113      NA           NA      NA      NA       NA #> Nb_Comp_4  -0.70355579 68.23976      NA           NA      NA      NA       NA #> Nb_Comp_5  -0.94905654 70.02009      NA           NA      NA      NA       NA #> Nb_Comp_6  -1.27568315 71.67313      NA           NA      NA      NA       NA #> Nb_Comp_7  -1.63309014 72.95511      NA           NA      NA      NA       NA #> Nb_Comp_8  -1.67907859 74.82787      NA           NA      NA      NA       NA #> Nb_Comp_9  -2.15165796 76.47507      NA           NA      NA      NA       NA #>           DoF.naive sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0         1      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1         2      0.5983679 0.3797438 0.4122175 -11.413749 #> Nb_Comp_2         3      0.5442372 0.3231208 0.3634169 -12.847656 #> Nb_Comp_3         4      0.5210941 0.3044529 0.3537087 -12.776843 #> Nb_Comp_4         5      0.4965569 0.2839276 0.3398355 -12.891035 #> Nb_Comp_5         6      0.5039885 0.3001871 0.3692997 -11.349498 #> Nb_Comp_6         7      0.5108963 0.3163819 0.3992388  -9.922119 #> Nb_Comp_7         8      0.5153766 0.3300041 0.4263658  -8.696873 #> Nb_Comp_8         9      0.5249910 0.3507834 0.4632727  -7.337679 #> Nb_Comp_9        10      0.5334234 0.3707649 0.4998004  -6.033403 rm(list=c(\"Xpine\",\"XpineNAX21\",\"ypine\",\"bbb\",\"bbb2\"))    data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] bbb <- cv.plsRglm(Y~.,data=Cornell,nt=10,NK=1,modele=\"pls\",verbose=FALSE) summary(bbb) #> ____************************************************____ #>  #> Model: pls  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC     Q2cum_Y LimQ2_Y       Q2_Y  PRESS_Y      RSS_Y      R2_Y #> Nb_Comp_0 82.01205          NA      NA         NA       NA 467.796667        NA #> Nb_Comp_1 53.15173   0.8375127  0.0975  0.8375127 76.01101  35.742486 0.9235940 #> Nb_Comp_2 41.08283   0.7843768  0.0975 -0.3270158 47.43084  11.066606 0.9763431 #> Nb_Comp_3 32.06411   0.3361792  0.0975 -2.0786151 34.06982   4.418081 0.9905556 #> Nb_Comp_4 33.76477  -5.7521467  0.0975 -9.1716408 44.93914   4.309235 0.9907882 #> Nb_Comp_5 33.34373 -64.2459132  0.0975 -8.6629881 41.64009   3.521924 0.9924713 #> Nb_Comp_6 35.25533          NA  0.0975         NA       NA   3.496074 0.9925265 #>              AIC.std  DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof #> Nb_Comp_0  37.010388 1.000000    6.5212706 46.0708838 47.7893514 27.59461 #> Nb_Comp_1   8.150064 2.740749    1.8665281  4.5699686  4.9558156 21.34020 #> Nb_Comp_2  -3.918831 5.085967    1.1825195  2.1075461  2.3949331 27.40202 #> Nb_Comp_3 -12.937550 5.121086    0.7488308  0.8467795  0.9628191 24.40842 #> Nb_Comp_4 -11.236891 5.103312    0.7387162  0.8232505  0.9357846 24.23105 #> Nb_Comp_5 -11.657929 6.006316    0.7096382  0.7976101  0.9198348 28.21184 #> Nb_Comp_6  -9.746328 7.000002    0.7633343  0.9711322  1.1359502 33.18348 #>           DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0         1      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1         2      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2         3      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3         4      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4         5      0.7846050  0.8721072  0.9964867   24.16510 #> Nb_Comp_5         6      0.7661509  0.8804809  1.0227979   28.64206 #> Nb_Comp_6         7      0.8361907  1.1070902  1.3048716   33.63927 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\"  cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele=\"pls-glm-inverse.gaussian\",K=12,verbose=FALSE) #> Number of repeated crossvalidations: #> [1] 1 #> Number of folds for each crossvalidation: #> [1] 12 cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele=\"pls-glm-family\", family=inverse.gaussian,K=12,verbose=FALSE) #> Number of repeated crossvalidations: #> [1] 1 #> Number of folds for each crossvalidation: #> [1] 12 cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele=\"pls-glm-inverse.gaussian\",K=6, NK=2,verbose=FALSE)$results_kfolds #> [[1]] #> [[1]][[1]] #>       [,1]     [,2]     [,3] #> 2 95.08010 96.44940 97.09980 #> 1 93.23005 94.54028 95.85236 #>  #> [[1]][[2]] #>        [,1]     [,2]     [,3] #> 11 82.41674 82.38616 81.93566 #> 12 87.54766 87.52369 89.40288 #>  #> [[1]][[3]] #>        [,1]     [,2]     [,3] #> 10 82.18756 82.96181 82.81149 #> 8  81.97836 82.48513 82.34459 #>  #> [[1]][[4]] #>       [,1]     [,2]     [,3] #> 7 81.79662 81.77255 81.88023 #> 9 82.08282 82.45580 82.57525 #>  #> [[1]][[5]] #>       [,1]     [,2]     [,3] #> 3 96.52367 97.77654 97.81463 #> 6 94.13493 92.01372 92.13219 #>  #> [[1]][[6]] #>       [,1]     [,2]     [,3] #> 4 95.96203 92.91269 90.22726 #> 5 88.58623 88.32200 84.41198 #>  #>  #> [[2]] #> [[2]][[1]] #>       [,1]    [,2]     [,3] #> 5 87.61323 89.0497 85.81831 #> 3 95.69562 97.8202 98.24510 #>  #> [[2]][[2]] #>        [,1]     [,2]     [,3] #> 6  94.15649 92.49562 92.41182 #> 11 82.51704 82.52189 82.31869 #>  #> [[2]][[3]] #>       [,1]     [,2]     [,3] #> 2 95.08010 96.44940 97.09980 #> 1 93.23005 94.54028 95.85236 #>  #> [[2]][[4]] #>        [,1]     [,2]     [,3] #> 8  82.18031 82.59243 82.48103 #> 12 87.40306 87.79647 89.48632 #>  #> [[2]][[5]] #>        [,1]     [,2]     [,3] #> 7  81.66306 81.74072 81.79826 #> 10 82.35888 83.04357 83.02591 #>  #> [[2]][[6]] #>       [,1]     [,2]     [,3] #> 4 95.36489 92.51571 91.52622 #> 9 82.06647 82.55843 82.55524 #>  #>  cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele=\"pls-glm-family\",family=inverse.gaussian(), K=6,NK=2,verbose=FALSE)$results_kfolds #> [[1]] #> [[1]][[1]] #>       [,1]     [,2]     [,3] #> 2 96.97257 97.56815 97.41466 #> 6 93.60394 92.25570 92.59526 #>  #> [[1]][[2]] #>        [,1]     [,2]     [,3] #> 11 82.41674 82.38616 81.93566 #> 12 87.54766 87.52369 89.40288 #>  #> [[1]][[3]] #>        [,1]     [,2]     [,3] #> 5  88.12776 88.54310 85.32603 #> 10 82.67247 82.97135 83.00083 #>  #> [[1]][[4]] #>       [,1]     [,2]     [,3] #> 3 95.54239 98.04545 98.06654 #> 8 82.24235 82.35979 82.49361 #>  #> [[1]][[5]] #>       [,1]     [,2]     [,3] #> 1 93.67092 95.01013 96.02979 #> 9 82.11977 82.40273 82.50324 #>  #> [[1]][[6]] #>       [,1]     [,2]     [,3] #> 4 95.44676 92.43331 91.48325 #> 7 81.79505 81.83779 81.76982 #>  #>  #> [[2]] #> [[2]][[1]] #>        [,1]     [,2]     [,3] #> 10 82.52637 83.25532 83.27621 #> 11 82.09018 82.10220 82.32048 #>  #> [[2]][[2]] #>       [,1]     [,2]     [,3] #> 5 88.06746 88.53727 85.25048 #> 8 82.44673 82.50563 82.40858 #>  #> [[2]][[3]] #>        [,1]     [,2]     [,3] #> 12 86.83575 86.59791 88.12756 #> 1  93.48074 94.34564 96.46141 #>  #> [[2]][[4]] #>       [,1]     [,2]     [,3] #> 4 95.36489 92.51571 91.52622 #> 9 82.06647 82.55843 82.55524 #>  #> [[2]][[5]] #>       [,1]     [,2]     [,3] #> 7 81.85234 81.83027 81.82584 #> 6 93.64727 92.15930 92.37209 #>  #> [[2]][[6]] #>       [,1]     [,2]     [,3] #> 3 94.00695 96.56079 97.64113 #> 2 94.75823 96.91475 98.01025 #>  #>  cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele=\"pls-glm-inverse.gaussian\",K=6, NK=2,verbose=FALSE)$results_kfolds #> [[1]] #> [[1]][[1]] #>        [,1]     [,2]     [,3] #> 9  81.89236 82.51683 82.52717 #> 10 82.30686 83.12912 83.03868 #>  #> [[1]][[2]] #>        [,1]     [,2]     [,3] #> 4  95.56230 93.12092 91.09742 #> 12 87.64961 87.08013 89.59203 #>  #> [[1]][[3]] #>       [,1]     [,2]     [,3] #> 2 95.08010 96.44940 97.09980 #> 1 93.23005 94.54028 95.85236 #>  #> [[1]][[4]] #>       [,1]     [,2]     [,3] #> 6 93.64727 92.15930 92.37209 #> 7 81.85234 81.83027 81.82584 #>  #> [[1]][[5]] #>       [,1]     [,2]     [,3] #> 5 88.06746 88.53727 85.25048 #> 8 82.44673 82.50563 82.40858 #>  #> [[1]][[6]] #>        [,1]     [,2]     [,3] #> 3  95.03541 97.95611 97.96361 #> 11 82.63660 81.45836 82.07905 #>  #>  #> [[2]] #> [[2]][[1]] #>       [,1]     [,2]     [,3] #> 5 87.65801 88.80272 85.50149 #> 2 96.42504 97.55338 98.02034 #>  #> [[2]][[2]] #>        [,1]     [,2]     [,3] #> 4  95.56230 93.12092 91.09742 #> 12 87.64961 87.08013 89.59203 #>  #> [[2]][[3]] #>       [,1]     [,2]     [,3] #> 3 95.36186 97.94995 98.04350 #> 7 82.03388 81.64447 81.78355 #>  #> [[2]][[4]] #>        [,1]     [,2]     [,3] #> 8  82.34082 82.65220 82.70685 #> 11 82.09986 81.91098 82.20593 #>  #> [[2]][[5]] #>        [,1]     [,2]     [,3] #> 9  81.89236 82.51683 82.52717 #> 10 82.30686 83.12912 83.03868 #>  #> [[2]][[6]] #>       [,1]     [,2]     [,3] #> 1 93.41724 95.97174 95.91487 #> 6 91.29124 90.70632 90.64439 #>  #>  cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele=\"pls-glm-family\", family=inverse.gaussian(link = \"1/mu^2\"),K=6,NK=2,verbose=FALSE)$results_kfolds #> [[1]] #> [[1]][[1]] #>       [,1]     [,2]     [,3] #> 3 95.36186 97.94995 98.04350 #> 7 82.03388 81.64447 81.78355 #>  #> [[1]][[2]] #>       [,1]     [,2]     [,3] #> 8 82.33405 82.57720 82.55853 #> 1 93.67751 95.07576 96.06678 #>  #> [[1]][[3]] #>        [,1]     [,2]     [,3] #> 5  88.12776 88.54310 85.32603 #> 10 82.67247 82.97135 83.00083 #>  #> [[1]][[4]] #>        [,1]     [,2]     [,3] #> 12 87.64961 87.08013 89.59203 #> 4  95.56230 93.12092 91.09742 #>  #> [[1]][[5]] #>       [,1]     [,2]     [,3] #> 9 82.12535 82.56460 82.53338 #> 6 93.45057 92.26382 92.21097 #>  #> [[1]][[6]] #>        [,1]     [,2]     [,3] #> 2  95.74052 97.89405 98.00186 #> 11 82.56310 81.59883 82.15787 #>  #>  #> [[2]] #> [[2]][[1]] #>       [,1]     [,2]     [,3] #> 2 96.13073 97.86873 97.96498 #> 8 82.24293 82.38287 82.48015 #>  #> [[2]][[2]] #>        [,1]     [,2]     [,3] #> 6  93.25013 92.42267 92.24201 #> 10 82.56492 82.99060 82.94155 #>  #> [[2]][[3]] #>        [,1]     [,2]     [,3] #> 12 87.46933 87.90360 89.32176 #> 9  82.06973 82.52492 82.68256 #>  #> [[2]][[4]] #>       [,1]     [,2]    [,3] #> 3 96.61339 98.57737 98.3464 #> 4 95.61777 92.38878 92.0582 #>  #> [[2]][[5]] #>       [,1]     [,2]     [,3] #> 5 88.04376 88.64422 85.34050 #> 7 82.05772 81.84324 81.76576 #>  #> [[2]][[6]] #>        [,1]     [,2]     [,3] #> 11 82.31956 82.01545 82.35014 #> 1  93.72589 94.82253 95.92674 #>  #>   bbb2 <- cv.plsRglm(Y~.,data=Cornell,nt=10, modele=\"pls-glm-inverse.gaussian\",keepcoeffs=TRUE,verbose=FALSE)  #For Jackknife computations kfolds2coeff(bbb2) #>               [,1]          [,2]          [,3]          [,4]          [,5] #> [1,]  0.0002136666 -3.152061e-05 -8.004098e-05 -5.358504e-05 -4.875042e-05 #> [2,]  0.0024298065 -3.505496e-03 -2.306928e-03  3.172305e-04 -2.115984e-03 #> [3,]  0.0001395896  2.587855e-04 -6.570595e-06 -3.435778e-04  1.261472e-05 #> [4,] -0.0019335956  2.585441e-03  2.063289e-03  1.273572e-03  2.075435e-03 #> [5,] -0.0001726175  7.866832e-04  3.087020e-04 -4.618726e-04  3.028237e-04 #>               [,6]          [,7]          [,8] #> [1,] -6.981066e-05 -1.163207e-04 -1.863569e-04 #> [2,] -2.324571e-03 -2.277295e-03 -3.688473e-03 #> [3,] -2.704572e-05 -3.926685e-05 -4.286597e-05 #> [4,]  2.065248e-03  2.026394e-03  2.118389e-03 #> [5,]  2.972386e-04  2.591324e-04  4.486940e-04 boxplot(kfolds2coeff(bbb2)[,1])   kfolds2Chisqind(bbb2) #> [[1]] #> [[1]][[1]] #> [1] 5.663753e-06 3.892966e-06 7.464327e-06 6.280145e-06 6.778551e-06 #>  #> [[1]][[2]] #> [1] 1.158086e-05 3.364512e-07 1.070409e-07 7.188387e-07 2.196760e-05 #> [6] 1.109926e-04 #>  #> [[1]][[3]] #> [1] 3.173657e-05 1.576891e-05 8.341915e-06 6.792655e-06 6.613310e-06 #> [6] 6.593724e-06 #>  #> [[1]][[4]] #> [1] 5.899971e-06 1.970303e-06 1.500514e-06 3.123051e-06 1.437575e-06 #> [6] 2.530327e-06 #>  #> [[1]][[5]] #> [1] 4.053814e-06 5.416716e-06 3.479330e-06 5.235664e-06 4.606876e-06 #> [6] 5.506172e-06 #>  #>  kfolds2Chisq(bbb2) #> [[1]] #> [1] 5.893496e-05 2.738535e-05 2.089313e-05 2.215035e-05 4.140391e-05 #>  summary(bbb2) #> ____************************************************____ #>  #> Family: inverse.gaussian  #> Link function: 1/mu^2  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC Q2Chisqcum_Y  limQ2   Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 81.67928 82.64909           NA     NA          NA                NA #> Nb_Comp_1 49.90521 51.35993    0.9124267 0.0975   0.9124267      5.893496e-05 #> Nb_Comp_2 31.06918 33.00881    0.9394032 0.0975   0.3080453      2.738535e-05 #> Nb_Comp_3 28.40632 30.83085    0.8193787 0.0975  -1.9807078      2.089313e-05 #> Nb_Comp_4 27.08522 29.99466    0.1537615 0.0975  -3.6851524      2.215035e-05 #> Nb_Comp_5 28.46056 31.85490   -8.7751672 0.0975 -10.5513153      4.140391e-05 #> Nb_Comp_6 29.68366 33.56292           NA 0.0975          NA                NA #>           Chi2_Pearson_Y      RSS_Y      R2_Y #> Nb_Comp_0   6.729783e-04 467.796667        NA #> Nb_Comp_1   3.957680e-05  32.478677 0.9305710 #> Nb_Comp_2   7.009452e-06   6.020269 0.9871306 #> Nb_Comp_3   4.727777e-06   3.795855 0.9918857 #> Nb_Comp_4   3.584346e-06   2.699884 0.9942285 #> Nb_Comp_5   3.408069e-06   2.598572 0.9944451 #> Nb_Comp_6   3.195402e-06   2.492371 0.9946721 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" PLS_lm(yCornell,XCornell,10,typeVC=\"standard\")$InfCrit #> ____************************************************____ #> ____TypeVC____ standard ____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>                AIC   Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y      RSS_Y      R2_Y #> Nb_Comp_0 82.01205        NA      NA          NA        NA 467.796667        NA #> Nb_Comp_1 53.15173 0.8966556  0.0975  0.89665563 48.344150  35.742486 0.9235940 #> Nb_Comp_2 41.08283 0.9175426  0.0975  0.20210989 28.518576  11.066606 0.9763431 #> Nb_Comp_3 32.06411 0.9399676  0.0975  0.27195907  8.056942   4.418081 0.9905556 #> Nb_Comp_4 33.76477 0.9197009  0.0975 -0.33759604  5.909608   4.309235 0.9907882 #> Nb_Comp_5 33.34373 0.9281373  0.0975  0.10506161  3.856500   3.521924 0.9924713 #> Nb_Comp_6 35.25533 0.9232562  0.0975 -0.06792167  3.761138   3.496074 0.9925265 #>           R2_residY  RSS_residY PRESS_residY   Q2_residY  LimQ2 Q2cum_residY #> Nb_Comp_0        NA 11.00000000           NA          NA     NA           NA #> Nb_Comp_1 0.9235940  0.84046633   1.13678803  0.89665563 0.0975    0.8966556 #> Nb_Comp_2 0.9763431  0.26022559   0.67059977  0.20210989 0.0975    0.9175426 #> Nb_Comp_3 0.9905556  0.10388893   0.18945488  0.27195907 0.0975    0.9399676 #> Nb_Comp_4 0.9907882  0.10132947   0.13896142 -0.33759604 0.0975    0.9197009 #> Nb_Comp_5 0.9924713  0.08281624   0.09068364  0.10506161 0.0975    0.9281373 #> Nb_Comp_6 0.9925265  0.08220840   0.08844125 -0.06792167 0.0975    0.9232562 #>              AIC.std  DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof #> Nb_Comp_0  37.010388 1.000000    6.5212706 46.0708838 47.7893514 27.59461 #> Nb_Comp_1   8.150064 2.740749    1.8665281  4.5699686  4.9558156 21.34020 #> Nb_Comp_2  -3.918831 5.085967    1.1825195  2.1075461  2.3949331 27.40202 #> Nb_Comp_3 -12.937550 5.121086    0.7488308  0.8467795  0.9628191 24.40842 #> Nb_Comp_4 -11.236891 5.103312    0.7387162  0.8232505  0.9357846 24.23105 #> Nb_Comp_5 -11.657929 6.006316    0.7096382  0.7976101  0.9198348 28.21184 #> Nb_Comp_6  -9.746328 7.000002    0.7633343  0.9711322  1.1359502 33.18348 #>           DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0         1      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1         2      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2         3      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3         4      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4         5      0.7846050  0.8721072  0.9964867   24.16510 #> Nb_Comp_5         6      0.7661509  0.8804809  1.0227979   28.64206 #> Nb_Comp_6         7      0.8361907  1.1070902  1.3048716   33.63927 rm(list=c(\"XCornell\",\"yCornell\",\"bbb\",\"bbb2\")) # } data(Cornell) bbb <- cv.plsRglm(Y~.,data=Cornell,nt=10,NK=1,modele=\"pls\") #>  #> Model: pls  #>  #> NK: 1  #> Number of groups : 5  #> 1  #> ____************************************************____ #>  #> Model: pls  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #>  #> Model: pls  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #>  #> Model: pls  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 5 components could thus be extracted #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #>  #> Model: pls  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #>  #> Model: pls  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ****________________________________________________**** #>  summary(bbb) #> ____************************************************____ #>  #> Model: pls  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC    Q2cum_Y LimQ2_Y       Q2_Y  PRESS_Y      RSS_Y      R2_Y #> Nb_Comp_0 82.01205         NA      NA         NA       NA 467.796667        NA #> Nb_Comp_1 53.15173  0.8825364  0.0975  0.8825364 54.94910  35.742486 0.9235940 #> Nb_Comp_2 41.08283  0.8269042  0.0975 -0.4736115 52.67054  11.066606 0.9763431 #> Nb_Comp_3 32.06411  0.5775041  0.0975 -1.4408218 27.01161   4.418081 0.9905556 #> Nb_Comp_4 33.76477 -0.6610330  0.0975 -2.9314767 17.36958   4.309235 0.9907882 #> Nb_Comp_5 33.34373 -4.2608140  0.0975 -2.1671942 13.64819   3.521924 0.9924713 #> Nb_Comp_6 35.25533         NA  0.0975         NA       NA   3.496074 0.9925265 #>              AIC.std  DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof #> Nb_Comp_0  37.010388 1.000000    6.5212706 46.0708838 47.7893514 27.59461 #> Nb_Comp_1   8.150064 2.740749    1.8665281  4.5699686  4.9558156 21.34020 #> Nb_Comp_2  -3.918831 5.085967    1.1825195  2.1075461  2.3949331 27.40202 #> Nb_Comp_3 -12.937550 5.121086    0.7488308  0.8467795  0.9628191 24.40842 #> Nb_Comp_4 -11.236891 5.103312    0.7387162  0.8232505  0.9357846 24.23105 #> Nb_Comp_5 -11.657929 6.006316    0.7096382  0.7976101  0.9198348 28.21184 #> Nb_Comp_6  -9.746328 7.000002    0.7633343  0.9711322  1.1359502 33.18348 #>           DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0         1      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1         2      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2         3      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3         4      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4         5      0.7846050  0.8721072  0.9964867   24.16510 #> Nb_Comp_5         6      0.7661509  0.8804809  1.0227979   28.64206 #> Nb_Comp_6         7      0.8361907  1.1070902  1.3048716   33.63927 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\"  cv.plsRglm(Y~.,data=Cornell,nt=3,modele=\"pls-glm-family\",family=gaussian(),K=12) #>  #> Family: gaussian  #> Link function: identity  #>  #> NK: 1  #> Leave One Out #> Number of groups : 12  #> 1  #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> 6  #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> 7  #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> 8  #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> 9  #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> 10  #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> 11  #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> 12  #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ****________________________________________________**** #>  #> Number of repeated crossvalidations: #> [1] 1 #> Number of folds for each crossvalidation: #> [1] 12  # \\donttest{ cv.plsRglm(Y~.,data=Cornell,nt=3,modele=\"pls-glm-family\",family=gaussian(),K=6, NK=2,random=TRUE,keepfolds=TRUE,verbose=FALSE)$results_kfolds #> [[1]] #> [[1]][[1]] #>       [,1]     [,2]     [,3] #> 8 82.26250 82.68784 82.57390 #> 1 93.77726 95.43707 96.22502 #>  #> [[1]][[2]] #>        [,1]     [,2]     [,3] #> 12 87.99852 88.21195 90.33982 #> 7  81.62441 81.45137 81.59378 #>  #> [[1]][[3]] #>       [,1]     [,2]     [,3] #> 5 88.69762 88.72588 84.52895 #> 9 82.14663 82.42626 82.57381 #>  #> [[1]][[4]] #>       [,1]     [,2]     [,3] #> 2 94.64037 96.78604 97.68458 #> 3 94.04046 96.54685 97.38485 #>  #> [[1]][[5]] #>        [,1]     [,2]     [,3] #> 10 82.55134 83.14227 83.15714 #> 6  93.61280 93.23121 92.59065 #>  #> [[1]][[6]] #>        [,1]     [,2]     [,3] #> 4  95.67527 93.25885 92.29906 #> 11 82.27810 82.82857 82.12475 #>  #>  #> [[2]] #> [[2]][[1]] #>       [,1]     [,2]     [,3] #> 1 93.77726 95.43707 96.22502 #> 8 82.26250 82.68784 82.57390 #>  #> [[2]][[2]] #>        [,1]     [,2]     [,3] #> 9  81.71032 82.63498 82.60915 #> 10 82.25439 83.47314 83.41923 #>  #> [[2]][[3]] #>       [,1]     [,2]     [,3] #> 2 95.70841 97.71098 97.74896 #> 7 81.76041 81.36644 81.45882 #>  #> [[2]][[4]] #>        [,1]     [,2]     [,3] #> 11 82.50024 81.21191 82.58315 #> 5  88.65842 88.57044 84.05944 #>  #> [[2]][[5]] #>        [,1]     [,2]     [,3] #> 12 88.28185 87.27538 89.61124 #> 4  95.61065 93.37520 91.52727 #>  #> [[2]][[6]] #>       [,1]     [,2]     [,3] #> 6 94.33615 92.86486 92.25602 #> 3 96.32394 97.51708 97.76579 #>  #>   #Different ways of model specifications cv.plsRglm(Y~.,data=Cornell,nt=3,modele=\"pls-glm-family\",family=gaussian(),K=6, NK=2,verbose=FALSE)$results_kfolds #> [[1]] #> [[1]][[1]] #>       [,1]     [,2]     [,3] #> 3 96.32394 97.51708 97.76579 #> 6 94.33615 92.86486 92.25602 #>  #> [[1]][[2]] #>       [,1]     [,2]     [,3] #> 7 81.76041 81.36644 81.45882 #> 2 95.70841 97.71098 97.74896 #>  #> [[1]][[3]] #>       [,1]     [,2]     [,3] #> 1 94.22332 95.36373 95.85522 #> 4 94.54209 93.49347 92.39735 #>  #> [[1]][[4]] #>       [,1]     [,2]     [,3] #> 5 88.70327 88.65979 84.42108 #> 8 82.42406 82.59556 82.40613 #>  #> [[1]][[5]] #>        [,1]     [,2]     [,3] #> 10 82.42399 83.46719 83.47687 #> 12 88.03750 88.00537 89.86291 #>  #> [[1]][[6]] #>        [,1]     [,2]     [,3] #> 11 82.17510 82.18875 82.36369 #> 9  82.14254 82.73114 82.84385 #>  #>  #> [[2]] #> [[2]][[1]] #>       [,1]     [,2]     [,3] #> 9 81.66333 82.45539 82.42717 #> 8 81.93358 82.62278 82.54069 #>  #> [[2]][[2]] #>       [,1]     [,2]     [,3] #> 3 95.63098 97.65603 97.96495 #> 5 88.20917 89.24828 84.89718 #>  #> [[2]][[3]] #>        [,1]     [,2]     [,3] #> 4  95.37792 93.28680 91.85874 #> 10 82.45503 83.28528 83.40513 #>  #> [[2]][[4]] #>       [,1]     [,2]     [,3] #> 1 93.69278 96.29864 96.20283 #> 6 91.81562 91.42217 91.03072 #>  #> [[2]][[5]] #>        [,1]     [,2]     [,3] #> 11 82.51652 81.57490 82.10380 #> 2  95.49781 97.77827 97.75467 #>  #> [[2]][[6]] #>        [,1]     [,2]     [,3] #> 7  81.62441 81.45137 81.59378 #> 12 87.99852 88.21195 90.33982 #>  #>  cv.plsRglm(Y~.,data=Cornell,nt=3,modele=\"pls-glm-family\",family=gaussian, K=6,NK=2,verbose=FALSE)$results_kfolds #> [[1]] #> [[1]][[1]] #>       [,1]     [,2]     [,3] #> 6 93.82267 93.12621 92.64847 #> 2 96.55892 97.35037 97.35321 #>  #> [[1]][[2]] #>        [,1]     [,2]     [,3] #> 12 87.63217 89.62193 89.26717 #> 3  95.16282 98.45056 98.26072 #>  #> [[1]][[3]] #>        [,1]     [,2]     [,3] #> 8  82.22220 82.78130 82.65782 #> 11 81.99705 82.07142 81.97785 #>  #> [[1]][[4]] #>       [,1]     [,2]     [,3] #> 5 88.69762 88.72588 84.52895 #> 9 82.14663 82.42626 82.57381 #>  #> [[1]][[5]] #>        [,1]     [,2]     [,3] #> 7  81.35111 81.44917 81.42097 #> 10 82.27244 83.31538 83.23261 #>  #> [[1]][[6]] #>       [,1]     [,2]     [,3] #> 4 94.54209 93.49347 92.39735 #> 1 94.22332 95.36373 95.85522 #>  #>  #> [[2]] #> [[2]][[1]] #>       [,1]     [,2]     [,3] #> 8 82.19502 82.44263 82.39279 #> 6 93.70842 93.19639 92.60544 #>  #> [[2]][[2]] #>        [,1]     [,2]     [,3] #> 11 82.36708 82.46841 81.46889 #> 12 88.07277 87.76781 89.97618 #>  #> [[2]][[3]] #>       [,1]     [,2]     [,3] #> 9 81.95438 82.40908 82.47999 #> 1 93.77529 95.37353 96.19607 #>  #> [[2]][[4]] #>       [,1]     [,2]     [,3] #> 2 95.70841 97.71098 97.74896 #> 7 81.76041 81.36644 81.45882 #>  #> [[2]][[5]] #>       [,1]     [,2]     [,3] #> 4 96.08759 93.15114 90.18511 #> 5 89.33387 88.45998 83.14531 #>  #> [[2]][[6]] #>        [,1]     [,2]     [,3] #> 10 82.38856 83.32360 83.40165 #> 3  95.44801 98.06096 98.01431 #>  #>  cv.plsRglm(Y~.,data=Cornell,nt=3,modele=\"pls-glm-family\",family=gaussian(), K=6,NK=2,verbose=FALSE)$results_kfolds #> [[1]] #> [[1]][[1]] #>       [,1]     [,2]     [,3] #> 7 81.82483 81.49752 81.34635 #> 5 88.63291 88.75749 84.45984 #>  #> [[1]][[2]] #>        [,1]     [,2]     [,3] #> 12 87.98256 88.00708 89.95495 #> 8  82.13009 82.67518 82.62926 #>  #> [[1]][[3]] #>       [,1]     [,2]     [,3] #> 2 96.55892 97.35037 97.35321 #> 6 93.82267 93.12621 92.64847 #>  #> [[1]][[4]] #>        [,1]     [,2]     [,3] #> 9  82.14254 82.73114 82.84385 #> 11 82.17510 82.18875 82.36369 #>  #> [[1]][[5]] #>        [,1]     [,2]     [,3] #> 10 82.45503 83.28528 83.40513 #> 4  95.37792 93.28680 91.85874 #>  #> [[1]][[6]] #>       [,1]     [,2]     [,3] #> 3 94.52271 97.05014 97.42782 #> 1 93.47990 95.48701 96.41990 #>  #>  #> [[2]] #> [[2]][[1]] #>        [,1]     [,2]     [,3] #> 10 82.42248 83.29460 83.33617 #> 2  95.80543 97.75045 97.79476 #>  #> [[2]][[2]] #>       [,1]     [,2]     [,3] #> 7 81.53113 81.55462 81.46664 #> 6 93.95423 92.98641 92.45456 #>  #> [[2]][[3]] #>       [,1]     [,2]     [,3] #> 3 95.63098 97.65603 97.96495 #> 5 88.20917 89.24828 84.89718 #>  #> [[2]][[4]] #>        [,1]     [,2]     [,3] #> 11 81.99705 82.07142 81.97785 #> 8  82.22220 82.78130 82.65782 #>  #> [[2]][[5]] #>        [,1]     [,2]     [,3] #> 12 88.03359 88.12688 90.22298 #> 9  81.94172 82.56690 82.72971 #>  #> [[2]][[6]] #>       [,1]     [,2]     [,3] #> 4 94.54209 93.49347 92.39735 #> 1 94.22332 95.36373 95.85522 #>  #>  cv.plsRglm(Y~.,data=Cornell,nt=3,modele=\"pls-glm-family\",family=gaussian(link=log), K=6,NK=2,verbose=FALSE)$results_kfolds #> [[1]] #> [[1]][[1]] #>       [,1]     [,2]     [,3] #> 3 95.65204 97.76671 98.02903 #> 5 87.97354 89.18415 85.16903 #>  #> [[1]][[2]] #>       [,1]     [,2]     [,3] #> 4 95.00945 95.18881 93.46179 #> 6 93.02499 94.69311 93.97618 #>  #> [[1]][[3]] #>       [,1]     [,2]     [,3] #> 7 81.83718 81.47340 81.60346 #> 2 95.83184 97.76267 97.84660 #>  #> [[1]][[4]] #>        [,1]     [,2]     [,3] #> 9  81.95851 82.55679 82.74230 #> 12 87.80288 88.01796 90.32582 #>  #> [[1]][[5]] #>        [,1]     [,2]     [,3] #> 11 82.22853 82.01571 82.35287 #> 1  93.81539 95.00873 95.97317 #>  #> [[1]][[6]] #>        [,1]     [,2]     [,3] #> 8  81.87769 82.59788 82.45967 #> 10 82.12875 83.20064 83.06435 #>  #>  #> [[2]] #> [[2]][[1]] #>       [,1]     [,2]     [,3] #> 3 95.65204 97.76671 98.02903 #> 5 87.97354 89.18415 85.16903 #>  #> [[2]][[2]] #>        [,1]     [,2]     [,3] #> 10 82.52382 83.26628 83.19475 #> 1  93.76363 95.29913 96.21594 #>  #> [[2]][[3]] #>        [,1]     [,2]     [,3] #> 6  93.59266 92.73169 92.08803 #> 12 87.88944 87.81086 89.95350 #>  #> [[2]][[4]] #>       [,1]     [,2]     [,3] #> 4 95.43796 92.88376 91.78010 #> 9 81.91009 82.54160 82.56662 #>  #> [[2]][[5]] #>        [,1]     [,2]     [,3] #> 8  82.22865 82.72594 82.71324 #> 11 81.99015 81.96542 82.16627 #>  #> [[2]][[6]] #>       [,1]     [,2]     [,3] #> 7 81.83718 81.47340 81.60346 #> 2 95.83184 97.76267 97.84660 #>  #>   bbb2 <- cv.plsRglm(Y~.,data=Cornell,nt=10, modele=\"pls-glm-gaussian\",keepcoeffs=TRUE,verbose=FALSE) bbb2 <- cv.plsRglm(Y~.,data=Cornell,nt=3,modele=\"pls-glm-family\", family=gaussian(link=log),K=6,keepcoeffs=TRUE,verbose=FALSE)  #For Jackknife computations kfolds2coeff(bbb2) #>          [,1]        [,2]         [,3]        [,4]        [,5]         [,6] #> [1,] 4.470273 -0.06317216 -0.015130085 -0.10739267 -0.05657930  0.030866914 #> [2,] 4.468766 -0.08427095 -0.019204062 -0.13596596 -0.05734367  0.031006389 #> [3,] 4.465960 -0.06389364 -0.019541280 -0.10394949 -0.05167567  0.060119790 #> [4,] 4.477324 -0.09243744 -0.027226841 -0.15458083 -0.05247624  0.022959125 #> [5,] 4.452397 -0.04645103 -0.004221374 -0.07332015 -0.04885178 -0.001590875 #> [6,] 4.496170 -0.08978082 -0.046226381 -0.14905411 -0.05666651  0.079637184 #>           [,7]       [,8] #> [1,] 0.1612710 -0.2068408 #> [2,] 0.1628564 -0.1304898 #> [3,] 0.1729426 -0.2247461 #> [4,] 0.1554308 -0.2314175 #> [5,] 0.1889002 -0.2092133 #> [6,] 0.1230279 -0.3766808 boxplot(kfolds2coeff(bbb2)[,1])   kfolds2Chisqind(bbb2) #> [[1]] #> [[1]][[1]] #> [1] 0.6460407 0.5745404 1.3085258 #>  #> [[1]][[2]] #> [1] 4.374429 1.490981 0.657909 #>  #> [[1]][[3]] #> [1] 13.027216  3.804195  2.570854 #>  #> [[1]][[4]] #> [1] 2.6416340 0.2521208 0.4284244 #>  #> [[1]][[5]] #> [1] 3.304672 4.409153 3.740272 #>  #> [[1]][[6]] #> [1] 25.751584  6.278168  6.934872 #>  #>  kfolds2Chisq(bbb2) #> [[1]] #> [1] 49.74558 16.80916 15.64086 #>  summary(bbb2) #> ____************************************************____ #>  #> Family: gaussian  #> Link function: log  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 82.01205 82.98186           NA     NA         NA                NA #> Nb_Comp_1 52.67938 54.13410    0.8936598 0.0975  0.8936598          49.74558 #> Nb_Comp_2 32.16524 34.10487    0.9479820 0.0975  0.5108343          16.80916 #> Nb_Comp_3 30.58789 33.01242    0.8454256 0.0975 -1.9715587          15.64086 #>           Chi2_Pearson_Y      RSS_Y      R2_Y #> Nb_Comp_0     467.796667 467.796667        NA #> Nb_Comp_1      34.362913  34.362913 0.9265431 #> Nb_Comp_2       5.263520   5.263520 0.9887483 #> Nb_Comp_3       3.906676   3.906676 0.9916488 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" PLS_lm_formula(Y~.,data=Cornell,10,typeVC=\"standard\")$InfCrit #> ____************************************************____ #> ____TypeVC____ standard ____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>                AIC   Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y      RSS_Y      R2_Y #> Nb_Comp_0 82.01205        NA      NA          NA        NA 467.796667        NA #> Nb_Comp_1 53.15173 0.8966556  0.0975  0.89665563 48.344150  35.742486 0.9235940 #> Nb_Comp_2 41.08283 0.9175426  0.0975  0.20210989 28.518576  11.066606 0.9763431 #> Nb_Comp_3 32.06411 0.9399676  0.0975  0.27195907  8.056942   4.418081 0.9905556 #> Nb_Comp_4 33.76477 0.9197009  0.0975 -0.33759604  5.909608   4.309235 0.9907882 #> Nb_Comp_5 33.34373 0.9281373  0.0975  0.10506161  3.856500   3.521924 0.9924713 #> Nb_Comp_6 35.25533 0.9232562  0.0975 -0.06792167  3.761138   3.496074 0.9925265 #>           R2_residY  RSS_residY PRESS_residY   Q2_residY  LimQ2 Q2cum_residY #> Nb_Comp_0        NA 11.00000000           NA          NA     NA           NA #> Nb_Comp_1 0.9235940  0.84046633   1.13678803  0.89665563 0.0975    0.8966556 #> Nb_Comp_2 0.9763431  0.26022559   0.67059977  0.20210989 0.0975    0.9175426 #> Nb_Comp_3 0.9905556  0.10388893   0.18945488  0.27195907 0.0975    0.9399676 #> Nb_Comp_4 0.9907882  0.10132947   0.13896142 -0.33759604 0.0975    0.9197009 #> Nb_Comp_5 0.9924713  0.08281624   0.09068364  0.10506161 0.0975    0.9281373 #> Nb_Comp_6 0.9925265  0.08220840   0.08844125 -0.06792167 0.0975    0.9232562 #>              AIC.std  DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof #> Nb_Comp_0  37.010388 1.000000    6.5212706 46.0708838 47.7893514 27.59461 #> Nb_Comp_1   8.150064 2.740749    1.8665281  4.5699686  4.9558156 21.34020 #> Nb_Comp_2  -3.918831 5.085967    1.1825195  2.1075461  2.3949331 27.40202 #> Nb_Comp_3 -12.937550 5.121086    0.7488308  0.8467795  0.9628191 24.40842 #> Nb_Comp_4 -11.236891 5.103312    0.7387162  0.8232505  0.9357846 24.23105 #> Nb_Comp_5 -11.657929 6.006316    0.7096382  0.7976101  0.9198348 28.21184 #> Nb_Comp_6  -9.746328 7.000002    0.7633343  0.9711322  1.1359502 33.18348 #>           DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0         1      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1         2      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2         3      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3         4      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4         5      0.7846050  0.8721072  0.9964867   24.16510 #> Nb_Comp_5         6      0.7661509  0.8804809  1.0227979   28.64206 #> Nb_Comp_6         7      0.8361907  1.1070902  1.3048716   33.63927 rm(list=c(\"bbb\",\"bbb2\"))   data(pine) bbb <- cv.plsRglm(x11~.,data=pine,nt=10,modele=\"pls-glm-family\", family=gaussian(log),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE) #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge bbb <- cv.plsRglm(x11~.,data=pine,nt=10,modele=\"pls-glm-family\",family=gaussian(), K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)  #For Jackknife computations kfolds2coeff(bbb) #>           [,1]         [,2]        [,3]        [,4]       [,5]       [,6] #>  [1,] 8.156030 -0.002843084 -0.03644892 0.027297442 -0.4943102 0.10194191 #>  [2,] 8.588526 -0.002897746 -0.03843733 0.018948973 -0.5076750 0.10318074 #>  [3,] 7.346555 -0.002639189 -0.03197018 0.029176977 -0.3788608 0.09274711 #>  [4,] 7.644263 -0.002720788 -0.03020072 0.025195551 -0.5070876 0.11257349 #>  [5,] 9.468184 -0.003056342 -0.03244721 0.080968844 -0.5349550 0.08134066 #>  [6,] 8.476948 -0.003052482 -0.03844314 0.043200815 -0.3823907 0.09840346 #>  [7,] 7.485734 -0.002118536 -0.03848000 0.006338868 -0.1314073 0.03168094 #>  [8,] 8.415013 -0.003637688 -0.03532410 0.026646064 -0.6087039 0.17020306 #>  [9,] 9.000407 -0.003254954 -0.03482172 0.027392108 -0.5920017 0.12489329 #> [10,] 8.641954 -0.002960673 -0.03038941 0.024750762 -0.4061744 0.09193541 #>              [,7]        [,8]          [,9]      [,10]        [,11] #>  [1,] -0.02168238 -0.32787943  0.0522727243 -0.7800157 -0.268530683 #>  [2,]  0.31824223 -0.41832606  0.0139150953 -0.8928500 -0.330604891 #>  [3,]  0.09974150  0.02083909  0.0009329017 -0.8186071 -0.516438300 #>  [4,] -0.01614965 -0.22930917  0.0376489360 -0.7629602 -0.294052133 #>  [5,] -0.74630708 -0.22164995  0.1547819588 -1.1247555 -0.416971506 #>  [6,] -0.21142520 -0.22984493  0.0096712788 -0.7951799 -0.316391684 #>  [7,]  0.51108868 -0.64801419 -0.0627153804 -1.0417407  0.000622326 #>  [8,] -0.06239897  0.12598389 -0.0484719959 -0.5177580 -0.379773648 #>  [9,]  0.33490906 -0.45844428  0.0711930649 -1.2312607 -0.222402358 #> [10,]  0.18660012 -0.36608742  0.0016756723 -0.9511047 -0.435404655 boxplot(kfolds2coeff(bbb)[,1])   kfolds2Chisqind(bbb) #> [[1]] #> [[1]][[1]] #>  [1] 0.6822920 0.9898822 0.4567531 0.2848432 0.2855490 0.2581613 0.2622199 #>  [8] 0.2682081 0.2664009 0.2665069 #>  #> [[1]][[2]] #>  [1] 0.3290331 0.6943732 0.8920147 0.6517735 0.7773682 0.8291191 0.7856140 #>  [8] 0.7803094 0.7793632 0.7830987 #>  #> [[1]][[3]] #>  [1] 5.134608 4.352800 4.110543 4.101116 4.142351 3.957491 3.937956 4.015741 #>  [9] 4.009503 4.010102 #>  #> [[1]][[4]] #>  [1] 1.5892089 0.8884867 0.3169854 0.3283711 0.3081848 0.4885121 0.4698701 #>  [8] 0.4410752 0.4635755 0.4632303 #>  #> [[1]][[5]] #>  [1] 0.9480681 0.5598881 0.3043579 0.2901408 0.5615256 0.7317172 1.0167362 #>  [8] 0.9335151 0.8741441 0.8688230 #>  #> [[1]][[6]] #>  [1] 0.8326586 1.3736050 0.9055842 0.9137274 0.6946235 0.6002510 0.6703785 #>  [8] 0.6943911 0.7019240 0.6976481 #>  #> [[1]][[7]] #>  [1] 2.391120 1.841140 1.594341 1.835096 1.618454 1.638564 1.609431 1.594453 #>  [9] 1.594428 1.594464 #>  #> [[1]][[8]] #>  [1] 0.9870604 1.7092037 1.6641294 1.9964626 2.2877309 2.7372381 2.7936109 #>  [8] 2.8345897 2.8228265 2.8242678 #>  #> [[1]][[9]] #>  [1] 0.9878324 0.5034288 0.4767363 0.7297164 1.0435982 0.9677027 1.0976810 #>  [8] 1.0734911 1.0457530 1.0454549 #>  #> [[1]][[10]] #>  [1] 0.7573681 0.8173985 0.5431485 0.5457155 0.5348865 0.5413112 0.4724061 #>  [8] 0.3789233 0.4008979 0.4007754 #>  #>  kfolds2Chisq(bbb) #> [[1]] #>  [1] 14.63925 13.73021 11.26459 11.67696 12.25427 12.75007 13.11590 13.01470 #>  [9] 12.95882 12.95437 #>  summary(bbb) #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                 AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0  82.41888 85.41190           NA     NA         NA                NA #> Nb_Comp_1  63.61896 68.10848    0.2961950 0.0975  0.2961950          14.63925 #> Nb_Comp_2  54.15489 60.14092    0.1274325 0.0975 -0.2397860          13.73021 #> Nb_Comp_3  53.47303 60.95556   -0.2561931 0.0975 -0.4396515          11.26459 #> Nb_Comp_4  54.83398 63.81302   -1.0333990 0.0975 -0.6186993          11.67696 #> Nb_Comp_5  56.32757 66.80312   -2.5217342 0.0975 -0.7319445          12.25427 #> Nb_Comp_6  57.45220 69.42426   -5.4443638 0.0975 -0.8298836          12.75007 #> Nb_Comp_7  59.31417 72.78274  -11.4568863 0.0975 -0.9329893          13.11590 #> Nb_Comp_8  61.20356 76.16863  -22.9933784 0.0975 -0.9261136          13.01470 #> Nb_Comp_9  63.16270 79.62429  -45.1700349 0.0975 -0.9242824          12.95882 #> Nb_Comp_10 65.15982 83.11791  -87.9237460 0.0975 -0.9260056          12.95437 #>            Chi2_Pearson_Y     RSS_Y      R2_Y #> Nb_Comp_0       20.800152 20.800152        NA #> Nb_Comp_1       11.074659 11.074659 0.4675684 #> Nb_Comp_2        7.824528  7.824528 0.6238235 #> Nb_Comp_3        7.213793  7.213793 0.6531855 #> Nb_Comp_4        7.075441  7.075441 0.6598370 #> Nb_Comp_5        6.967693  6.967693 0.6650172 #> Nb_Comp_6        6.785296  6.785296 0.6737862 #> Nb_Comp_7        6.756973  6.756973 0.6751479 #> Nb_Comp_8        6.734363  6.734363 0.6762349 #> Nb_Comp_9        6.726030  6.726030 0.6766355 #> Nb_Comp_10       6.725443  6.725443 0.6766638 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" PLS_lm_formula(x11~.,data=pine,nt=10,typeVC=\"standard\")$InfCrit #> ____************************************************____ #> ____TypeVC____ standard ____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>                 AIC     Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y     RSS_Y #> Nb_Comp_0  82.41888          NA      NA          NA        NA 20.800152 #> Nb_Comp_1  63.61896  0.38248575  0.0975  0.38248575 12.844390 11.074659 #> Nb_Comp_2  58.47638  0.34836456  0.0975 -0.05525570 11.686597  8.919303 #> Nb_Comp_3  56.55421  0.23688359  0.0975 -0.17107874 10.445206  7.919786 #> Nb_Comp_4  54.35053  0.06999681  0.0975 -0.21869112  9.651773  6.972542 #> Nb_Comp_5  55.99834 -0.07691053  0.0975 -0.15796434  8.073955  6.898523 #> Nb_Comp_6  57.69592 -0.19968885  0.0975 -0.11400977  7.685022  6.835594 #> Nb_Comp_7  59.37953 -0.27722139  0.0975 -0.06462721  7.277359  6.770369 #> Nb_Comp_8  61.21213 -0.30602578  0.0975 -0.02255238  6.923057  6.736112 #> Nb_Comp_9  63.18426 -0.39920228  0.0975 -0.07134354  7.216690  6.730426 #> Nb_Comp_10 65.15982 -0.43743644  0.0975 -0.02732569  6.914340  6.725443 #>                 R2_Y R2_residY RSS_residY PRESS_residY   Q2_residY  LimQ2 #> Nb_Comp_0         NA        NA   32.00000           NA          NA     NA #> Nb_Comp_1  0.4675684 0.4675684   17.03781     19.76046  0.38248575 0.0975 #> Nb_Comp_2  0.5711905 0.5711905   13.72190     17.97925 -0.05525570 0.0975 #> Nb_Comp_3  0.6192438 0.6192438   12.18420     16.06943 -0.17107874 0.0975 #> Nb_Comp_4  0.6647841 0.6647841   10.72691     14.84877 -0.21869112 0.0975 #> Nb_Comp_5  0.6683426 0.6683426   10.61304     12.42138 -0.15796434 0.0975 #> Nb_Comp_6  0.6713681 0.6713681   10.51622     11.82303 -0.11400977 0.0975 #> Nb_Comp_7  0.6745039 0.6745039   10.41588     11.19586 -0.06462721 0.0975 #> Nb_Comp_8  0.6761508 0.6761508   10.36317     10.65078 -0.02255238 0.0975 #> Nb_Comp_9  0.6764242 0.6764242   10.35443     11.10252 -0.07134354 0.0975 #> Nb_Comp_10 0.6766638 0.6766638   10.34676     10.63737 -0.02732569 0.0975 #>            Q2cum_residY  AIC.std   DoF.dof sigmahat.dof   AIC.dof   BIC.dof #> Nb_Comp_0            NA 96.63448  1.000000    0.8062287 0.6697018 0.6991787 #> Nb_Comp_1    0.38248575 77.83455  3.176360    0.5994089 0.4047616 0.4565153 #> Nb_Comp_2    0.34836456 72.69198  7.133559    0.5761829 0.4138120 0.5212090 #> Nb_Comp_3    0.23688359 70.76981  8.778329    0.5603634 0.4070516 0.5320535 #> Nb_Comp_4    0.06999681 68.56612  8.427874    0.5221703 0.3505594 0.4547689 #> Nb_Comp_5   -0.07691053 70.21393  9.308247    0.5285695 0.3666578 0.4845912 #> Nb_Comp_6   -0.19968885 71.91152  9.291931    0.5259794 0.3629363 0.4795121 #> Nb_Comp_7   -0.27722139 73.59512  9.756305    0.5284535 0.3702885 0.4938445 #> Nb_Comp_8   -0.30602578 75.42772 10.363948    0.5338475 0.3831339 0.5170783 #> Nb_Comp_9   -0.39920228 77.39986 10.732148    0.5378277 0.3920957 0.5328747 #> Nb_Comp_10  -0.43743644 79.37542 11.000000    0.5407500 0.3987417 0.5446065 #>             GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0  -3.605128         1      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1  -9.875081         2      0.5977015 0.3788984 0.4112998 -11.451340 #> Nb_Comp_2  -6.985517         3      0.5452615 0.3243383 0.3647862 -12.822703 #> Nb_Comp_3  -6.260610         4      0.5225859 0.3061986 0.3557368 -12.756838 #> Nb_Comp_4  -8.152986         5      0.4990184 0.2867496 0.3432131 -12.811575 #> Nb_Comp_5  -7.111583         6      0.5054709 0.3019556 0.3714754 -11.329638 #> Nb_Comp_6  -7.233043         7      0.5127450 0.3186757 0.4021333  -9.918688 #> Nb_Comp_7  -6.742195         8      0.5203986 0.3364668 0.4347156  -8.592770 #> Nb_Comp_8  -6.038372         9      0.5297842 0.3572181 0.4717708  -7.287834 #> Nb_Comp_9  -5.600235        10      0.5409503 0.3813021 0.5140048  -6.008747 #> Nb_Comp_10 -5.288422        11      0.5529032 0.4076026 0.5600977  -4.799453  data(pineNAX21) bbb2 <- cv.plsRglm(x11~.,data=pineNAX21,nt=10, modele=\"pls-glm-family\",family=gaussian(log),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE) #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: algorithm did not converge bbb2 <- cv.plsRglm(x11~.,data=pineNAX21,nt=10, modele=\"pls-glm-gaussian\",K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)  #For Jackknife computations kfolds2coeff(bbb2) #>           [,1]         [,2]        [,3]        [,4]       [,5]       [,6] #>  [1,] 9.417696 -0.003085519 -0.03292365 0.081998660 -0.8184090 0.19049980 #>  [2,] 7.145708 -0.002834763 -0.02678488 0.007015912 -0.3495267 0.08573336 #>  [3,] 8.817251 -0.003483655 -0.03351176 0.091086187 -0.4417299 0.11033386 #>  [4,] 8.622256 -0.003640537 -0.02347172 0.066090708 -0.5491435 0.14689903 #>  [5,] 7.747370 -0.003093857 -0.03153373 0.053811988 -0.6004494 0.12626423 #>  [6,] 7.317040 -0.002601577 -0.03656803 0.031504671 -0.6394931 0.12915114 #>  [7,] 7.219156 -0.002823633 -0.03491071 0.016672955 -0.4603733 0.11156140 #>  [8,] 9.296004 -0.003476210 -0.03318613 0.095264146 -0.6903655 0.13611562 #>  [9,] 7.748634 -0.003134650 -0.03015868 0.052055792 -0.5073365 0.11210967 #> [10,] 7.052572 -0.002695906 -0.03075540 0.019841606 -0.5949681 0.12257379 #>              [,7]         [,8]         [,9]      [,10]      [,11] #>  [1,] -0.76515582 -1.113753776  0.042258992 -0.2870644 -0.6195097 #>  [2,]  0.35323924 -0.453700941 -0.001620362 -0.9331617 -0.2876929 #>  [3,] -0.94698645 -0.130691076  0.015035900 -0.6366736 -0.5886837 #>  [4,] -0.49671881 -0.191433470 -0.018161853 -0.6552005 -0.5806575 #>  [5,] -0.29506311  0.241657428  0.025942148 -0.7431118 -0.7081757 #>  [6,] -0.04158871 -0.130602216  0.076694670 -0.9206700 -0.4439884 #>  [7,]  0.17786780 -0.006821097 -0.037157408 -0.5816967 -0.2203753 #>  [8,] -0.90468636  0.249695617  0.068564185 -0.7575834 -0.9584379 #>  [9,] -0.27249346  0.042666152  0.026255077 -0.7869057 -0.5688790 #> [10,] -0.02787941 -0.295338724  0.051259453 -0.6910382 -0.2890005 boxplot(kfolds2coeff(bbb2)[,1])   kfolds2Chisqind(bbb2) #> [[1]] #> [[1]][[1]] #> [1] 3.402945 3.656572 3.273628 3.450831 3.486171 3.235487 3.218240 3.080754 #> [9] 3.936084 #>  #> [[1]][[2]] #> [1] 1.0828422 0.9777051 0.5551255 0.6121587 0.5185004 0.6057535 0.3657192 #> [8] 0.3336632 0.3226815 #>  #> [[1]][[3]] #> [1] 0.8152388 0.7651711 0.4826267 0.5750911 0.6830450 0.9995395 1.0633777 #> [8] 0.8130788 0.9121713 #>  #> [[1]][[4]] #> [1] 2.855770 2.230451 2.292592 2.502052 2.367000 2.268647 2.237789 2.188098 #> [9] 1.913121 #>  #> [[1]][[5]] #> [1] 0.5917999 0.2743389 0.5452149 0.4854152 0.4633855 0.4810781 0.4958757 #> [8] 0.5344595 0.4076186 #>  #> [[1]][[6]] #> [1] 0.2165681 0.2511958 0.4173566 0.4109749 0.4086318 0.6283137 0.6012819 #> [8] 0.5056380 0.4856855 #>  #> [[1]][[7]] #> [1]   1.7034215   1.6926689   0.5584487   0.9850864   3.3320737   8.2268787 #> [7]   7.5009589   3.2474497 551.7200782 #>  #> [[1]][[8]] #> [1] 0.4455789 0.9113333 0.8791301 1.0514390 1.0140258 1.0458390 1.0655180 #> [8] 1.1615826 1.3890024 #>  #> [[1]][[9]] #> [1] 0.7294811 0.3893972 0.3488275 0.2704331 0.2958156 0.2396339 0.2289992 #> [8] 0.2062736 0.1403598 #>  #> [[1]][[10]] #> [1] 2.1323545 1.6146945 0.8255678 0.6813533 0.6899731 0.7938227 1.0181191 #> [8] 1.0462273 1.0227324 #>  #>  kfolds2Chisq(bbb2) #> [[1]] #> [1]  13.97600  12.76353  10.17852  11.02483  13.25862  18.52499  17.79588 #> [8]  13.11723 562.24953 #>  summary(bbb2) #> ____************************************************____ #> Only naive DoF can be used with missing data #>  #> Family: gaussian  #> Link function: identity  #>  #> ____There are some NAs in X but not in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> Warning : reciprocal condition number of t(cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE])%*%cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE] < 10^{-12} #> Warning only 9 components could thus be extracted #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC  Q2Chisqcum_Y  limQ2   Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 82.41888 85.41190            NA     NA          NA                NA #> Nb_Comp_1 63.90814 68.39766  3.280818e-01 0.0975   0.3280818          13.97600 #> Nb_Comp_2 54.06295 60.04898  2.323716e-01 0.0975  -0.1424432          12.76353 #> Nb_Comp_3 53.77276 61.25530 -1.353191e-03 0.0975  -0.3044765          10.17852 #> Nb_Comp_4 55.18223 64.16127 -5.165300e-01 0.0975  -0.5144806          11.02483 #> Nb_Comp_5 56.53963 67.01518 -1.811983e+00 0.0975  -0.8542221          13.25862 #> Nb_Comp_6 57.73540 69.70746 -6.428327e+00 0.0975  -1.6416682          18.52499 #> Nb_Comp_7 59.46634 72.93491 -1.831589e+01 0.0975  -1.6003014          17.79588 #> Nb_Comp_8 60.79943 75.76451 -3.632518e+01 0.0975  -0.9323561          13.11723 #> Nb_Comp_9 62.14147 78.60305 -3.153663e+03 0.0975 -83.5183678         562.24953 #>           Chi2_Pearson_Y     RSS_Y      R2_Y #> Nb_Comp_0      20.800152 20.800152        NA #> Nb_Comp_1      11.172133 11.172133 0.4628821 #> Nb_Comp_2       7.802760  7.802760 0.6248700 #> Nb_Comp_3       7.279614  7.279614 0.6500211 #> Nb_Comp_4       7.150504  7.150504 0.6562283 #> Nb_Comp_5       7.012612  7.012612 0.6628577 #> Nb_Comp_6       6.843775  6.843775 0.6709747 #> Nb_Comp_7       6.788203  6.788203 0.6736465 #> Nb_Comp_8       6.652395  6.652395 0.6801757 #> Nb_Comp_9       6.521071  6.521071 0.6864893 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" PLS_lm_formula(x11~.,data=pineNAX21,nt=10,typeVC=\"standard\")$InfCrit #> ____************************************************____ #> Only naive DoF can be used with missing data #> ____There are some NAs in X but not in Y____ #> ____TypeVC____ standard ____ #> ____TypeVC____ standard ____unknown____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> Warning : reciprocal condition number of t(cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE])%*%cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE] < 10^{-12} #> Warning only 9 components could thus be extracted #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  #>                AIC     Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y     RSS_Y #> Nb_Comp_0 82.41888          NA      NA          NA        NA 20.800152 #> Nb_Comp_1 63.69250  0.35639805  0.0975  0.35639805 13.387018 11.099368 #> Nb_Comp_2 58.35228  0.28395028  0.0975 -0.11256611 12.348781  8.885823 #> Nb_Comp_3 56.36553  0.07664889  0.0975 -0.28950699 11.458331  7.874634 #> Nb_Comp_4 54.02416 -0.70355579  0.0975 -0.84497074 14.528469  6.903925 #> Nb_Comp_5 55.80450 -0.94905654  0.0975 -0.14411078  7.898855  6.858120 #> Nb_Comp_6 57.45753 -1.27568315  0.0975 -0.16758190  8.007417  6.786392 #> Nb_Comp_7 58.73951 -1.63309014  0.0975 -0.15705481  7.852227  6.640327 #> Nb_Comp_8 60.61227 -1.67907859  0.0975 -0.01746558  6.756304  6.614773 #> Nb_Comp_9 62.25948 -2.15165796  0.0975 -0.17639623  7.781594  6.544432 #>                R2_Y R2_residY RSS_residY PRESS_residY   Q2_residY  LimQ2 #> Nb_Comp_0        NA        NA   32.00000           NA          NA     NA #> Nb_Comp_1 0.4663804 0.4663804   17.07583     20.59526  0.35639805 0.0975 #> Nb_Comp_2 0.5728001 0.5728001   13.67040     18.99799 -0.11256611 0.0975 #> Nb_Comp_3 0.6214146 0.6214146   12.11473     17.62807 -0.28950699 0.0975 #> Nb_Comp_4 0.6680830 0.6680830   10.62135     22.35133 -0.84497074 0.0975 #> Nb_Comp_5 0.6702851 0.6702851   10.55088     12.15200 -0.14411078 0.0975 #> Nb_Comp_6 0.6737336 0.6737336   10.44053     12.31901 -0.16758190 0.0975 #> Nb_Comp_7 0.6807558 0.6807558   10.21581     12.08026 -0.15705481 0.0975 #> Nb_Comp_8 0.6819844 0.6819844   10.17650     10.39424 -0.01746558 0.0975 #> Nb_Comp_9 0.6853661 0.6853661   10.06828     11.97160 -0.17639623 0.0975 #>           Q2cum_residY  AIC.std DoF.dof sigmahat.dof AIC.dof BIC.dof GMDL.dof #> Nb_Comp_0           NA 96.63448      NA           NA      NA      NA       NA #> Nb_Comp_1   0.35639805 77.90810      NA           NA      NA      NA       NA #> Nb_Comp_2   0.28395028 72.56787      NA           NA      NA      NA       NA #> Nb_Comp_3   0.07664889 70.58113      NA           NA      NA      NA       NA #> Nb_Comp_4  -0.70355579 68.23976      NA           NA      NA      NA       NA #> Nb_Comp_5  -0.94905654 70.02009      NA           NA      NA      NA       NA #> Nb_Comp_6  -1.27568315 71.67313      NA           NA      NA      NA       NA #> Nb_Comp_7  -1.63309014 72.95511      NA           NA      NA      NA       NA #> Nb_Comp_8  -1.67907859 74.82787      NA           NA      NA      NA       NA #> Nb_Comp_9  -2.15165796 76.47507      NA           NA      NA      NA       NA #>           DoF.naive sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0         1      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1         2      0.5983679 0.3797438 0.4122175 -11.413749 #> Nb_Comp_2         3      0.5442372 0.3231208 0.3634169 -12.847656 #> Nb_Comp_3         4      0.5210941 0.3044529 0.3537087 -12.776843 #> Nb_Comp_4         5      0.4965569 0.2839276 0.3398355 -12.891035 #> Nb_Comp_5         6      0.5039885 0.3001871 0.3692997 -11.349498 #> Nb_Comp_6         7      0.5108963 0.3163819 0.3992388  -9.922119 #> Nb_Comp_7         8      0.5153766 0.3300041 0.4263658  -8.696873 #> Nb_Comp_8         9      0.5249910 0.3507834 0.4632727  -7.337679 #> Nb_Comp_9        10      0.5334234 0.3707649 0.4998004  -6.033403 rm(list=c(\"bbb\",\"bbb2\"))   data(aze_compl) bbb <- cv.plsRglm(y~.,data=aze_compl,nt=10,K=10,modele=\"pls\", keepcoeffs=TRUE,verbose=FALSE)  #For Jackknife computations kfolds2coeff(bbb) #>            [,1]        [,2]      [,3]       [,4]      [,5]       [,6] #>  [1,] 0.2904228 -0.16546999 0.4613569 -0.2286029 0.3856101 0.19997604 #>  [2,] 0.2788494 -0.15379671 0.2872360 -0.1616180 0.2799155 0.06554366 #>  [3,] 0.2611695 -0.10970491 0.4432985 -0.1519190 0.2286516 0.16025696 #>  [4,] 0.3107607 -0.09353284 0.4504198 -0.1732064 0.1558267 0.14893733 #>  [5,] 0.2353885 -0.20528895 0.4614184 -0.2310755 0.3168370 0.06767269 #>  [6,] 0.3838840 -0.14015351 0.4260461 -0.2183473 0.2572394 0.12343355 #>  [7,] 0.4397244 -0.05753894 0.4190984 -0.1646686 0.2418824 0.08820954 #>  [8,] 0.3215070 -0.15750170 0.4834184 -0.1708883 0.3484636 0.07815465 #>  [9,] 0.4178985 -0.16920876 0.4723971 -0.1464944 0.1380466 0.09771230 #> [10,] 0.1603134 -0.10438813 0.5847150 -0.2461680 0.3367957 0.05361732 #>              [,7]         [,8]        [,9]        [,10]       [,11]       [,12] #>  [1,] -0.03147007  0.005447243 -0.25466893  0.075540157 -0.12212338  0.07503150 #>  [2,] -0.04483009  0.006006823 -0.12822608  0.059277262 -0.05628416  0.01172033 #>  [3,] -0.08010147 -0.004494762 -0.17458325  0.079604238 -0.03021918 -0.01326882 #>  [4,] -0.07870415  0.046118297 -0.16437668  0.047937140 -0.11303248  0.05961749 #>  [5,] -0.02190554 -0.035631497 -0.25287862  0.032991764 -0.12731337  0.07825341 #>  [6,] -0.12150132  0.041957218 -0.27680064 -0.007849660 -0.02937310  0.09737774 #>  [7,] -0.09555267 -0.004121272 -0.16888557  0.008354877 -0.10718182  0.07161800 #>  [8,]  0.03342254 -0.076191370 -0.35907808  0.045943810 -0.13552329  0.08341805 #>  [9,] -0.06646697  0.037302167 -0.04875343  0.006454279 -0.15806923  0.09880511 #> [10,]  0.02576205  0.057609599 -0.30717154  0.111079203 -0.11998307  0.06447860 #>             [,13]      [,14]      [,15]       [,16]        [,17]     [,18] #>  [1,] -0.23605039 0.09132327 0.11871387  0.05238841  0.079533632 0.2310862 #>  [2,] -0.08778194 0.20025677 0.14271415  0.15825821 -0.005158815 0.1463330 #>  [3,] -0.13167005 0.18791410 0.13124435  0.01007703 -0.051049524 0.2258172 #>  [4,] -0.03986917 0.01164343 0.13930641  0.07874179  0.024434649 0.2053491 #>  [5,] -0.08399076 0.06113521 0.12303185  0.01037210  0.025948557 0.2763917 #>  [6,] -0.07048540 0.07374076 0.09789945  0.02290605 -0.025232369 0.3149448 #>  [7,] -0.11999560 0.18408022 0.04962935 -0.01007692 -0.031605435 0.1593562 #>  [8,] -0.16316496 0.12610938 0.04204067  0.19241795  0.057004170 0.2224195 #>  [9,] -0.12803369 0.03888839 0.14377609  0.06005691 -0.027012090 0.2602918 #> [10,] -0.22418988 0.07889964 0.11437179  0.05428228  0.060792746 0.3352487 #>              [,19]        [,20]       [,21]       [,22]      [,23]       [,24] #>  [1,]  0.052229631  0.007385233 -0.25282651 0.056446650 0.33429850 -0.15217124 #>  [2,]  0.038417870  0.107278283 -0.07953724 0.075446065 0.13550787 -0.16390057 #>  [3,]  0.006927076  0.080982967 -0.10468827 0.108960415 0.18333130 -0.13508928 #>  [4,] -0.022328933  0.182848961 -0.17171106 0.047373613 0.06461360 -0.11134306 #>  [5,]  0.012402191  0.088233652 -0.07156676 0.136283685 0.17319692 -0.13247308 #>  [6,] -0.025334581  0.122883152 -0.05858277 0.008872599 0.26877774 -0.13744291 #>  [7,]  0.036579422 -0.035798152 -0.12907028 0.028579269 0.24776651 -0.20559335 #>  [8,] -0.089062486  0.088824430 -0.15330373 0.025641891 0.24578349 -0.17179775 #>  [9,]  0.053065315  0.052679782 -0.18413276 0.121779310 0.01200132 -0.02829972 #> [10,]  0.068251735  0.063652085 -0.09165695 0.076084106 0.22637119 -0.19472896 #>            [,25]      [,26]     [,27]     [,28]       [,29]        [,30] #>  [1,] -0.1964368 -0.2665771 0.1585707 0.1804507 -0.03106563  0.069155087 #>  [2,] -0.1684274 -0.2475508 0.1589951 0.1262438 -0.10324404 -0.001352712 #>  [3,] -0.1957547 -0.3164055 0.1924212 0.2549146 -0.09565424  0.034795798 #>  [4,] -0.2086419 -0.1905443 0.2017151 0.1801214 -0.17652333  0.082746808 #>  [5,] -0.1229588 -0.2931490 0.2342065 0.1693008 -0.13782128 -0.049492555 #>  [6,] -0.1806949 -0.3787962 0.1944198 0.1825709 -0.10505455  0.039556420 #>  [7,] -0.2023592 -0.2792575 0.1746820 0.2441362 -0.11303775 -0.007783524 #>  [8,] -0.1649146 -0.2956775 0.1993148 0.2920899 -0.06420454 -0.010086608 #>  [9,] -0.1756940 -0.3132950 0.1772571 0.2278046 -0.10498110 -0.043764396 #> [10,] -0.2225357 -0.3225024 0.1896744 0.1260020 -0.06321541  0.057762191 #>            [,31]       [,32]      [,33]        [,34] #>  [1,] 0.04102614 -0.07503820 -0.3786917 -0.028915111 #>  [2,] 0.23692286 -0.09989328 -0.3971052 -0.053458363 #>  [3,] 0.06245648 -0.03138443 -0.4016336 -0.037755788 #>  [4,] 0.10169762 -0.06906329 -0.3787767 -0.032138377 #>  [5,] 0.12463061 -0.03563325 -0.2891516 -0.009933863 #>  [6,] 0.10843944 -0.05708189 -0.3841296 -0.032853634 #>  [7,] 0.17627414 -0.07719379 -0.4426674  0.093447741 #>  [8,] 0.06843106 -0.09879500 -0.2923301  0.013059072 #>  [9,] 0.22575481  0.07828888 -0.5832959 -0.039093844 #> [10,] 0.11795164 -0.02646349 -0.4134898 -0.029182528 bbb2 <- cv.plsRglm(y~.,data=aze_compl,nt=3,K=10, modele=\"pls-glm-family\",family=binomial(probit),keepcoeffs=TRUE,verbose=FALSE) bbb2 <- cv.plsRglm(y~.,data=aze_compl,nt=3,K=10, modele=\"pls-glm-logistic\",keepcoeffs=TRUE,verbose=FALSE) summary(bbb,MClassed=TRUE) #> ____************************************************____ #>  #> Model: pls  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                 AIC MissClassed CV_MissClassed       Q2cum_Y LimQ2_Y #> Nb_Comp_0  154.6179          49             NA            NA      NA #> Nb_Comp_1  126.4083          27             44   -0.07967991  0.0975 #> Nb_Comp_2  119.3375          25             45   -0.61560068  0.0975 #> Nb_Comp_3  114.2313          27             44   -1.79789662  0.0975 #> Nb_Comp_4  112.3463          23             44   -4.49018690  0.0975 #> Nb_Comp_5  113.2362          22             42  -10.27579259  0.0975 #> Nb_Comp_6  114.7620          21             42  -22.63990722  0.0975 #> Nb_Comp_7  116.5264          20             43  -49.21935486  0.0975 #> Nb_Comp_8  118.4601          20             43 -107.06034605  0.0975 #> Nb_Comp_9  120.4452          19             43 -232.31457561  0.0975 #> Nb_Comp_10 122.4395          19             43 -502.49592428  0.0975 #>                   Q2_Y  PRESS_Y    RSS_Y      R2_Y  AIC.std  DoF.dof #> Nb_Comp_0           NA       NA 25.91346        NA 298.1344  1.00000 #> Nb_Comp_1  -0.07967991 27.97824 19.38086 0.2520929 269.9248 22.55372 #> Nb_Comp_2  -0.49637005 29.00094 17.76209 0.3145613 262.8540 27.31542 #> Nb_Comp_3  -0.73179960 30.76038 16.58896 0.3598323 257.7478 30.52370 #> Nb_Comp_4  -0.96225510 32.55177 15.98071 0.3833049 255.8628 34.00000 #> Nb_Comp_5  -1.05380851 32.82131 15.81104 0.3898523 256.7527 34.00000 #> Nb_Comp_6  -1.09651845 33.14814 15.73910 0.3926285 258.2785 34.00000 #> Nb_Comp_7  -1.12434653 33.43530 15.70350 0.3940024 260.0429 33.71066 #> Nb_Comp_8  -1.15176691 33.79026 15.69348 0.3943888 261.9766 34.00000 #> Nb_Comp_9  -1.15911372 33.88401 15.69123 0.3944758 263.9617 33.87284 #> Nb_Comp_10 -1.15801316 33.86188 15.69037 0.3945088 265.9560 34.00000 #>            sigmahat.dof   AIC.dof   BIC.dof  GMDL.dof DoF.naive sigmahat.naive #> Nb_Comp_0     0.5015845 0.2540061 0.2604032 -67.17645         1      0.5015845 #> Nb_Comp_1     0.4848429 0.2883114 0.4231184 -53.56607         2      0.4358996 #> Nb_Comp_2     0.4781670 0.2908950 0.4496983 -52.42272         3      0.4193593 #> Nb_Comp_3     0.4719550 0.2902572 0.4631316 -51.93343         4      0.4072955 #> Nb_Comp_4     0.4744263 0.3008285 0.4954133 -50.37079         5      0.4017727 #> Nb_Comp_5     0.4719012 0.2976347 0.4901536 -50.65724         6      0.4016679 #> Nb_Comp_6     0.4708264 0.2962804 0.4879234 -50.78005         7      0.4028135 #> Nb_Comp_7     0.4693382 0.2937976 0.4826103 -51.05525         8      0.4044479 #> Nb_Comp_8     0.4701436 0.2954217 0.4865092 -50.85833         9      0.4064413 #> Nb_Comp_9     0.4696894 0.2945815 0.4845867 -50.95616        10      0.4085682 #> Nb_Comp_10    0.4700970 0.2953632 0.4864128 -50.86368        11      0.4107477 #>            AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0  0.2540061 0.2604032  -67.17645 #> Nb_Comp_1  0.1936625 0.2033251  -79.67755 #> Nb_Comp_2  0.1809352 0.1943501  -81.93501 #> Nb_Comp_3  0.1722700 0.1891422  -83.31503 #> Nb_Comp_4  0.1691819 0.1897041  -83.23369 #> Nb_Comp_5  0.1706451 0.1952588  -81.93513 #> Nb_Comp_6  0.1731800 0.2020601  -80.42345 #> Nb_Comp_7  0.1761610 0.2094352  -78.87607 #> Nb_Comp_8  0.1794902 0.2172936  -77.31942 #> Nb_Comp_9  0.1829787 0.2254232  -75.80069 #> Nb_Comp_10 0.1865584 0.2337468  -74.33325 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\" summary(bbb2,MClassed=TRUE) #> ____************************************************____ #>  #> Family: binomial  #> Link function: logit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC MissClassed CV_MissClassed Q2Chisqcum_Y  limQ2 #> Nb_Comp_0 145.8283 148.4727          49             NA           NA     NA #> Nb_Comp_1 118.1398 123.4285          28             45   -0.7312501 0.0975 #> Nb_Comp_2 109.9553 117.8885          26             45   -5.6396262 0.0975 #> Nb_Comp_3 105.1591 115.7366          22             46 -184.3864110 0.0975 #>             Q2Chisq_Y PREChi2_Pearson_Y Chi2_Pearson_Y    RSS_Y      R2_Y #> Nb_Comp_0          NA                NA      104.00000 25.91346        NA #> Nb_Comp_1  -0.7312501          180.0500      100.53823 19.32272 0.2543365 #> Nb_Comp_2  -2.8351629          385.5805       99.17955 17.33735 0.3309519 #> Nb_Comp_3 -26.9212121         2769.2134      123.37836 15.58198 0.3986915 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" kfolds2coeff(bbb2) #>             [,1]        [,2]     [,3]       [,4]      [,5]        [,6] #>  [1,] -0.5856366 -0.70593213 1.852552 -0.3050775 0.9084177 -0.18877819 #>  [2,] -0.8149337 -0.73838107 2.763618 -0.4614720 0.9635515 -0.04805976 #>  [3,] -1.2104711 -0.32395091 2.662943 -0.6279237 0.6450661 -0.05595700 #>  [4,] -2.1711113 -0.50606432 1.759972 -0.4426020 1.3427648  0.64588373 #>  [5,] -1.9935056  0.06530008 1.770743 -0.5783879 1.3377936 -0.17958544 #>  [6,] -1.4859983 -0.53089451 2.462009 -0.5974124 0.9383782  0.23660079 #>  [7,] -0.3864483 -0.60078416 2.859719 -0.5107874 1.6598961  0.41849554 #>  [8,] -1.6510734  0.27315603 3.038843  0.3358956 0.7353031 -0.34258677 #>  [9,] -0.1003971 -0.89129549 2.183817 -0.3697520 0.4157663  0.17963575 #> [10,] -0.6625460 -0.64377729 2.526018 -0.6559876 0.9569176 -0.10450252 #>               [,7]        [,8]       [,9]      [,10]      [,11]       [,12] #>  [1,]  0.008477155  0.25577898 -0.5714143 -0.1721756 -0.7181097  0.29542011 #>  [2,] -0.986938549  0.03781580 -0.3094900  0.2855071 -0.5693793 -0.18382052 #>  [3,] -0.251958563 -0.51486260 -0.6625394  0.3355462 -0.2945604  0.38942886 #>  [4,] -0.510662840  0.36978247 -0.3460350 -0.3202278 -0.8925107  0.53442304 #>  [5,] -0.355457619  0.28457491 -0.7914298  0.1330579 -0.9832421 -0.08610594 #>  [6,] -0.845401022  0.45731976 -0.6975156  0.1994099 -0.6196171 -0.50806788 #>  [7,] -0.965694039 -0.15612775 -0.9140809 -0.6073345 -0.7170569 -0.13182391 #>  [8,] -0.618266882  0.68708061 -1.1213766  0.4119966 -0.6572498 -0.27936091 #>  [9,] -0.732194986  0.06256693 -0.6381877  0.1896016 -0.8825244 -0.17045254 #> [10,] -0.745248026  0.39187113 -0.7105860  0.6766861 -0.4629398 -0.15548511 #>            [,13]     [,14]     [,15]     [,16]        [,17]     [,18] #>  [1,] -0.4677350 1.0126091 1.3258372 0.8628136  0.194131085 0.6326976 #>  [2,] -0.3216674 0.4738930 1.6062460 0.1129500  0.300569466 1.4939696 #>  [3,] -0.4222692 0.3927179 1.0300889 0.2752369 -0.348980574 1.4146577 #>  [4,] -0.6229572 0.9921400 1.4742803 0.3985643 -0.252523176 1.4527357 #>  [5,] -0.4068965 0.8343620 1.6595472 0.5022135  0.110644396 0.5872420 #>  [6,] -0.5202251 1.1988388 1.1544251 0.5638662 -0.080060451 0.9634235 #>  [7,] -0.4290171 1.1734399 0.8459654 0.8235340 -0.124221608 0.7714531 #>  [8,] -0.5769116 0.4822520 0.9691335 0.6861565 -0.047622093 1.2112867 #>  [9,] -0.1023990 0.6408009 0.9996327 0.1723059  0.072142725 1.1117595 #> [10,] -0.5754584 0.6461705 0.7156629 0.6338462  0.005688769 0.9835615 #>             [,19]     [,20]      [,21]       [,22]     [,23]      [,24] #>  [1,]  0.04211886 0.4712776 -0.8024290  0.33306839 0.9916961 -0.4896372 #>  [2,] -0.31380722 1.0799777 -0.9825220  0.40162252 0.4462640 -0.4953247 #>  [3,]  0.23966705 0.7437650 -0.5270733  0.59611897 0.4822368 -0.9027950 #>  [4,]  0.27264659 0.2713775 -0.9791310  0.04606772 0.5686849 -0.6341368 #>  [5,] -0.17400214 0.5198480 -0.8645098  0.47231855 0.4960366 -0.5216491 #>  [6,] -0.05327875 0.8808986 -0.6839469  0.04770620 1.0180354 -1.0647194 #>  [7,]  0.34305492 0.7716648 -0.6110081 -0.10219774 0.7983989 -0.8266582 #>  [8,]  0.44811485 1.1579532 -0.8321312 -0.25480175 0.7151986 -1.0043173 #>  [9,]  0.02639448 0.6706990 -1.2267333  0.49189615 1.5613934 -0.4508710 #> [10,]  0.51225877 0.4497280 -0.8426358  0.33018067 0.4243222 -0.5258497 #>            [,25]     [,26]     [,27]     [,28]      [,29]        [,30] #>  [1,] -1.0528126 -1.093123 0.2301459 1.1119871 -1.2893685 -0.252093424 #>  [2,] -0.7105976 -1.244015 0.7649467 0.4726965 -0.6243811 -0.617331695 #>  [3,] -0.7793126 -1.427220 0.5230731 0.7290150 -1.3367052 -0.333563870 #>  [4,] -0.8968540 -1.552835 0.4248156 1.0669958 -1.2727016 -0.338020891 #>  [5,] -1.0773448 -1.315935 0.5379118 0.6151999 -0.6221073 -0.497233136 #>  [6,] -0.9794836 -1.410567 0.7320261 1.1101333 -0.9543077  0.031837790 #>  [7,] -1.5409095 -1.361478 1.1317922 0.9686751 -1.0120843  0.001022957 #>  [8,] -1.6981563 -1.321080 0.6577176 0.6252492 -1.0105108 -0.287975245 #>  [9,] -1.9329688 -1.384525 0.7801307 1.3864025 -1.4512861  0.062855637 #> [10,] -1.3367175 -1.550137 0.3331949 0.7286957 -0.9973156  0.002383937 #>           [,31]       [,32]     [,33]       [,34] #>  [1,] 0.4374923  0.39035300 -2.005615 -0.56751270 #>  [2,] 0.8935647  0.92683013 -3.433172  0.05492884 #>  [3,] 0.9212239  0.41337778 -1.953009  0.02387227 #>  [4,] 1.9460768  0.47684686 -2.389454 -0.03604205 #>  [5,] 1.5763427  0.57492711 -1.512309 -0.09687232 #>  [6,] 1.0673302  0.31128852 -2.564469  0.17118097 #>  [7,] 0.8383126 -0.16979131 -2.321932 -0.14154021 #>  [8,] 1.1259856  0.80665697 -2.443683 -0.24572429 #>  [9,] 1.0663707  0.06049022 -2.333540  0.12834523 #> [10,] 1.3432225  0.28651553 -2.245218 -0.05168191  kfolds2Chisqind(bbb2) #> [[1]] #> [[1]][[1]] #> [1] 15.68058 23.48326 32.28129 #>  #> [[1]][[2]] #> [1]  21.65825  43.32133 130.13947 #>  #> [[1]][[3]] #> [1] 12.76393 18.59163 20.19642 #>  #> [[1]][[4]] #> [1]   29.20445  141.47670 1049.38071 #>  #> [[1]][[5]] #> [1] 19.37300 22.62269 67.59520 #>  #> [[1]][[6]] #> [1] 12.04765 11.04876 16.55832 #>  #> [[1]][[7]] #> [1]  8.342431 13.462267 21.782027 #>  #> [[1]][[8]] #> [1]   27.47098   72.62313 1371.03149 #>  #> [[1]][[9]] #> [1] 25.54239 32.29002 49.76008 #>  #> [[1]][[10]] #> [1]  7.966339  6.660717 10.488378 #>  #>  kfolds2Chisq(bbb2) #> [[1]] #> [1]  180.0500  385.5805 2769.2134 #>  summary(bbb2) #> ____************************************************____ #>  #> Family: binomial  #> Link function: logit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC Q2Chisqcum_Y  limQ2   Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 145.8283 148.4727           NA     NA          NA                NA #> Nb_Comp_1 118.1398 123.4285   -0.7312501 0.0975  -0.7312501          180.0500 #> Nb_Comp_2 109.9553 117.8885   -5.6396262 0.0975  -2.8351629          385.5805 #> Nb_Comp_3 105.1591 115.7366 -184.3864110 0.0975 -26.9212121         2769.2134 #>           Chi2_Pearson_Y    RSS_Y      R2_Y #> Nb_Comp_0      104.00000 25.91346        NA #> Nb_Comp_1      100.53823 19.32272 0.2543365 #> Nb_Comp_2       99.17955 17.33735 0.3309519 #> Nb_Comp_3      123.37836 15.58198 0.3986915 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" rm(list=c(\"bbb\",\"bbb2\"))    data(pine) bbb <- cv.plsRglm(round(x11)~.,data=pine,nt=10, modele=\"pls-glm-family\",family=poisson(log),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE) bbb <- cv.plsRglm(round(x11)~.,data=pine,nt=10, modele=\"pls-glm-poisson\",K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)  #For Jackknife computations kfolds2coeff(bbb) #>            [,1]         [,2]        [,3]        [,4]      [,5]      [,6] #>  [1,] 12.369713 -0.005162288 -0.06978464  0.17333712 -1.003630 0.2542444 #>  [2,] 18.595676 -0.007618793 -0.10171648  0.38178258 -2.058722 0.3901663 #>  [3,] 10.439251 -0.003661678 -0.06094272  0.13807230 -1.159559 0.1945328 #>  [4,] 11.174660 -0.004349033 -0.05703580  0.16881400 -1.595398 0.3185621 #>  [5,] 14.936104 -0.006093933 -0.08391264  0.23973512 -1.888993 0.3310605 #>  [6,] 12.720096 -0.004960265 -0.07100791  0.20115847 -1.664469 0.3199172 #>  [7,]  9.840377 -0.005871246 -0.04793368 -0.02075348 -1.456662 0.3313351 #>  [8,] 13.417143 -0.005196755 -0.07659319  0.22685674 -1.477207 0.2718937 #>  [9,]  9.339715 -0.001426923 -0.08756677  0.05029940 -2.686784 0.4757555 #> [10,] 15.500859 -0.008217655 -0.02902573  0.24560682 -1.416538 0.3865396 #>             [,7]        [,8]         [,9]      [,10]       [,11] #>  [1,] -1.3872315 -0.35245353 -0.117514452 -0.8409484 -0.13511343 #>  [2,] -4.5777802  0.97951382  0.380612480 -1.4135057 -0.88985041 #>  [3,] -1.1331280 -0.45746498  0.211733634 -1.7934177  0.43987485 #>  [4,] -1.6008622  0.05812548  0.125109859 -1.2903566  0.02656087 #>  [5,] -2.8304007  0.35310677  0.412611650 -1.2485473 -0.56204672 #>  [6,] -2.2556346  0.15811178  0.267798052 -1.2996562 -0.27977888 #>  [7,]  0.3502972  0.11215452 -0.004967203 -0.3011419 -0.10658889 #>  [8,] -2.6726333 -0.01341568  0.314708765 -1.2911608 -0.21758564 #>  [9,]  0.4321676 -0.49098634  0.549019098 -2.8407172 -0.29880651 #> [10,] -1.6104299 -0.37225662  0.062205959 -2.1753942  0.17092750 boxplot(kfolds2coeff(bbb)[,1])   kfolds2Chisqind(bbb) #> [[1]] #> [[1]][[1]] #>  [1] 1.442471 3.497844 2.502086 3.154369 2.886545 2.477623 1.469552 1.470941 #>  [9] 1.459521 1.499906 #>  #> [[1]][[2]] #>  [1]  4.621335  9.188534 16.661907 20.626577 29.550254 40.300071 41.829950 #>  [8] 36.588292 34.654527 34.533510 #>  #> [[1]][[3]] #>  [1] 3.804516 2.939185 2.319704 2.577046 2.516617 2.225765 2.034626 1.959327 #>  [9] 1.870617 1.878698 #>  #> [[1]][[4]] #>  [1] 1.0568966 0.7058201 0.7850168 1.0004793 0.9951409 1.0467010 1.0351800 #>  [8] 0.9764938 0.9525828 0.9524766 #>  #> [[1]][[5]] #>  [1] 0.8650672 2.9059687 1.5640753 1.7104577 1.7760062 2.1871950 2.4698616 #>  [8] 2.5659205 2.7486451 2.7553889 #>  #> [[1]][[6]] #>  [1] 0.8074381 0.8314659 1.5289475 1.2617571 2.0096085 1.6901759 1.1023362 #>  [8] 0.3897635 0.3220244 0.3349922 #>  #> [[1]][[7]] #>  [1] 6.570202 6.113771 3.698447 2.392023 2.231749 6.478331 4.839590 7.044384 #>  [9] 6.959666 6.696944 #>  #> [[1]][[8]] #>  [1] 1.1780765 1.3030034 0.7083136 0.9203929 1.9469712 1.8634631 0.8699945 #>  [8] 0.5797420 0.5698208 0.5709594 #>  #> [[1]][[9]] #>  [1]  2.398462  4.625143  5.114656  4.291948  7.453888 34.281484 34.383919 #>  [8] 39.286581 32.056548 32.308211 #>  #> [[1]][[10]] #>  [1]  9.742179  3.683467  2.045690  7.493754 13.338690 12.916636 15.621795 #>  [8] 13.471434 12.546697 12.695515 #>  #>  kfolds2Chisq(bbb) #> [[1]] #>  [1]  32.48664  35.79420  36.92884  45.42880  64.70547 105.46744 105.65680 #>  [8] 104.33288  94.14065  94.22660 #>  summary(bbb) #> ____************************************************____ #>  #> Family: poisson  #> Link function: log  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                 AIC      BIC  Q2Chisqcum_Y  limQ2   Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0  76.61170 78.10821            NA     NA          NA                NA #> Nb_Comp_1  65.70029 68.69331  3.743278e-02 0.0975  0.03743278          32.48664 #> Nb_Comp_2  62.49440 66.98392 -4.440862e-01 0.0975 -0.50024450          35.79420 #> Nb_Comp_3  62.47987 68.46590 -2.082583e+00 0.0975 -1.13462541          36.92884 #> Nb_Comp_4  64.21704 71.69958 -8.029256e+00 0.0975 -1.92912009          45.42880 #> Nb_Comp_5  65.81654 74.79559 -3.733778e+01 0.0975 -3.24595068          64.70547 #> Nb_Comp_6  66.48888 76.96443 -2.639187e+02 0.0975 -5.91012285         105.46744 #> Nb_Comp_7  68.40234 80.37440 -1.576257e+03 0.0975 -4.95373885         105.65680 #> Nb_Comp_8  70.39399 83.86256 -9.118614e+03 0.0975 -4.78194582         104.33288 #> Nb_Comp_9  72.37642 87.34149 -4.722576e+04 0.0975 -4.17859136          94.14065 #> Nb_Comp_10 74.37612 90.83770 -2.425167e+05 0.0975 -4.13517493          94.22660 #>            Chi2_Pearson_Y     RSS_Y      R2_Y #> Nb_Comp_0        33.75000 24.545455        NA #> Nb_Comp_1        23.85891 12.599337 0.4866937 #> Nb_Comp_2        17.29992  9.056074 0.6310488 #> Nb_Comp_3        15.50937  8.232069 0.6646194 #> Nb_Comp_4        15.23934  8.125808 0.6689485 #> Nb_Comp_5        15.26275  7.862134 0.6796909 #> Nb_Comp_6        17.74629  6.203270 0.7472742 #> Nb_Comp_7        18.04460  5.879880 0.7604493 #> Nb_Comp_8        18.17881  5.827065 0.7626011 #> Nb_Comp_9        18.34925  5.837300 0.7621841 #> Nb_Comp_10       18.39332  5.832437 0.7623822 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" PLS_lm_formula(x11~.,data=pine,10,typeVC=\"standard\")$InfCrit #> ____************************************************____ #> ____TypeVC____ standard ____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>                 AIC     Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y     RSS_Y #> Nb_Comp_0  82.41888          NA      NA          NA        NA 20.800152 #> Nb_Comp_1  63.61896  0.38248575  0.0975  0.38248575 12.844390 11.074659 #> Nb_Comp_2  58.47638  0.34836456  0.0975 -0.05525570 11.686597  8.919303 #> Nb_Comp_3  56.55421  0.23688359  0.0975 -0.17107874 10.445206  7.919786 #> Nb_Comp_4  54.35053  0.06999681  0.0975 -0.21869112  9.651773  6.972542 #> Nb_Comp_5  55.99834 -0.07691053  0.0975 -0.15796434  8.073955  6.898523 #> Nb_Comp_6  57.69592 -0.19968885  0.0975 -0.11400977  7.685022  6.835594 #> Nb_Comp_7  59.37953 -0.27722139  0.0975 -0.06462721  7.277359  6.770369 #> Nb_Comp_8  61.21213 -0.30602578  0.0975 -0.02255238  6.923057  6.736112 #> Nb_Comp_9  63.18426 -0.39920228  0.0975 -0.07134354  7.216690  6.730426 #> Nb_Comp_10 65.15982 -0.43743644  0.0975 -0.02732569  6.914340  6.725443 #>                 R2_Y R2_residY RSS_residY PRESS_residY   Q2_residY  LimQ2 #> Nb_Comp_0         NA        NA   32.00000           NA          NA     NA #> Nb_Comp_1  0.4675684 0.4675684   17.03781     19.76046  0.38248575 0.0975 #> Nb_Comp_2  0.5711905 0.5711905   13.72190     17.97925 -0.05525570 0.0975 #> Nb_Comp_3  0.6192438 0.6192438   12.18420     16.06943 -0.17107874 0.0975 #> Nb_Comp_4  0.6647841 0.6647841   10.72691     14.84877 -0.21869112 0.0975 #> Nb_Comp_5  0.6683426 0.6683426   10.61304     12.42138 -0.15796434 0.0975 #> Nb_Comp_6  0.6713681 0.6713681   10.51622     11.82303 -0.11400977 0.0975 #> Nb_Comp_7  0.6745039 0.6745039   10.41588     11.19586 -0.06462721 0.0975 #> Nb_Comp_8  0.6761508 0.6761508   10.36317     10.65078 -0.02255238 0.0975 #> Nb_Comp_9  0.6764242 0.6764242   10.35443     11.10252 -0.07134354 0.0975 #> Nb_Comp_10 0.6766638 0.6766638   10.34676     10.63737 -0.02732569 0.0975 #>            Q2cum_residY  AIC.std   DoF.dof sigmahat.dof   AIC.dof   BIC.dof #> Nb_Comp_0            NA 96.63448  1.000000    0.8062287 0.6697018 0.6991787 #> Nb_Comp_1    0.38248575 77.83455  3.176360    0.5994089 0.4047616 0.4565153 #> Nb_Comp_2    0.34836456 72.69198  7.133559    0.5761829 0.4138120 0.5212090 #> Nb_Comp_3    0.23688359 70.76981  8.778329    0.5603634 0.4070516 0.5320535 #> Nb_Comp_4    0.06999681 68.56612  8.427874    0.5221703 0.3505594 0.4547689 #> Nb_Comp_5   -0.07691053 70.21393  9.308247    0.5285695 0.3666578 0.4845912 #> Nb_Comp_6   -0.19968885 71.91152  9.291931    0.5259794 0.3629363 0.4795121 #> Nb_Comp_7   -0.27722139 73.59512  9.756305    0.5284535 0.3702885 0.4938445 #> Nb_Comp_8   -0.30602578 75.42772 10.363948    0.5338475 0.3831339 0.5170783 #> Nb_Comp_9   -0.39920228 77.39986 10.732148    0.5378277 0.3920957 0.5328747 #> Nb_Comp_10  -0.43743644 79.37542 11.000000    0.5407500 0.3987417 0.5446065 #>             GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0  -3.605128         1      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1  -9.875081         2      0.5977015 0.3788984 0.4112998 -11.451340 #> Nb_Comp_2  -6.985517         3      0.5452615 0.3243383 0.3647862 -12.822703 #> Nb_Comp_3  -6.260610         4      0.5225859 0.3061986 0.3557368 -12.756838 #> Nb_Comp_4  -8.152986         5      0.4990184 0.2867496 0.3432131 -12.811575 #> Nb_Comp_5  -7.111583         6      0.5054709 0.3019556 0.3714754 -11.329638 #> Nb_Comp_6  -7.233043         7      0.5127450 0.3186757 0.4021333  -9.918688 #> Nb_Comp_7  -6.742195         8      0.5203986 0.3364668 0.4347156  -8.592770 #> Nb_Comp_8  -6.038372         9      0.5297842 0.3572181 0.4717708  -7.287834 #> Nb_Comp_9  -5.600235        10      0.5409503 0.3813021 0.5140048  -6.008747 #> Nb_Comp_10 -5.288422        11      0.5529032 0.4076026 0.5600977  -4.799453  data(pineNAX21) bbb2 <- cv.plsRglm(round(x11)~.,data=pineNAX21,nt=10, modele=\"pls-glm-family\",family=poisson(log),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE) bbb2 <- cv.plsRglm(round(x11)~.,data=pineNAX21,nt=10, modele=\"pls-glm-poisson\",K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)  #For Jackknife computations kfolds2coeff(bbb2) #>           [,1]         [,2]        [,3]      [,4]      [,5]      [,6]      [,7] #>  [1,] 15.65181 -0.007778317 -0.06133387 0.1036472 -2.074764 0.4148445 -1.606337 #>  [2,] 13.30561 -0.005364141 -0.07112078 0.2051332 -1.660789 0.3152937 -2.471535 #>  [3,] 14.57700 -0.005969412 -0.05590340 0.2797425 -1.307411 0.3266281 -3.285194 #>  [4,] 13.74618 -0.005485595 -0.07071813 0.2056446 -1.455331 0.2976372 -2.208170 #>  [5,] 14.71844 -0.005191698 -0.06892616 0.2096098 -1.441988 0.2616690 -2.123594 #>  [6,] 14.86525 -0.004366072 -0.09181109 0.2197708 -2.340261 0.4152243 -2.461445 #>  [7,] 12.78220 -0.004449958 -0.05367658 0.1936654 -1.549712 0.3031097 -2.000991 #>  [8,] 13.42163 -0.005025979 -0.07101602 0.2134477 -1.582596 0.3004695 -2.430726 #>  [9,] 14.53850 -0.005304882 -0.07734715 0.2055085 -1.671481 0.3139955 -2.073842 #> [10,] 12.98226 -0.004161051 -0.05999490 0.1676080 -1.530884 0.2934076 -1.490332 #>              [,8]      [,9]      [,10]       [,11] #>  [1,]  0.64825723 0.2888299 -0.7376983 -0.52127608 #>  [2,]  0.61557923 0.2823063 -0.9779591 -0.44916262 #>  [3,]  0.33256224 0.0805504 -0.9983641 -0.42883521 #>  [4,]  0.31729630 0.1439375 -0.9912127 -0.35008193 #>  [5,] -0.40598118 0.2896055 -1.8549197  0.14768310 #>  [6,] -0.10506358 0.4162079 -1.5268739 -0.19955829 #>  [7,] -0.09727505 0.1616900 -1.3406024 -0.05705524 #>  [8,] -0.07500994 0.2802244 -1.3008857 -0.37809504 #>  [9,] -0.03135411 0.2668785 -1.5388738 -0.10759112 #> [10,] -0.19670296 0.2650178 -1.8288462 -0.39311440 boxplot(kfolds2coeff(bbb2)[,1])   kfolds2Chisqind(bbb2) #> [[1]] #> [[1]][[1]] #> [1] 22.30920 29.23253 16.89312 16.54502 14.47897 24.43505 28.58459 38.21246 #> [9] 34.50836 #>  #> [[1]][[2]] #> [1] 1.1231678 1.3189809 1.3043031 0.9071203 0.6560976 0.5265062 0.6533294 #> [8] 0.6962001 0.7081156 #>  #> [[1]][[3]] #> [1] 2.321301 2.809304 2.705924 3.273676 3.215357 3.327397 3.522555 3.417765 #> [9] 3.448266 #>  #> [[1]][[4]] #> [1] 0.8934032 0.9573415 1.1667939 1.0615698 0.8037625 0.4884185 0.4289901 #> [8] 0.5158235 0.5869685 #>  #> [[1]][[5]] #> [1] 11.8654685  3.8776805  0.8366341  0.7053157  0.7784905  0.6245028  0.4691767 #> [8]  0.4447110  0.4106887 #>  #> [[1]][[6]] #> [1] 1.040822 2.636376 1.931004 3.001160 2.714714 5.141380 6.656049 6.141840 #> [9] 6.046703 #>  #> [[1]][[7]] #> [1] 1.4926251 0.8745468 0.8276476 1.1504958 1.0421087 1.0187052 0.9176570 #> [8] 0.9049428 0.9112573 #>  #> [[1]][[8]] #> [1]     1.013730     2.392011     6.919940     8.271099     8.235061 #> [6]   133.731586   689.611775 40203.426627    38.049486 #>  #> [[1]][[9]] #> [1] 1.099190 2.058695 2.055539 2.312350 2.354769 2.341801 2.343791 2.444479 #> [9] 2.282510 #>  #> [[1]][[10]] #> [1] 2.657995 3.817680 2.635557 2.687763 2.749222 3.255578 2.576799 1.898348 #> [9] 1.067236 #>  #>  kfolds2Chisq(bbb2) #> [[1]] #> [1]    45.81690    49.97515    37.27647    39.91557    37.02856   174.89092 #> [7]   735.76471 40258.10319    88.01959 #>  summary(bbb2) #> ____************************************************____ #> Only naive DoF can be used with missing data #>  #> Family: poisson  #> Link function: log  #>  #> ____There are some NAs in X but not in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> Warning : reciprocal condition number of t(cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE])%*%cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE] < 10^{-12} #> Warning only 9 components could thus be extracted #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC  Q2Chisqcum_Y  limQ2     Q2Chisq_Y #> Nb_Comp_0 76.61170 78.10821            NA     NA            NA #> Nb_Comp_1 65.74449 68.73751 -3.575379e-01 0.0975    -0.3575379 #> Nb_Comp_2 62.35674 66.84626 -1.839690e+00 0.0975    -1.0917941 #> Nb_Comp_3 62.39804 68.38407 -5.114561e+00 0.0975    -1.1532497 #> Nb_Comp_4 64.08113 71.56366 -1.472926e+01 0.0975    -1.5724268 #> Nb_Comp_5 65.63784 74.61689 -3.703721e+01 0.0975    -1.4182454 #> Nb_Comp_6 67.18468 77.66024 -4.278641e+02 0.0975   -10.2748564 #> Nb_Comp_7 68.61004 80.58210 -1.935096e+04 0.0975   -44.1237524 #> Nb_Comp_8 70.54487 84.01344 -4.446747e+07 0.0975 -2296.8277321 #> Nb_Comp_9 72.37296 87.33803 -2.204124e+08 0.0975    -3.9567104 #>           PREChi2_Pearson_Y Chi2_Pearson_Y     RSS_Y      R2_Y #> Nb_Comp_0                NA       33.75000 24.545455        NA #> Nb_Comp_1          45.81690       23.89105 12.654950 0.4844280 #> Nb_Comp_2          49.97515       17.31172  8.871122 0.6385839 #> Nb_Comp_3          37.27647       15.51670  8.203709 0.6657748 #> Nb_Comp_4          39.91557       15.31216  7.959332 0.6757309 #> Nb_Comp_5          37.02856       15.51159  7.724832 0.6852846 #> Nb_Comp_6         174.89092       16.30549  6.814620 0.7223673 #> Nb_Comp_7         735.76471       17.52007  6.284737 0.7439552 #> Nb_Comp_8       40258.10319       17.75766  6.160827 0.7490034 #> Nb_Comp_9          88.01959       18.30206  5.831059 0.7624383 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" PLS_lm_formula(x11~.,data=pineNAX21,10,typeVC=\"standard\")$InfCrit #> ____************************************************____ #> Only naive DoF can be used with missing data #> ____There are some NAs in X but not in Y____ #> ____TypeVC____ standard ____ #> ____TypeVC____ standard ____unknown____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> Warning : reciprocal condition number of t(cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE])%*%cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE] < 10^{-12} #> Warning only 9 components could thus be extracted #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  #>                AIC     Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y     RSS_Y #> Nb_Comp_0 82.41888          NA      NA          NA        NA 20.800152 #> Nb_Comp_1 63.69250  0.35639805  0.0975  0.35639805 13.387018 11.099368 #> Nb_Comp_2 58.35228  0.28395028  0.0975 -0.11256611 12.348781  8.885823 #> Nb_Comp_3 56.36553  0.07664889  0.0975 -0.28950699 11.458331  7.874634 #> Nb_Comp_4 54.02416 -0.70355579  0.0975 -0.84497074 14.528469  6.903925 #> Nb_Comp_5 55.80450 -0.94905654  0.0975 -0.14411078  7.898855  6.858120 #> Nb_Comp_6 57.45753 -1.27568315  0.0975 -0.16758190  8.007417  6.786392 #> Nb_Comp_7 58.73951 -1.63309014  0.0975 -0.15705481  7.852227  6.640327 #> Nb_Comp_8 60.61227 -1.67907859  0.0975 -0.01746558  6.756304  6.614773 #> Nb_Comp_9 62.25948 -2.15165796  0.0975 -0.17639623  7.781594  6.544432 #>                R2_Y R2_residY RSS_residY PRESS_residY   Q2_residY  LimQ2 #> Nb_Comp_0        NA        NA   32.00000           NA          NA     NA #> Nb_Comp_1 0.4663804 0.4663804   17.07583     20.59526  0.35639805 0.0975 #> Nb_Comp_2 0.5728001 0.5728001   13.67040     18.99799 -0.11256611 0.0975 #> Nb_Comp_3 0.6214146 0.6214146   12.11473     17.62807 -0.28950699 0.0975 #> Nb_Comp_4 0.6680830 0.6680830   10.62135     22.35133 -0.84497074 0.0975 #> Nb_Comp_5 0.6702851 0.6702851   10.55088     12.15200 -0.14411078 0.0975 #> Nb_Comp_6 0.6737336 0.6737336   10.44053     12.31901 -0.16758190 0.0975 #> Nb_Comp_7 0.6807558 0.6807558   10.21581     12.08026 -0.15705481 0.0975 #> Nb_Comp_8 0.6819844 0.6819844   10.17650     10.39424 -0.01746558 0.0975 #> Nb_Comp_9 0.6853661 0.6853661   10.06828     11.97160 -0.17639623 0.0975 #>           Q2cum_residY  AIC.std DoF.dof sigmahat.dof AIC.dof BIC.dof GMDL.dof #> Nb_Comp_0           NA 96.63448      NA           NA      NA      NA       NA #> Nb_Comp_1   0.35639805 77.90810      NA           NA      NA      NA       NA #> Nb_Comp_2   0.28395028 72.56787      NA           NA      NA      NA       NA #> Nb_Comp_3   0.07664889 70.58113      NA           NA      NA      NA       NA #> Nb_Comp_4  -0.70355579 68.23976      NA           NA      NA      NA       NA #> Nb_Comp_5  -0.94905654 70.02009      NA           NA      NA      NA       NA #> Nb_Comp_6  -1.27568315 71.67313      NA           NA      NA      NA       NA #> Nb_Comp_7  -1.63309014 72.95511      NA           NA      NA      NA       NA #> Nb_Comp_8  -1.67907859 74.82787      NA           NA      NA      NA       NA #> Nb_Comp_9  -2.15165796 76.47507      NA           NA      NA      NA       NA #>           DoF.naive sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0         1      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1         2      0.5983679 0.3797438 0.4122175 -11.413749 #> Nb_Comp_2         3      0.5442372 0.3231208 0.3634169 -12.847656 #> Nb_Comp_3         4      0.5210941 0.3044529 0.3537087 -12.776843 #> Nb_Comp_4         5      0.4965569 0.2839276 0.3398355 -12.891035 #> Nb_Comp_5         6      0.5039885 0.3001871 0.3692997 -11.349498 #> Nb_Comp_6         7      0.5108963 0.3163819 0.3992388  -9.922119 #> Nb_Comp_7         8      0.5153766 0.3300041 0.4263658  -8.696873 #> Nb_Comp_8         9      0.5249910 0.3507834 0.4632727  -7.337679 #> Nb_Comp_9        10      0.5334234 0.3707649 0.4998004  -6.033403 rm(list=c(\"bbb\",\"bbb2\"))    data(pine) bbb <- cv.plsRglm(x11~.,data=pine,nt=10,modele=\"pls-glm-family\", family=Gamma,K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE) #> Warning: NaNs produced bbb <- cv.plsRglm(x11~.,data=pine,nt=10,modele=\"pls-glm-Gamma\", K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)  #For Jackknife computations kfolds2coeff(bbb) #>             [,1]        [,2]        [,3]        [,4]     [,5]       [,6] #>  [1,] -16.792342 0.005236079  0.10926655 -0.21333447 2.301769 -0.4448298 #>  [2,] -14.234610 0.006332738  0.04999250 -0.27453618 1.891351 -0.3488068 #>  [3,]  -5.844789 0.007117475 -0.06469022  0.37920549 1.335298 -0.3061289 #>  [4,]  -9.932799 0.005322613  0.05942021 -0.07160385 2.053345 -0.4252070 #>  [5,] -12.774065 0.006741090  0.03326580 -0.17160692 1.876863 -0.3876373 #>  [6,] -13.702999 0.006244324  0.03880042 -0.25984490 1.532138 -0.2949647 #>  [7,] -14.210322 0.007292974  0.04353365 -0.22707691 1.832913 -0.3381223 #>  [8,]  -9.939151 0.005128945  0.03243690 -0.09119951 1.710555 -0.3699950 #>  [9,] -10.404425 0.004419537  0.03893195 -0.18407583 1.337004 -0.2877251 #> [10,] -11.697334 0.005560470  0.03743670 -0.17084381 1.694513 -0.3408502 #>            [,7]        [,8]        [,9]      [,10]     [,11] #>  [1,]  2.469793  1.06903574 -0.31839346 1.48350871 0.8169467 #>  [2,]  3.828627 -0.67658291 -0.37425278 1.00617016 1.0680206 #>  [3,] -3.970980  0.05992600  0.15889027 0.08461725 0.5449955 #>  [4,]  0.893972 -0.23958181 -0.19695678 0.60757259 0.3634518 #>  [5,]  2.136043 -0.51600999 -0.26135056 1.14341243 0.8057468 #>  [6,]  3.153256 -0.46261855 -0.27290448 1.44831281 0.8710504 #>  [7,]  3.264836 -0.73899822 -0.36692526 0.96385542 0.8439426 #>  [8,]  1.111675 -0.21287594 -0.06494115 0.69672266 0.5415921 #>  [9,]  2.212431  0.01529659 -0.06112184 0.96665142 0.3672662 #> [10,]  2.366473 -0.34801334 -0.22585906 0.99273080 0.6957553 boxplot(kfolds2coeff(bbb)[,1])   kfolds2Chisqind(bbb) #> [[1]] #> [[1]][[1]] #>  [1]  1.808792  7.389144 37.357823 42.822663 40.651261 32.182244 27.405606 #>  [8] 19.943324 21.130738 21.328443 #>  #> [[1]][[2]] #>  [1] 2.504751 2.832532 3.891738 3.326394 3.717222 4.439722 3.872176 4.442990 #>  [9] 4.548204 4.543575 #>  #> [[1]][[3]] #>  [1]  7.111664 14.015567 13.460548  9.065039  9.165900 15.536605 21.252966 #>  [8] 22.590195 22.753271 22.532481 #>  #> [[1]][[4]] #>  [1] 0.9888071 1.0380953 1.5109132 1.7599616 2.8706034 2.8579693 3.2660505 #>  [8] 2.9585912 2.8708790 2.8854578 #>  #> [[1]][[5]] #>  [1] 1.290575 1.517099 2.095550 2.146920 2.067903 2.380557 2.726492 2.898626 #>  [9] 2.949727 2.963570 #>  #> [[1]][[6]] #>  [1] 0.8579215 0.9098802 1.1676478 1.5733520 0.8350086 0.7874430 0.7413699 #>  [8] 0.8274457 1.2608567 1.2490741 #>  #> [[1]][[7]] #>  [1] 5.368180 5.871824 5.103292 3.566623 2.076320 1.258609 1.163719 1.578068 #>  [9] 1.675131 1.848546 #>  #> [[1]][[8]] #>  [1] 0.5809221 0.3984722 0.4063174 0.3905960 0.7137581 0.6295201 0.5258256 #>  [8] 0.4425445 0.4416428 0.4417972 #>  #> [[1]][[9]] #>  [1] 1.4802246 1.2855399 1.2226406 1.2563456 1.2601723 1.1563125 0.9961827 #>  [8] 0.9637558 0.9623069 0.9632302 #>  #> [[1]][[10]] #>  [1] 0.9228911 1.9663336 1.0890906 1.0790010 1.0428587 0.6505922 0.6577698 #>  [8] 0.5757015 0.5376012 0.5715564 #>  #>  kfolds2Chisq(bbb) #> [[1]] #>  [1] 22.91473 37.22449 67.30556 66.98689 64.40101 61.87957 62.60816 57.22124 #>  [9] 59.13036 59.32773 #>  summary(bbb) #> ____************************************************____ #>  #> Family: Gamma  #> Link function: inverse  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                 AIC      BIC  Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0  56.60919 59.60220            NA     NA         NA                NA #> Nb_Comp_1  39.01090 43.50042  2.750349e-01 0.0975  0.2750349          22.91473 #> Nb_Comp_2  37.30801 43.29404 -5.586218e-01 0.0975 -1.1499267          37.22449 #> Nb_Comp_3  36.87524 44.35777 -5.167057e+00 0.0975 -2.9567375          67.30556 #> Nb_Comp_4  36.55795 45.53700 -2.508982e+01 0.0975 -3.2305135          66.98689 #> Nb_Comp_5  37.13611 47.61167 -1.232138e+02 0.0975 -3.7610086          64.40101 #> Nb_Comp_6  38.27656 50.24862 -5.637695e+02 0.0975 -3.5467515          61.87957 #> Nb_Comp_7  39.39377 52.86234 -2.540713e+03 0.0975 -3.5004430          62.60816 #> Nb_Comp_8  40.96122 55.92630 -9.731400e+03 0.0975 -2.8290712          57.22124 #> Nb_Comp_9  42.90816 59.36974 -3.772214e+04 0.0975 -2.8760368          59.13036 #> Nb_Comp_10 44.90815 62.86625 -1.476674e+05 0.0975 -2.9145302          59.32773 #>            Chi2_Pearson_Y     RSS_Y      R2_Y #> Nb_Comp_0        31.60805 20.800152        NA #> Nb_Comp_1        17.31431 11.804594 0.4324756 #> Nb_Comp_2        17.01037  6.357437 0.6943562 #> Nb_Comp_3        15.83422  5.699662 0.7259798 #> Nb_Comp_4        13.52676  7.679741 0.6307844 #> Nb_Comp_5        13.60962  6.099077 0.7067773 #> Nb_Comp_6        13.91155  5.205052 0.7497590 #> Nb_Comp_7        14.94390  4.650377 0.7764258 #> Nb_Comp_8        15.25537  4.321314 0.7922461 #> Nb_Comp_9        15.15577  4.307757 0.7928978 #> Nb_Comp_10       15.15490  4.307391 0.7929154 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" PLS_lm_formula(x11~.,data=pine,10,typeVC=\"standard\")$InfCrit #> ____************************************************____ #> ____TypeVC____ standard ____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>                 AIC     Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y     RSS_Y #> Nb_Comp_0  82.41888          NA      NA          NA        NA 20.800152 #> Nb_Comp_1  63.61896  0.38248575  0.0975  0.38248575 12.844390 11.074659 #> Nb_Comp_2  58.47638  0.34836456  0.0975 -0.05525570 11.686597  8.919303 #> Nb_Comp_3  56.55421  0.23688359  0.0975 -0.17107874 10.445206  7.919786 #> Nb_Comp_4  54.35053  0.06999681  0.0975 -0.21869112  9.651773  6.972542 #> Nb_Comp_5  55.99834 -0.07691053  0.0975 -0.15796434  8.073955  6.898523 #> Nb_Comp_6  57.69592 -0.19968885  0.0975 -0.11400977  7.685022  6.835594 #> Nb_Comp_7  59.37953 -0.27722139  0.0975 -0.06462721  7.277359  6.770369 #> Nb_Comp_8  61.21213 -0.30602578  0.0975 -0.02255238  6.923057  6.736112 #> Nb_Comp_9  63.18426 -0.39920228  0.0975 -0.07134354  7.216690  6.730426 #> Nb_Comp_10 65.15982 -0.43743644  0.0975 -0.02732569  6.914340  6.725443 #>                 R2_Y R2_residY RSS_residY PRESS_residY   Q2_residY  LimQ2 #> Nb_Comp_0         NA        NA   32.00000           NA          NA     NA #> Nb_Comp_1  0.4675684 0.4675684   17.03781     19.76046  0.38248575 0.0975 #> Nb_Comp_2  0.5711905 0.5711905   13.72190     17.97925 -0.05525570 0.0975 #> Nb_Comp_3  0.6192438 0.6192438   12.18420     16.06943 -0.17107874 0.0975 #> Nb_Comp_4  0.6647841 0.6647841   10.72691     14.84877 -0.21869112 0.0975 #> Nb_Comp_5  0.6683426 0.6683426   10.61304     12.42138 -0.15796434 0.0975 #> Nb_Comp_6  0.6713681 0.6713681   10.51622     11.82303 -0.11400977 0.0975 #> Nb_Comp_7  0.6745039 0.6745039   10.41588     11.19586 -0.06462721 0.0975 #> Nb_Comp_8  0.6761508 0.6761508   10.36317     10.65078 -0.02255238 0.0975 #> Nb_Comp_9  0.6764242 0.6764242   10.35443     11.10252 -0.07134354 0.0975 #> Nb_Comp_10 0.6766638 0.6766638   10.34676     10.63737 -0.02732569 0.0975 #>            Q2cum_residY  AIC.std   DoF.dof sigmahat.dof   AIC.dof   BIC.dof #> Nb_Comp_0            NA 96.63448  1.000000    0.8062287 0.6697018 0.6991787 #> Nb_Comp_1    0.38248575 77.83455  3.176360    0.5994089 0.4047616 0.4565153 #> Nb_Comp_2    0.34836456 72.69198  7.133559    0.5761829 0.4138120 0.5212090 #> Nb_Comp_3    0.23688359 70.76981  8.778329    0.5603634 0.4070516 0.5320535 #> Nb_Comp_4    0.06999681 68.56612  8.427874    0.5221703 0.3505594 0.4547689 #> Nb_Comp_5   -0.07691053 70.21393  9.308247    0.5285695 0.3666578 0.4845912 #> Nb_Comp_6   -0.19968885 71.91152  9.291931    0.5259794 0.3629363 0.4795121 #> Nb_Comp_7   -0.27722139 73.59512  9.756305    0.5284535 0.3702885 0.4938445 #> Nb_Comp_8   -0.30602578 75.42772 10.363948    0.5338475 0.3831339 0.5170783 #> Nb_Comp_9   -0.39920228 77.39986 10.732148    0.5378277 0.3920957 0.5328747 #> Nb_Comp_10  -0.43743644 79.37542 11.000000    0.5407500 0.3987417 0.5446065 #>             GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0  -3.605128         1      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1  -9.875081         2      0.5977015 0.3788984 0.4112998 -11.451340 #> Nb_Comp_2  -6.985517         3      0.5452615 0.3243383 0.3647862 -12.822703 #> Nb_Comp_3  -6.260610         4      0.5225859 0.3061986 0.3557368 -12.756838 #> Nb_Comp_4  -8.152986         5      0.4990184 0.2867496 0.3432131 -12.811575 #> Nb_Comp_5  -7.111583         6      0.5054709 0.3019556 0.3714754 -11.329638 #> Nb_Comp_6  -7.233043         7      0.5127450 0.3186757 0.4021333  -9.918688 #> Nb_Comp_7  -6.742195         8      0.5203986 0.3364668 0.4347156  -8.592770 #> Nb_Comp_8  -6.038372         9      0.5297842 0.3572181 0.4717708  -7.287834 #> Nb_Comp_9  -5.600235        10      0.5409503 0.3813021 0.5140048  -6.008747 #> Nb_Comp_10 -5.288422        11      0.5529032 0.4076026 0.5600977  -4.799453  data(pineNAX21) bbb2 <- cv.plsRglm(x11~.,data=pineNAX21,nt=10, modele=\"pls-glm-family\",family=Gamma(),K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE) #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced bbb2 <- cv.plsRglm(x11~.,data=pineNAX21,nt=10, modele=\"pls-glm-Gamma\",K=10,keepcoeffs=TRUE,keepfolds=FALSE,verbose=FALSE)  #For Jackknife computations kfolds2coeff(bbb2) #>            [,1]        [,2]        [,3]       [,4]     [,5]       [,6] #>  [1,] -21.14485 0.008616130  0.03674745 -0.3581602 1.921926 -0.4081026 #>  [2,] -14.59880 0.006080550  0.04715798 -0.2438525 1.489233 -0.2797521 #>  [3,] -18.91294 0.006700005  0.01866432 -0.3322595 2.532909 -0.4118893 #>  [4,] -12.67608 0.009417885 -0.01566997  0.2352732 1.859993 -0.3336438 #>  [5,] -13.34389 0.004652787  0.07361635 -0.1620116 2.834521 -0.5773882 #>  [6,] -13.17192 0.005094255  0.04154328 -0.1750301 1.509127 -0.3823807 #>  [7,] -14.64076 0.005851807  0.04253858 -0.1765887 1.619940 -0.3502596 #>  [8,] -14.05079 0.006416756  0.04498837 -0.1547725 1.853500 -0.3772898 #>  [9,] -14.81978 0.005565971  0.03091156 -0.2176143 1.414826 -0.2538928 #> [10,] -16.70714 0.006712930  0.05073523 -0.2151543 2.071076 -0.4216196 #>            [,7]        [,8]        [,9]       [,10]     [,11] #>  [1,]  5.085774 -1.20930485 -0.11055368 -0.08804458 2.4880806 #>  [2,]  3.129944  0.44686098 -0.34791666  1.35572433 0.7578715 #>  [3,]  4.666129 -1.54297343 -0.47202093  0.90615274 2.4111899 #>  [4,] -2.131302 -0.64364488 -0.40458513  0.81511245 0.7576426 #>  [5,]  2.318833 -0.91278561 -0.28582585  0.48299052 1.0030298 #>  [6,]  1.722917  0.35048599  0.04318401  1.14731994 0.0239185 #>  [7,]  2.522483 -0.06485633 -0.15403482  0.62898504 0.7546944 #>  [8,]  2.363459 -0.65334098 -0.21317757  0.36778230 0.7469297 #>  [9,]  2.547778  0.02973721 -0.22484351  1.55589269 0.3409361 #> [10,]  2.939051 -0.48799520 -0.26474681  0.85336920 1.1093337 boxplot(kfolds2coeff(bbb2)[,1])   kfolds2Chisqind(bbb2) #> [[1]] #> [[1]][[1]] #> [1] 1.5637590 1.9472693 2.4293377 2.4682266 2.6485379 1.8780839 3.0477354 #> [8] 1.9262077 0.9543384 #>  #> [[1]][[2]] #> [1]   4.025842   3.038711   2.047105   1.733664  13.830160   5.476366   7.459766 #> [8] 162.164516 328.668945 #>  #> [[1]][[3]] #> [1] 1.353088 1.230745 1.853877 1.652835 2.044960 1.925549 4.037331 5.819196 #> [9] 5.768777 #>  #> [[1]][[4]] #> [1]  4.367846  8.781205  9.795686  7.331274  7.078643 11.860184 17.346241 #> [8] 17.441595 18.973908 #>  #> [[1]][[5]] #> [1]  1.5409040  1.2572200  0.8826944  1.4788250  5.1469919  6.9076489  9.1371463 #> [8]  9.3146664 10.0796670 #>  #> [[1]][[6]] #> [1] 0.995341 1.182147 1.935280 2.606784 3.395031 3.590911 3.551189 3.542292 #> [9] 2.958227 #>  #> [[1]][[7]] #> [1] 0.9363526 2.0250566 1.3365585 1.3255119 1.2139431 0.7986019 0.7214274 #> [8] 0.7431937 0.7012414 #>  #> [[1]][[8]] #> [1] 2.3558721 2.4111042 1.2959681 0.8814170 0.9030853 1.1141395 0.8587302 #> [8] 1.2287049 1.3399233 #>  #> [[1]][[9]] #> [1] 1.744605 1.030181 2.756148 1.911259 1.973422 2.584232 1.308875 1.322855 #> [9] 1.313170 #>  #> [[1]][[10]] #> [1] 1.391131 2.178484 2.576971 2.933348 2.922503 3.144702 3.639320 4.031659 #> [9] 4.392899 #>  #>  kfolds2Chisq(bbb2) #> [[1]] #> [1]  20.27474  25.08212  26.90963  24.32314  41.15728  39.28042  51.10776 #> [8] 207.53489 375.15110 #>  summary(bbb2) #> ____************************************************____ #> Only naive DoF can be used with missing data #>  #> Family: Gamma  #> Link function: inverse  #>  #> ____There are some NAs in X but not in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> Warning : reciprocal condition number of t(cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE])%*%cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE] < 10^{-12} #> Warning only 9 components could thus be extracted #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC  Q2Chisqcum_Y  limQ2   Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 56.60919 59.60220            NA     NA          NA                NA #> Nb_Comp_1 39.08940 43.57892  3.585576e-01 0.0975   0.3585576          20.27474 #> Nb_Comp_2 37.36154 43.34757  7.049318e-02 0.0975  -0.4490885          25.08212 #> Nb_Comp_3 36.81173 44.29427 -4.624220e-01 0.0975  -0.5733311          26.90963 #> Nb_Comp_4 36.53654 45.51559 -1.253337e+00 0.0975  -0.5408256          24.32314 #> Nb_Comp_5 37.24312 47.71867 -5.874748e+00 0.0975  -2.0509186          41.15728 #> Nb_Comp_6 38.18649 50.15855 -1.890119e+01 0.0975  -1.8948253          39.28042 #> Nb_Comp_7 39.35575 52.82432 -7.153151e+01 0.0975  -2.6445807          51.10776 #> Nb_Comp_8 40.86209 55.82716 -9.985920e+02 0.0975 -12.7814859         207.53489 #> Nb_Comp_9 42.80511 59.26669 -2.453992e+04 0.0975 -23.5509407         375.15110 #>           Chi2_Pearson_Y     RSS_Y      R2_Y #> Nb_Comp_0       31.60805 20.800152        NA #> Nb_Comp_1       17.30890 12.031518 0.4215659 #> Nb_Comp_2       17.10360  6.183372 0.7027247 #> Nb_Comp_3       15.78579  5.756462 0.7232490 #> Nb_Comp_4       13.49013  7.630460 0.6331536 #> Nb_Comp_5       13.56918  6.303455 0.6969515 #> Nb_Comp_6       14.02295  5.274716 0.7464097 #> Nb_Comp_7       15.05896  4.867806 0.7659726 #> Nb_Comp_8       15.28052  4.317488 0.7924300 #> Nb_Comp_9       15.19429  4.298593 0.7933384 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" PLS_lm_formula(x11~.,data=pineNAX21,10,typeVC=\"standard\")$InfCrit #> ____************************************************____ #> Only naive DoF can be used with missing data #> ____There are some NAs in X but not in Y____ #> ____TypeVC____ standard ____ #> ____TypeVC____ standard ____unknown____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> Warning : reciprocal condition number of t(cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE])%*%cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE] < 10^{-12} #> Warning only 9 components could thus be extracted #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  #>                AIC     Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y     RSS_Y #> Nb_Comp_0 82.41888          NA      NA          NA        NA 20.800152 #> Nb_Comp_1 63.69250  0.35639805  0.0975  0.35639805 13.387018 11.099368 #> Nb_Comp_2 58.35228  0.28395028  0.0975 -0.11256611 12.348781  8.885823 #> Nb_Comp_3 56.36553  0.07664889  0.0975 -0.28950699 11.458331  7.874634 #> Nb_Comp_4 54.02416 -0.70355579  0.0975 -0.84497074 14.528469  6.903925 #> Nb_Comp_5 55.80450 -0.94905654  0.0975 -0.14411078  7.898855  6.858120 #> Nb_Comp_6 57.45753 -1.27568315  0.0975 -0.16758190  8.007417  6.786392 #> Nb_Comp_7 58.73951 -1.63309014  0.0975 -0.15705481  7.852227  6.640327 #> Nb_Comp_8 60.61227 -1.67907859  0.0975 -0.01746558  6.756304  6.614773 #> Nb_Comp_9 62.25948 -2.15165796  0.0975 -0.17639623  7.781594  6.544432 #>                R2_Y R2_residY RSS_residY PRESS_residY   Q2_residY  LimQ2 #> Nb_Comp_0        NA        NA   32.00000           NA          NA     NA #> Nb_Comp_1 0.4663804 0.4663804   17.07583     20.59526  0.35639805 0.0975 #> Nb_Comp_2 0.5728001 0.5728001   13.67040     18.99799 -0.11256611 0.0975 #> Nb_Comp_3 0.6214146 0.6214146   12.11473     17.62807 -0.28950699 0.0975 #> Nb_Comp_4 0.6680830 0.6680830   10.62135     22.35133 -0.84497074 0.0975 #> Nb_Comp_5 0.6702851 0.6702851   10.55088     12.15200 -0.14411078 0.0975 #> Nb_Comp_6 0.6737336 0.6737336   10.44053     12.31901 -0.16758190 0.0975 #> Nb_Comp_7 0.6807558 0.6807558   10.21581     12.08026 -0.15705481 0.0975 #> Nb_Comp_8 0.6819844 0.6819844   10.17650     10.39424 -0.01746558 0.0975 #> Nb_Comp_9 0.6853661 0.6853661   10.06828     11.97160 -0.17639623 0.0975 #>           Q2cum_residY  AIC.std DoF.dof sigmahat.dof AIC.dof BIC.dof GMDL.dof #> Nb_Comp_0           NA 96.63448      NA           NA      NA      NA       NA #> Nb_Comp_1   0.35639805 77.90810      NA           NA      NA      NA       NA #> Nb_Comp_2   0.28395028 72.56787      NA           NA      NA      NA       NA #> Nb_Comp_3   0.07664889 70.58113      NA           NA      NA      NA       NA #> Nb_Comp_4  -0.70355579 68.23976      NA           NA      NA      NA       NA #> Nb_Comp_5  -0.94905654 70.02009      NA           NA      NA      NA       NA #> Nb_Comp_6  -1.27568315 71.67313      NA           NA      NA      NA       NA #> Nb_Comp_7  -1.63309014 72.95511      NA           NA      NA      NA       NA #> Nb_Comp_8  -1.67907859 74.82787      NA           NA      NA      NA       NA #> Nb_Comp_9  -2.15165796 76.47507      NA           NA      NA      NA       NA #>           DoF.naive sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0         1      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1         2      0.5983679 0.3797438 0.4122175 -11.413749 #> Nb_Comp_2         3      0.5442372 0.3231208 0.3634169 -12.847656 #> Nb_Comp_3         4      0.5210941 0.3044529 0.3537087 -12.776843 #> Nb_Comp_4         5      0.4965569 0.2839276 0.3398355 -12.891035 #> Nb_Comp_5         6      0.5039885 0.3001871 0.3692997 -11.349498 #> Nb_Comp_6         7      0.5108963 0.3163819 0.3992388  -9.922119 #> Nb_Comp_7         8      0.5153766 0.3300041 0.4263658  -8.696873 #> Nb_Comp_8         9      0.5249910 0.3507834 0.4632727  -7.337679 #> Nb_Comp_9        10      0.5334234 0.3707649 0.4998004  -6.033403 rm(list=c(\"bbb\",\"bbb2\"))    data(Cornell) summary(cv.plsRglm(Y~.,data=Cornell,nt=10,NK=1,modele=\"pls\",verbose=FALSE)) #> ____************************************************____ #>  #> Model: pls  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC    Q2cum_Y LimQ2_Y       Q2_Y  PRESS_Y      RSS_Y      R2_Y #> Nb_Comp_0 82.01205         NA      NA         NA       NA 467.796667        NA #> Nb_Comp_1 53.15173  0.8909588  0.0975  0.8909588 51.00912  35.742486 0.9235940 #> Nb_Comp_2 41.08283  0.8463898  0.0975 -0.4087353 50.35170  11.066606 0.9763431 #> Nb_Comp_3 32.06411  0.5671404  0.0975 -1.8179088 31.18469   4.418081 0.9905556 #> Nb_Comp_4 33.76477 -0.7046676  0.0975 -2.9381536 17.39908   4.309235 0.9907882 #> Nb_Comp_5 33.34373 -5.1246265  0.0975 -2.5928569 15.48247   3.521924 0.9924713 #> Nb_Comp_6 35.25533         NA  0.0975         NA       NA   3.496074 0.9925265 #>              AIC.std  DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof #> Nb_Comp_0  37.010388 1.000000    6.5212706 46.0708838 47.7893514 27.59461 #> Nb_Comp_1   8.150064 2.740749    1.8665281  4.5699686  4.9558156 21.34020 #> Nb_Comp_2  -3.918831 5.085967    1.1825195  2.1075461  2.3949331 27.40202 #> Nb_Comp_3 -12.937550 5.121086    0.7488308  0.8467795  0.9628191 24.40842 #> Nb_Comp_4 -11.236891 5.103312    0.7387162  0.8232505  0.9357846 24.23105 #> Nb_Comp_5 -11.657929 6.006316    0.7096382  0.7976101  0.9198348 28.21184 #> Nb_Comp_6  -9.746328 7.000002    0.7633343  0.9711322  1.1359502 33.18348 #>           DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0         1      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1         2      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2         3      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3         4      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4         5      0.7846050  0.8721072  0.9964867   24.16510 #> Nb_Comp_5         6      0.7661509  0.8804809  1.0227979   28.64206 #> Nb_Comp_6         7      0.8361907  1.1070902  1.3048716   33.63927 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\"  cv.plsRglm(Y~.,data=Cornell,nt=3, modele=\"pls-glm-inverse.gaussian\",K=12,verbose=FALSE) #> Number of repeated crossvalidations: #> [1] 1 #> Number of folds for each crossvalidation: #> [1] 12 cv.plsRglm(Y~.,data=Cornell,nt=3,modele=\"pls-glm-family\",family=inverse.gaussian,K=12,verbose=FALSE) #> Number of repeated crossvalidations: #> [1] 1 #> Number of folds for each crossvalidation: #> [1] 12 cv.plsRglm(Y~.,data=Cornell,nt=3,modele=\"pls-glm-inverse.gaussian\",K=6, NK=2,verbose=FALSE)$results_kfolds #> [[1]] #> [[1]][[1]] #>       [,1]     [,2]     [,3] #> 8 82.44673 82.50563 82.40858 #> 5 88.06746 88.53727 85.25048 #>  #> [[1]][[2]] #>        [,1]     [,2]     [,3] #> 11 82.28528 82.07951 82.44527 #> 9  82.32583 82.66131 82.84802 #>  #> [[1]][[3]] #>        [,1]     [,2]     [,3] #> 2  95.94380 98.36164 98.28510 #> 12 87.18968 88.98872 88.53361 #>  #> [[1]][[4]] #>        [,1]     [,2]     [,3] #> 4  95.30802 92.66692 91.51834 #> 10 82.47953 83.11466 83.10610 #>  #> [[1]][[5]] #>       [,1]     [,2]     [,3] #> 3 94.68038 96.79879 97.49218 #> 1 93.43561 94.90620 96.45368 #>  #> [[1]][[6]] #>       [,1]     [,2]     [,3] #> 6 93.64727 92.15930 92.37209 #> 7 81.85234 81.83027 81.82584 #>  #>  #> [[2]] #> [[2]][[1]] #>       [,1]     [,2]     [,3] #> 8 82.44673 82.50563 82.40858 #> 5 88.06746 88.53727 85.25048 #>  #> [[2]][[2]] #>        [,1]     [,2]     [,3] #> 7  82.20239 81.91655 82.10715 #> 11 82.43803 81.94278 82.36685 #>  #> [[2]][[3]] #>       [,1]     [,2]     [,3] #> 1 94.09586 95.21985 95.90520 #> 4 94.47572 93.13652 92.02753 #>  #> [[2]][[4]] #>        [,1]     [,2]     [,3] #> 10 82.30686 83.12912 83.03868 #> 9  81.89236 82.51683 82.52717 #>  #> [[2]][[5]] #>        [,1]     [,2]     [,3] #> 12 87.18968 88.98872 88.53361 #> 2  95.94380 98.36164 98.28510 #>  #> [[2]][[6]] #>       [,1]     [,2]     [,3] #> 6 94.13493 92.01372 92.13219 #> 3 96.52367 97.77654 97.81463 #>  #>  cv.plsRglm(Y~.,data=Cornell,nt=3,modele=\"pls-glm-family\", family=inverse.gaussian(),K=6,NK=2,verbose=FALSE)$results_kfolds #> [[1]] #> [[1]][[1]] #>       [,1]     [,2]     [,3] #> 7 81.90468 81.80099 81.86165 #> 1 93.69623 94.94396 95.94943 #>  #> [[1]][[2]] #>       [,1]     [,2]     [,3] #> 2 97.09841 98.35471 97.69241 #> 4 95.14378 92.16193 91.45998 #>  #> [[1]][[3]] #>        [,1]     [,2]     [,3] #> 9  82.06973 82.52492 82.68256 #> 12 87.46933 87.90360 89.32176 #>  #> [[1]][[4]] #>       [,1]     [,2]     [,3] #> 5 88.39491 88.16441 85.28231 #> 6 93.14888 91.74712 92.43230 #>  #> [[1]][[5]] #>        [,1]     [,2]     [,3] #> 11 82.63660 81.45836 82.07905 #> 3  95.03541 97.95611 97.96361 #>  #> [[1]][[6]] #>        [,1]     [,2]     [,3] #> 8  81.97836 82.48513 82.34459 #> 10 82.18756 82.96181 82.81149 #>  #>  #> [[2]] #> [[2]][[1]] #>        [,1]     [,2]     [,3] #> 5  88.12776 88.54310 85.32603 #> 10 82.67247 82.97135 83.00083 #>  #> [[2]][[2]] #>        [,1]     [,2]     [,3] #> 12 87.05810 89.17920 88.66667 #> 3  95.15935 98.49925 98.29314 #>  #> [[2]][[3]] #>       [,1]     [,2]     [,3] #> 8 82.29409 82.44771 82.38932 #> 6 93.35929 92.34801 92.29057 #>  #> [[2]][[4]] #>        [,1]     [,2]     [,3] #> 11 82.31956 82.01545 82.35014 #> 1  93.72589 94.82253 95.92674 #>  #> [[2]][[5]] #>       [,1]     [,2]     [,3] #> 7 81.79662 81.77255 81.88023 #> 9 82.08282 82.45580 82.57525 #>  #> [[2]][[6]] #>       [,1]     [,2]     [,3] #> 4 95.14378 92.16193 91.45998 #> 2 97.09841 98.35471 97.69241 #>  #>  cv.plsRglm(Y~.,data=Cornell,nt=3,modele=\"pls-glm-inverse.gaussian\",K=6, NK=2,verbose=FALSE)$results_kfolds #> [[1]] #> [[1]][[1]] #>       [,1]    [,2]     [,3] #> 4 94.61069 94.6878 92.64353 #> 6 92.42551 94.1008 93.10934 #>  #> [[1]][[2]] #>       [,1]     [,2]     [,3] #> 7 81.79662 81.77255 81.88023 #> 9 82.08282 82.45580 82.57525 #>  #> [[1]][[3]] #>        [,1]     [,2]     [,3] #> 10 82.55172 83.05563 83.04611 #> 1  93.66264 95.12181 96.09819 #>  #> [[1]][[4]] #>       [,1]     [,2]     [,3] #> 3 95.54239 98.04545 98.06654 #> 8 82.24235 82.35979 82.49361 #>  #> [[1]][[5]] #>        [,1]     [,2]     [,3] #> 2  95.74052 97.89405 98.00186 #> 11 82.56310 81.59883 82.15787 #>  #> [[1]][[6]] #>        [,1]     [,2]     [,3] #> 12 86.95192 89.39536 89.96552 #> 5  87.39911 88.86951 86.84356 #>  #>  #> [[2]] #> [[2]][[1]] #>       [,1]     [,2]     [,3] #> 7 82.00848 81.70431 81.82650 #> 2 95.99115 97.79793 97.97055 #>  #> [[2]][[2]] #>        [,1]     [,2]     [,3] #> 11 82.09018 82.10220 82.32048 #> 10 82.52637 83.25532 83.27621 #>  #> [[2]][[3]] #>        [,1]     [,2]     [,3] #> 6  93.31880 92.30725 91.80362 #> 12 87.50317 87.66747 89.49735 #>  #> [[2]][[4]] #>       [,1]     [,2]     [,3] #> 5 88.08780 88.60220 85.35196 #> 9 82.27548 82.42662 82.55342 #>  #> [[2]][[5]] #>       [,1]     [,2]     [,3] #> 8 82.21740 82.59449 82.51095 #> 4 95.36584 92.58378 91.54210 #>  #> [[2]][[6]] #>       [,1]     [,2]     [,3] #> 3 94.68038 96.79879 97.49218 #> 1 93.43561 94.90620 96.45368 #>  #>  cv.plsRglm(Y~.,data=Cornell,nt=3,modele=\"pls-glm-family\", family=inverse.gaussian(link = \"1/mu^2\"),K=6,NK=2,verbose=FALSE)$results_kfolds #> [[1]] #> [[1]][[1]] #>        [,1]     [,2]     [,3] #> 8  82.18031 82.59243 82.48103 #> 12 87.40306 87.79647 89.48632 #>  #> [[1]][[2]] #>       [,1]     [,2]     [,3] #> 1 93.69623 94.94396 95.94943 #> 7 81.90468 81.80099 81.86165 #>  #> [[1]][[3]] #>       [,1]     [,2]     [,3] #> 9 82.19603 82.39724 82.56306 #> 2 96.05821 97.84569 97.96973 #>  #> [[1]][[4]] #>        [,1]     [,2]     [,3] #> 3  95.57967 98.07234 98.07855 #> 10 82.42733 82.91391 83.08196 #>  #> [[1]][[5]] #>        [,1]     [,2]     [,3] #> 11 82.34138 82.53805 81.96853 #> 4  95.67965 92.85545 91.69008 #>  #> [[1]][[6]] #>       [,1]     [,2]     [,3] #> 6 93.14888 91.74712 92.43230 #> 5 88.39491 88.16441 85.28231 #>  #>  #> [[2]] #> [[2]][[1]] #>       [,1]     [,2]     [,3] #> 2 97.09841 98.35471 97.69241 #> 4 95.14378 92.16193 91.45998 #>  #> [[2]][[2]] #>       [,1]    [,2]     [,3] #> 3 95.69562 97.8202 98.24510 #> 5 87.61323 89.0497 85.81831 #>  #> [[2]][[3]] #>        [,1]     [,2]     [,3] #> 12 87.40306 87.79647 89.48632 #> 8  82.18031 82.59243 82.48103 #>  #> [[2]][[4]] #>       [,1]     [,2]     [,3] #> 9 82.12535 82.56460 82.53338 #> 6 93.45057 92.26382 92.21097 #>  #> [[2]][[5]] #>        [,1]     [,2]     [,3] #> 7  82.20239 81.91655 82.10715 #> 11 82.43803 81.94278 82.36685 #>  #> [[2]][[6]] #>        [,1]     [,2]     [,3] #> 1  93.66264 95.12181 96.09819 #> 10 82.55172 83.05563 83.04611 #>  #>   bbb2 <- cv.plsRglm(Y~.,data=Cornell,nt=10, modele=\"pls-glm-inverse.gaussian\",keepcoeffs=TRUE,verbose=FALSE)  #For Jackknife computations kfolds2coeff(bbb2) #>              [,1]          [,2]          [,3]          [,4]          [,5] #> [1,] 1.869017e-04 -4.553089e-04 -5.660398e-05  0.0009027358  2.218935e-05 #> [2,] 8.072612e-02 -7.841236e-02 -8.059362e-02 -0.0844419827 -8.056704e-02 #> [3,] 9.950651e-05  6.063947e-05  3.349715e-05  0.0001030871  5.553751e-05 #> [4,] 1.388570e-04  4.047152e-04 -5.789572e-06 -0.0005984148  1.281348e-05 #> [5,] 4.184020e-04  8.662012e-04 -2.791667e-04 -0.0023317762 -3.214869e-04 #>               [,6]          [,7]          [,8] #> [1,] -6.507130e-05 -7.137429e-05 -5.643925e-04 #> [2,] -8.060043e-02 -8.064432e-02 -8.033502e-02 #> [3,]  3.123945e-05 -2.142796e-06 -2.646177e-05 #> [4,] -2.663498e-05 -3.872940e-05 -3.725056e-05 #> [5,] -3.190328e-04 -3.460991e-04  1.883699e-04 boxplot(kfolds2coeff(bbb2)[,1])   kfolds2Chisqind(bbb2) #> [[1]] #> [[1]][[1]] #> [1] 1.280882e-05 8.859810e-07 1.508736e-06 1.489118e-06 5.221609e-06 #> [6] 1.434565e-05 #>  #> [[1]][[2]] #> [1] 8.135250e-06 4.261351e-05 2.765591e-05 7.890466e-06 8.773406e-06 #> [6] 1.853646e-04 #>  #> [[1]][[3]] #> [1] 2.087888e-06 5.359476e-07 1.750401e-06 1.106243e-06 6.336654e-07 #>  #> [[1]][[4]] #> [1] 3.091430e-05 1.587497e-05 8.070417e-06 6.269215e-06 6.277834e-06 #> [6] 6.416394e-06 #>  #> [[1]][[5]] #> [1] 2.258340e-06 2.441722e-06 2.341430e-06 2.221772e-06 2.804888e-06 #> [6] 1.415334e-05 #>  #>  kfolds2Chisq(bbb2) #> [[1]] #> [1] 5.620460e-05 6.235213e-05 4.132689e-05 1.897681e-05 2.371140e-05 #>  summary(bbb2) #> ____************************************************____ #>  #> Family: inverse.gaussian  #> Link function: 1/mu^2  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 81.67928 82.64909           NA     NA         NA                NA #> Nb_Comp_1 49.90521 51.35993    0.9164838 0.0975  0.9164838      5.620460e-05 #> Nb_Comp_2 31.06918 33.00881    0.8684226 0.0975 -0.5754719      6.235213e-05 #> Nb_Comp_3 28.40632 30.83085    0.2242351 0.0975 -4.8958805      4.132689e-05 #> Nb_Comp_4 27.08522 29.99466   -2.1138412 0.0975 -3.0138981      1.897681e-05 #> Nb_Comp_5 28.46056 31.85490  -19.5988890 0.0975 -5.6152664      2.371140e-05 #> Nb_Comp_6 29.68366 33.56292           NA 0.0975         NA                NA #>           Chi2_Pearson_Y      RSS_Y      R2_Y #> Nb_Comp_0   6.729783e-04 467.796667        NA #> Nb_Comp_1   3.957680e-05  32.478677 0.9305710 #> Nb_Comp_2   7.009452e-06   6.020269 0.9871306 #> Nb_Comp_3   4.727777e-06   3.795855 0.9918857 #> Nb_Comp_4   3.584346e-06   2.699884 0.9942285 #> Nb_Comp_5   3.408069e-06   2.598572 0.9944451 #> Nb_Comp_6   3.195402e-06   2.492371 0.9946721 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" PLS_lm_formula(Y~.,data=Cornell,10,typeVC=\"standard\")$InfCrit #> ____************************************************____ #> ____TypeVC____ standard ____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>                AIC   Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y      RSS_Y      R2_Y #> Nb_Comp_0 82.01205        NA      NA          NA        NA 467.796667        NA #> Nb_Comp_1 53.15173 0.8966556  0.0975  0.89665563 48.344150  35.742486 0.9235940 #> Nb_Comp_2 41.08283 0.9175426  0.0975  0.20210989 28.518576  11.066606 0.9763431 #> Nb_Comp_3 32.06411 0.9399676  0.0975  0.27195907  8.056942   4.418081 0.9905556 #> Nb_Comp_4 33.76477 0.9197009  0.0975 -0.33759604  5.909608   4.309235 0.9907882 #> Nb_Comp_5 33.34373 0.9281373  0.0975  0.10506161  3.856500   3.521924 0.9924713 #> Nb_Comp_6 35.25533 0.9232562  0.0975 -0.06792167  3.761138   3.496074 0.9925265 #>           R2_residY  RSS_residY PRESS_residY   Q2_residY  LimQ2 Q2cum_residY #> Nb_Comp_0        NA 11.00000000           NA          NA     NA           NA #> Nb_Comp_1 0.9235940  0.84046633   1.13678803  0.89665563 0.0975    0.8966556 #> Nb_Comp_2 0.9763431  0.26022559   0.67059977  0.20210989 0.0975    0.9175426 #> Nb_Comp_3 0.9905556  0.10388893   0.18945488  0.27195907 0.0975    0.9399676 #> Nb_Comp_4 0.9907882  0.10132947   0.13896142 -0.33759604 0.0975    0.9197009 #> Nb_Comp_5 0.9924713  0.08281624   0.09068364  0.10506161 0.0975    0.9281373 #> Nb_Comp_6 0.9925265  0.08220840   0.08844125 -0.06792167 0.0975    0.9232562 #>              AIC.std  DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof #> Nb_Comp_0  37.010388 1.000000    6.5212706 46.0708838 47.7893514 27.59461 #> Nb_Comp_1   8.150064 2.740749    1.8665281  4.5699686  4.9558156 21.34020 #> Nb_Comp_2  -3.918831 5.085967    1.1825195  2.1075461  2.3949331 27.40202 #> Nb_Comp_3 -12.937550 5.121086    0.7488308  0.8467795  0.9628191 24.40842 #> Nb_Comp_4 -11.236891 5.103312    0.7387162  0.8232505  0.9357846 24.23105 #> Nb_Comp_5 -11.657929 6.006316    0.7096382  0.7976101  0.9198348 28.21184 #> Nb_Comp_6  -9.746328 7.000002    0.7633343  0.9711322  1.1359502 33.18348 #>           DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0         1      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1         2      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2         3      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3         4      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4         5      0.7846050  0.8721072  0.9964867   24.16510 #> Nb_Comp_5         6      0.7661509  0.8804809  1.0227979   28.64206 #> Nb_Comp_6         7      0.8361907  1.1070902  1.3048716   33.63927 rm(list=c(\"bbb\",\"bbb2\")) #> Warning: object 'bbb' not found   data(bordeaux) summary(cv.plsRglm(Quality~.,data=bordeaux,10, modele=\"pls-glm-polr\",K=7)) #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> NK: 1  #> Number of groups : 7  #> 1  #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> Warning : 1 2 3 4 < 10^{-12} #> Warning only 4 components could thus be extracted #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> ____Component____ 4 ____ #> Warning : 1 2 3 4 < 10^{-12} #> Warning only 4 components could thus be extracted #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> Warning : 1 2 3 4 < 10^{-12} #> Warning only 4 components could thus be extracted #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> Warning : 1 2 3 4 < 10^{-12} #> Warning only 4 components could thus be extracted #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> Warning : 1 2 3 4 < 10^{-12} #> Warning only 4 components could thus be extracted #> ****________________________________________________**** #>  #> 6  #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> Warning : 1 2 3 4 < 10^{-12} #> Warning only 4 components could thus be extracted #> ****________________________________________________**** #>  #> 7  #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> Warning : 1 2 3 4 < 10^{-12} #> Warning only 4 components could thus be extracted #> ****________________________________________________**** #>  #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> Warning : 1 2 3 4 < 10^{-12} #> Warning only 4 components could thus be extracted #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 78.64736 81.70009           NA     NA         NA                NA #> Nb_Comp_1 36.50286 41.08194   -0.2712984 0.0975 -0.2712984          79.24427 #> Nb_Comp_2 35.58058 41.68602   -7.2493492 0.0975 -5.4889164          60.71369 #> Nb_Comp_3 36.26588 43.89768  -77.8965681 0.0975 -8.5639749          81.95328 #> Nb_Comp_4 38.15799 47.31616 -840.7049976 0.0975 -9.6684615          88.34565 #>           Chi2_Pearson_Y #> Nb_Comp_0      62.333333 #> Nb_Comp_1       9.356521 #> Nb_Comp_2       8.568956 #> Nb_Comp_3       8.281011 #> Nb_Comp_4       8.321689 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\"  data(bordeauxNA) summary(cv.plsRglm(Quality~.,data=bordeauxNA, 10,modele=\"pls-glm-polr\",K=10,verbose=FALSE)) #> ____************************************************____ #> Only naive DoF can be used with missing data #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____There are some NAs in X but not in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> Warning : reciprocal condition number of t(cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE])%*%cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE] < 10^{-12} #> Warning only 3 components could thus be extracted #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 78.64736 81.70009           NA     NA         NA                NA #> Nb_Comp_1 36.21263 40.79171    -0.952643 0.0975  -0.952643         121.71475 #> Nb_Comp_2 35.29582 41.40126   -19.462740 0.0975  -9.479509          99.07386 #> Nb_Comp_3 35.81623 43.44803  -319.967215 0.0975 -14.685446         129.16455 #>           Chi2_Pearson_Y #> Nb_Comp_0      62.333333 #> Nb_Comp_1       9.454055 #> Nb_Comp_2       8.234674 #> Nb_Comp_3       7.803408 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\"  summary(cv.plsRglm(Quality~.,data=bordeaux,nt=2,K=7, modele=\"pls-glm-polr\",method=\"logistic\",verbose=FALSE)) #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC Q2Chisqcum_Y  limQ2 Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 78.64736 81.70009           NA     NA        NA                NA #> Nb_Comp_1 36.50286 41.08194    -0.398239 0.0975 -0.398239          87.15690 #> Nb_Comp_2 35.58058 41.68602   -10.548048 0.0975 -7.258994          77.27545 #>           Chi2_Pearson_Y #> Nb_Comp_0      62.333333 #> Nb_Comp_1       9.356521 #> Nb_Comp_2       8.568956 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" summary(cv.plsRglm(Quality~.,data=bordeaux,nt=2,K=7, modele=\"pls-glm-polr\",method=\"probit\",verbose=FALSE)) #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: probit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 78.64736 81.70009           NA     NA         NA                NA #> Nb_Comp_1 36.01661 40.59569    -1.784808 0.0975  -1.784808          173.5868 #> Nb_Comp_2 35.13428 41.23972   -32.476519 0.0975 -11.021123          116.8062 #>           Chi2_Pearson_Y #> Nb_Comp_0      62.333496 #> Nb_Comp_1       9.716750 #> Nb_Comp_2       8.549269 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" summary(cv.plsRglm(Quality~.,data=bordeaux,nt=2,K=7, modele=\"pls-glm-polr\",method=\"cloglog\",verbose=FALSE)) #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: cloglog  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC Q2Chisqcum_Y  limQ2   Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 78.64736 81.70009           NA     NA          NA                NA #> Nb_Comp_1 36.92722 41.50630    -34871.68 0.0975 -34871.6758       2173779.069 #> Nb_Comp_2 35.54609 41.65153  -6433390.79 0.0975   -183.4823          1904.251 #>           Chi2_Pearson_Y #> Nb_Comp_0      62.334737 #> Nb_Comp_1      10.322134 #> Nb_Comp_2       7.727154 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" suppressWarnings(summary(cv.plsRglm(Quality~.,data=bordeaux,nt=2,K=7, modele=\"pls-glm-polr\",method=\"cauchit\",verbose=FALSE))) #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: cauchit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC Q2Chisqcum_Y  limQ2   Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 79.08163 82.13436           NA     NA          NA                NA #> Nb_Comp_1 38.11253 42.69161   -0.2568805 0.0975  -0.2568805          78.02523 #> Nb_Comp_2 38.01624 44.12168  -24.1650786 0.0975 -19.0218552         172.04196 #>           Chi2_Pearson_Y #> Nb_Comp_0      62.078483 #> Nb_Comp_1       8.592708 #> Nb_Comp_2       7.421182 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" # }"},{"path":"https://fbertran.github.io/plsRglm/reference/cvtable.html","id":null,"dir":"Reference","previous_headings":"","what":"Table method for summary of cross validated PLSR and PLSGLR models — cvtable","title":"Table method for summary of cross validated PLSR and PLSGLR models — cvtable","text":"function cvtable wrapper cvtable.plsR cvtable.plsRglm provides table summary classes \"summary.cv.plsRmodel\" \"summary.cv.plsRglmmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cvtable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Table method for summary of cross validated PLSR and PLSGLR models — cvtable","text":"","code":"cvtable(x, verbose = TRUE, ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/cvtable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Table method for summary of cross validated PLSR and PLSGLR models — cvtable","text":"x object class \"summary.cv.plsRmodel\" verbose results displayed ? ... arguments passed methods.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cvtable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Table method for summary of cross validated PLSR and PLSGLR models — cvtable","text":"listList Information Criteria computed fold.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cvtable.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Table method for summary of cross validated PLSR and PLSGLR models — cvtable","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/cvtable.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Table method for summary of cross validated PLSR and PLSGLR models — cvtable","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/cvtable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Table method for summary of cross validated PLSR and PLSGLR models — cvtable","text":"","code":"data(Cornell) cv.modpls <- cv.plsR(Y~.,data=Cornell,nt=6,K=6,NK=5) #> NK: 1  #> Number of groups : 6  #> 1  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 5 components could thus be extracted #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 6  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> NK: 2  #> Number of groups : 6  #> 1  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 6  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 5 components could thus be extracted #> ****________________________________________________**** #>  #> NK: 3  #> Number of groups : 6  #> 1  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 5 components could thus be extracted #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 6  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> NK: 4  #> Number of groups : 6  #> 1  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 5 components could thus be extracted #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 6  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> NK: 5  #> Number of groups : 6  #> 1  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 5 components could thus be extracted #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 6  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  res.cv.modpls <- cvtable(summary(cv.modpls)) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1,  2,  3,  4,  5 #>  #> CV Q2 criterion: #> 0 1 2  #> 0 4 1  #>  #> CV Press criterion: #> 1 2 3 4  #> 0 0 4 1  plot(res.cv.modpls) #defaults to type=\"CVQ2\"  rm(list=c(\"cv.modpls\",\"res.cv.modpls\"))  # \\donttest{ data(Cornell) cv.modpls <- cv.plsR(Y~.,data=Cornell,nt=6,K=6,NK=25,verbose=FALSE) res.cv.modpls <- cvtable(summary(cv.modpls)) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1,  2,  3,  4,  5,  6,  7,  8,  9,  10 #> NK: 11,  12,  13,  14,  15,  16,  17,  18,  19,  20 #> NK: 21,  22,  23,  24,  25 #>  #> CV Q2 criterion: #>  0  1  2  #>  0 23  2  #>  #> CV Press criterion: #>  1  2  3  4  5  #>  0  0  8 13  4  plot(res.cv.modpls) #defaults to type=\"CVQ2\"  rm(list=c(\"cv.modpls\",\"res.cv.modpls\"))    data(Cornell) cv.modpls <- cv.plsR(Y~.,data=Cornell,nt=6,K=6,NK=100,verbose=FALSE) res.cv.modpls <- cvtable(summary(cv.modpls)) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1,  2,  3,  4,  5,  6,  7,  8,  9,  10 #> NK: 11,  12,  13,  14,  15,  16,  17,  18,  19,  20 #> NK: 21,  22,  23,  24,  25,  26,  27,  28,  29,  30 #> NK: 31,  32,  33,  34,  35,  36,  37,  38,  39,  40 #> NK: 41,  42,  43,  44,  45,  46,  47,  48,  49,  50 #> NK: 51,  52,  53,  54,  55,  56,  57,  58,  59,  60 #> NK: 61,  62,  63,  64,  65,  66,  67,  68,  69,  70 #> NK: 71,  72,  73,  74,  75,  76,  77,  78,  79,  80 #> NK: 81,  82,  83,  84,  85,  86,  87,  88,  89,  90 #> NK: 91,  92,  93,  94,  95,  96,  97,  98,  99,  100 #>  #> CV Q2 criterion: #>  0  1  2  #>  0 88 12  #>  #> CV Press criterion: #>  1  2  3  4  5  #>  0  0 42 52  6  plot(res.cv.modpls) #defaults to type=\"CVQ2\"  rm(list=c(\"cv.modpls\",\"res.cv.modpls\"))  data(Cornell) cv.modplsglm <- cv.plsRglm(Y~.,data=Cornell,nt=6,K=6, modele=\"pls-glm-gaussian\",NK=100,verbose=FALSE) res.cv.modplsglm <- cvtable(summary(cv.modplsglm)) #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1,  2,  3,  4,  5,  6,  7,  8,  9,  10 #> NK: 11,  12,  13,  14,  15,  16,  17,  18,  19,  20 #> NK: 21,  22,  23,  24,  25,  26,  27,  28,  29,  30 #> NK: 31,  32,  33,  34,  35,  36,  37,  38,  39,  40 #> NK: 41,  42,  43,  44,  45,  46,  47,  48,  49,  50 #> NK: 51,  52,  53,  54,  55,  56,  57,  58,  59,  60 #> NK: 61,  62,  63,  64,  65,  66,  67,  68,  69,  70 #> NK: 71,  72,  73,  74,  75,  76,  77,  78,  79,  80 #> NK: 81,  82,  83,  84,  85,  86,  87,  88,  89,  90 #> NK: 91,  92,  93,  94,  95,  96,  97,  98,  99,  100 #>  #> CV Q2Chi2 criterion: #>  0  1  2  #>  0 20 80  #>  #> CV PreChi2 criterion: #>  1  2  3  4  #>  0 23 62 15  plot(res.cv.modplsglm) #defaults to type=\"CVQ2Chi2\"  rm(list=c(\"res.cv.modplsglm\")) # }"},{"path":"https://fbertran.github.io/plsRglm/reference/dicho.html","id":null,"dir":"Reference","previous_headings":"","what":"Dichotomization — dicho","title":"Dichotomization — dicho","text":"function takes real value converts 1 positive else 0.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/dicho.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dichotomization — dicho","text":"","code":"dicho(val)"},{"path":"https://fbertran.github.io/plsRglm/reference/dicho.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dichotomization — dicho","text":"val real value","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/dicho.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dichotomization — dicho","text":"0 1.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/dicho.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Dichotomization — dicho","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/dicho.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dichotomization — dicho","text":"","code":"dimX <- 6 Astar <- 4 (dataAstar4 <- t(replicate(10,simul_data_YX(dimX,Astar)))) #>              Y 1         Y 2          Y 3        Y 4          X1          X2 #>  [1,]  0.1840605  12.3386332   1.18292348 -3.9336499  2.73096571  8.01733002 #>  [2,]  0.5783818  -5.2498839   5.45163573  0.8504209  2.20484007 -1.53972725 #>  [3,] -1.2882143   4.2744900  -8.74408888 10.8853138 -0.01137552 -5.99483536 #>  [4,] -2.7033914  -3.5151111   4.79665303  2.9938076  3.75962469 -1.35952720 #>  [5,] -2.7455350   2.6455381   4.45152113 -9.2327510  0.75079690  8.12451955 #>  [6,]  2.4614809  -0.1395659 -12.19422659  3.2585881 -7.47411138 -5.91929540 #>  [7,]  0.3702670   0.8479074  13.26009764 -4.6596718  7.03296925  6.52806228 #>  [8,] -7.6143137 -11.4572728  -1.23301745  9.9110744  0.86816570 -9.75733684 #>  [9,] -4.5217220  -9.0551277   0.46018517  6.9684074  1.27499390 -6.94924222 #> [10,] -6.8124286  -4.2039732  -0.08122419 -0.9362211 -0.08702740  0.01235493 #>               X3         X4          X5        X6 #>  [1,]  7.2302373 -1.0025756   4.2816227  3.504236 #>  [2,] -4.6000618  3.3607151  -0.3772456 -3.414823 #>  [3,]  7.4682490 -0.9609521  -6.9058364  6.497262 #>  [4,] -2.1428548  2.0889551  -3.0214268 -3.813715 #>  [5,] -0.5424408 -2.7004279   4.6369886 -4.011397 #>  [6,]  2.2186564 -3.7116216  -2.1406431  5.980646 #>  [7,] -3.0511856  5.0705640   4.5793837 -4.985306 #>  [8,] -4.3827471 -1.1882134 -11.8305442 -6.444355 #>  [9,] -3.8188897  0.4960563  -7.7096033 -4.587585 #> [10,] -1.5672810 -3.8871170  -3.7895268 -5.390915  dicho(dataAstar4) #>       Y 1 Y 2 Y 3 Y 4 X1 X2 X3 X4 X5 X6 #>  [1,]   1   1   1   0  1  1  1  0  1  1 #>  [2,]   1   0   1   1  1  0  0  1  0  0 #>  [3,]   0   1   0   1  0  0  1  0  0  1 #>  [4,]   0   0   1   1  1  0  0  1  0  0 #>  [5,]   0   1   1   0  1  1  0  0  1  0 #>  [6,]   1   0   0   1  0  0  1  0  0  1 #>  [7,]   1   1   1   0  1  1  0  1  1  0 #>  [8,]   0   0   0   1  1  0  0  0  0  0 #>  [9,]   0   0   1   1  1  0  0  1  0  0 #> [10,]   0   0   0   0  0  1  0  0  0  0  rm(list=c(\"dimX\",\"Astar\"))"},{"path":"https://fbertran.github.io/plsRglm/reference/fowlkes.html","id":null,"dir":"Reference","previous_headings":"","what":"Fowlkes dataset — fowlkes","title":"Fowlkes dataset — fowlkes","text":"classic dataset Fowlkes.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/fowlkes.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Fowlkes dataset — fowlkes","text":"data frame 9949 observations following 13 variables. Y binary response MA numeric vector MW numeric vector NE numeric vector NW numeric vector PA numeric vector numeric vector SW numeric vector color numeric vector age1 numeric vector age2 numeric vector age3 numeric vector sexe numeric vector","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/fowlkes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fowlkes dataset — fowlkes","text":"","code":"data(fowlkes) str(fowlkes) #> 'data.frame':\t9949 obs. of  13 variables: #>  $ Y    : int  0 0 0 0 0 0 0 0 0 0 ... #>  $ MA   : int  0 0 0 0 0 0 0 0 0 0 ... #>  $ MW   : int  0 0 0 0 0 0 0 0 0 0 ... #>  $ NE   : int  1 1 1 1 1 1 1 1 1 1 ... #>  $ NW   : int  0 0 0 0 0 0 0 0 0 0 ... #>  $ PA   : int  0 0 0 0 0 0 0 0 0 0 ... #>  $ SO   : int  0 0 0 0 0 0 0 0 0 0 ... #>  $ SW   : int  0 0 0 0 0 0 0 0 0 0 ... #>  $ color: int  0 0 0 0 0 0 0 0 0 0 ... #>  $ age1 : int  1 1 1 1 1 1 1 1 1 1 ... #>  $ age2 : int  0 0 0 0 0 0 0 0 0 0 ... #>  $ age3 : int  0 0 0 0 0 0 0 0 0 0 ... #>  $ sexe : int  0 0 0 0 0 0 0 0 0 0 ..."},{"path":"https://fbertran.github.io/plsRglm/reference/infcrit.dof.html","id":null,"dir":"Reference","previous_headings":"","what":"Information criteria — infcrit.dof","title":"Information criteria — infcrit.dof","text":"function computes information criteria existing plsR model using Degrees Freedom estimation.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/infcrit.dof.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Information criteria — infcrit.dof","text":"","code":"infcrit.dof(modplsR, naive = FALSE)"},{"path":"https://fbertran.github.io/plsRglm/reference/infcrit.dof.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Information criteria — infcrit.dof","text":"modplsR plsR model .e. object returned one functions plsR, plsRmodel.default, plsRmodel.formula, PLS_lm PLS_lm_formula. naive boolean.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/infcrit.dof.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Information criteria — infcrit.dof","text":"matrix AIC, BIC gmdl values NULL.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/infcrit.dof.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Information criteria — infcrit.dof","text":"naive=FALSE returns AIC, BIC gmdl values estimated naive degrees freedom. naive=TRUE returns NULL.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/infcrit.dof.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Information criteria — infcrit.dof","text":"M. Hansen, B. Yu. (2001). Model Selection Minimum Descripion Length Principle, Journal American Statistical Association, 96, 746-774. N. Kraemer, M. Sugiyama. (2011). Degrees Freedom Partial Least Squares Regression. Journal American Statistical Association, 106(494), 697-705. N. Kraemer, M. Sugiyama, M.L. Braun. (2009). Lanczos Approximations Speedup Kernel Partial Least Squares Regression, Proceedings Twelfth International Conference Artificial Intelligence Statistics (AISTATS), 272-279.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/infcrit.dof.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Information criteria — infcrit.dof","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/infcrit.dof.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Information criteria — infcrit.dof","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] modpls <- plsR(yCornell,XCornell,4) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  infcrit.dof(modpls) #>            DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof DoF.naive #> Nb_Comp_0 1.000000    6.5212706 46.0708838 47.7893514 27.59461         1 #> Nb_Comp_1 2.740749    1.8665281  4.5699686  4.9558156 21.34020         2 #> Nb_Comp_2 5.085967    1.1825195  2.1075461  2.3949331 27.40202         3 #> Nb_Comp_3 5.121086    0.7488308  0.8467795  0.9628191 24.40842         4 #> Nb_Comp_4 5.103312    0.7387162  0.8232505  0.9357846 24.23105         5 #>           sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4      0.7846050  0.8721072  0.9964867   24.16510"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares glm models — kfolds2CVinfos_glm","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares glm models — kfolds2CVinfos_glm","text":"function extracts computes information criteria fits statistics k-fold cross validated partial least squares glm models formula classic specifications model.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_glm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares glm models — kfolds2CVinfos_glm","text":"","code":"kfolds2CVinfos_glm(pls_kfolds, MClassed = FALSE, verbose = TRUE)"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_glm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares glm models — kfolds2CVinfos_glm","text":"pls_kfolds object computed using cv.plsRglm MClassed number miss classed computed ? verbose infos displayed ?","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_glm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares glm models — kfolds2CVinfos_glm","text":"list table fit statistics first group partition list() ... list table fit statistics last group partition","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_glm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares glm models — kfolds2CVinfos_glm","text":"Mclassed option set TRUE response binary.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_glm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares glm models — kfolds2CVinfos_glm","text":"Use summary cv.plsRglm instead.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_glm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares glm models — kfolds2CVinfos_glm","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_glm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares glm models — kfolds2CVinfos_glm","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_glm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares glm models — kfolds2CVinfos_glm","text":"","code":"# \\donttest{ data(Cornell) summary(cv.plsRglm(Y~.,data=Cornell, nt=6,K=12,NK=1,keepfolds=FALSE,keepdataY=TRUE,modele=\"pls\",verbose=FALSE),MClassed=TRUE) #> ____************************************************____ #>  #> Model: pls  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC MissClassed CV_MissClassed    Q2cum_Y LimQ2_Y       Q2_Y #> Nb_Comp_0 82.01205          12             NA         NA      NA         NA #> Nb_Comp_1 53.15173          12             12  0.8809146  0.0975  0.8809146 #> Nb_Comp_2 41.08283          12             12  0.8619560  0.0975 -0.1592015 #> Nb_Comp_3 32.06411          12             12  0.7471041  0.0975 -0.8319956 #> Nb_Comp_4 33.76477          12             12 -0.2159389  0.0975 -3.8080607 #> Nb_Comp_5 33.34373          12             12 -5.9182568  0.0975 -4.6896417 #> Nb_Comp_6 35.25533          12             NA         NA  0.0975         NA #>            PRESS_Y      RSS_Y      R2_Y    AIC.std  DoF.dof sigmahat.dof #> Nb_Comp_0       NA 467.796667        NA  37.010388 1.000000    6.5212706 #> Nb_Comp_1 55.70774  35.742486 0.9235940   8.150064 2.740749    1.8665281 #> Nb_Comp_2 41.43274  11.066606 0.9763431  -3.918831 5.085967    1.1825195 #> Nb_Comp_3 20.27397   4.418081 0.9905556 -12.937550 5.121086    0.7488308 #> Nb_Comp_4 21.24240   4.309235 0.9907882 -11.236891 5.103312    0.7387162 #> Nb_Comp_5 24.51801   3.521924 0.9924713 -11.657929 6.006316    0.7096382 #> Nb_Comp_6       NA   3.496074 0.9925265  -9.746328 7.000002    0.7633343 #>              AIC.dof    BIC.dof GMDL.dof DoF.naive sigmahat.naive  AIC.naive #> Nb_Comp_0 46.0708838 47.7893514 27.59461         1      6.5212706 46.0708838 #> Nb_Comp_1  4.5699686  4.9558156 21.34020         2      1.8905683  4.1699567 #> Nb_Comp_2  2.1075461  2.3949331 27.40202         3      1.1088836  1.5370286 #> Nb_Comp_3  0.8467795  0.9628191 24.40842         4      0.7431421  0.7363469 #> Nb_Comp_4  0.8232505  0.9357846 24.23105         5      0.7846050  0.8721072 #> Nb_Comp_5  0.7976101  0.9198348 28.21184         6      0.7661509  0.8804809 #> Nb_Comp_6  0.9711322  1.1359502 33.18348         7      0.8361907  1.1070902 #>            BIC.naive GMDL.naive #> Nb_Comp_0 47.7893514   27.59461 #> Nb_Comp_1  4.4588195   18.37545 #> Nb_Comp_2  1.6860917   17.71117 #> Nb_Comp_3  0.8256118   19.01033 #> Nb_Comp_4  0.9964867   24.16510 #> Nb_Comp_5  1.0227979   28.64206 #> Nb_Comp_6  1.3048716   33.63927 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\"   data(aze_compl) summary(cv.plsR(y~.,data=aze_compl,nt=10,K=8,modele=\"pls\",verbose=FALSE), MClassed=TRUE,verbose=FALSE) #> [[1]] #>                 AIC MissClassed CV_MissClassed       Q2cum_Y LimQ2_Y       Q2_Y #> Nb_Comp_0  154.6179          49             NA            NA      NA         NA #> Nb_Comp_1  126.4083          27             50    -0.1644349  0.0975 -0.1644349 #> Nb_Comp_2  119.3375          25             51    -0.9368004  0.0975 -0.6632964 #> Nb_Comp_3  114.2313          27             49    -2.7588358  0.0975 -0.9407451 #> Nb_Comp_4  112.3463          23             51    -7.9590981  0.0975 -1.3834768 #> Nb_Comp_5  113.2362          22             50   -21.7176352  0.0975 -1.5357056 #> Nb_Comp_6  114.7620          21             50   -58.9588752  0.0975 -1.6393097 #> Nb_Comp_7  116.5264          20             47  -158.6242020  0.0975 -1.6622281 #> Nb_Comp_8  118.4601          20             49  -425.6996662  0.0975 -1.6731514 #> Nb_Comp_9  120.4452          19             49 -1141.4655676  0.0975 -1.6774466 #> Nb_Comp_10 122.4395          19             50 -3058.2149555  0.0975 -1.6777306 #>             PRESS_Y    RSS_Y      R2_Y  AIC.std  DoF.dof sigmahat.dof   AIC.dof #> Nb_Comp_0        NA 25.91346        NA 298.1344  1.00000    0.5015845 0.2540061 #> Nb_Comp_1  30.17454 19.38086 0.2520929 269.9248 22.55372    0.4848429 0.2883114 #> Nb_Comp_2  32.23612 17.76209 0.3145613 262.8540 27.31542    0.4781670 0.2908950 #> Nb_Comp_3  34.47169 16.58896 0.3598323 257.7478 30.52370    0.4719550 0.2902572 #> Nb_Comp_4  39.53941 15.98071 0.3833049 255.8628 34.00000    0.4744263 0.3008285 #> Nb_Comp_5  40.52236 15.81104 0.3898523 256.7527 34.00000    0.4719012 0.2976347 #> Nb_Comp_6  41.73023 15.73910 0.3926285 258.2785 34.00000    0.4708264 0.2962804 #> Nb_Comp_7  41.90107 15.70350 0.3940024 260.0429 33.71066    0.4693382 0.2937976 #> Nb_Comp_8  41.97782 15.69348 0.3943888 261.9766 34.00000    0.4701436 0.2954217 #> Nb_Comp_9  42.01846 15.69123 0.3944758 263.9617 33.87284    0.4696894 0.2945815 #> Nb_Comp_10 42.01688 15.69037 0.3945088 265.9560 34.00000    0.4700970 0.2953632 #>              BIC.dof  GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive #> Nb_Comp_0  0.2604032 -67.17645         1      0.5015845 0.2540061 0.2604032 #> Nb_Comp_1  0.4231184 -53.56607         2      0.4358996 0.1936625 0.2033251 #> Nb_Comp_2  0.4496983 -52.42272         3      0.4193593 0.1809352 0.1943501 #> Nb_Comp_3  0.4631316 -51.93343         4      0.4072955 0.1722700 0.1891422 #> Nb_Comp_4  0.4954133 -50.37079         5      0.4017727 0.1691819 0.1897041 #> Nb_Comp_5  0.4901536 -50.65724         6      0.4016679 0.1706451 0.1952588 #> Nb_Comp_6  0.4879234 -50.78005         7      0.4028135 0.1731800 0.2020601 #> Nb_Comp_7  0.4826103 -51.05525         8      0.4044479 0.1761610 0.2094352 #> Nb_Comp_8  0.4865092 -50.85833         9      0.4064413 0.1794902 0.2172936 #> Nb_Comp_9  0.4845867 -50.95616        10      0.4085682 0.1829787 0.2254232 #> Nb_Comp_10 0.4864128 -50.86368        11      0.4107477 0.1865584 0.2337468 #>            GMDL.naive #> Nb_Comp_0   -67.17645 #> Nb_Comp_1   -79.67755 #> Nb_Comp_2   -81.93501 #> Nb_Comp_3   -83.31503 #> Nb_Comp_4   -83.23369 #> Nb_Comp_5   -81.93513 #> Nb_Comp_6   -80.42345 #> Nb_Comp_7   -78.87607 #> Nb_Comp_8   -77.31942 #> Nb_Comp_9   -75.80069 #> Nb_Comp_10  -74.33325 #> attr(,\"computed_nt\") #> [1] 10 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\" summary(cv.plsRglm(y~.,data=aze_compl,nt=10,K=8,modele=\"pls\",verbose=FALSE), MClassed=TRUE,verbose=FALSE) #> [[1]] #>                 AIC MissClassed CV_MissClassed      Q2cum_Y LimQ2_Y       Q2_Y #> Nb_Comp_0  154.6179          49             NA           NA      NA         NA #> Nb_Comp_1  126.4083          27             48   -0.1831188  0.0975 -0.1831188 #> Nb_Comp_2  119.3375          25             47   -0.8027725  0.0975 -0.5237460 #> Nb_Comp_3  114.2313          27             46   -2.3498032  0.0975 -0.8581397 #> Nb_Comp_4  112.3463          23             46   -6.0371280  0.0975 -1.1007586 #> Nb_Comp_5  113.2362          22             46  -14.5911203  0.0975 -1.2155516 #> Nb_Comp_6  114.7620          21             48  -33.9231748  0.0975 -1.2399401 #> Nb_Comp_7  116.5264          20             48  -77.7075380  0.0975 -1.2537338 #> Nb_Comp_8  118.4601          20             48 -176.8951415  0.0975 -1.2602046 #> Nb_Comp_9  120.4452          19             48 -401.7658972  0.0975 -1.2640635 #> Nb_Comp_10 122.4395          19             48 -912.7341538  0.0975 -1.2686483 #>             PRESS_Y    RSS_Y      R2_Y  AIC.std  DoF.dof sigmahat.dof   AIC.dof #> Nb_Comp_0        NA 25.91346        NA 298.1344  1.00000    0.5015845 0.2540061 #> Nb_Comp_1  30.65870 19.38086 0.2520929 269.9248 22.55372    0.4848429 0.2883114 #> Nb_Comp_2  29.53151 17.76209 0.3145613 262.8540 27.31542    0.4781670 0.2908950 #> Nb_Comp_3  33.00444 16.58896 0.3598323 257.7478 30.52370    0.4719550 0.2902572 #> Nb_Comp_4  34.84940 15.98071 0.3833049 255.8628 34.00000    0.4744263 0.3008285 #> Nb_Comp_5  35.40608 15.81104 0.3898523 256.7527 34.00000    0.4719012 0.2976347 #> Nb_Comp_6  35.41578 15.73910 0.3926285 258.2785 34.00000    0.4708264 0.2962804 #> Nb_Comp_7  35.47174 15.70350 0.3940024 260.0429 33.71066    0.4693382 0.2937976 #> Nb_Comp_8  35.49311 15.69348 0.3943888 261.9766 34.00000    0.4701436 0.2954217 #> Nb_Comp_9  35.53104 15.69123 0.3944758 263.9617 33.87284    0.4696894 0.2945815 #> Nb_Comp_10 35.59788 15.69037 0.3945088 265.9560 34.00000    0.4700970 0.2953632 #>              BIC.dof  GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive #> Nb_Comp_0  0.2604032 -67.17645         1      0.5015845 0.2540061 0.2604032 #> Nb_Comp_1  0.4231184 -53.56607         2      0.4358996 0.1936625 0.2033251 #> Nb_Comp_2  0.4496983 -52.42272         3      0.4193593 0.1809352 0.1943501 #> Nb_Comp_3  0.4631316 -51.93343         4      0.4072955 0.1722700 0.1891422 #> Nb_Comp_4  0.4954133 -50.37079         5      0.4017727 0.1691819 0.1897041 #> Nb_Comp_5  0.4901536 -50.65724         6      0.4016679 0.1706451 0.1952588 #> Nb_Comp_6  0.4879234 -50.78005         7      0.4028135 0.1731800 0.2020601 #> Nb_Comp_7  0.4826103 -51.05525         8      0.4044479 0.1761610 0.2094352 #> Nb_Comp_8  0.4865092 -50.85833         9      0.4064413 0.1794902 0.2172936 #> Nb_Comp_9  0.4845867 -50.95616        10      0.4085682 0.1829787 0.2254232 #> Nb_Comp_10 0.4864128 -50.86368        11      0.4107477 0.1865584 0.2337468 #>            GMDL.naive #> Nb_Comp_0   -67.17645 #> Nb_Comp_1   -79.67755 #> Nb_Comp_2   -81.93501 #> Nb_Comp_3   -83.31503 #> Nb_Comp_4   -83.23369 #> Nb_Comp_5   -81.93513 #> Nb_Comp_6   -80.42345 #> Nb_Comp_7   -78.87607 #> Nb_Comp_8   -77.31942 #> Nb_Comp_9   -75.80069 #> Nb_Comp_10  -74.33325 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\" summary(cv.plsRglm(y~.,data=aze_compl,nt=10,K=8, modele=\"pls-glm-family\", family=gaussian(),verbose=FALSE), MClassed=TRUE,verbose=FALSE) #> [[1]] #>                 AIC      BIC MissClassed CV_MissClassed  Q2Chisqcum_Y  limQ2 #> Nb_Comp_0  154.6179 159.9067          49             NA            NA     NA #> Nb_Comp_1  126.4083 134.3415          27             47    -0.1453856 0.0975 #> Nb_Comp_2  119.2021 129.7796          28             47    -0.8099674 0.0975 #> Nb_Comp_3  113.9553 127.1773          26             48    -2.5559644 0.0975 #> Nb_Comp_4  112.4466 128.3130          25             49    -7.3670862 0.0975 #> Nb_Comp_5  113.2280 131.7387          23             49   -20.0581535 0.0975 #> Nb_Comp_6  114.7095 135.8646          21             49   -52.2274814 0.0975 #> Nb_Comp_7  116.5144 140.3139          20             50  -134.8843601 0.0975 #> Nb_Comp_8  118.4615 144.9054          20             49  -349.9646424 0.0975 #> Nb_Comp_9  120.4453 149.5336          19             48  -908.5700082 0.0975 #> Nb_Comp_10 122.4403 154.1729          19             48 -2354.9438614 0.0975 #>             Q2Chisq_Y PREChi2_Pearson_Y Chi2_Pearson_Y    RSS_Y      R2_Y #> Nb_Comp_0          NA                NA       25.91346 25.91346        NA #> Nb_Comp_1  -0.1453856          29.68091       19.38086 19.38086 0.2520929 #> Nb_Comp_2  -0.5802254          30.62613       17.73898 17.73898 0.3154532 #> Nb_Comp_3  -0.9646566          34.85100       16.54501 16.54501 0.3615285 #> Nb_Comp_4  -1.3529724          38.92994       15.99613 15.99613 0.3827095 #> Nb_Comp_5  -1.5167846          40.25882       15.80978 15.80978 0.3899009 #> Nb_Comp_6  -1.5276424          39.96147       15.73116 15.73116 0.3929346 #> Nb_Comp_7  -1.5528985          40.16007       15.70168 15.70168 0.3940726 #> Nb_Comp_8  -1.5828185          40.55458       15.69369 15.69369 0.3943807 #> Nb_Comp_9  -1.5916286          40.67222       15.69125 15.69125 0.3944749 #> Nb_Comp_10 -1.5901732          40.64306       15.69049 15.69049 0.3945043 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" summary(cv.plsRglm(y~.,data=aze_compl,nt=10,K=8, modele=\"pls-glm-logistic\", verbose=FALSE),MClassed=TRUE,verbose=FALSE) #> [[1]] #>                 AIC      BIC MissClassed CV_MissClassed  Q2Chisqcum_Y  limQ2 #> Nb_Comp_0  145.8283 148.4727          49             NA            NA     NA #> Nb_Comp_1  118.1398 123.4285          28             43 -5.824077e-01 0.0975 #> Nb_Comp_2  109.9553 117.8885          26             42 -3.009528e+00 0.0975 #> Nb_Comp_3  105.1591 115.7366          22             40 -2.397657e+01 0.0975 #> Nb_Comp_4  103.8382 117.0601          21             42 -3.332401e+02 0.0975 #> Nb_Comp_5  104.7338 120.6001          21             44 -8.016615e+03 0.0975 #> Nb_Comp_6  105.6770 124.1878          21             47 -2.915479e+05 0.0975 #> Nb_Comp_7  107.2828 128.4380          20             47 -1.393612e+07 0.0975 #> Nb_Comp_8  109.0172 132.8167          22             47 -7.271549e+08 0.0975 #> Nb_Comp_9  110.9354 137.3793          21             46 -3.443722e+10 0.0975 #> Nb_Comp_10 112.9021 141.9904          20             46 -1.429540e+12 0.0975 #>              Q2Chisq_Y PREChi2_Pearson_Y Chi2_Pearson_Y    RSS_Y      R2_Y #> Nb_Comp_0           NA                NA      104.00000 25.91346        NA #> Nb_Comp_1   -0.5824077          164.5704      100.53823 19.32272 0.2543365 #> Nb_Comp_2   -1.5338150          254.7453       99.17955 17.33735 0.3309519 #> Nb_Comp_3   -5.2293034          617.8195      123.37836 15.58198 0.3986915 #> Nb_Comp_4  -12.3821465         1651.0673      114.77551 15.14046 0.4157299 #> Nb_Comp_5  -22.9875903         2753.1879      105.35382 15.08411 0.4179043 #> Nb_Comp_6  -35.3635495         3831.0388       98.87767 14.93200 0.4237744 #> Nb_Comp_7  -46.8002829         4726.3806       97.04072 14.87506 0.4259715 #> Nb_Comp_8  -51.1777103         5063.3625       98.90110 14.84925 0.4269676 #> Nb_Comp_9  -46.3588535         4683.8427      100.35563 14.84317 0.4272022 #> Nb_Comp_10 -40.5114777         4165.9105      102.85214 14.79133 0.4292027 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" summary(cv.plsRglm(y~.,data=aze_compl,nt=10,K=8, modele=\"pls-glm-family\", family=binomial(),verbose=FALSE), MClassed=TRUE,verbose=FALSE) #> [[1]] #>                 AIC      BIC MissClassed CV_MissClassed  Q2Chisqcum_Y  limQ2 #> Nb_Comp_0  145.8283 148.4727          49             NA            NA     NA #> Nb_Comp_1  118.1398 123.4285          28             43 -1.206801e+00 0.0975 #> Nb_Comp_2  109.9553 117.8885          26             49 -7.872226e+00 0.0975 #> Nb_Comp_3  105.1591 115.7366          22             50 -1.682392e+02 0.0975 #> Nb_Comp_4  103.8382 117.0601          21             53 -1.068885e+04 0.0975 #> Nb_Comp_5  104.7338 120.6001          21             54 -1.345857e+06 0.0975 #> Nb_Comp_6  105.6770 124.1878          21             50 -2.734945e+08 0.0975 #> Nb_Comp_7  107.2828 128.4380          20             47 -6.274124e+10 0.0975 #> Nb_Comp_8  109.0172 132.8167          22             50 -1.950143e+13 0.0975 #> Nb_Comp_9  110.9354 137.3793          21             51 -7.253979e+15 0.0975 #> Nb_Comp_10 112.9021 141.9904          20             49 -3.481376e+18 0.0975 #>              Q2Chisq_Y PREChi2_Pearson_Y Chi2_Pearson_Y    RSS_Y      R2_Y #> Nb_Comp_0           NA                NA      104.00000 25.91346        NA #> Nb_Comp_1    -1.206801          229.5073      100.53823 19.32272 0.2543365 #> Nb_Comp_2    -3.020402          404.2041       99.17955 17.33735 0.3309519 #> Nb_Comp_3   -18.075169         1891.8668      123.37836 15.58198 0.3986915 #> Nb_Comp_4   -62.164168         7793.0914      114.77551 15.14046 0.4157299 #> Nb_Comp_5  -124.900478        14450.2916      105.35382 15.08411 0.4179043 #> Nb_Comp_6  -202.212071        21409.1674       98.87767 14.93200 0.4237744 #> Nb_Comp_7  -228.405804        22683.1114       97.04072 14.87506 0.4259715 #> Nb_Comp_8  -309.823158        30162.5024       98.90110 14.84925 0.4269676 #> Nb_Comp_9  -370.971686        36788.4087      100.35563 14.84317 0.4272022 #> Nb_Comp_10 -478.926330        48163.3090      102.85214 14.79133 0.4292027 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\"   if(require(chemometrics)){ data(hyptis) hyptis yhyptis <- factor(hyptis$Group,ordered=TRUE) Xhyptis <- as.data.frame(hyptis[,c(1:6)]) options(contrasts = c(\"contr.treatment\", \"contr.poly\")) modpls2 <- plsRglm(yhyptis,Xhyptis,6,modele=\"pls-glm-polr\") modpls2$Coeffsmodel_vals modpls2$InfCrit modpls2$Coeffs modpls2$std.coeffs  table(yhyptis,predict(modpls2$FinalModel,type=\"class\"))  modpls3 <- PLS_glm(yhyptis[-c(1,2,3)],Xhyptis[-c(1,2,3),],3,modele=\"pls-glm-polr\", dataPredictY=Xhyptis[c(1,2,3),],verbose=FALSE)  summary(cv.plsRglm(factor(Group,ordered=TRUE)~.,data=hyptis[,-c(7,8)],nt=4,K=10, random=TRUE,modele=\"pls-glm-polr\",keepcoeffs=TRUE,verbose=FALSE), MClassed=TRUE,verbose=FALSE) } #> Loading required package: chemometrics #> Warning: there is no package called ‘chemometrics’ # }"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares models — kfolds2CVinfos_lm","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares models — kfolds2CVinfos_lm","text":"function extracts computes information criteria fits statistics k-fold cross validated partial least squares models formula classic specifications model.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares models — kfolds2CVinfos_lm","text":"","code":"kfolds2CVinfos_lm(pls_kfolds, MClassed = FALSE, verbose = TRUE)"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares models — kfolds2CVinfos_lm","text":"pls_kfolds object computed using PLS_lm_kfoldcv MClassed number miss classed computed verbose infos displayed ?","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares models — kfolds2CVinfos_lm","text":"list table fit statistics first group partition list() ... list table fit statistics last group partition","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares models — kfolds2CVinfos_lm","text":"Mclassed option set TRUE response binary.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_lm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares models — kfolds2CVinfos_lm","text":"Use summary cv.plsR instead.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_lm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares models — kfolds2CVinfos_lm","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_lm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares models — kfolds2CVinfos_lm","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2CVinfos_lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extracts and computes information criteria and fits statistics for k-fold cross validated partial least squares models — kfolds2CVinfos_lm","text":"","code":"# \\donttest{ data(Cornell) summary(cv.plsR(Y~.,data=Cornell,nt=10,K=6,verbose=FALSE)) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC    Q2cum_Y LimQ2_Y        Q2_Y  PRESS_Y      RSS_Y      R2_Y #> Nb_Comp_0 82.01205         NA      NA          NA       NA 467.796667        NA #> Nb_Comp_1 53.15173  0.8833692  0.0975  0.88336915 54.55952  35.742486 0.9235940 #> Nb_Comp_2 41.08283  0.8805715  0.0975 -0.02398696 36.59984  11.066606 0.9763431 #> Nb_Comp_3 32.06411  0.7922562  0.0975 -0.73948309 19.25017   4.418081 0.9905556 #> Nb_Comp_4 33.76477  0.2690413  0.0975 -2.51855868 15.54528   4.309235 0.9907882 #> Nb_Comp_5 33.34373 -3.6031367  0.0975 -5.29739609 27.13696   3.521924 0.9924713 #> Nb_Comp_6 35.25533         NA  0.0975          NA       NA   3.496074 0.9925265 #>              AIC.std  DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof #> Nb_Comp_0  37.010388 1.000000    6.5212706 46.0708838 47.7893514 27.59461 #> Nb_Comp_1   8.150064 2.740749    1.8665281  4.5699686  4.9558156 21.34020 #> Nb_Comp_2  -3.918831 5.085967    1.1825195  2.1075461  2.3949331 27.40202 #> Nb_Comp_3 -12.937550 5.121086    0.7488308  0.8467795  0.9628191 24.40842 #> Nb_Comp_4 -11.236891 5.103312    0.7387162  0.8232505  0.9357846 24.23105 #> Nb_Comp_5 -11.657929 6.006316    0.7096382  0.7976101  0.9198348 28.21184 #> Nb_Comp_6  -9.746328 7.000002    0.7633343  0.9711322  1.1359502 33.18348 #>           DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0         1      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1         2      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2         3      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3         4      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4         5      0.7846050  0.8721072  0.9964867   24.16510 #> Nb_Comp_5         6      0.7661509  0.8804809  1.0227979   28.64206 #> Nb_Comp_6         7      0.8361907  1.1070902  1.3048716   33.63927 #> attr(,\"computed_nt\") #> [1] 6 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\"   data(pine) summary(cv.plsR(x11~.,data=pine,nt=10,NK=3,verbose=FALSE),verbose=FALSE) #> [[1]] #>                 AIC       Q2cum_Y LimQ2_Y       Q2_Y  PRESS_Y     RSS_Y #> Nb_Comp_0  82.41888            NA      NA         NA       NA 20.800152 #> Nb_Comp_1  63.61896    0.33236241  0.0975  0.3323624 13.88696 11.074659 #> Nb_Comp_2  58.47638    0.08602135  0.0975 -0.3689742 15.16092  8.919303 #> Nb_Comp_3  56.55421   -0.64686696  0.0975 -0.8018659 16.07139  7.919786 #> Nb_Comp_4  54.35053   -2.07842135  0.0975 -0.8692593 14.80413  6.972542 #> Nb_Comp_5  55.99834   -5.26758156  0.0975 -1.0359726 14.19590  6.898523 #> Nb_Comp_6  57.69592  -11.24110783  0.0975 -0.9530831 13.47339  6.835594 #> Nb_Comp_7  59.37953  -23.44871994  0.0975 -0.9972637 13.65248  6.770369 #> Nb_Comp_8  61.21213  -51.30545992  0.0975 -1.1393946 14.48449  6.736112 #> Nb_Comp_9  63.18426 -112.65581728  0.0975 -1.1729245 14.63706  6.730426 #> Nb_Comp_10 65.15982 -248.80085723  0.0975 -1.1978713 14.79261  6.725443 #>                 R2_Y  AIC.std   DoF.dof sigmahat.dof   AIC.dof   BIC.dof #> Nb_Comp_0         NA 96.63448  1.000000    0.8062287 0.6697018 0.6991787 #> Nb_Comp_1  0.4675684 77.83455  3.176360    0.5994089 0.4047616 0.4565153 #> Nb_Comp_2  0.5711905 72.69198  7.133559    0.5761829 0.4138120 0.5212090 #> Nb_Comp_3  0.6192438 70.76981  8.778329    0.5603634 0.4070516 0.5320535 #> Nb_Comp_4  0.6647841 68.56612  8.427874    0.5221703 0.3505594 0.4547689 #> Nb_Comp_5  0.6683426 70.21393  9.308247    0.5285695 0.3666578 0.4845912 #> Nb_Comp_6  0.6713681 71.91152  9.291931    0.5259794 0.3629363 0.4795121 #> Nb_Comp_7  0.6745039 73.59512  9.756305    0.5284535 0.3702885 0.4938445 #> Nb_Comp_8  0.6761508 75.42772 10.363948    0.5338475 0.3831339 0.5170783 #> Nb_Comp_9  0.6764242 77.39986 10.732148    0.5378277 0.3920957 0.5328747 #> Nb_Comp_10 0.6766638 79.37542 11.000000    0.5407500 0.3987417 0.5446065 #>             GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0  -3.605128         1      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1  -9.875081         2      0.5977015 0.3788984 0.4112998 -11.451340 #> Nb_Comp_2  -6.985517         3      0.5452615 0.3243383 0.3647862 -12.822703 #> Nb_Comp_3  -6.260610         4      0.5225859 0.3061986 0.3557368 -12.756838 #> Nb_Comp_4  -8.152986         5      0.4990184 0.2867496 0.3432131 -12.811575 #> Nb_Comp_5  -7.111583         6      0.5054709 0.3019556 0.3714754 -11.329638 #> Nb_Comp_6  -7.233043         7      0.5127450 0.3186757 0.4021333  -9.918688 #> Nb_Comp_7  -6.742195         8      0.5203986 0.3364668 0.4347156  -8.592770 #> Nb_Comp_8  -6.038372         9      0.5297842 0.3572181 0.4717708  -7.287834 #> Nb_Comp_9  -5.600235        10      0.5409503 0.3813021 0.5140048  -6.008747 #> Nb_Comp_10 -5.288422        11      0.5529032 0.4076026 0.5600977  -4.799453 #> attr(,\"computed_nt\") #> [1] 10 #>  #> [[2]] #>                 AIC     Q2cum_Y LimQ2_Y       Q2_Y  PRESS_Y     RSS_Y      R2_Y #> Nb_Comp_0  82.41888          NA      NA         NA       NA 20.800152        NA #> Nb_Comp_1  63.61896   0.2883611  0.0975  0.2883611 14.80220 11.074659 0.4675684 #> Nb_Comp_2  58.47638   0.1495497  0.0975 -0.1950588 13.23487  8.919303 0.5711905 #> Nb_Comp_3  56.55421  -0.2339077  0.0975 -0.4508876 12.94091  7.919786 0.6192438 #> Nb_Comp_4  54.35053  -0.8654831  0.0975 -0.5118498 11.97353  6.972542 0.6647841 #> Nb_Comp_5  55.99834  -2.0764393  0.0975 -0.6491381 11.49868  6.898523 0.6683426 #> Nb_Comp_6  57.69592  -3.9268641  0.0975 -0.6014826 11.04787  6.835594 0.6713681 #> Nb_Comp_7  59.37953  -7.4958507  0.0975 -0.7243932 11.78725  6.770369 0.6745039 #> Nb_Comp_8  61.21213 -14.0681481  0.0975 -0.7735891 12.00785  6.736112 0.6761508 #> Nb_Comp_9  63.18426 -28.2071979  0.0975 -0.9383402 13.05688  6.730426 0.6764242 #> Nb_Comp_10 65.15982 -55.9051868  0.0975 -0.9483275 13.11307  6.725443 0.6766638 #>             AIC.std   DoF.dof sigmahat.dof   AIC.dof   BIC.dof  GMDL.dof #> Nb_Comp_0  96.63448  1.000000    0.8062287 0.6697018 0.6991787 -3.605128 #> Nb_Comp_1  77.83455  3.176360    0.5994089 0.4047616 0.4565153 -9.875081 #> Nb_Comp_2  72.69198  7.133559    0.5761829 0.4138120 0.5212090 -6.985517 #> Nb_Comp_3  70.76981  8.778329    0.5603634 0.4070516 0.5320535 -6.260610 #> Nb_Comp_4  68.56612  8.427874    0.5221703 0.3505594 0.4547689 -8.152986 #> Nb_Comp_5  70.21393  9.308247    0.5285695 0.3666578 0.4845912 -7.111583 #> Nb_Comp_6  71.91152  9.291931    0.5259794 0.3629363 0.4795121 -7.233043 #> Nb_Comp_7  73.59512  9.756305    0.5284535 0.3702885 0.4938445 -6.742195 #> Nb_Comp_8  75.42772 10.363948    0.5338475 0.3831339 0.5170783 -6.038372 #> Nb_Comp_9  77.39986 10.732148    0.5378277 0.3920957 0.5328747 -5.600235 #> Nb_Comp_10 79.37542 11.000000    0.5407500 0.3987417 0.5446065 -5.288422 #>            DoF.naive sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0          1      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1          2      0.5977015 0.3788984 0.4112998 -11.451340 #> Nb_Comp_2          3      0.5452615 0.3243383 0.3647862 -12.822703 #> Nb_Comp_3          4      0.5225859 0.3061986 0.3557368 -12.756838 #> Nb_Comp_4          5      0.4990184 0.2867496 0.3432131 -12.811575 #> Nb_Comp_5          6      0.5054709 0.3019556 0.3714754 -11.329638 #> Nb_Comp_6          7      0.5127450 0.3186757 0.4021333  -9.918688 #> Nb_Comp_7          8      0.5203986 0.3364668 0.4347156  -8.592770 #> Nb_Comp_8          9      0.5297842 0.3572181 0.4717708  -7.287834 #> Nb_Comp_9         10      0.5409503 0.3813021 0.5140048  -6.008747 #> Nb_Comp_10        11      0.5529032 0.4076026 0.5600977  -4.799453 #> attr(,\"computed_nt\") #> [1] 10 #>  #> [[3]] #>                 AIC      Q2cum_Y LimQ2_Y       Q2_Y  PRESS_Y     RSS_Y #> Nb_Comp_0  82.41888           NA      NA         NA       NA 20.800152 #> Nb_Comp_1  63.61896    0.3706202  0.0975  0.3706202 13.09120 11.074659 #> Nb_Comp_2  58.47638    0.2227707  0.0975 -0.2349129 13.67624  8.919303 #> Nb_Comp_3  56.55421   -0.2745327  0.0975 -0.6398414 14.62624  7.919786 #> Nb_Comp_4  54.35053   -0.9662890  0.0975 -0.5427529 12.21827  6.972542 #> Nb_Comp_5  55.99834   -2.2579216  0.0975 -0.6568885 11.55272  6.898523 #> Nb_Comp_6  57.69592   -4.5773450  0.0975 -0.7119335 11.80981  6.835594 #> Nb_Comp_7  59.37953   -9.2588465  0.0975 -0.8393781 12.57324  6.770369 #> Nb_Comp_8  61.21213  -18.3325334  0.0975 -0.8844744 12.75859  6.736112 #> Nb_Comp_9  63.18426  -43.1148562  0.0975 -1.2818973 15.37112  6.730426 #> Nb_Comp_10 65.15982 -108.3254239  0.0975 -1.4781997 16.67934  6.725443 #>                 R2_Y  AIC.std   DoF.dof sigmahat.dof   AIC.dof   BIC.dof #> Nb_Comp_0         NA 96.63448  1.000000    0.8062287 0.6697018 0.6991787 #> Nb_Comp_1  0.4675684 77.83455  3.176360    0.5994089 0.4047616 0.4565153 #> Nb_Comp_2  0.5711905 72.69198  7.133559    0.5761829 0.4138120 0.5212090 #> Nb_Comp_3  0.6192438 70.76981  8.778329    0.5603634 0.4070516 0.5320535 #> Nb_Comp_4  0.6647841 68.56612  8.427874    0.5221703 0.3505594 0.4547689 #> Nb_Comp_5  0.6683426 70.21393  9.308247    0.5285695 0.3666578 0.4845912 #> Nb_Comp_6  0.6713681 71.91152  9.291931    0.5259794 0.3629363 0.4795121 #> Nb_Comp_7  0.6745039 73.59512  9.756305    0.5284535 0.3702885 0.4938445 #> Nb_Comp_8  0.6761508 75.42772 10.363948    0.5338475 0.3831339 0.5170783 #> Nb_Comp_9  0.6764242 77.39986 10.732148    0.5378277 0.3920957 0.5328747 #> Nb_Comp_10 0.6766638 79.37542 11.000000    0.5407500 0.3987417 0.5446065 #>             GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0  -3.605128         1      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1  -9.875081         2      0.5977015 0.3788984 0.4112998 -11.451340 #> Nb_Comp_2  -6.985517         3      0.5452615 0.3243383 0.3647862 -12.822703 #> Nb_Comp_3  -6.260610         4      0.5225859 0.3061986 0.3557368 -12.756838 #> Nb_Comp_4  -8.152986         5      0.4990184 0.2867496 0.3432131 -12.811575 #> Nb_Comp_5  -7.111583         6      0.5054709 0.3019556 0.3714754 -11.329638 #> Nb_Comp_6  -7.233043         7      0.5127450 0.3186757 0.4021333  -9.918688 #> Nb_Comp_7  -6.742195         8      0.5203986 0.3364668 0.4347156  -8.592770 #> Nb_Comp_8  -6.038372         9      0.5297842 0.3572181 0.4717708  -7.287834 #> Nb_Comp_9  -5.600235        10      0.5409503 0.3813021 0.5140048  -6.008747 #> Nb_Comp_10 -5.288422        11      0.5529032 0.4076026 0.5600977  -4.799453 #> attr(,\"computed_nt\") #> [1] 10 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\" data(pineNAX21) summary(cv.plsR(x11~.,data=pineNAX21,nt=10,NK=3, verbose=FALSE),verbose=FALSE) #> [[1]] #>                AIC      Q2cum_Y LimQ2_Y       Q2_Y  PRESS_Y     RSS_Y      R2_Y #> Nb_Comp_0 82.41888           NA      NA         NA       NA 20.800152        NA #> Nb_Comp_1 63.69250    0.1644558  0.0975  0.1644558 17.37945 11.099368 0.4663804 #> Nb_Comp_2 58.35228   -0.1643470  0.0975 -0.3935193 15.46718  8.885823 0.5728001 #> Nb_Comp_3 56.36553   -1.0741068  0.0975 -0.7813476 15.82874  7.874634 0.6214146 #> Nb_Comp_4 54.02416   -2.2496103  0.0975 -0.5667516 12.33760  6.903925 0.6680830 #> Nb_Comp_5 55.80450   -5.6345125  0.0975 -1.0416333 14.09528  6.858120 0.6702851 #> Nb_Comp_6 57.45753  -11.9901592  0.0975 -0.9579674 13.42798  6.786392 0.6737336 #> Nb_Comp_7 58.73951  -21.9760455  0.0975 -0.7687270 12.00327  6.640327 0.6807558 #> Nb_Comp_8 60.61227  -43.4713170  0.0975 -0.9355514 12.85269  6.614773 0.6819844 #> Nb_Comp_9 62.25948 -171.1558997  0.0975 -2.8711671 25.60689  6.544432 0.6853661 #>            AIC.std DoF.dof sigmahat.dof AIC.dof BIC.dof GMDL.dof DoF.naive #> Nb_Comp_0 96.63448      NA           NA      NA      NA       NA         1 #> Nb_Comp_1 77.90810      NA           NA      NA      NA       NA         2 #> Nb_Comp_2 72.56787      NA           NA      NA      NA       NA         3 #> Nb_Comp_3 70.58113      NA           NA      NA      NA       NA         4 #> Nb_Comp_4 68.23976      NA           NA      NA      NA       NA         5 #> Nb_Comp_5 70.02009      NA           NA      NA      NA       NA         6 #> Nb_Comp_6 71.67313      NA           NA      NA      NA       NA         7 #> Nb_Comp_7 72.95511      NA           NA      NA      NA       NA         8 #> Nb_Comp_8 74.82787      NA           NA      NA      NA       NA         9 #> Nb_Comp_9 76.47507      NA           NA      NA      NA       NA        10 #>           sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1      0.5983679 0.3797438 0.4122175 -11.413749 #> Nb_Comp_2      0.5442372 0.3231208 0.3634169 -12.847656 #> Nb_Comp_3      0.5210941 0.3044529 0.3537087 -12.776843 #> Nb_Comp_4      0.4965569 0.2839276 0.3398355 -12.891035 #> Nb_Comp_5      0.5039885 0.3001871 0.3692997 -11.349498 #> Nb_Comp_6      0.5108963 0.3163819 0.3992388  -9.922119 #> Nb_Comp_7      0.5153766 0.3300041 0.4263658  -8.696873 #> Nb_Comp_8      0.5249910 0.3507834 0.4632727  -7.337679 #> Nb_Comp_9      0.5334234 0.3707649 0.4998004  -6.033403 #> attr(,\"computed_nt\") #> [1] 9 #>  #> [[2]] #>                AIC      Q2cum_Y LimQ2_Y       Q2_Y  PRESS_Y     RSS_Y      R2_Y #> Nb_Comp_0 82.41888           NA      NA         NA       NA 20.800152        NA #> Nb_Comp_1 63.69250   0.31341253  0.0975  0.3134125 14.28112 11.099368 0.4663804 #> Nb_Comp_2 58.35228   0.08234691  0.0975 -0.3365421 14.83477  8.885823 0.5728001 #> Nb_Comp_3 56.36553  -0.45720572  0.0975 -0.5879702 14.11042  7.874634 0.6214146 #> Nb_Comp_4 54.02416  -1.20066552  0.0975 -0.5101955 11.89224  6.903925 0.6680830 #> Nb_Comp_5 55.80450  -2.54778037  0.0975 -0.6121398 11.13009  6.858120 0.6702851 #> Nb_Comp_6 57.45753  -5.55466263  0.0975 -0.8475390 12.67064  6.786392 0.6737336 #> Nb_Comp_7 58.73951 -11.31988857  0.0975 -0.8795610 12.75544  6.640327 0.6807558 #> Nb_Comp_8 60.61227 -19.41015264  0.0975 -0.6566832 11.00092  6.614773 0.6819844 #> Nb_Comp_9 62.25948 -40.36330967  0.0975 -1.0266046 13.40553  6.544432 0.6853661 #>            AIC.std DoF.dof sigmahat.dof AIC.dof BIC.dof GMDL.dof DoF.naive #> Nb_Comp_0 96.63448      NA           NA      NA      NA       NA         1 #> Nb_Comp_1 77.90810      NA           NA      NA      NA       NA         2 #> Nb_Comp_2 72.56787      NA           NA      NA      NA       NA         3 #> Nb_Comp_3 70.58113      NA           NA      NA      NA       NA         4 #> Nb_Comp_4 68.23976      NA           NA      NA      NA       NA         5 #> Nb_Comp_5 70.02009      NA           NA      NA      NA       NA         6 #> Nb_Comp_6 71.67313      NA           NA      NA      NA       NA         7 #> Nb_Comp_7 72.95511      NA           NA      NA      NA       NA         8 #> Nb_Comp_8 74.82787      NA           NA      NA      NA       NA         9 #> Nb_Comp_9 76.47507      NA           NA      NA      NA       NA        10 #>           sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1      0.5983679 0.3797438 0.4122175 -11.413749 #> Nb_Comp_2      0.5442372 0.3231208 0.3634169 -12.847656 #> Nb_Comp_3      0.5210941 0.3044529 0.3537087 -12.776843 #> Nb_Comp_4      0.4965569 0.2839276 0.3398355 -12.891035 #> Nb_Comp_5      0.5039885 0.3001871 0.3692997 -11.349498 #> Nb_Comp_6      0.5108963 0.3163819 0.3992388  -9.922119 #> Nb_Comp_7      0.5153766 0.3300041 0.4263658  -8.696873 #> Nb_Comp_8      0.5249910 0.3507834 0.4632727  -7.337679 #> Nb_Comp_9      0.5334234 0.3707649 0.4998004  -6.033403 #> attr(,\"computed_nt\") #> [1] 9 #>  #> [[3]] #>                AIC      Q2cum_Y LimQ2_Y       Q2_Y  PRESS_Y     RSS_Y      R2_Y #> Nb_Comp_0 82.41888           NA      NA         NA       NA 20.800152        NA #> Nb_Comp_1 63.69250    0.3365687  0.0975  0.3365687 13.79947 11.099368 0.4663804 #> Nb_Comp_2 58.35228    0.1455661  0.0975 -0.2879011 14.29489  8.885823 0.5728001 #> Nb_Comp_3 56.36553   -0.4774579  0.0975 -0.7291658 15.36506  7.874634 0.6214146 #> Nb_Comp_4 54.02416   -2.6861938  0.0975 -1.4949568 19.64687  6.903925 0.6680830 #> Nb_Comp_5 55.80450   -8.2679002  0.0975 -1.5142195 17.35798  6.858120 0.6702851 #> Nb_Comp_6 57.45753  -21.8257919  0.0975 -1.4628871 16.89078  6.786392 0.6737336 #> Nb_Comp_7 58.73951  -62.7683695  0.0975 -1.7936980 18.95913  6.640327 0.6807558 #> Nb_Comp_8 60.61227 -180.3072283  0.0975 -1.8432157 18.87988  6.614773 0.6819844 #> Nb_Comp_9 62.25948 -538.8858574  0.0975 -1.9777404 19.69708  6.544432 0.6853661 #>            AIC.std DoF.dof sigmahat.dof AIC.dof BIC.dof GMDL.dof DoF.naive #> Nb_Comp_0 96.63448      NA           NA      NA      NA       NA         1 #> Nb_Comp_1 77.90810      NA           NA      NA      NA       NA         2 #> Nb_Comp_2 72.56787      NA           NA      NA      NA       NA         3 #> Nb_Comp_3 70.58113      NA           NA      NA      NA       NA         4 #> Nb_Comp_4 68.23976      NA           NA      NA      NA       NA         5 #> Nb_Comp_5 70.02009      NA           NA      NA      NA       NA         6 #> Nb_Comp_6 71.67313      NA           NA      NA      NA       NA         7 #> Nb_Comp_7 72.95511      NA           NA      NA      NA       NA         8 #> Nb_Comp_8 74.82787      NA           NA      NA      NA       NA         9 #> Nb_Comp_9 76.47507      NA           NA      NA      NA       NA        10 #>           sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0      0.8062287 0.6697018 0.6991787  -3.605128 #> Nb_Comp_1      0.5983679 0.3797438 0.4122175 -11.413749 #> Nb_Comp_2      0.5442372 0.3231208 0.3634169 -12.847656 #> Nb_Comp_3      0.5210941 0.3044529 0.3537087 -12.776843 #> Nb_Comp_4      0.4965569 0.2839276 0.3398355 -12.891035 #> Nb_Comp_5      0.5039885 0.3001871 0.3692997 -11.349498 #> Nb_Comp_6      0.5108963 0.3163819 0.3992388  -9.922119 #> Nb_Comp_7      0.5153766 0.3300041 0.4263658  -8.696873 #> Nb_Comp_8      0.5249910 0.3507834 0.4632727  -7.337679 #> Nb_Comp_9      0.5334234 0.3707649 0.4998004  -6.033403 #> attr(,\"computed_nt\") #> [1] 9 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\"   data(aze_compl) summary(cv.plsR(y~.,data=aze_compl,nt=10,K=8,NK=3, verbose=FALSE),MClassed=TRUE,verbose=FALSE) #> [[1]] #>                 AIC MissClassed CV_MissClassed      Q2cum_Y LimQ2_Y       Q2_Y #> Nb_Comp_0  154.6179          49             NA           NA      NA         NA #> Nb_Comp_1  126.4083          27             42   -0.1061711  0.0975 -0.1061711 #> Nb_Comp_2  119.3375          25             39   -0.5960203  0.0975 -0.4428331 #> Nb_Comp_3  114.2313          27             45   -1.8401711  0.0975 -0.7795332 #> Nb_Comp_4  112.3463          23             43   -4.9481058  0.0975 -1.0942773 #> Nb_Comp_5  113.2362          22             41  -12.0833749  0.0975 -1.1995868 #> Nb_Comp_6  114.7620          21             42  -28.5283073  0.0975 -1.2569335 #> Nb_Comp_7  116.5264          20             41  -66.5458644  0.0975 -1.2874953 #> Nb_Comp_8  118.4601          20             41 -153.7402407  0.0975 -1.2908914 #> Nb_Comp_9  120.4452          19             41 -355.4269515  0.0975 -1.3033889 #> Nb_Comp_10 122.4395          19             41 -821.2862196  0.0975 -1.3070259 #>             PRESS_Y    RSS_Y      R2_Y  AIC.std  DoF.dof sigmahat.dof   AIC.dof #> Nb_Comp_0        NA 25.91346        NA 298.1344  1.00000    0.5015845 0.2540061 #> Nb_Comp_1  28.66472 19.38086 0.2520929 269.9248 22.55372    0.4848429 0.2883114 #> Nb_Comp_2  27.96335 17.76209 0.3145613 262.8540 27.31542    0.4781670 0.2908950 #> Nb_Comp_3  31.60823 16.58896 0.3598323 257.7478 30.52370    0.4719550 0.2902572 #> Nb_Comp_4  34.74189 15.98071 0.3833049 255.8628 34.00000    0.4744263 0.3008285 #> Nb_Comp_5  35.15095 15.81104 0.3898523 256.7527 34.00000    0.4719012 0.2976347 #> Nb_Comp_6  35.68447 15.73910 0.3926285 258.2785 34.00000    0.4708264 0.2962804 #> Nb_Comp_7  36.00312 15.70350 0.3940024 260.0429 33.71066    0.4693382 0.2937976 #> Nb_Comp_8  35.97500 15.69348 0.3943888 261.9766 34.00000    0.4701436 0.2954217 #> Nb_Comp_9  36.14819 15.69123 0.3944758 263.9617 33.87284    0.4696894 0.2945815 #> Nb_Comp_10 36.20007 15.69037 0.3945088 265.9560 34.00000    0.4700970 0.2953632 #>              BIC.dof  GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive #> Nb_Comp_0  0.2604032 -67.17645         1      0.5015845 0.2540061 0.2604032 #> Nb_Comp_1  0.4231184 -53.56607         2      0.4358996 0.1936625 0.2033251 #> Nb_Comp_2  0.4496983 -52.42272         3      0.4193593 0.1809352 0.1943501 #> Nb_Comp_3  0.4631316 -51.93343         4      0.4072955 0.1722700 0.1891422 #> Nb_Comp_4  0.4954133 -50.37079         5      0.4017727 0.1691819 0.1897041 #> Nb_Comp_5  0.4901536 -50.65724         6      0.4016679 0.1706451 0.1952588 #> Nb_Comp_6  0.4879234 -50.78005         7      0.4028135 0.1731800 0.2020601 #> Nb_Comp_7  0.4826103 -51.05525         8      0.4044479 0.1761610 0.2094352 #> Nb_Comp_8  0.4865092 -50.85833         9      0.4064413 0.1794902 0.2172936 #> Nb_Comp_9  0.4845867 -50.95616        10      0.4085682 0.1829787 0.2254232 #> Nb_Comp_10 0.4864128 -50.86368        11      0.4107477 0.1865584 0.2337468 #>            GMDL.naive #> Nb_Comp_0   -67.17645 #> Nb_Comp_1   -79.67755 #> Nb_Comp_2   -81.93501 #> Nb_Comp_3   -83.31503 #> Nb_Comp_4   -83.23369 #> Nb_Comp_5   -81.93513 #> Nb_Comp_6   -80.42345 #> Nb_Comp_7   -78.87607 #> Nb_Comp_8   -77.31942 #> Nb_Comp_9   -75.80069 #> Nb_Comp_10  -74.33325 #> attr(,\"computed_nt\") #> [1] 10 #>  #> [[2]] #>                 AIC MissClassed CV_MissClassed       Q2cum_Y LimQ2_Y       Q2_Y #> Nb_Comp_0  154.6179          49             NA            NA      NA         NA #> Nb_Comp_1  126.4083          27             47    -0.1977984  0.0975 -0.1977984 #> Nb_Comp_2  119.3375          25             50    -0.9531630  0.0975 -0.6306276 #> Nb_Comp_3  114.2313          27             44    -2.6313264  0.0975 -0.8592029 #> Nb_Comp_4  112.3463          23             49    -6.6647559  0.0975 -1.1107318 #> Nb_Comp_5  113.2362          22             50   -16.2882937  0.0975 -1.2555570 #> Nb_Comp_6  114.7620          21             49   -38.3610775  0.0975 -1.2767474 #> Nb_Comp_7  116.5264          20             49   -88.7850764  0.0975 -1.2810625 #> Nb_Comp_8  118.4601          20             49  -205.1585036  0.0975 -1.2961333 #> Nb_Comp_9  120.4452          19             48  -473.9867210  0.0975 -1.3039880 #> Nb_Comp_10 122.4395          19             49 -1098.9905814  0.0975 -1.3158344 #>             PRESS_Y    RSS_Y      R2_Y  AIC.std  DoF.dof sigmahat.dof   AIC.dof #> Nb_Comp_0        NA 25.91346        NA 298.1344  1.00000    0.5015845 0.2540061 #> Nb_Comp_1  31.03910 19.38086 0.2520929 269.9248 22.55372    0.4848429 0.2883114 #> Nb_Comp_2  31.60297 17.76209 0.3145613 262.8540 27.31542    0.4781670 0.2908950 #> Nb_Comp_3  33.02333 16.58896 0.3598323 257.7478 30.52370    0.4719550 0.2902572 #> Nb_Comp_4  35.01485 15.98071 0.3833049 255.8628 34.00000    0.4744263 0.3008285 #> Nb_Comp_5  36.04539 15.81104 0.3898523 256.7527 34.00000    0.4719012 0.2976347 #> Nb_Comp_6  35.99774 15.73910 0.3926285 258.2785 34.00000    0.4708264 0.2962804 #> Nb_Comp_7  35.90187 15.70350 0.3940024 260.0429 33.71066    0.4693382 0.2937976 #> Nb_Comp_8  36.05732 15.69348 0.3943888 261.9766 34.00000    0.4701436 0.2954217 #> Nb_Comp_9  36.15759 15.69123 0.3944758 263.9617 33.87284    0.4696894 0.2945815 #> Nb_Comp_10 36.33829 15.69037 0.3945088 265.9560 34.00000    0.4700970 0.2953632 #>              BIC.dof  GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive #> Nb_Comp_0  0.2604032 -67.17645         1      0.5015845 0.2540061 0.2604032 #> Nb_Comp_1  0.4231184 -53.56607         2      0.4358996 0.1936625 0.2033251 #> Nb_Comp_2  0.4496983 -52.42272         3      0.4193593 0.1809352 0.1943501 #> Nb_Comp_3  0.4631316 -51.93343         4      0.4072955 0.1722700 0.1891422 #> Nb_Comp_4  0.4954133 -50.37079         5      0.4017727 0.1691819 0.1897041 #> Nb_Comp_5  0.4901536 -50.65724         6      0.4016679 0.1706451 0.1952588 #> Nb_Comp_6  0.4879234 -50.78005         7      0.4028135 0.1731800 0.2020601 #> Nb_Comp_7  0.4826103 -51.05525         8      0.4044479 0.1761610 0.2094352 #> Nb_Comp_8  0.4865092 -50.85833         9      0.4064413 0.1794902 0.2172936 #> Nb_Comp_9  0.4845867 -50.95616        10      0.4085682 0.1829787 0.2254232 #> Nb_Comp_10 0.4864128 -50.86368        11      0.4107477 0.1865584 0.2337468 #>            GMDL.naive #> Nb_Comp_0   -67.17645 #> Nb_Comp_1   -79.67755 #> Nb_Comp_2   -81.93501 #> Nb_Comp_3   -83.31503 #> Nb_Comp_4   -83.23369 #> Nb_Comp_5   -81.93513 #> Nb_Comp_6   -80.42345 #> Nb_Comp_7   -78.87607 #> Nb_Comp_8   -77.31942 #> Nb_Comp_9   -75.80069 #> Nb_Comp_10  -74.33325 #> attr(,\"computed_nt\") #> [1] 10 #>  #> [[3]] #>                 AIC MissClassed CV_MissClassed      Q2cum_Y LimQ2_Y       Q2_Y #> Nb_Comp_0  154.6179          49             NA           NA      NA         NA #> Nb_Comp_1  126.4083          27             46   -0.1232931  0.0975 -0.1232931 #> Nb_Comp_2  119.3375          25             48   -0.7269344  0.0975 -0.5373854 #> Nb_Comp_3  114.2313          27             45   -2.1064449  0.0975 -0.7988204 #> Nb_Comp_4  112.3463          23             50   -5.5416837  0.0975 -1.1058425 #> Nb_Comp_5  113.2362          22             51  -13.4470511  0.0975 -1.2084607 #> Nb_Comp_6  114.7620          21             50  -31.7742632  0.0975 -1.2685781 #> Nb_Comp_7  116.5264          20             50  -74.0957259  0.0975 -1.2913017 #> Nb_Comp_8  118.4601          20             50 -172.7995657  0.0975 -1.3143736 #> Nb_Comp_9  120.4452          19             51 -402.7194577  0.0975 -1.3229026 #> Nb_Comp_10 122.4395          19             51 -938.6834170  0.0975 -1.3275653 #>             PRESS_Y    RSS_Y      R2_Y  AIC.std  DoF.dof sigmahat.dof   AIC.dof #> Nb_Comp_0        NA 25.91346        NA 298.1344  1.00000    0.5015845 0.2540061 #> Nb_Comp_1  29.10841 19.38086 0.2520929 269.9248 22.55372    0.4848429 0.2883114 #> Nb_Comp_2  29.79585 17.76209 0.3145613 262.8540 27.31542    0.4781670 0.2908950 #> Nb_Comp_3  31.95081 16.58896 0.3598323 257.7478 30.52370    0.4719550 0.2902572 #> Nb_Comp_4  34.93374 15.98071 0.3833049 255.8628 34.00000    0.4744263 0.3008285 #> Nb_Comp_5  35.29276 15.81104 0.3898523 256.7527 34.00000    0.4719012 0.2976347 #> Nb_Comp_6  35.86858 15.73910 0.3926285 258.2785 34.00000    0.4708264 0.2962804 #> Nb_Comp_7  36.06303 15.70350 0.3940024 260.0429 33.71066    0.4693382 0.2937976 #> Nb_Comp_8  36.34376 15.69348 0.3943888 261.9766 34.00000    0.4701436 0.2954217 #> Nb_Comp_9  36.45443 15.69123 0.3944758 263.9617 33.87284    0.4696894 0.2945815 #> Nb_Comp_10 36.52236 15.69037 0.3945088 265.9560 34.00000    0.4700970 0.2953632 #>              BIC.dof  GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive #> Nb_Comp_0  0.2604032 -67.17645         1      0.5015845 0.2540061 0.2604032 #> Nb_Comp_1  0.4231184 -53.56607         2      0.4358996 0.1936625 0.2033251 #> Nb_Comp_2  0.4496983 -52.42272         3      0.4193593 0.1809352 0.1943501 #> Nb_Comp_3  0.4631316 -51.93343         4      0.4072955 0.1722700 0.1891422 #> Nb_Comp_4  0.4954133 -50.37079         5      0.4017727 0.1691819 0.1897041 #> Nb_Comp_5  0.4901536 -50.65724         6      0.4016679 0.1706451 0.1952588 #> Nb_Comp_6  0.4879234 -50.78005         7      0.4028135 0.1731800 0.2020601 #> Nb_Comp_7  0.4826103 -51.05525         8      0.4044479 0.1761610 0.2094352 #> Nb_Comp_8  0.4865092 -50.85833         9      0.4064413 0.1794902 0.2172936 #> Nb_Comp_9  0.4845867 -50.95616        10      0.4085682 0.1829787 0.2254232 #> Nb_Comp_10 0.4864128 -50.86368        11      0.4107477 0.1865584 0.2337468 #>            GMDL.naive #> Nb_Comp_0   -67.17645 #> Nb_Comp_1   -79.67755 #> Nb_Comp_2   -81.93501 #> Nb_Comp_3   -83.31503 #> Nb_Comp_4   -83.23369 #> Nb_Comp_5   -81.93513 #> Nb_Comp_6   -80.42345 #> Nb_Comp_7   -78.87607 #> Nb_Comp_8   -77.31942 #> Nb_Comp_9   -75.80069 #> Nb_Comp_10  -74.33325 #> attr(,\"computed_nt\") #> [1] 10 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\" # }"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisq.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes Predicted Chisquare for k-fold cross-validated partial least squares regression models. — kfolds2Chisq","title":"Computes Predicted Chisquare for k-fold cross-validated partial least squares regression models. — kfolds2Chisq","text":"function computes Predicted Chisquare k-fold cross validated partial least squares regression models.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes Predicted Chisquare for k-fold cross-validated partial least squares regression models. — kfolds2Chisq","text":"","code":"kfolds2Chisq(pls_kfolds)"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes Predicted Chisquare for k-fold cross-validated partial least squares regression models. — kfolds2Chisq","text":"pls_kfolds k-fold cross validated partial least squares regression glm model","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes Predicted Chisquare for k-fold cross-validated partial least squares regression models. — kfolds2Chisq","text":"list Total Predicted Chisquare vs number components first group partition list() ... list Total Predicted Chisquare vs number components last group partition","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisq.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes Predicted Chisquare for k-fold cross-validated partial least squares regression models. — kfolds2Chisq","text":"Use cv.plsRglm create k-fold cross validated partial least squares regression glm models.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisq.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Computes Predicted Chisquare for k-fold cross-validated partial least squares regression models. — kfolds2Chisq","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisq.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Computes Predicted Chisquare for k-fold cross-validated partial least squares regression models. — kfolds2Chisq","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes Predicted Chisquare for k-fold cross-validated partial least squares regression models. — kfolds2Chisq","text":"","code":"# \\donttest{ data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] bbb <- cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele=\"pls-glm-gaussian\",K=16,verbose=FALSE) bbb2 <- cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele=\"pls-glm-gaussian\",K=5,verbose=FALSE) kfolds2Chisq(bbb) #> [[1]] #> [1] 55.70774 24.52966 20.84377 #>  kfolds2Chisq(bbb2) #> [[1]] #> [1] 69.55157 27.20145 26.54985 #>  rm(list=c(\"XCornell\",\"yCornell\",\"bbb\",\"bbb2\"))   data(pine) Xpine<-pine[,1:10] ypine<-pine[,11] bbb <- cv.plsRglm(object=ypine,dataX=Xpine,nt=4,modele=\"pls-glm-gaussian\",verbose=FALSE) bbb2 <- cv.plsRglm(object=ypine,dataX=Xpine,nt=10,modele=\"pls-glm-gaussian\",K=10,verbose=FALSE) kfolds2Chisq(bbb) #> [[1]] #> [1] 12.89898 12.44225 10.44155 10.35581 #>  kfolds2Chisq(bbb2) #> [[1]] #>  [1] 13.55527 12.30310 10.45758 10.94869 11.48481 12.23844 12.10153 11.98165 #>  [9] 12.11042 12.10683 #>                     XpineNAX21 <- Xpine XpineNAX21[1,2] <- NA bbbNA <- cv.plsRglm(object=ypine,dataX=XpineNAX21,nt=10,modele=\"pls\",K=10,verbose=FALSE) kfolds2Press(bbbNA) #> [[1]] #> [1]  14.05196  14.10976  13.88910  11.23984  11.38487  13.36423  20.93071 #> [8]  39.65877 178.10012 #>  kfolds2Chisq(bbbNA) #> [[1]] #> [1]  14.05196  14.10976  13.88910  11.23984  11.38487  13.36423  20.93071 #> [8]  39.65877 178.10012 #>  bbbNA2 <- cv.plsRglm(object=ypine,dataX=XpineNAX21,nt=4,modele=\"pls-glm-gaussian\",verbose=FALSE) bbbNA3 <- cv.plsRglm(object=ypine,dataX=XpineNAX21,nt=10,modele=\"pls-glm-gaussian\",K=10, verbose=FALSE) kfolds2Chisq(bbbNA2) #> [[1]] #> [1] 13.88537 13.76352 10.31822 12.90021 #>  kfolds2Chisq(bbbNA3) #> [[1]] #> [1] 14.193035 13.426074 12.152154 12.708522 12.930586 10.740865  9.980292 #> [8] 10.665961 10.920715 #>  rm(list=c(\"Xpine\",\"XpineNAX21\",\"ypine\",\"bbb\",\"bbb2\",\"bbbNA\",\"bbbNA2\",\"bbbNA3\"))   data(aze_compl) Xaze_compl<-aze_compl[,2:34] yaze_compl<-aze_compl$y kfolds2Chisq(cv.plsRglm(object=yaze_compl,dataX=Xaze_compl,nt=4,modele=\"pls-glm-family\", family=\"binomial\",verbose=FALSE)) #> [[1]] #> [1]   212.6266   367.4410  1786.6113 12084.5509 #>  kfolds2Chisq(cv.plsRglm(object=yaze_compl,dataX=Xaze_compl,nt=4,modele=\"pls-glm-logistic\", verbose=FALSE)) #> [[1]] #> [1]    213.0669   2087.8089  75802.6131 604360.4772 #>  kfolds2Chisq(cv.plsRglm(object=yaze_compl,dataX=Xaze_compl,nt=10,modele=\"pls-glm-family\", family=binomial(),K=10,verbose=FALSE)) #> [[1]] #>  [1]     205.0276     399.5351    5357.1214   19652.8925   22438.1409 #>  [6]   45101.3065   91601.8014  359566.1556  899715.6936 1600524.6150 #>  kfolds2Chisq(cv.plsRglm(object=yaze_compl,dataX=Xaze_compl,nt=10,modele=\"pls-glm-logistic\", K=10,verbose=FALSE)) #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> [[1]] #>  [1] 2.225894e+02 5.840101e+02 1.268689e+04 3.661034e+05 1.466490e+08 #>  [6] 3.505241e+12 4.505082e+15 1.351087e+16 2.251800e+16 2.251800e+16 #>  rm(list=c(\"Xaze_compl\",\"yaze_compl\")) # }"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisqind.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes individual Predicted Chisquare for k-fold cross validated partial least squares regression models. — kfolds2Chisqind","title":"Computes individual Predicted Chisquare for k-fold cross validated partial least squares regression models. — kfolds2Chisqind","text":"function computes individual Predicted Chisquare k-fold cross validated partial least squares regression models.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisqind.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes individual Predicted Chisquare for k-fold cross validated partial least squares regression models. — kfolds2Chisqind","text":"","code":"kfolds2Chisqind(pls_kfolds)"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisqind.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes individual Predicted Chisquare for k-fold cross validated partial least squares regression models. — kfolds2Chisqind","text":"pls_kfolds k-fold cross validated partial least squares regression glm model","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisqind.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes individual Predicted Chisquare for k-fold cross validated partial least squares regression models. — kfolds2Chisqind","text":"list Individual PChisq vs number components first group partition list() ... list Individual PChisq vs number components last group partition","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisqind.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes individual Predicted Chisquare for k-fold cross validated partial least squares regression models. — kfolds2Chisqind","text":"Use cv.plsRglm create k-fold cross validated partial least squares regression glm models.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisqind.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Computes individual Predicted Chisquare for k-fold cross validated partial least squares regression models. — kfolds2Chisqind","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisqind.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Computes individual Predicted Chisquare for k-fold cross validated partial least squares regression models. — kfolds2Chisqind","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Chisqind.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes individual Predicted Chisquare for k-fold cross validated partial least squares regression models. — kfolds2Chisqind","text":"","code":"# \\donttest{ data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] bbb <- cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele=\"pls-glm-gaussian\",K=16,verbose=FALSE) bbb2 <- cv.plsRglm(object=yCornell,dataX=XCornell,nt=3,modele=\"pls-glm-gaussian\",K=5,verbose=FALSE) kfolds2Chisqind(bbb) #> [[1]] #> [[1]][[1]] #>       [,1]    [,2]     [,3] #> 1 24.52456 11.3923 6.837075 #>  #> [[1]][[2]] #>       [,1]        [,2]        [,3] #> 2 4.124502 0.007566232 0.005169207 #>  #> [[1]][[3]] #>       [,1]     [,2]     [,3] #> 3 1.551301 1.917305 1.907019 #>  #> [[1]][[4]] #>       [,1]     [,2]        [,3] #> 4 12.26717 1.278425 0.003572679 #>  #> [[1]][[5]] #>       [,1]     [,2]     [,3] #> 5 4.315406 5.393862 4.249662 #>  #> [[1]][[6]] #>       [,1]     [,2]     [,3] #> 6 6.209332 3.528493 1.696534 #>  #> [[1]][[7]] #>         [,1]     [,2]      [,3] #> 7 0.08812214 0.256731 0.1887149 #>  #> [[1]][[8]] #>        [,1]     [,2]     [,3] #> 8 0.9442012 0.240037 0.359011 #>  #> [[1]][[9]] #>        [,1]       [,2]       [,3] #> 9 0.2203272 0.02253865 0.03724274 #>  #> [[1]][[10]] #>         [,1]       [,2]       [,3] #> 10 0.6034613 0.05144812 0.01893424 #>  #> [[1]][[11]] #>         [,1]      [,2]      [,3] #> 11 0.8275623 0.4409475 0.7467284 #>  #> [[1]][[12]] #>          [,1]         [,2]     [,3] #> 12 0.03180524 1.455262e-05 4.794104 #>  #>  kfolds2Chisqind(bbb2) #> [[1]] #> [[1]][[1]] #> [1] 5.270827 1.511911 1.430687 #>  #> [[1]][[2]] #> [1] 0.6394877 0.4095096 1.0584582 #>  #> [[1]][[3]] #> [1] 26.502867 13.361154  8.250662 #>  #> [[1]][[4]] #> [1] 1.985502 2.149674 2.040927 #>  #> [[1]][[5]] #> [1] 11.849695  2.460984  6.748015 #>  #>  rm(list=c(\"XCornell\",\"yCornell\",\"bbb\",\"bbb2\"))   data(pine) Xpine<-pine[,1:10] ypine<-pine[,11] bbb <- cv.plsRglm(object=ypine,dataX=Xpine,nt=4,modele=\"pls-glm-gaussian\",verbose=FALSE) bbb2 <- cv.plsRglm(object=ypine,dataX=Xpine,nt=10,modele=\"pls-glm-gaussian\",K=10,verbose=FALSE) kfolds2Chisqind(bbb) #> [[1]] #> [[1]][[1]] #> [1] 3.403086 4.775572 4.519409 5.002448 #>  #> [[1]][[2]] #> [1] 1.824134 2.162432 1.596622 1.359406 #>  #> [[1]][[3]] #> [1] 2.587970 1.691074 1.391184 1.443778 #>  #> [[1]][[4]] #> [1] 1.266668 1.572788 1.260169 1.344553 #>  #> [[1]][[5]] #> [1] 3.749667 3.031469 1.618427 1.615485 #>  #>  kfolds2Chisqind(bbb2) #> [[1]] #> [[1]][[1]] #>  [1] 0.8869803 0.8201235 0.7967343 0.7834618 0.7443253 0.7626616 0.6772168 #>  [8] 0.6074659 0.6187567 0.6415269 #>  #> [[1]][[2]] #>  [1] 4.727405 4.636497 4.341603 4.546572 4.759693 5.077514 5.229127 5.471423 #>  [9] 5.487885 5.488157 #>  #> [[1]][[3]] #>  [1] 1.077921 1.151543 1.204886 1.550415 1.729665 1.970757 1.940021 2.001377 #>  [9] 2.000931 1.989826 #>  #> [[1]][[4]] #>  [1] 1.5252320 1.1816437 0.3847527 0.3050577 0.2951873 0.2509198 0.3295281 #>  [8] 0.3587540 0.3784665 0.3785523 #>  #> [[1]][[5]] #>  [1] 0.650217 1.536378 1.535037 1.563574 1.454718 1.198908 1.244873 1.296059 #>  [9] 1.271407 1.272678 #>  #> [[1]][[6]] #>  [1] 0.5208920 0.1635685 0.2768095 0.3350192 0.4934330 0.4361214 0.4658536 #>  [8] 0.4806951 0.4824459 0.4827584 #>  #> [[1]][[7]] #>  [1] 0.006366112 1.201509729 0.769069823 0.770990708 0.805811006 0.908296996 #>  [7] 0.883070758 0.858064121 0.854869289 0.854843256 #>  #> [[1]][[8]] #>  [1] 0.05687795 0.16551094 0.37338030 0.32373596 0.30780311 0.17014380 #>  [7] 0.16251227 0.17074300 0.17904736 0.17889468 #>  #> [[1]][[9]] #>  [1] 2.514685 1.264220 1.034154 1.011181 1.009631 1.368947 1.651633 1.731609 #>  [9] 1.770509 1.760526 #>  #> [[1]][[10]] #>  [1] 1.0707442 0.3930249 0.2207084 0.5900025 0.9509311 0.7454288 0.7667870 #>  [8] 0.7697079 0.7585861 0.7579902 #>  #>                     XpineNAX21 <- Xpine XpineNAX21[1,2] <- NA bbbNA <- cv.plsRglm(object=ypine,dataX=XpineNAX21,nt=10,modele=\"pls\",K=10,verbose=FALSE) kfolds2Pressind(bbbNA) #> [[1]] #> [[1]][[1]] #> [1] 3.641936 2.715888 2.815467 1.642285 1.704489 1.733388 1.742250 1.746528 #> [9] 1.703715 #>  #> [[1]][[2]] #> [1] 0.2565236 0.5619357 0.6086918 0.5428673 0.5498746 0.6248340 0.8229439 #> [8] 0.8311556 0.9891515 #>  #> [[1]][[3]] #> [1] 1.9831732 2.8387181 2.8462283 1.4337590 1.2091250 0.9997404 1.2264522 #> [8] 1.2905409 1.4198860 #>  #> [[1]][[4]] #> [1] 2.791337 2.883241 2.413335 2.479880 2.666350 2.654463 2.730224 2.694283 #> [9] 2.493838 #>  #> [[1]][[5]] #> [1]  1.392256  1.558197  1.293175  0.928126  1.770689  3.311278  4.164474 #> [8] 18.322802 19.378881 #>  #> [[1]][[6]] #> [1] 0.6020566 0.2924178 0.2213609 0.2406571 0.4891932 0.4846383 0.5742382 #> [8] 0.5750435 0.7232366 #>  #> [[1]][[7]] #> [1] 0.6683048 1.3658249 1.8962920 0.8775053 0.8153458 0.7861862 0.3650173 #> [8] 0.3374038 1.0031900 #>  #> [[1]][[8]] #> [1] 0.9329137 0.6598429 0.3628448 0.4212905 0.4961495 0.7362372 0.8537199 #> [8] 0.8657835 0.8664770 #>  #> [[1]][[9]] #> [1] 0.5409445 0.8358791 0.5884406 0.5631689 0.5332073 0.4849964 0.3831118 #> [8] 0.3429699 0.4277211 #>  #> [[1]][[10]] #> [1] 0.6720491 0.9014411 1.2582868 1.4982960 1.3938938 1.4452417 1.4827895 #> [8] 1.4351993 1.5402511 #>  #>  kfolds2Chisqind(bbbNA) #> [[1]] #> [[1]][[1]] #> [1] 3.641936 2.715888 2.815467 1.642285 1.704489 1.733388 1.742250 1.746528 #> [9] 1.703715 #>  #> [[1]][[2]] #> [1] 0.2565236 0.5619357 0.6086918 0.5428673 0.5498746 0.6248340 0.8229439 #> [8] 0.8311556 0.9891515 #>  #> [[1]][[3]] #> [1] 1.9831732 2.8387181 2.8462283 1.4337590 1.2091250 0.9997404 1.2264522 #> [8] 1.2905409 1.4198860 #>  #> [[1]][[4]] #> [1] 2.791337 2.883241 2.413335 2.479880 2.666350 2.654463 2.730224 2.694283 #> [9] 2.493838 #>  #> [[1]][[5]] #> [1]  1.392256  1.558197  1.293175  0.928126  1.770689  3.311278  4.164474 #> [8] 18.322802 19.378881 #>  #> [[1]][[6]] #> [1] 0.6020566 0.2924178 0.2213609 0.2406571 0.4891932 0.4846383 0.5742382 #> [8] 0.5750435 0.7232366 #>  #> [[1]][[7]] #> [1] 0.6683048 1.3658249 1.8962920 0.8775053 0.8153458 0.7861862 0.3650173 #> [8] 0.3374038 1.0031900 #>  #> [[1]][[8]] #> [1] 0.9329137 0.6598429 0.3628448 0.4212905 0.4961495 0.7362372 0.8537199 #> [8] 0.8657835 0.8664770 #>  #> [[1]][[9]] #> [1] 0.5409445 0.8358791 0.5884406 0.5631689 0.5332073 0.4849964 0.3831118 #> [8] 0.3429699 0.4277211 #>  #> [[1]][[10]] #> [1] 0.6720491 0.9014411 1.2582868 1.4982960 1.3938938 1.4452417 1.4827895 #> [8] 1.4351993 1.5402511 #>  #>  bbbNA2 <- cv.plsRglm(object=ypine,dataX=XpineNAX21,nt=4,modele=\"pls-glm-gaussian\",verbose=FALSE) bbbNA3 <- cv.plsRglm(object=ypine,dataX=XpineNAX21,nt=10,modele=\"pls-glm-gaussian\", K=10,verbose=FALSE) kfolds2Chisqind(bbbNA2) #> [[1]] #> [[1]][[1]] #> [1] 5.091976 5.668531 7.992906 8.948263 #>  #> [[1]][[2]] #> [1] 2.312984 1.441495 1.488056 1.738745 #>  #> [[1]][[3]] #> [1] 1.553196 2.551305 2.206062 2.006054 #>  #> [[1]][[4]] #> [1] 3.749187 3.766897 3.202139 3.041355 #>  #> [[1]][[5]] #> [1] 0.7240605 4.1309348 3.9388575 4.4043879 #>  #>  kfolds2Chisqind(bbbNA3) #> [[1]] #> [[1]][[1]] #> [1] 1.1794345 1.1577211 0.5312897 0.7023919 0.9409709 1.1335568 1.5944448 #> [8] 1.0753626 1.0515777 #>  #> [[1]][[2]] #> [1] 1.0068477 0.5015760 0.2035914 0.6133291 0.9741998 1.2965126 1.4742455 #> [8] 1.6903695 0.8815662 #>  #> [[1]][[3]] #> [1] 1.872407 3.523068 2.687198 4.599433 5.535495 6.715902 6.318444 3.070310 #> [9] 4.747822 #>  #> [[1]][[4]] #> [1] 2.680572 1.515843 1.609055 1.487503 1.489059 1.568317 1.673913 1.541438 #> [9] 1.695382 #>  #> [[1]][[5]] #> [1] 0.9831575 1.0232133 0.9547098 0.8725859 0.9718035 0.9406500 0.9357887 #> [8] 0.9024237 1.0029078 #>  #> [[1]][[6]] #> [1] 0.7022996 1.1960171 0.9894453 0.9033905 0.9318882 1.0201916 1.1004181 #> [8] 1.1643403 1.2396577 #>  #> [[1]][[7]] #> [1] 2.893779 2.984157 2.908782 2.823959 2.736246 2.848856 2.692257 2.665015 #> [9] 2.664210 #>  #> [[1]][[8]] #> [1] 0.1939123 0.3389540 0.2573845 0.3813121 0.4585366 0.3817952 0.5314726 #> [8] 0.6209207 0.7590313 #>  #> [[1]][[9]] #> [1] 0.3042696 0.1721206 0.3637156 0.3045094 0.3176336 0.2976240 0.2469196 #> [8] 0.2111337 0.1470695 #>  #> [[1]][[10]] #> [1] 0.9630187 0.8365556 0.5605143 0.5959843 0.4754921 0.4567590 0.5664468 #> [8] 0.6122550 0.6728351 #>  #>  rm(list=c(\"Xpine\",\"XpineNAX21\",\"ypine\",\"bbb\",\"bbb2\",\"bbbNA\",\"bbbNA2\",\"bbbNA3\"))   data(aze_compl) Xaze_compl<-aze_compl[,2:34] yaze_compl<-aze_compl$y kfolds2Chisqind(cv.plsRglm(object=yaze_compl,dataX=Xaze_compl,nt=4,modele=\"pls-glm-family\", family=binomial(),verbose=FALSE)) #> [[1]] #> [[1]][[1]] #> [1] 26.90170 36.40484 38.51725 38.87166 #>  #> [[1]][[2]] #> [1]   32.61727   62.73811  148.57031 2226.98288 #>  #> [[1]][[3]] #> [1]  26.01683  95.75682 614.09120 759.75406 #>  #> [[1]][[4]] #> [1]   52.94904  114.88423  989.88793 4112.44160 #>  #> [[1]][[5]] #> [1]  29.93034  34.08810  53.25737 113.07159 #>  #>  kfolds2Chisqind(cv.plsRglm(object=yaze_compl,dataX=Xaze_compl,nt=4,modele=\"pls-glm-logistic\", verbose=FALSE)) #> [[1]] #> [[1]][[1]] #> [1]  47.59640  80.94215 113.33396 183.61306 #>  #> [[1]][[2]] #> [1]  74.79705 207.64307 335.03829 752.79300 #>  #> [[1]][[3]] #> [1]   47.09273   74.93908  266.56083 1377.30320 #>  #> [[1]][[4]] #> [1]  31.73475  54.16956  93.65354 133.03732 #>  #> [[1]][[5]] #> [1]  26.46269  47.19208  98.07683 167.21246 #>  #>  kfolds2Chisqind(cv.plsRglm(object=yaze_compl,dataX=Xaze_compl,nt=10,modele=\"pls-glm-family\", family=binomial(),K=10,verbose=FALSE)) #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> [[1]] #> [[1]][[1]] #>  [1]  30.37905 131.61933 295.07586 449.43316 465.95404 622.34039 594.66732 #>  [8] 552.40620 541.41116 461.34886 #>  #> [[1]][[2]] #>  [1] 12.54716 14.91610 24.01796 31.44286 28.58675 31.12905 30.44918 30.91007 #>  [9] 30.29058 32.20295 #>  #> [[1]][[3]] #>  [1]  19.25542  30.38544  37.77202 128.59382 150.09659 243.47865 413.22428 #>  [8] 642.23408 700.38212 741.01251 #>  #> [[1]][[4]] #>  [1] 4.490421e+01 1.732139e+02 1.051098e+04 6.309520e+05 9.187609e+06 #>  [6] 1.949896e+09 4.503771e+15 9.010711e+15 1.801494e+16 2.251800e+16 #>  #> [[1]][[5]] #>  [1] 16.966171  7.672902  9.012394 11.454132 11.474949 14.098260 14.840711 #>  [8] 14.254955 13.197875 12.721494 #>  #> [[1]][[6]] #>  [1]  7.444570  6.333452  8.840397 10.865892 15.210250 16.900480 21.882404 #>  [8] 27.511089 27.772383 28.208200 #>  #> [[1]][[7]] #>  [1]  12.57589  15.83949  31.31110 123.82153 135.82582 122.53225  96.60512 #>  [8]  75.62408  88.89131  99.92953 #>  #> [[1]][[8]] #>  [1]  36.78350  58.18266 124.57593 241.31382 404.07471 501.45468 515.44248 #>  [8] 504.49675 437.32656 388.22272 #>  #> [[1]][[9]] #>  [1]   9.679721  13.718786  15.340246  27.822643  49.031872  78.163101 #>  [7] 152.973442 264.490718 300.856504 253.825429 #>  #> [[1]][[10]] #>  [1]  23.52748  35.34624  53.95292 112.67853 182.33070 201.99742 217.28400 #>  [8] 287.72665 298.27349 288.38705 #>  #>  kfolds2Chisqind(cv.plsRglm(object=yaze_compl,dataX=Xaze_compl,nt=10, modele=\"pls-glm-logistic\",K=10,verbose=FALSE)) #> [[1]] #> [[1]][[1]] #>  [1] 17.16111 20.54780 42.96324 50.41764 67.83271 72.45856 87.38555 86.40900 #>  [9] 93.93810 92.43602 #>  #> [[1]][[2]] #>  [1] 17.488320 10.097871  8.616709 15.236710 22.035719 26.949970 25.709833 #>  [8] 27.980402 27.834312 27.664695 #>  #> [[1]][[3]] #>  [1]   9.314635  10.629045  24.802254  47.837962  66.721316 107.068433 #>  [7] 124.279462 134.636647 138.991686 137.468731 #>  #> [[1]][[4]] #>  [1]    81.06815   210.21352  3665.07542 19566.78091 33527.51517 32555.33438 #>  [7] 53366.06399 47213.13269 64700.19582 68795.91094 #>  #> [[1]][[5]] #>  [1]  23.37379  50.96192 367.69449 344.31163 401.72190 504.27506 762.19446 #>  [8] 810.07412 668.38914 617.19564 #>  #> [[1]][[6]] #>  [1]  22.49615  33.89744  60.19610 149.92402 187.79812 217.12727 224.88363 #>  [8] 214.55649 211.12614 227.56614 #>  #> [[1]][[7]] #>  [1] 16.26003 19.50735 21.72989 20.71220 20.25186 17.73315 20.04467 27.39599 #>  [9] 26.88810 26.90085 #>  #> [[1]][[8]] #>  [1]  12.09134  13.00128  21.37000  29.14232  30.79322  54.11291  79.85591 #>  [8] 159.90995 162.14637 169.92531 #>  #> [[1]][[9]] #>  [1] 25.68953 40.57266 39.28939 91.36514 87.23446 80.54601 80.31430 88.24899 #>  [9] 90.94341 89.85898 #>  #> [[1]][[10]] #>  [1]   16.42260   36.44474   73.14231  290.03249  575.97750 1119.96831 #>  [7] 1669.19671 1947.92863 1990.44154 1704.00586 #>  #>  rm(list=c(\"Xaze_compl\",\"yaze_compl\")) # }"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassed.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of missclassified individuals for k-fold cross validated partial least squares regression models. — kfolds2Mclassed","title":"Number of missclassified individuals for k-fold cross validated partial least squares regression models. — kfolds2Mclassed","text":"function indicates total number missclassified individuals k-fold cross validated partial least squares regression models.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of missclassified individuals for k-fold cross validated partial least squares regression models. — kfolds2Mclassed","text":"","code":"kfolds2Mclassed(pls_kfolds)"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of missclassified individuals for k-fold cross validated partial least squares regression models. — kfolds2Mclassed","text":"pls_kfolds k-fold cross validated partial least squares regression model used binary data","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number of missclassified individuals for k-fold cross validated partial least squares regression models. — kfolds2Mclassed","text":"list Total number missclassified individuals vs number components first group partition list() ... list Total number missclassified individuals vs number components last group partition","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassed.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Number of missclassified individuals for k-fold cross validated partial least squares regression models. — kfolds2Mclassed","text":"Use cv.plsR create k-fold cross validated partial least squares regression models.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassed.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Number of missclassified individuals for k-fold cross validated partial least squares regression models. — kfolds2Mclassed","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassed.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Number of missclassified individuals for k-fold cross validated partial least squares regression models. — kfolds2Mclassed","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Number of missclassified individuals for k-fold cross validated partial least squares regression models. — kfolds2Mclassed","text":"","code":"# \\donttest{ data(aze_compl) Xaze_compl<-aze_compl[,2:34] yaze_compl<-aze_compl$y kfolds2Mclassed(cv.plsR(object=yaze_compl,dataX=Xaze_compl,nt=10,K=8,NK=1,verbose=FALSE)) #> [[1]] #>  [1] 44 48 41 39 39 39 39 38 38 38 #>  kfolds2Mclassed(cv.plsR(object=yaze_compl,dataX=Xaze_compl,nt=10,K=8,NK=2,verbose=FALSE)) #> [[1]] #>  [1] 49 46 41 45 44 45 44 46 46 46 #>  #> [[2]] #>  [1] 49 48 48 50 48 49 50 52 51 51 #>  rm(list=c(\"Xaze_compl\",\"yaze_compl\")) # }"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassedind.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of missclassified individuals per group for k-fold cross validated partial least squares regression models. — kfolds2Mclassedind","title":"Number of missclassified individuals per group for k-fold cross validated partial least squares regression models. — kfolds2Mclassedind","text":"function indicates number missclassified individuals per group k-fold cross validated partial least squares regression models.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassedind.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of missclassified individuals per group for k-fold cross validated partial least squares regression models. — kfolds2Mclassedind","text":"","code":"kfolds2Mclassedind(pls_kfolds)"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassedind.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of missclassified individuals per group for k-fold cross validated partial least squares regression models. — kfolds2Mclassedind","text":"pls_kfolds k-fold cross validated partial least squares regression model used binary data","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassedind.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number of missclassified individuals per group for k-fold cross validated partial least squares regression models. — kfolds2Mclassedind","text":"list Number missclassified individuals per group vs number components first group partition list() ... list Number missclassified individuals per group vs number components last group partition","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassedind.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Number of missclassified individuals per group for k-fold cross validated partial least squares regression models. — kfolds2Mclassedind","text":"Use cv.plsR cv.plsRglm create k-fold cross validated partial least squares regression models generalized linear ones.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassedind.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Number of missclassified individuals per group for k-fold cross validated partial least squares regression models. — kfolds2Mclassedind","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassedind.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Number of missclassified individuals per group for k-fold cross validated partial least squares regression models. — kfolds2Mclassedind","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Mclassedind.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Number of missclassified individuals per group for k-fold cross validated partial least squares regression models. — kfolds2Mclassedind","text":"","code":"# \\donttest{ data(aze_compl) Xaze_compl<-aze_compl[,2:34] yaze_compl<-aze_compl$y kfolds2Mclassedind(cv.plsR(object=yaze_compl,dataX=Xaze_compl,nt=10,K=8,NK=1,verbose=FALSE)) #> [[1]] #> [[1]][[1]] #>  [1] 8 9 7 7 7 8 8 8 8 8 #>  #> [[1]][[2]] #>  [1] 5 4 4 4 5 4 4 4 4 4 #>  #> [[1]][[3]] #>  [1] 4 4 4 4 4 5 5 5 4 4 #>  #> [[1]][[4]] #>  [1] 7 6 6 7 6 6 6 6 6 6 #>  #> [[1]][[5]] #>  [1] 4 2 4 4 5 4 4 5 5 5 #>  #> [[1]][[6]] #>  [1] 7 7 7 7 7 7 6 6 6 6 #>  #> [[1]][[7]] #>  [1] 7 6 8 8 7 7 6 6 6 6 #>  #> [[1]][[8]] #>  [1] 5 4 4 5 5 5 5 5 5 5 #>  #>  kfolds2Mclassedind(cv.plsR(object=yaze_compl,dataX=Xaze_compl,nt=10,K=8,NK=2,verbose=FALSE)) #> [[1]] #> [[1]][[1]] #>  [1] 6 6 6 6 7 7 7 7 7 7 #>  #> [[1]][[2]] #>  [1] 7 8 7 5 5 5 5 5 5 5 #>  #> [[1]][[3]] #>  [1] 5 6 6 5 5 5 5 5 5 5 #>  #> [[1]][[4]] #>  [1] 3 1 2 2 2 3 3 3 3 3 #>  #> [[1]][[5]] #>  [1] 5 6 6 6 6 6 6 6 6 6 #>  #> [[1]][[6]] #>  [1] 8 8 6 6 8 7 7 7 7 7 #>  #> [[1]][[7]] #>  [1] 9 9 9 8 7 8 8 7 7 7 #>  #> [[1]][[8]] #>  [1] 9 9 7 7 7 8 7 7 7 7 #>  #>  #> [[2]] #> [[2]][[1]] #>  [1] 7 7 5 6 6 6 5 5 5 5 #>  #> [[2]][[2]] #>  [1] 5 5 3 3 3 3 3 3 3 3 #>  #> [[2]][[3]] #>  [1] 3 3 3 3 3 3 3 3 3 3 #>  #> [[2]][[4]] #>  [1] 7 6 7 7 7 7 7 7 7 8 #>  #> [[2]][[5]] #>  [1] 6 6 6 6 6 6 6 6 6 6 #>  #> [[2]][[6]] #>  [1] 7 6 5 4 4 4 4 4 4 4 #>  #> [[2]][[7]] #>  [1] 4 6 8 7 7 7 6 6 6 6 #>  #> [[2]][[8]] #>  [1] 8 7 7 8 7 7 8 8 8 8 #>  #>  rm(list=c(\"Xaze_compl\",\"yaze_compl\")) # }"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Press.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes PRESS for k-fold cross validated partial least squares regression models. — kfolds2Press","title":"Computes PRESS for k-fold cross validated partial least squares regression models. — kfolds2Press","text":"function computes PRESS k-fold cross validated partial least squares regression models.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Press.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes PRESS for k-fold cross validated partial least squares regression models. — kfolds2Press","text":"","code":"kfolds2Press(pls_kfolds)"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Press.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes PRESS for k-fold cross validated partial least squares regression models. — kfolds2Press","text":"pls_kfolds k-fold cross validated partial least squares regression model","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Press.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes PRESS for k-fold cross validated partial least squares regression models. — kfolds2Press","text":"list Press vs number components first group partition list() ... list Press vs number components last group partition","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Press.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes PRESS for k-fold cross validated partial least squares regression models. — kfolds2Press","text":"Use cv.plsR create k-fold cross validated partial least squares regression models.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Press.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Computes PRESS for k-fold cross validated partial least squares regression models. — kfolds2Press","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Press.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Computes PRESS for k-fold cross validated partial least squares regression models. — kfolds2Press","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Press.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes PRESS for k-fold cross validated partial least squares regression models. — kfolds2Press","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] kfolds2Press(cv.plsR(object=yCornell,dataX=data.frame(scale(as.matrix(XCornell))[,]), nt=6,K=12,NK=1,verbose=FALSE)) #> [[1]] #> [1] 55.70774 41.43274 20.27397 21.24240 24.51801 #>  kfolds2Press(cv.plsR(object=yCornell,dataX=data.frame(scale(as.matrix(XCornell))[,]), nt=6,K=6,NK=1,verbose=FALSE)) #> [[1]] #> [1] 60.67384 37.44834 17.35983 25.14694 26.97979 #>  rm(list=c(\"XCornell\",\"yCornell\"))  # \\donttest{ data(pine) Xpine<-pine[,1:10] ypine<-pine[,11] kfolds2Press(cv.plsR(object=ypine,dataX=Xpine,nt=10,NK=1,verbose=FALSE)) #> [[1]] #>  [1] 13.11383 16.07115 16.80484 16.01002 15.72696 16.01078 16.72261 16.89642 #>  [9] 16.85360 17.47502 #>  kfolds2Press(cv.plsR(object=ypine,dataX=Xpine,nt=10,NK=2,verbose=FALSE)) #> [[1]] #>  [1] 14.34299 13.86224 14.29954 13.07896 13.11752 13.26533 14.52682 15.94571 #>  [9] 16.40371 16.99492 #>  #> [[2]] #>  [1] 15.67525 15.99173 18.33649 17.94999 16.68851 15.81142 16.55737 17.36604 #>  [9] 18.05244 18.14532 #>   XpineNAX21 <- Xpine XpineNAX21[1,2] <- NA kfolds2Press(cv.plsR(object=ypine,dataX=XpineNAX21,nt=10,NK=1,verbose=FALSE)) #> [[1]] #> [1] 14.27440 14.75048 16.91953 15.77344 16.32399 16.01672 18.12347 21.36587 #> [9] 19.93249 #>  kfolds2Press(cv.plsR(object=ypine,dataX=XpineNAX21,nt=10,NK=2,verbose=FALSE)) #> [[1]] #> [1] 15.98650 15.70826 14.85051 13.35485 21.30392 29.71824 21.93329 18.27147 #> [9] 18.92796 #>  #> [[2]] #> [1] 14.58396 15.69717 25.24154 14.46923 21.63037 12.84356 12.93730 28.12907 #> [9] 19.54269 #>  rm(list=c(\"Xpine\",\"XpineNAX21\",\"ypine\")) # }"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Pressind.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes individual PRESS for k-fold cross validated partial least squares regression models. — kfolds2Pressind","title":"Computes individual PRESS for k-fold cross validated partial least squares regression models. — kfolds2Pressind","text":"function computes individual PRESS k-fold cross validated partial least squares regression models.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Pressind.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes individual PRESS for k-fold cross validated partial least squares regression models. — kfolds2Pressind","text":"","code":"kfolds2Pressind(pls_kfolds)"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Pressind.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes individual PRESS for k-fold cross validated partial least squares regression models. — kfolds2Pressind","text":"pls_kfolds k-fold cross validated partial least squares regression model","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Pressind.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes individual PRESS for k-fold cross validated partial least squares regression models. — kfolds2Pressind","text":"list Individual Press vs number components first group partition list() ... list Individual Press vs number components last group partition","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Pressind.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes individual PRESS for k-fold cross validated partial least squares regression models. — kfolds2Pressind","text":"Use cv.plsR create k-fold cross validated partial least squares regression models.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Pressind.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Computes individual PRESS for k-fold cross validated partial least squares regression models. — kfolds2Pressind","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Pressind.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Computes individual PRESS for k-fold cross validated partial least squares regression models. — kfolds2Pressind","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2Pressind.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes individual PRESS for k-fold cross validated partial least squares regression models. — kfolds2Pressind","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] kfolds2Pressind(cv.plsR(object=yCornell,dataX=data.frame(scale(as.matrix(XCornell))[,]), nt=6,K=12,NK=1)) #> NK: 1  #> Leave One Out #> Number of groups : 12  #> 1  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 6  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 7  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 8  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 9  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 10  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 11  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 5 components could thus be extracted #> ****________________________________________________**** #>  #> 12  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> [[1]] #> [[1]][[1]] #>       [,1]     [,2]     [,3]     [,4]     [,5]     [,6] #> 1 24.52456 19.46751 9.132702 6.212796 6.260403 6.294375 #>  #> [[1]][[2]] #>       [,1]      [,2]      [,3]      [,4]     [,5]      [,6] #> 2 4.124502 0.6664187 0.4453306 0.0288125 0.468846 0.6001117 #>  #> [[1]][[3]] #>       [,1]      [,2]     [,3]     [,4]     [,5]     [,6] #> 3 1.551301 0.9608429 1.224441 2.534867 1.991568 5.504755 #>  #> [[1]][[4]] #>       [,1]     [,2]        [,3]     [,4]       [,5]       [,6] #> 4 12.26717 0.247437 0.001516247 0.111019 0.06429773 0.05142279 #>  #> [[1]][[5]] #>       [,1]     [,2]     [,3]     [,4]     [,5]    [,6] #> 5 4.315406 9.872769 2.420394 4.187705 8.869722 8.95432 #>  #> [[1]][[6]] #>       [,1]     [,2]     [,3]     [,4]     [,5]     [,6] #> 6 6.209332 5.820357 3.366519 1.798485 0.950924 1.959007 #>  #> [[1]][[7]] #>         [,1]      [,2]      [,3]      [,4]       [,5]        [,6] #> 7 0.08812214 0.4818875 0.2496785 0.2425807 0.00951357 0.008071516 #>  #> [[1]][[8]] #>        [,1]      [,2]      [,3]     [,4]     [,5]      [,6] #> 8 0.9442012 0.5163166 0.4084427 0.351376 0.248757 0.2347731 #>  #> [[1]][[9]] #>        [,1]       [,2]       [,3]       [,4]      [,5]      [,6] #> 9 0.2203272 0.01149677 0.02486984 0.02827224 0.1233742 0.1658223 #>  #> [[1]][[10]] #>         [,1]         [,2]        [,3]       [,4]        [,5]       [,6] #> 10 0.6034613 0.0005521844 0.006299065 0.01764824 0.006014414 0.02841849 #>  #> [[1]][[11]] #>         [,1]       [,2]      [,3]      [,4]       [,5] #> 11 0.8275623 0.01285346 0.6440788 0.7149959 0.06577128 #>  #> [[1]][[12]] #>          [,1]     [,2]     [,3]     [,4]     [,5]    [,6] #> 12 0.03180524 3.374303 2.349701 5.013846 5.458814 8.13772 #>  #>  kfolds2Pressind(cv.plsR(object=yCornell,dataX=data.frame(scale(as.matrix(XCornell))[,]), nt=6,K=6,NK=1)) #> NK: 1  #> Number of groups : 6  #> 1  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 5 components could thus be extracted #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 6  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> [[1]] #> [[1]][[1]] #> [1] 4.880619 9.479174 4.198758 5.262137 9.681688 9.669555 #>  #> [[1]][[2]] #> [1] 24.808710 17.584379  9.111413  6.206053  6.259251  6.317143 #>  #> [[1]][[3]] #> [1] 0.83738525 0.65811917 0.60483914 0.63522265 0.07106985 #>  #> [[1]][[4]] #> [1] 12.882761 49.116623 38.311814  9.663014 22.578142 71.849877 #>  #> [[1]][[5]] #> [1]  4.597799  5.142740  4.371768  6.750691  5.412892 11.637487 #>  #> [[1]][[6]] #> [1] 1.661627 1.018517 1.303515 2.536627 1.900569 5.465581 #>  #>  rm(list=c(\"XCornell\",\"yCornell\"))  # \\donttest{ data(pine) Xpine<-pine[,1:10] ypine<-pine[,11] kfolds2Pressind(cv.plsR(object=ypine,dataX=Xpine,nt=10,NK=1,verbose=FALSE)) #> [[1]] #> [[1]][[1]] #>  [1] 2.342151 2.218636 2.126248 1.684389 1.563846 1.552798 1.473877 1.538851 #>  [9] 1.525891 1.545314 #>  #> [[1]][[2]] #>  [1] 5.199456 4.118474 3.850497 3.391300 3.644524 3.596471 3.566044 3.917529 #>  [9] 4.128891 4.191982 #>  #> [[1]][[3]] #>  [1] 1.752371 2.098495 2.594762 2.899234 2.490813 2.347570 2.304964 2.302503 #>  [9] 2.242565 2.237447 #>  #> [[1]][[4]] #>  [1] 0.7826082 3.6071430 3.6587396 4.7975991 4.7680548 4.7571587 4.7413192 #>  [8] 5.2665608 5.4529557 5.7367919 #>  #> [[1]][[5]] #>  [1] 3.696523 3.064659 2.374765 1.813269 2.150099 2.110946 1.973100 2.261847 #>  [9] 2.136085 2.198083 #>  #>  kfolds2Pressind(cv.plsR(object=ypine,dataX=Xpine,nt=10,NK=2,verbose=FALSE)) #> [[1]] #> [[1]][[1]] #>  [1] 2.275282 2.987106 3.437917 3.851224 3.423336 3.708752 3.813981 3.943732 #>  [9] 4.190839 4.252629 #>  #> [[1]][[2]] #>  [1] 1.956497 2.214037 2.660120 3.371085 3.605217 3.673265 3.830250 3.915479 #>  [9] 3.948725 3.918604 #>  #> [[1]][[3]] #>  [1] 3.737994 4.596768 4.043005 3.756683 3.494852 3.374156 3.551765 3.511339 #>  [9] 3.564252 3.600758 #>  #> [[1]][[4]] #>  [1] 4.145755 2.915002 3.224384 2.447451 2.450237 2.332576 2.605988 2.706925 #>  [9] 2.658907 2.805306 #>  #> [[1]][[5]] #>  [1] 0.4199873 0.5516132 0.9560758 0.7934037 0.5865402 0.4701086 0.4837466 #>  [8] 0.5320106 0.8890206 0.9157411 #>  #>  #> [[2]] #> [[2]][[1]] #>  [1] 3.411202 2.822411 3.513383 2.875797 2.634304 2.455586 2.429512 2.330214 #>  [9] 2.440069 2.538443 #>  #> [[2]][[2]] #>  [1] 1.682559 1.479959 1.786883 1.837744 1.825986 2.235630 3.631814 3.791986 #>  [9] 4.814206 5.242127 #>  #> [[2]][[3]] #>  [1] 3.494780 3.703488 2.195711 1.998145 1.867244 1.803017 1.528848 1.609933 #>  [9] 1.559220 1.573920 #>  #> [[2]][[4]] #>  [1] 1.761601 1.767602 1.891638 1.550560 1.270254 1.369555 1.332052 1.382803 #>  [9] 1.345839 1.391600 #>  #> [[2]][[5]] #>  [1] 3.171187 3.778985 3.175236 3.843570 4.067677 4.060807 4.031779 3.983545 #>  [9] 3.957146 3.947849 #>  #>   XpineNAX21 <- Xpine XpineNAX21[1,2] <- NA kfolds2Pressind(cv.plsR(object=ypine,dataX=XpineNAX21,nt=10,NK=1,verbose=FALSE)) #> [[1]] #> [[1]][[1]] #> [1] 3.849149 5.752942 2.735378 3.984203 2.459746 2.942909 5.273890 6.473331 #> [9] 6.539830 #>  #> [[1]][[2]] #> [1] 0.7393361 1.1071199 0.4127204 0.3853208 0.4306980 0.3629602 0.4710221 #> [8] 0.4896732 0.5083137 #>  #> [[1]][[3]] #> [1] 2.248253 2.944479 3.254695 2.641474 3.191958 3.250845 3.311406 3.447073 #> [9] 3.575448 #>  #> [[1]][[4]] #> [1] 5.498725 5.122205 3.880136 4.177558 4.348146 4.098910 4.201643 4.223440 #> [9] 4.061385 #>  #> [[1]][[5]] #> [1] 1.636114 1.853155 2.760082 1.872755 1.617061 1.648602 1.753168 1.690348 #> [9] 1.262019 #>  #>  kfolds2Pressind(cv.plsR(object=ypine,dataX=XpineNAX21,nt=10,NK=2,verbose=FALSE)) #> [[1]] #> [[1]][[1]] #> [1] 1.297974 1.530903 1.536840 1.041452 1.052710 1.173904 1.465349 1.681633 #> [9] 2.027705 #>  #> [[1]][[2]] #> [1] 1.943300 1.823133 2.085198 2.145016 2.078058 1.824871 1.707368 1.624454 #> [9] 1.613452 #>  #> [[1]][[3]] #> [1] 2.8807131 2.2204980 3.3987872 4.9532763 2.6831597 1.3558769 0.7035967 #> [8] 1.2092064 0.7011148 #>  #> [[1]][[4]] #> [1] 3.558262 4.040055 3.226564 3.521774 3.586731 3.746520 4.204176 4.065597 #> [9] 4.001694 #>  #> [[1]][[5]] #> [1] 3.096450 2.857964 3.015091 2.883974 3.068952 3.035802 2.942332 2.988776 #> [9] 3.380554 #>  #>  #> [[2]] #> [[2]][[1]] #> [1] 0.9685304 0.9122828 0.7885177 1.3065461 1.8234641 1.7404674 2.1599134 #> [8] 1.9837580 2.2375557 #>  #> [[2]][[2]] #> [1] 7.470791 6.871658 6.817698 6.124524 5.937033 5.539184 5.618064 5.927220 #> [9] 5.872932 #>  #> [[2]][[3]] #> [1] 2.594546 2.896596 4.605220 3.139865 4.419324 6.461079 5.035024 6.683542 #> [9] 4.720656 #>  #> [[2]][[4]] #> [1] 1.201038 1.909526 1.839511 1.962370 1.914030 2.190047 2.958085 2.983242 #> [9] 4.161789 #>  #> [[2]][[5]] #> [1] 1.2355768 1.7140491 2.3410282 1.3111511 1.2945952 1.2548052 1.0631360 #> [8] 0.9455445 1.2175567 #>  #>  rm(list=c(\"Xpine\",\"XpineNAX21\",\"ypine\")) # }"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2coeff.html","id":null,"dir":"Reference","previous_headings":"","what":"Extracts coefficients from k-fold cross validated partial least squares regression models — kfolds2coeff","title":"Extracts coefficients from k-fold cross validated partial least squares regression models — kfolds2coeff","text":"fonction extracts coefficients k-fold cross validated partial least squares regression models","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2coeff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extracts coefficients from k-fold cross validated partial least squares regression models — kfolds2coeff","text":"","code":"kfolds2coeff(pls_kfolds)"},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2coeff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extracts coefficients from k-fold cross validated partial least squares regression models — kfolds2coeff","text":"pls_kfolds object k-fold cross validated partial least squares regression models either lm glm","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2coeff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extracts coefficients from k-fold cross validated partial least squares regression models — kfolds2coeff","text":"coef.matrix values coefficients leave one step NULL another type cross validation used.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2coeff.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extracts coefficients from k-fold cross validated partial least squares regression models — kfolds2coeff","text":"fonctions works plsR plsRglm models.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2coeff.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extracts coefficients from k-fold cross validated partial least squares regression models — kfolds2coeff","text":"NK=1 leave one CV","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2coeff.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extracts coefficients from k-fold cross validated partial least squares regression models — kfolds2coeff","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2coeff.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extracts coefficients from k-fold cross validated partial least squares regression models — kfolds2coeff","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/kfolds2coeff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extracts coefficients from k-fold cross validated partial least squares regression models — kfolds2coeff","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] bbb <- PLS_lm_kfoldcv(dataY=yCornell,dataX=XCornell,nt=3,K=nrow(XCornell),keepcoeffs=TRUE, verbose=FALSE) kfolds2coeff(bbb) #>           [,1]       [,2]      [,3]      [,4]      [,5]        [,6]      [,7] #>  [1,] 90.87298  -7.730285 -5.317939 -13.05518 -7.612449  10.6111677  9.346481 #>  [2,] 92.08375 -10.476510 -5.782367 -17.77961 -7.207449  -7.0528029 10.556420 #>  [3,] 91.99726  -9.787064 -6.457435 -16.59124 -7.879221  -5.1780580 11.296555 #>  [4,] 93.11223  -9.180395 -7.969940 -15.39982 -9.450540  -0.4784392  9.484642 #>  [5,] 93.60436 -10.510020 -7.605163 -17.88485 -9.971635 -11.5650708  9.778748 #>  [6,] 94.86937 -11.914366 -7.224898 -20.18752 -8.149944  -8.9696175  8.585089 #>  [7,] 92.23105  -9.632494 -6.603052 -16.34906 -8.168203  -3.6682514 10.603008 #>  [8,] 92.46569  -9.885233 -6.735075 -16.81921 -8.272827  -4.0839573 10.373591 #>  [9,] 92.46387  -9.579230 -6.777947 -16.25454 -8.298890  -4.1484044 10.358129 #> [10,] 92.60529  -9.691082 -6.914517 -16.46361 -8.382754  -4.2807356 10.236205 #> [11,] 92.36316  -8.747489 -6.589638 -14.87073 -8.309297  -3.4465827 10.445493 #> [12,] 93.42592 -11.114193 -8.038234 -18.87582 -8.783616  -6.9236077  9.690647 #>            [,8] #>  [1,] -29.60954 #>  [2,] -33.45639 #>  [3,] -31.02182 #>  [4,] -34.89010 #>  [5,] -34.37588 #>  [6,] -53.16098 #>  [7,] -33.39444 #>  [8,] -34.49712 #>  [9,] -33.70987 #> [10,] -34.34320 #> [11,] -34.82607 #> [12,] -31.84496 boxplot(kfolds2coeff(bbb)[,2])  rm(list=c(\"XCornell\",\"yCornell\",\"bbb\"))  data(pine) Xpine<-pine[,1:10] ypine<-pine[,11] bbb2 <- cv.plsR(object=ypine,dataX=Xpine,nt=4,K=nrow(Xpine),keepcoeffs=TRUE,verbose=FALSE) kfolds2coeff(bbb2) #>           [,1]         [,2]        [,3]       [,4]       [,5]       [,6] #>  [1,] 7.814246 -0.002869674 -0.03549716 0.02107684 -0.2219176 0.07293649 #>  [2,] 8.361383 -0.002854043 -0.03743841 0.02249864 -0.2164871 0.06909414 #>  [3,] 8.650702 -0.002814409 -0.03797563 0.02335471 -0.2733051 0.07768935 #>  [4,] 8.558683 -0.002769261 -0.03941925 0.02261582 -0.2486856 0.07253035 #>  [5,] 8.218008 -0.002808356 -0.03512320 0.02344851 -0.2380859 0.07483498 #>  [6,] 8.305299 -0.002728968 -0.03775406 0.02226888 -0.2278873 0.07310943 #>  [7,] 8.544910 -0.002866033 -0.04077690 0.02255038 -0.1986620 0.08297200 #>  [8,] 8.071791 -0.002768139 -0.03735800 0.01911647 -0.1574095 0.06347242 #>  [9,] 7.713087 -0.002301366 -0.03350332 0.02179469 -0.1982322 0.06886116 #> [10,] 8.193386 -0.002427074 -0.03899699 0.02178240 -0.2476962 0.07823805 #> [11,] 8.878504 -0.003085315 -0.03992126 0.01865159 -0.2000119 0.06161356 #> [12,] 9.117046 -0.003179412 -0.03520851 0.02509672 -0.2355585 0.07948714 #> [13,] 7.765163 -0.002551739 -0.03589722 0.02021236 -0.2297687 0.07507578 #> [14,] 8.298677 -0.002659646 -0.03597977 0.02186039 -0.2382632 0.06852447 #> [15,] 8.306726 -0.002731392 -0.03769351 0.02271611 -0.2067318 0.06867246 #> [16,] 8.700332 -0.003000855 -0.03968194 0.02031214 -0.2439055 0.07971910 #> [17,] 8.363382 -0.002725646 -0.03760331 0.02239444 -0.2284354 0.07265824 #> [18,] 8.297162 -0.002703300 -0.03809335 0.02228154 -0.2452161 0.07683082 #> [19,] 8.262983 -0.002749134 -0.03604436 0.02181592 -0.2560591 0.07712466 #> [20,] 8.876407 -0.003129747 -0.04096829 0.02442558 -0.2257238 0.07799168 #> [21,] 8.201937 -0.002817385 -0.04037497 0.01866908 -0.2256173 0.07206968 #> [22,] 8.284944 -0.002533698 -0.04058031 0.02165310 -0.2387052 0.07384772 #> [23,] 8.797446 -0.002860185 -0.03849982 0.02287225 -0.2398173 0.06896626 #> [24,] 7.929182 -0.002433262 -0.04104596 0.02373045 -0.2080378 0.07196279 #> [25,] 7.989959 -0.002757493 -0.04265244 0.02273451 -0.2204082 0.07554612 #> [26,] 8.387502 -0.002676524 -0.03883171 0.02166663 -0.2438722 0.07389119 #> [27,] 8.472460 -0.002825763 -0.03726580 0.02081686 -0.2401187 0.07506551 #> [28,] 7.911123 -0.002181740 -0.03810400 0.01767450 -0.1808041 0.04804859 #> [29,] 8.351547 -0.002759590 -0.03948543 0.02215742 -0.2302882 0.07157444 #> [30,] 8.433206 -0.002887146 -0.03839730 0.02024058 -0.2138490 0.06996299 #> [31,] 8.443818 -0.003194742 -0.03679137 0.02566206 -0.2401347 0.09821587 #> [32,] 8.304524 -0.003016708 -0.03992431 0.02217589 -0.1715886 0.06046621 #> [33,] 8.457649 -0.002769321 -0.03834922 0.02197341 -0.2326822 0.07359720 #>            [,7]       [,8]        [,9]      [,10]      [,11] #>  [1,] 0.2447542 -0.2023747 -0.08867027 -0.6756387 -0.3860024 #>  [2,] 0.2508868 -0.4458012 -0.08263970 -0.7356824 -0.3964378 #>  [3,] 0.2606680 -0.4565363 -0.09217752 -0.7261476 -0.4746015 #>  [4,] 0.2586394 -0.5379771 -0.08575226 -0.7061042 -0.4206479 #>  [5,] 0.2133057 -0.3908510 -0.08249627 -0.7398298 -0.3869324 #>  [6,] 0.2557966 -0.5581856 -0.08777483 -0.7309410 -0.3373923 #>  [7,] 0.2140205 -0.5802810 -0.10056348 -0.7089801 -0.3989933 #>  [8,] 0.2412951 -0.5263135 -0.09178826 -0.7010010 -0.2785220 #>  [9,] 0.2802143 -0.5919984 -0.07268121 -0.8076147 -0.4227010 #> [10,] 0.2415159 -0.6658565 -0.08619423 -0.7333098 -0.3641896 #> [11,] 0.2358135 -0.5397474 -0.06518898 -0.6304151 -0.5049983 #> [12,] 0.2670978 -0.9590753 -0.08518518 -0.6965007 -0.2282369 #> [13,] 0.2021548 -0.4795504 -0.07983647 -0.6572603 -0.3362084 #> [14,] 0.2422333 -0.6637845 -0.07746177 -0.7198954 -0.2925045 #> [15,] 0.2466642 -0.5335098 -0.09370588 -0.6981061 -0.3848060 #> [16,] 0.2507118 -0.4494593 -0.09915981 -0.6924289 -0.4327700 #> [17,] 0.2490739 -0.5898428 -0.08451685 -0.7448365 -0.3305126 #> [18,] 0.2564153 -0.5118346 -0.08873345 -0.7275463 -0.3785027 #> [19,] 0.2611840 -0.4432492 -0.09082157 -0.7323138 -0.3756275 #> [20,] 0.2454048 -0.4253930 -0.09794089 -0.7144557 -0.4743556 #> [21,] 0.2600754 -0.3528332 -0.07860586 -0.6946200 -0.4181529 #> [22,] 0.2715177 -0.6308057 -0.09274944 -0.7124415 -0.3325791 #> [23,] 0.2610561 -0.6266037 -0.08359975 -0.6979821 -0.4452225 #> [24,] 0.2350859 -0.5378953 -0.09799516 -0.7206555 -0.2957781 #> [25,] 0.2374591 -0.3632903 -0.08893607 -0.7293388 -0.2622970 #> [26,] 0.2396266 -0.5755539 -0.08208888 -0.7096107 -0.3818814 #> [27,] 0.2637412 -0.4868311 -0.08269255 -0.7191352 -0.4532000 #> [28,] 0.2315868 -0.6747620 -0.08792043 -0.7548252 -0.2050949 #> [29,] 0.2622808 -0.5122030 -0.08093838 -0.7864637 -0.2986094 #> [30,] 0.2040295 -0.5588206 -0.10558610 -0.5334666 -0.3581429 #> [31,] 0.2718858 -0.3416514 -0.10653476 -0.8057978 -0.3245760 #> [32,] 0.1956558 -0.3607404 -0.06637462 -0.7149729 -0.3418038 #> [33,] 0.2524494 -0.5331250 -0.08739496 -0.7228717 -0.4052381 boxplot(kfolds2coeff(bbb2)[,1])  rm(list=c(\"Xpine\",\"ypine\",\"bbb2\"))"},{"path":"https://fbertran.github.io/plsRglm/reference/loglikpls.html","id":null,"dir":"Reference","previous_headings":"","what":"loglikelihood function for plsR models — loglikpls","title":"loglikelihood function for plsR models — loglikpls","text":"function provides loglikelihood computation univariate plsR model.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/loglikpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"loglikelihood function for plsR models — loglikpls","text":"","code":"loglikpls(residpls, weights = rep.int(1, length(residpls)))"},{"path":"https://fbertran.github.io/plsRglm/reference/loglikpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"loglikelihood function for plsR models — loglikpls","text":"residpls Residuals fitted univariate plsR model weights Weights observations","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/loglikpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"loglikelihood function for plsR models — loglikpls","text":"real Loglikelihood value","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/loglikpls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"loglikelihood function for plsR models — loglikpls","text":"Loglikelihood functions plsR models univariate response.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/loglikpls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"loglikelihood function for plsR models — loglikpls","text":"Baibing Li, Julian Morris, Elaine B. Martin, Model selection partial least squares regression, Chemometrics Intelligent Laboratory Systems 64 (2002) 79-89, doi:10.1016/S0169-7439(02)00051-5 .","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/loglikpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"loglikelihood function for plsR models — loglikpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/loglikpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"loglikelihood function for plsR models — loglikpls","text":"","code":"data(pine) ypine <- pine[,11] Xpine <- pine[,1:10] (Pinscaled <- as.data.frame(cbind(scale(ypine),scale(as.matrix(Xpine))))) #>             V1           x1           x2          x3          x4          x5 #> 1   1.93343137 -0.893800639 -0.962578437 -1.09627645 -0.43382827 -0.10494125 #> 2   0.81712282  0.206659107 -0.141067529 -0.36224787 -0.04949719  0.63880345 #> 3   0.39540626 -0.653559427 -0.141067529 -0.67683154 -1.97115262 -1.73188279 #> 4   0.04811027 -0.475315947 -0.141067529  0.68636438 -1.39465599 -1.40649448 #> 5  -0.70849886  0.322904855  0.406606409 -0.46710909 -0.72207659 -1.05786415 #> 6   0.84192968 -0.506314813 -0.277986014 -1.09627645 -0.04949719 -0.10494125 #> 7  -0.63407829  0.826636429  1.091198831  1.10580928 -1.39465599 -1.66215672 #> 8  -0.91935714 -0.049081538  2.323465192 -0.46710909  1.19957885  1.01067580 #> 9   2.71484735 -1.459529946 -0.688741468 -0.99141522 -0.91424213 -0.61626573 #> 10  0.49463369 -1.862515205  0.680443378 -0.25738664 -0.14557996 -0.75571786 #> 11 -0.53485086 -1.157291001 -0.688741468  0.58150316  1.00741330  0.33665717 #> 12 -0.13794116 -1.033295537  1.638872769  2.15442154  0.91133053  1.47551624 #> 13  2.26832393 -1.056544686 -1.921007828 -1.20113767 -1.20249045 -1.10434819 #> 14  1.53652166 -0.459816514 -1.099496921 -1.20113767  0.62308222  0.98743378 #> 15  1.16441881 -0.498565096 -0.414904499 -0.99141522 -0.24166273  0.26693110 #> 16 -0.93176057  1.710104113  1.228117316  2.04956031  1.19957885  0.59231941 #> 17 -0.84493657  1.849599011 -0.277986014  0.89608683  1.10349607  1.15012793 #> 18  0.23416169 -0.080080404  0.132769440 -0.57197032 -0.62599382  0.10423695 #> 19 -0.49764058  0.005166478  0.680443378 -0.36224787 -1.29857322 -0.89517000 #> 20 -0.11313430  0.865385012  1.365035800  0.79122561  0.14266836 -0.01197316 #> 21 -0.17515144  2.012343058 -1.236415406  2.15442154  0.71916499  0.84798165 #> 22 -0.85734000  0.632893516 -0.414904499  0.47664193 -0.24166273 -0.10494125 #> 23  0.19695141  0.477899186 -0.004149045 -0.78169277  0.81524776  1.05715985 #> 24 -0.91935714  2.004593341 -0.688741468  1.21067051  0.71916499  0.59231941 #> 25 -0.88214685  0.625143800  2.186546707  0.16205826  0.23875113 -0.01197316 #> 26 -0.16274801  0.601894650 -0.277986014 -0.67683154  0.23875113  0.70852952 #> 27 -0.84493657  0.911883311 -0.825659952  0.68636438  1.96824102  1.33606411 #> 28 -0.75811257  0.260907123 -0.688741468 -1.09627645 -1.68290430 -2.19672323 #> 29  0.34579255 -0.831802907 -0.825659952 -0.99141522 -0.91424213 -0.87192797 #> 30 -0.78291943 -0.909300072 -0.141067529  0.37178071 -0.52991104 -0.91841202 #> 31 -0.57206115 -0.676808577  0.269687924 -0.57197032  0.91133053  1.52200029 #> 32 -0.74570914 -0.669058860 -1.099496921 -0.04766419  1.29566162  0.33665717 #> 33 -0.96897085 -0.041331821  0.954280347  0.58150316  0.71916499  0.59231941 #>            x6         x7          x8          x9        x10 #> 1  -1.1025308 -2.9795617 -0.69706483 -1.02706110 -1.3713833 #> 2  -0.4055286 -0.8420501 -0.48446650 -0.49748272 -0.2009786 #> 3  -0.6843294 -0.3076721 -1.37737948 -0.85053497 -1.3713833 #> 4   0.7096750  0.2267058 -0.27186817  0.56167404 -0.5911135 #> 5  -0.5449290  0.2267058 -0.39942716 -0.32095659 -1.7615182 #> 6  -1.1025308  0.2267058 -0.73958449 -1.20358722 -1.3713833 #> 7   1.2672767  1.2954616  0.32340716  0.91472629  0.9694261 #> 8  -0.4055286 -1.9108059  0.11080883 -0.32095659 -0.5911135 #> 9  -1.1025308  0.2267058 -1.12226148 -0.85053497  0.9694261 #> 10 -0.2661281  0.7610837 -0.31438783  0.03209566  0.9694261 #> 11  0.8490754 -0.8420501  1.68403646  1.62083079 -0.2009786 #> 12  2.1036794 -1.3764280  1.59899713  1.44430467  0.9694261 #> 13 -1.1025308  0.2267058 -1.50493848 -1.55663947 -0.5911135 #> 14 -1.1025308  0.7610837 -0.73958449 -1.55663947 -1.3713833 #> 15 -0.9631303  0.2267058 -0.56950583 -1.20358722  0.1891563 #> 16  1.8248785  0.2267058  1.64151680  1.44430467  0.5792912 #> 17  1.4066772  1.2954616  0.70608415  1.26777854 -1.7615182 #> 18 -0.5449290 -2.4451838 -0.14430917  0.20862179  0.5792912 #> 19 -0.4055286  0.7610837 -1.07974182 -0.67400884  0.9694261 #> 20  0.8490754 -0.3076721  0.66356448  0.73820016  0.5792912 #> 21  1.6854781  0.2267058  0.79112348  0.91472629  0.1891563 #> 22  0.5702745 -0.3076721  0.06828916  0.38514791  0.1891563 #> 23 -0.8237299  0.7610837 -0.31438783 -0.67400884  0.5792912 #> 24  0.8490754  0.7610837  0.11080883  0.38514791  0.9694261 #> 25 -0.1267277 -0.3076721  0.11080883  0.20862179 -1.3713833 #> 26 -0.8237299  0.2267058 -0.01675017 -0.49748272  0.9694261 #> 27  1.2672767  0.7610837  2.61946911  1.26777854 -1.7615182 #> 28 -1.1025308  0.2267058 -1.67501714 -1.20358722  0.1891563 #> 29 -0.9631303  0.2267058 -0.90966315 -1.20358722  0.9694261 #> 30  0.2914737 -0.3076721 -0.05926984  1.44430467  0.9694261 #> 31 -0.6843294  0.2267058 -0.22934850 -0.85053497  0.5792912 #> 32 -0.1267277  0.7610837  1.04624148  0.56167404  0.9694261 #> 33  0.7096750  1.2954616  1.17380047  1.09125241  0.9694261 colnames(Pinscaled)[1] <- \"yy\"  lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled) #>  #> Call: #> lm(formula = yy ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 +  #>     x10, data = Pinscaled) #>  #> Coefficients: #> (Intercept)           x1           x2           x3           x4           x5   #>   1.119e-16   -4.601e-01   -3.175e-01    3.298e-01   -6.020e-01    5.539e-01   #>          x6           x7           x8           x9          x10   #>   6.720e-02   -6.054e-02    6.865e-02   -6.231e-01   -1.058e-01   #>   modpls <- plsR(ypine,Xpine,10) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  modpls$Std.Coeffs #>                  [,1] #> Intercept  0.00000000 #> x1        -0.46014550 #> x2        -0.31750091 #> x3         0.32980012 #> x4        -0.60199305 #> x5         0.55393816 #> x6         0.06720419 #> x7        -0.06054179 #> x8         0.06864663 #> x9        -0.62312421 #> x10       -0.10578863 lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled) #>  #> Call: #> lm(formula = yy ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 +  #>     x10, data = Pinscaled) #>  #> Coefficients: #> (Intercept)           x1           x2           x3           x4           x5   #>   1.119e-16   -4.601e-01   -3.175e-01    3.298e-01   -6.020e-01    5.539e-01   #>          x6           x7           x8           x9          x10   #>   6.720e-02   -6.054e-02    6.865e-02   -6.231e-01   -1.058e-01   #>   AIC(lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled)) #> [1] 79.37542 print(logLik(lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled))) #> 'log Lik.' -27.68771 (df=12)  sum(dnorm(modpls$RepY, modpls$Std.ValsPredictY, sqrt(mean(modpls$residY^2)), log=TRUE)) #> [1] -27.68771 sum(dnorm(Pinscaled$yy,fitted(lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled)), sqrt(mean(residuals(lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled))^2)), log=TRUE)) #> [1] -27.68771 loglikpls(modpls$residY) #> [1] -27.68771 loglikpls(residuals(lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled))) #> [1] -27.68771 AICpls(10,residuals(lm(yy~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10,data=Pinscaled))) #> [1] 79.37542 AICpls(10,modpls$residY) #> [1] 79.37542"},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsR.html","id":null,"dir":"Reference","previous_headings":"","what":"Coefficients for permutation bootstrap computations of PLSR models — permcoefs.plsR","title":"Coefficients for permutation bootstrap computations of PLSR models — permcoefs.plsR","text":"function passed boot perform bootstrap.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coefficients for permutation bootstrap computations of PLSR models — permcoefs.plsR","text":"","code":"permcoefs.plsR(dataset, ind, nt, modele, maxcoefvalues, ifbootfail, verbose)"},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coefficients for permutation bootstrap computations of PLSR models — permcoefs.plsR","text":"dataset dataset resample ind indices resampling nt number components use modele type modele use, see plsR maxcoefvalues maximum values allowed estimates coefficients discard coming singular bootstrap samples ifbootfail value return estimation fails bootstrap sample verbose info messages displayed ?","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coefficients for permutation bootstrap computations of PLSR models — permcoefs.plsR","text":"estimates bootstrap sample ifbootfail value bootstrap computation fails.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Coefficients for permutation bootstrap computations of PLSR models — permcoefs.plsR","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coefficients for permutation bootstrap computations of PLSR models — permcoefs.plsR","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8]  # Lazraq-Cleroux PLS (Y,X) bootstrap # statistic=permcoefs.plsR is the default for (Y,X) permutation resampling of PLSR models. set.seed(250) modpls <- plsR(yCornell,XCornell,1) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  Cornell.bootYX <- bootpls(modpls, sim=\"permutation\", R=250, statistic=permcoefs.plsR, verbose=FALSE)"},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsR.raw.html","id":null,"dir":"Reference","previous_headings":"","what":"Raw coefficients for permutation bootstrap computations of PLSR models — permcoefs.plsR.raw","title":"Raw coefficients for permutation bootstrap computations of PLSR models — permcoefs.plsR.raw","text":"function passed boot perform bootstrap.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsR.raw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Raw coefficients for permutation bootstrap computations of PLSR models — permcoefs.plsR.raw","text":"","code":"permcoefs.plsR.raw(   dataset,   ind,   nt,   modele,   maxcoefvalues,   ifbootfail,   verbose )"},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsR.raw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Raw coefficients for permutation bootstrap computations of PLSR models — permcoefs.plsR.raw","text":"dataset dataset resample ind indices resampling nt number components use modele type modele use, see plsR maxcoefvalues maximum values allowed estimates coefficients discard coming singular bootstrap samples ifbootfail value return estimation fails bootstrap sample verbose info messages displayed ?","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsR.raw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Raw coefficients for permutation bootstrap computations of PLSR models — permcoefs.plsR.raw","text":"estimates bootstrap sample ifbootfail value bootstrap computation fails.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsR.raw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Raw coefficients for permutation bootstrap computations of PLSR models — permcoefs.plsR.raw","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsR.raw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Raw coefficients for permutation bootstrap computations of PLSR models — permcoefs.plsR.raw","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8]  # Lazraq-Cleroux PLS (Y,X) bootstrap set.seed(250) modpls <- permcoefs.plsR.raw(Cornell[,-8],1:nrow(Cornell),nt=3, maxcoefvalues=1e5,ifbootfail=rep(0,3),verbose=FALSE)"},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglm.html","id":null,"dir":"Reference","previous_headings":"","what":"Coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglm","title":"Coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglm","text":"function passed boot perform bootstrap.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglm","text":"","code":"permcoefs.plsRglm(   dataset,   ind,   nt,   modele,   family = NULL,   maxcoefvalues,   ifbootfail,   verbose )"},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglm","text":"dataset dataset resample ind indices resampling nt number components use modele type modele use, see plsRglm family glm family use, see plsRglm maxcoefvalues maximum values allowed estimates coefficients discard coming singular bootstrap samples ifbootfail value return estimation fails bootstrap sample verbose info messages displayed ?","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglm","text":"estimates bootstrap sample ifbootfail value bootstrap computation fails.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglm","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglm","text":"","code":"data(Cornell)  # (Y,X) bootstrap of a PLSGLR model # statistic=coefs.plsRglm is the default for (Y,X) bootstrap of a PLSGLR models. set.seed(250) modplsglm <- plsRglm(Y~.,data=Cornell,1,modele=\"pls-glm-family\",family=gaussian) #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  Cornell.bootYX <- bootplsglm(modplsglm, R=250, typeboot=\"plsmodel\",  sim=\"permutation\", statistic=permcoefs.plsRglm, verbose=FALSE)"},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglm.raw.html","id":null,"dir":"Reference","previous_headings":"","what":"Raw coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglm.raw","title":"Raw coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglm.raw","text":"function passed boot perform bootstrap.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglm.raw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Raw coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglm.raw","text":"","code":"permcoefs.plsRglm.raw(   dataset,   ind,   nt,   modele,   family = NULL,   maxcoefvalues,   ifbootfail,   verbose )"},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglm.raw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Raw coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglm.raw","text":"dataset dataset resample ind indices resampling nt number components use modele type modele use, see plsRglm family glm family use, see plsRglm maxcoefvalues maximum values allowed estimates coefficients discard coming singular bootstrap samples ifbootfail value return estimation fails bootstrap sample verbose info messages displayed ?","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglm.raw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Raw coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglm.raw","text":"estimates bootstrap sample ifbootfail value bootstrap computation fails.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglm.raw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Raw coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglm.raw","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglm.raw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Raw coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglm.raw","text":"","code":"data(Cornell)  # (Y,X) bootstrap of a PLSGLR model set.seed(250) modplsglm <- permcoefs.plsRglm.raw(Cornell[,-8],1:nrow(Cornell),nt=3, modele=\"pls-glm-family\",family=gaussian,maxcoefvalues=1e5, ifbootfail=rep(0,3),verbose=FALSE)"},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglmnp.html","id":null,"dir":"Reference","previous_headings":"","what":"Coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglmnp","title":"Coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglmnp","text":"function passed boot perform bootstrap.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglmnp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglmnp","text":"","code":"permcoefs.plsRglmnp(   dataRepYtt,   ind,   nt,   modele,   family = NULL,   maxcoefvalues,   wwetoile,   ifbootfail )"},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglmnp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglmnp","text":"dataRepYtt components' coordinates bootstrap ind indices resampling nt number components use modele type modele use, see plsRglm family glm family use, see plsRglm maxcoefvalues maximum values allowed estimates coefficients discard coming singular bootstrap samples wwetoile values Wstar matrix original fit ifbootfail value return estimation fails bootstrap sample","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglmnp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglmnp","text":"estimates bootstrap sample ifbootfail value bootstrap computation fails.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglmnp.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglmnp","text":"~~notes~~","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglmnp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglmnp","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRglmnp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coefficients for permutation bootstrap computations of PLSGLR models — permcoefs.plsRglmnp","text":"","code":"data(Cornell)  # (Y,X) bootstrap of a PLSGLR model # statistic=coefs.plsRglm is the default for (Y,X) bootstrap of a PLSGLR models. set.seed(250) modplsglm <- plsRglm(Y~.,data=Cornell,1,modele=\"pls-glm-family\",family=gaussian) #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  Cornell.bootYT <- bootplsglm(modplsglm, R=250, statistic=permcoefs.plsRglmnp, verbose=FALSE)"},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRnp.html","id":null,"dir":"Reference","previous_headings":"","what":"Coefficients computation for permutation bootstrap — permcoefs.plsRnp","title":"Coefficients computation for permutation bootstrap — permcoefs.plsRnp","text":"function passed boot perform bootstrap.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRnp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coefficients computation for permutation bootstrap — permcoefs.plsRnp","text":"","code":"permcoefs.plsRnp(   dataRepYtt,   ind,   nt,   modele,   maxcoefvalues,   wwetoile,   ifbootfail )"},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRnp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coefficients computation for permutation bootstrap — permcoefs.plsRnp","text":"dataRepYtt components' coordinates bootstrap ind indices resampling nt number components use modele type modele use, see plsRglm maxcoefvalues maximum values allowed estimates coefficients discard coming singular bootstrap samples wwetoile values Wstar matrix original fit ifbootfail value return estimation fails bootstrap sample","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRnp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coefficients computation for permutation bootstrap — permcoefs.plsRnp","text":"estimates bootstrap sample ifbootfail value bootstrap computation fails.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRnp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Coefficients computation for permutation bootstrap — permcoefs.plsRnp","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/permcoefs.plsRnp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coefficients computation for permutation bootstrap — permcoefs.plsRnp","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8]  # Lazraq-Cleroux PLS (Y,X) bootstrap # statistic=coefs.plsR is the default for (Y,X) resampling of PLSR models. set.seed(250) modpls <- plsR(yCornell,XCornell,1) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  Cornell.bootYT <- bootpls(modpls, R=250, typeboot=\"fmodel_np\", sim=\"permutation\", statistic=permcoefs.plsRnp, verbose=FALSE)"},{"path":"https://fbertran.github.io/plsRglm/reference/pine.html","id":null,"dir":"Reference","previous_headings":"","what":"Pine dataset — pine","title":"Pine dataset — pine","text":"caterpillar dataset extracted 1973 study pine processionary caterpillars. assesses influence forest settlement characteristics development caterpillar colonies. response variable logarithmic transform average number nests caterpillars per tree area 500 square meters (x11). k=10 potentially explanatory variables defined n=33 areas.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pine.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Pine dataset — pine","text":"data frame 33 observations following 11 variables. x1 altitude (meters) x2 slope (en degrees) x3 number pines area x4 height (meters) tree sampled center area x5 diameter (meters) tree sampled center area x6 index settlement density x7 orientation area (1 southbound 2 otherwise) x8 height (meters) dominant tree x9 number vegetation strata x10 mix settlement index (1 mixed 2 mixed) x11 logarithmic transform average number nests caterpillars per tree","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pine.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Pine dataset — pine","text":"Tomassone R., Audrain S., Lesquoy-de Turckeim E., Millier C. (1992), “La régression, nouveaux regards sur une ancienne méthode statistique”, INRA, Actualités Scientifiques et Agronomiques, Masson, Paris.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pine.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pine dataset — pine","text":"caterpillars got names habit moving ground incredibly long head--tail processions leaving nest create new colony. pine_sup dataset can used test set assess model prediction error model trained pine dataset.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pine.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pine dataset — pine","text":"J.-M. Marin, C. Robert. (2007). Bayesian Core: Practical Approach Computational Bayesian Statistics. Springer, New-York, pages 48-49.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pine.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pine dataset — pine","text":"","code":"data(pine) str(pine) #> 'data.frame':\t33 obs. of  11 variables: #>  $ x1 : int  1200 1342 1231 1254 1357 1250 1422 1309 1127 1075 ... #>  $ x2 : int  22 28 28 28 32 27 37 46 24 34 ... #>  $ x3 : int  1 8 5 18 7 1 22 7 2 9 ... #>  $ x4 : num  4 4.4 2.4 3 3.7 4.4 3 5.7 3.5 4.3 ... #>  $ x5 : num  14.8 18 7.8 9.2 10.7 14.8 8.1 19.6 12.6 12 ... #>  $ x6 : num  1 1.5 1.3 2.3 1.4 1 2.7 1.5 1 1.6 ... #>  $ x7 : num  1.1 1.5 1.6 1.7 1.7 1.7 1.9 1.3 1.7 1.8 ... #>  $ x8 : num  5.9 6.4 4.3 6.9 6.6 5.8 8.3 7.8 4.9 6.8 ... #>  $ x9 : num  1.4 1.7 1.5 2.3 1.8 1.3 2.5 1.8 1.5 2 ... #>  $ x10: num  1.4 1.7 1.4 1.6 1.3 1.4 2 1.6 2 2 ... #>  $ x11: num  2.37 1.47 1.13 0.85 0.24 1.49 0.3 0.07 3 1.21 ..."},{"path":"https://fbertran.github.io/plsRglm/reference/pineNAX21.html","id":null,"dir":"Reference","previous_headings":"","what":"Incomplete dataset from the pine caterpillars example — pineNAX21","title":"Incomplete dataset from the pine caterpillars example — pineNAX21","text":"caterpillar dataset extracted 1973 study pine processionary caterpillars. assesses influence forest settlement characteristics development caterpillar colonies. k=10 potentially explanatory variables defined n=33 areas. value x2 first observation removed matrix predictors purpose.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pineNAX21.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Incomplete dataset from the pine caterpillars example — pineNAX21","text":"data frame 33 observations following 11 variables one missing value. x1 altitude (meters) x2 slope (en degrees) x3 number pines area x4 height (meters) tree sampled center area x5 diameter (meters) tree sampled center area x6 index settlement density x7 orientation area (1 southbound 2 otherwise) x8 height (meters) dominant tree x9 number vegetation strata x10 mix settlement index (1 mixed 2 mixed) x11 logarithmic transform average number nests caterpillars per tree","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pineNAX21.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Incomplete dataset from the pine caterpillars example — pineNAX21","text":"Tomassone R., Audrain S., Lesquoy-de Turckeim E., Millier C. (1992). “La régression, nouveaux regards sur une ancienne méthode statistique”, INRA, Actualités Scientifiques et Agronomiques, Masson, Paris.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pineNAX21.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Incomplete dataset from the pine caterpillars example — pineNAX21","text":"caterpillars got names habit moving ground incredibly long head--tail processions leaving nest create new colony. pineNAX21 dataset missing value testing purpose.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pineNAX21.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Incomplete dataset from the pine caterpillars example — pineNAX21","text":"","code":"data(pineNAX21) str(pineNAX21) #> 'data.frame':\t33 obs. of  11 variables: #>  $ x1 : int  1200 1342 1231 1254 1357 1250 1422 1309 1127 1075 ... #>  $ x2 : int  NA 28 28 28 32 27 37 46 24 34 ... #>  $ x3 : int  1 8 5 18 7 1 22 7 2 9 ... #>  $ x4 : num  4 4.4 2.4 3 3.7 4.4 3 5.7 3.5 4.3 ... #>  $ x5 : num  14.8 18 7.8 9.2 10.7 14.8 8.1 19.6 12.6 12 ... #>  $ x6 : num  1 1.5 1.3 2.3 1.4 1 2.7 1.5 1 1.6 ... #>  $ x7 : num  1.1 1.5 1.6 1.7 1.7 1.7 1.9 1.3 1.7 1.8 ... #>  $ x8 : num  5.9 6.4 4.3 6.9 6.6 5.8 8.3 7.8 4.9 6.8 ... #>  $ x9 : num  1.4 1.7 1.5 2.3 1.8 1.3 2.5 1.8 1.5 2 ... #>  $ x10: num  1.4 1.7 1.4 1.6 1.3 1.4 2 1.6 2 2 ... #>  $ x11: num  2.37 1.47 1.13 0.85 0.24 1.49 0.3 0.07 3 1.21 ..."},{"path":"https://fbertran.github.io/plsRglm/reference/pine_full.html","id":null,"dir":"Reference","previous_headings":"","what":"Complete Pine dataset — pine_full","title":"Complete Pine dataset — pine_full","text":"complete caterpillar dataset 1973 study pine_full processionary caterpillars. assesses influence forest settlement characteristics development caterpillar colonies. response variable logarithmic transform average number nests caterpillars per tree area 500 square meters (x11). k=10 potentially explanatory variables defined n=55 areas.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pine_full.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Complete Pine dataset — pine_full","text":"data frame 55 observations following 11 variables. x1 altitude (meters) x2 slope (en degrees) x3 number pine_fulls area x4 height (meters) tree sampled center area x5 diameter (meters) tree sampled center area x6 index settlement density x7 orientation area (1 southbound 2 otherwise) x8 height (meters) dominant tree x9 number vegetation strata x10 mix settlement index (1 mixed 2 mixed) x11 logarithmic transform average number nests caterpillars per tree","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pine_full.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Complete Pine dataset — pine_full","text":"Tomassone R., Audrain S., Lesquoy-de Turckeim E., Millier C. (1992), “La régression, nouveaux regards sur une ancienne méthode statistique”, INRA, Actualités Scientifiques et Agronomiques, Masson, Paris.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pine_full.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Complete Pine dataset — pine_full","text":"caterpillars got names habit moving ground incredibly long head--tail processions leaving nest create new colony.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pine_full.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Complete Pine dataset — pine_full","text":"J.-M. Marin, C. Robert. (2007). Bayesian Core: Practical Approach Computational Bayesian Statistics. Springer, New-York, pages 48-49.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pine_full.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Complete Pine dataset — pine_full","text":"","code":"data(pine_full) str(pine_full) #> 'data.frame':\t58 obs. of  11 variables: #>  $ x1 : int  1200 1342 1231 1254 1357 1250 1422 1309 1127 1075 ... #>  $ x2 : int  22 28 28 28 32 27 37 46 24 34 ... #>  $ x3 : int  1 8 5 18 7 1 22 7 2 9 ... #>  $ x4 : num  4 4.4 2.4 3 3.7 4.4 3 5.7 3.5 4.3 ... #>  $ x5 : num  14.8 18 7.8 9.2 10.7 14.8 8.1 19.6 12.6 12 ... #>  $ x6 : num  1 1.5 1.3 2.3 1.4 1 2.7 1.5 1 1.6 ... #>  $ x7 : num  1.1 1.5 1.6 1.7 1.7 1.7 1.9 1.3 1.7 1.8 ... #>  $ x8 : num  5.9 6.4 4.3 6.9 6.6 5.8 8.3 7.8 4.9 6.8 ... #>  $ x9 : num  1.4 1.7 1.5 2.3 1.8 1.3 2.5 1.8 1.5 2 ... #>  $ x10: num  1.4 1.7 1.4 1.6 1.3 1.4 2 1.6 2 2 ... #>  $ x11: num  2.37 1.47 1.13 0.85 0.24 1.49 0.3 0.07 3 1.21 ..."},{"path":"https://fbertran.github.io/plsRglm/reference/pine_sup.html","id":null,"dir":"Reference","previous_headings":"","what":"Complete Pine dataset — pine_sup","title":"Complete Pine dataset — pine_sup","text":"supplementary dataset (used test set pine dataset) extracted 1973 study pine_sup processionary caterpillars. assesses influence forest settlement characteristics development caterpillar colonies. response variable logarithmic transform average number nests caterpillars per tree area 500 square meters (x11). k=10 potentially explanatory variables defined n=22 areas.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pine_sup.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Complete Pine dataset — pine_sup","text":"data frame 22 observations following 11 variables. x1 altitude (meters) x2 slope (en degrees) x3 number pine_sups area x4 height (meters) tree sampled center area x5 diameter (meters) tree sampled center area x6 index settlement density x7 orientation area (1 southbound 2 otherwise) x8 height (meters) dominant tree x9 number vegetation strata x10 mix settlement index (1 mixed 2 mixed) x11 logarithmic transform average number nests caterpillars per tree","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pine_sup.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Complete Pine dataset — pine_sup","text":"Tomassone R., Audrain S., Lesquoy-de Turckeim E., Millier C. (1992), “La régression, nouveaux regards sur une ancienne méthode statistique”, INRA, Actualités Scientifiques et Agronomiques, Masson, Paris.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pine_sup.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Complete Pine dataset — pine_sup","text":"caterpillars got names habit moving ground incredibly long head--tail processions leaving nest create new colony. pine_sup dataset can used test set assess model prediction error model trained pine dataset.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pine_sup.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Complete Pine dataset — pine_sup","text":"J.-M. Marin, C. Robert. (2007). Bayesian Core: Practical Approach Computational Bayesian Statistics. Springer, New-York, pages 48-49.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/pine_sup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Complete Pine dataset — pine_sup","text":"","code":"data(pine_sup) str(pine_sup) #> 'data.frame':\t25 obs. of  11 variables: #>  $ x1 : int  1107 1116 1174 1131 1150 1132 1258 1114 1177 1146 ... #>  $ x2 : int  31 34 32 30 34 22 14 26 36 26 ... #>  $ x3 : int  23 6 22 6 12 18 0 9 3 18 ... #>  $ x4 : num  6 2.5 3.9 4.7 3.1 7 3.8 3.4 4 4.3 ... #>  $ x5 : num  22.2 6.6 11.9 15.3 9.4 37 8.5 9.6 14.2 17.9 ... #>  $ x6 : num  2.6 1.3 2.3 1.5 1.7 2.5 1 1.6 1.2 2.3 ... #>  $ x7 : num  1 1.8 1.7 1.5 1.8 1.5 1.2 1.6 1.3 1.6 ... #>  $ x8 : num  9 3.9 6.1 6.5 4.8 9 5.6 5.1 5.9 7.7 ... #>  $ x9 : num  3 1.2 1.8 1.4 1.6 2 1 1.5 1.3 2 ... #>  $ x10: num  1.4 1.5 1.5 1.3 1.3 1.5 1 1.3 1.6 1.4 ... #>  $ x11: num  1.17 0.67 0.9 2.32 3.89 6 3.18 0.9 2.5 2 ..."},{"path":"https://fbertran.github.io/plsRglm/reference/plot.table.summary.cv.plsRglmmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for table of summary of cross validated plsRglm models — plot.table.summary.cv.plsRglmmodel","title":"Plot method for table of summary of cross validated plsRglm models — plot.table.summary.cv.plsRglmmodel","text":"function provides table method class \"summary.cv.plsRglmmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plot.table.summary.cv.plsRglmmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for table of summary of cross validated plsRglm models — plot.table.summary.cv.plsRglmmodel","text":"","code":"# S3 method for class 'table.summary.cv.plsRglmmodel' plot(x, type = c(\"CVMC\", \"CVQ2Chi2\", \"CVPreChi2\"), ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/plot.table.summary.cv.plsRglmmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for table of summary of cross validated plsRglm models — plot.table.summary.cv.plsRglmmodel","text":"x object class \"table.summary.cv.plsRglmmodel\" type type cross validation criterion plot. ... arguments passed methods.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plot.table.summary.cv.plsRglmmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot method for table of summary of cross validated plsRglm models — plot.table.summary.cv.plsRglmmodel","text":"NULL","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plot.table.summary.cv.plsRglmmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot method for table of summary of cross validated plsRglm models — plot.table.summary.cv.plsRglmmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/plot.table.summary.cv.plsRglmmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot method for table of summary of cross validated plsRglm models — plot.table.summary.cv.plsRglmmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plot.table.summary.cv.plsRglmmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for table of summary of cross validated plsRglm models — plot.table.summary.cv.plsRglmmodel","text":"","code":"data(Cornell) bbb <- cv.plsRglm(Y~.,data=Cornell,nt=10,NK=1, modele=\"pls-glm-family\",family=gaussian(), verbose=FALSE) plot(cvtable(summary(bbb,verbose=FALSE)),type=\"CVQ2Chi2\") #>  #> CV Q2Chi2 criterion: #> 0 1 2  #> 0 0 1  #>  #> CV PreChi2 criterion: #> 1 2  #> 0 1   rm(list=c(\"bbb\"))  # \\donttest{ data(Cornell) plot(cvtable(summary(cv.plsRglm(Y~.,data=Cornell,nt=10,NK=100, modele=\"pls-glm-family\",family=gaussian(), verbose=FALSE), verbose=FALSE)),type=\"CVQ2Chi2\") #>  #> CV Q2Chi2 criterion: #>  0  1  2  #>  0 30 70  #>  #> CV PreChi2 criterion: #>  1  2  3  4  5  #>  0 20 55 22  3   # }"},{"path":"https://fbertran.github.io/plsRglm/reference/plot.table.summary.cv.plsRmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for table of summary of cross validated plsR models — plot.table.summary.cv.plsRmodel","title":"Plot method for table of summary of cross validated plsR models — plot.table.summary.cv.plsRmodel","text":"function provides table method class \"summary.cv.plsRmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plot.table.summary.cv.plsRmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for table of summary of cross validated plsR models — plot.table.summary.cv.plsRmodel","text":"","code":"# S3 method for class 'table.summary.cv.plsRmodel' plot(x, type = c(\"CVMC\", \"CVQ2\", \"CVPress\"), ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/plot.table.summary.cv.plsRmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for table of summary of cross validated plsR models — plot.table.summary.cv.plsRmodel","text":"x object class \"table.summary.cv.plsRmodel\" type type cross validation criterion plot. ... arguments passed methods.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plot.table.summary.cv.plsRmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot method for table of summary of cross validated plsR models — plot.table.summary.cv.plsRmodel","text":"NULL","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plot.table.summary.cv.plsRmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot method for table of summary of cross validated plsR models — plot.table.summary.cv.plsRmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/plot.table.summary.cv.plsRmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot method for table of summary of cross validated plsR models — plot.table.summary.cv.plsRmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plot.table.summary.cv.plsRmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for table of summary of cross validated plsR models — plot.table.summary.cv.plsRmodel","text":"","code":"data(Cornell) bbb <- cv.plsR(Y~.,data=Cornell,nt=6,K=6,NK=5, verbose=FALSE) plot(cvtable(summary(bbb)),type=\"CVQ2\") #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1,  2,  3,  4,  5 #>  #> CV Q2 criterion: #> 0 1  #> 0 5  #>  #> CV Press criterion: #> 1 2 3 4  #> 0 0 4 1   rm(list=c(\"bbb\"))  # \\donttest{ data(Cornell) plot(cvtable(summary(cv.plsR(Y~.,data=Cornell,nt=6,K=6,NK=100, verbose=FALSE))),type=\"CVQ2\") #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1,  2,  3,  4,  5,  6,  7,  8,  9,  10 #> NK: 11,  12,  13,  14,  15,  16,  17,  18,  19,  20 #> NK: 21,  22,  23,  24,  25,  26,  27,  28,  29,  30 #> NK: 31,  32,  33,  34,  35,  36,  37,  38,  39,  40 #> NK: 41,  42,  43,  44,  45,  46,  47,  48,  49,  50 #> NK: 51,  52,  53,  54,  55,  56,  57,  58,  59,  60 #> NK: 61,  62,  63,  64,  65,  66,  67,  68,  69,  70 #> NK: 71,  72,  73,  74,  75,  76,  77,  78,  79,  80 #> NK: 81,  82,  83,  84,  85,  86,  87,  88,  89,  90 #> NK: 91,  92,  93,  94,  95,  96,  97,  98,  99,  100 #>  #> CV Q2 criterion: #>  0  1  2  #>  0 89 11  #>  #> CV Press criterion: #>  1  2  3  4  5  #>  0  0 33 55 12   # }"},{"path":"https://fbertran.github.io/plsRglm/reference/plots.confints.bootpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot bootstrap confidence intervals — plots.confints.bootpls","title":"Plot bootstrap confidence intervals — plots.confints.bootpls","text":"function plots confidence intervals derived using function confints.bootpls bootpls based object.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plots.confints.bootpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot bootstrap confidence intervals — plots.confints.bootpls","text":"","code":"plots.confints.bootpls(   ic_bootobject,   indices = NULL,   legendpos = \"topleft\",   prednames = TRUE,   articlestyle = TRUE,   xaxisticks = TRUE,   ltyIC = c(2, 4, 5, 1),   colIC = c(\"darkgreen\", \"blue\", \"red\", \"black\"),   typeIC,   las = par(\"las\"),   mar,   mgp,   ... )"},{"path":"https://fbertran.github.io/plsRglm/reference/plots.confints.bootpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot bootstrap confidence intervals — plots.confints.bootpls","text":"ic_bootobject object created confints.bootpls function. indices vector indices variables plot. Defaults NULL: predictors used. legendpos position legend legend, defaults \"topleft\" prednames original names predictors shall plotted ? Defaults TRUE: names plotted. articlestyle extra blank zones margin shall removed plot ? Defaults TRUE: margins removed. xaxisticks ticks x axis shall plotted ? Defaults TRUE: ticks plotted. ltyIC lty plot colIC col plot typeIC type CI plot. Defaults typeIC=c(\"Normal\", \"Basic\", \"Percentile\", \"BCa\") BCa intervals limits computed typeIC=c(\"Normal\", \"Basic\", \"Percentile\") otherwise. las numeric 0,1,2,3; style axis labels. 0: always parallel axis [default], 1: always horizontal, 2: always perpendicular axis, 3: always vertical. mar numerical vector form c(bottom, left, top, right) gives number lines margin specified four sides plot. default c(5, 4, 4, 2) + 0.1. mgp margin line (mex units) axis title, axis labels axis line. Note mgp[1] affects title whereas mgp[2:3] affect axis. default c(3, 1, 0). ... options pass plot function.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plots.confints.bootpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot bootstrap confidence intervals — plots.confints.bootpls","text":"NULL","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/plots.confints.bootpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot bootstrap confidence intervals — plots.confints.bootpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plots.confints.bootpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot bootstrap confidence intervals — plots.confints.bootpls","text":"","code":"data(Cornell) modpls <- plsR(Y~.,data=Cornell,3) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>   # Lazraq-Cleroux PLS (Y,X) bootstrap set.seed(250) Cornell.bootYX <- bootpls(modpls, R=250, verbose=FALSE) temp.ci <- confints.bootpls(Cornell.bootYX,2:8) #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints  plots.confints.bootpls(temp.ci)  plots.confints.bootpls(temp.ci,prednames=FALSE)  plots.confints.bootpls(temp.ci,prednames=FALSE,articlestyle=FALSE, main=\"Bootstrap confidence intervals for the bj\")  plots.confints.bootpls(temp.ci,indices=1:3,prednames=FALSE)  plots.confints.bootpls(temp.ci,c(2,4,6),\"bottomright\")  plots.confints.bootpls(temp.ci,c(2,4,6),articlestyle=FALSE, main=\"Bootstrap confidence intervals for some of the bj\")   temp.ci <- confints.bootpls(Cornell.bootYX,typeBCa=FALSE) plots.confints.bootpls(temp.ci) #> Warning: zero-length arrow is of indeterminate angle and so skipped #> Warning: zero-length arrow is of indeterminate angle and so skipped #> Warning: zero-length arrow is of indeterminate angle and so skipped  plots.confints.bootpls(temp.ci,2:8)  plots.confints.bootpls(temp.ci,prednames=FALSE) #> Warning: zero-length arrow is of indeterminate angle and so skipped #> Warning: zero-length arrow is of indeterminate angle and so skipped #> Warning: zero-length arrow is of indeterminate angle and so skipped    # Bastien CSDA 2005 (Y,T) bootstrap Cornell.boot <- bootpls(modpls, typeboot=\"fmodel_np\", R=250, verbose=FALSE) temp.ci <- confints.bootpls(Cornell.boot,2:8)  plots.confints.bootpls(temp.ci)  plots.confints.bootpls(temp.ci,prednames=FALSE)  plots.confints.bootpls(temp.ci,prednames=FALSE,articlestyle=FALSE, main=\"Bootstrap confidence intervals for the bj\")  plots.confints.bootpls(temp.ci,indices=1:3,prednames=FALSE)  plots.confints.bootpls(temp.ci,c(2,4,6),\"bottomright\")  plots.confints.bootpls(temp.ci,c(2,4,6),articlestyle=FALSE, main=\"Bootstrap confidence intervals for some of the bj\")   temp.ci <- confints.bootpls(Cornell.boot,typeBCa=FALSE) plots.confints.bootpls(temp.ci) #> Warning: zero-length arrow is of indeterminate angle and so skipped #> Warning: zero-length arrow is of indeterminate angle and so skipped #> Warning: zero-length arrow is of indeterminate angle and so skipped  plots.confints.bootpls(temp.ci,2:8)  plots.confints.bootpls(temp.ci,prednames=FALSE) #> Warning: zero-length arrow is of indeterminate angle and so skipped #> Warning: zero-length arrow is of indeterminate angle and so skipped #> Warning: zero-length arrow is of indeterminate angle and so skipped    # \\donttest{ data(aze_compl) modplsglm <- plsRglm(y~.,data=aze_compl,3,modele=\"pls-glm-logistic\") #> ____************************************************____ #>  #> Family: binomial  #> Link function: logit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>   # Lazraq-Cleroux PLS (Y,X) bootstrap # should be run with R=1000 but takes much longer time aze_compl.bootYX3 <- bootplsglm(modplsglm, typeboot=\"plsmodel\", R=250, verbose=FALSE) #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred temp.ci <- confints.bootpls(aze_compl.bootYX3) #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints #> Warning: extreme order statistics used as endpoints  plots.confints.bootpls(temp.ci)  plots.confints.bootpls(temp.ci,prednames=FALSE)  plots.confints.bootpls(temp.ci,prednames=FALSE,articlestyle=FALSE, main=\"Bootstrap confidence intervals for the bj\")  plots.confints.bootpls(temp.ci,indices=1:33,prednames=FALSE)  plots.confints.bootpls(temp.ci,c(2,4,6),\"bottomleft\")  plots.confints.bootpls(temp.ci,c(2,4,6),articlestyle=FALSE, main=\"Bootstrap confidence intervals for some of the bj\")  plots.confints.bootpls(temp.ci,indices=1:34,prednames=FALSE)  plots.confints.bootpls(temp.ci,indices=1:33,prednames=FALSE,ltyIC=1,colIC=c(1,2))    temp.ci <- confints.bootpls(aze_compl.bootYX3,1:34,typeBCa=FALSE) plots.confints.bootpls(temp.ci,indices=1:33,prednames=FALSE)    # Bastien CSDA 2005 (Y,T) Bootstrap # much faster aze_compl.bootYT3 <- bootplsglm(modplsglm, R=1000, verbose=FALSE) temp.ci <- confints.bootpls(aze_compl.bootYT3)  plots.confints.bootpls(temp.ci)  plots.confints.bootpls(temp.ci,typeIC=\"Normal\")  plots.confints.bootpls(temp.ci,typeIC=c(\"Normal\",\"Basic\"))  plots.confints.bootpls(temp.ci,typeIC=\"BCa\",legendpos=\"bottomleft\")  plots.confints.bootpls(temp.ci,prednames=FALSE)  plots.confints.bootpls(temp.ci,prednames=FALSE,articlestyle=FALSE, main=\"Bootstrap confidence intervals for the bj\")  plots.confints.bootpls(temp.ci,indices=1:33,prednames=FALSE)  plots.confints.bootpls(temp.ci,c(2,4,6),\"bottomleft\")  plots.confints.bootpls(temp.ci,c(2,4,6),articlestyle=FALSE, main=\"Bootstrap confidence intervals for some of the bj\")  plots.confints.bootpls(temp.ci,prednames=FALSE,ltyIC=c(2,1),colIC=c(1,2))    temp.ci <- confints.bootpls(aze_compl.bootYT3,1:33,typeBCa=FALSE) plots.confints.bootpls(temp.ci,prednames=FALSE)  # }"},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.dof.html","id":null,"dir":"Reference","previous_headings":"","what":"Computation of the Degrees of Freedom — plsR.dof","title":"Computation of the Degrees of Freedom — plsR.dof","text":"function computes Degrees Freedom using Krylov representation PLS quantities used get information criteria values. time present, works complete datasets.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.dof.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computation of the Degrees of Freedom — plsR.dof","text":"","code":"# S3 method for class 'dof' plsR(modplsR, naive = FALSE)"},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.dof.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computation of the Degrees of Freedom — plsR.dof","text":"modplsR plsR model .e. object returned one functions plsR, plsRmodel.default, plsRmodel.formula, PLS_lm PLS_lm_formula. naive boolean.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.dof.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computation of the Degrees of Freedom — plsR.dof","text":"DoF Degrees Freedom sigmahat Estimates dispersion Yhat Predicted values yhat Square Euclidean norms predicted values RSS Residual Sums Squares","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.dof.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computation of the Degrees of Freedom — plsR.dof","text":"naive=FALSE returns values estimated degrees freedom error dispersion. naive=TRUE returns returns values naive degrees freedom error dispersion. original code Nicole Kraemer Mikio L. Braun unable handle models one component.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.dof.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Computation of the Degrees of Freedom — plsR.dof","text":"N. Kraemer, M. Sugiyama. (2011). Degrees Freedom Partial Least Squares Regression. Journal American Statistical Association, 106(494), 697-705. N. Kraemer, M. Sugiyama, M.L. Braun. (2009). Lanczos Approximations Speedup Kernel Partial Least Squares Regression, Proceedings Twelfth International Conference Artificial Intelligence Statistics (AISTATS), 272-279.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.dof.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Computation of the Degrees of Freedom — plsR.dof","text":"Nicole Kraemer, Mikio L. Braun improvements Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.dof.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computation of the Degrees of Freedom — plsR.dof","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] modpls <- plsR(yCornell,XCornell,4) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  plsR.dof(modpls)  #> $DoF #> [1] 1.000000 2.740749 5.085967 5.121086 5.103312 #>  #> $sigmahat #> [1] 6.5212706 1.8665281 1.1825195 0.7488308 0.7387162 #>  #> $Yhat #>        Nt_0     Nt_1     Nt_2     Nt_3     Nt_4 #> 1  88.58333 95.03164 96.49529 97.55864 97.46485 #> 2  88.58333 96.36241 97.51798 97.59151 97.72308 #> 3  88.58333 95.91107 97.56157 97.44534 97.54025 #> 4  88.58333 94.98711 92.14504 91.80793 91.88728 #> 5  88.58333 88.36924 87.98130 85.99452 85.97024 #> 6  88.58333 93.65634 91.12235 91.77507 91.62905 #> 7  88.58333 81.65428 81.33705 81.49670 81.50559 #> 8  88.58333 82.31664 82.49582 82.57542 82.61982 #> 9  88.58333 82.02100 82.28564 82.52399 82.53440 #> 10 88.58333 82.56111 83.12821 83.26027 83.30569 #> 11 88.58333 82.05655 81.23614 81.92924 81.97612 #> 12 88.58333 88.07261 89.69361 89.04136 88.84362 #>  #> $yhat #> [1] 94164.08 94596.14 94620.81 94627.46 94627.57 #>  #> $RSS #> [1] 467.796667  35.742486  11.066606   4.418081   4.309235 #>  plsR.dof(modpls,naive=TRUE)  #> $DoF #> [1] 1 2 3 4 5 #>  #> $sigmahat #> [1] 6.5212706 1.8905683 1.1088836 0.7431421 0.7846050 #>  #> $Yhat #>        Nt_0     Nt_1     Nt_2     Nt_3     Nt_4 #> 1  88.58333 95.03164 96.49529 97.55864 97.46485 #> 2  88.58333 96.36241 97.51798 97.59151 97.72308 #> 3  88.58333 95.91107 97.56157 97.44534 97.54025 #> 4  88.58333 94.98711 92.14504 91.80793 91.88728 #> 5  88.58333 88.36924 87.98130 85.99452 85.97024 #> 6  88.58333 93.65634 91.12235 91.77507 91.62905 #> 7  88.58333 81.65428 81.33705 81.49670 81.50559 #> 8  88.58333 82.31664 82.49582 82.57542 82.61982 #> 9  88.58333 82.02100 82.28564 82.52399 82.53440 #> 10 88.58333 82.56111 83.12821 83.26027 83.30569 #> 11 88.58333 82.05655 81.23614 81.92924 81.97612 #> 12 88.58333 88.07261 89.69361 89.04136 88.84362 #>  #> $yhat #> [1] 94164.08 94596.14 94620.81 94627.46 94627.57 #>  #> $RSS #> [1] 467.796667  35.742486  11.066606   4.418081   4.309235 #>"},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial least squares Regression models with leave one out cross validation — plsR","title":"Partial least squares Regression models with leave one out cross validation — plsR","text":"function implements Partial least squares Regression models leave one cross validation complete incomplete datasets.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial least squares Regression models with leave one out cross validation — plsR","text":"","code":"plsR(object, ...) # Default S3 method plsRmodel(object, dataX, nt = 2, limQ2set = 0.0975,  dataPredictY = dataX, modele = \"pls\", family = NULL, typeVC = \"none\",  EstimXNA = FALSE, scaleX = TRUE, scaleY = NULL, pvals.expli = FALSE,  alpha.pvals.expli = 0.05, MClassed = FALSE, tol_Xi = 10^(-12), weights, sparse = FALSE, sparseStop = TRUE, naive = FALSE,verbose=TRUE,...) # S3 method for class 'formula' plsRmodel(object, data, nt = 2, limQ2set = 0.0975, dataPredictY, modele = \"pls\", family = NULL, typeVC = \"none\", EstimXNA = FALSE, scaleX = TRUE, scaleY = NULL, pvals.expli = FALSE,  alpha.pvals.expli = 0.05, MClassed = FALSE, tol_Xi = 10^(-12), weights, subset, contrasts = NULL, sparse = FALSE, sparseStop = TRUE, naive = FALSE, verbose=TRUE,...) PLS_lm(dataY, dataX, nt = 2, limQ2set = 0.0975, dataPredictY = dataX,  modele = \"pls\", family = NULL, typeVC = \"none\", EstimXNA = FALSE,  scaleX = TRUE, scaleY = NULL, pvals.expli = FALSE,  alpha.pvals.expli = 0.05, MClassed = FALSE, tol_Xi = 10^(-12), weights,sparse=FALSE,sparseStop=FALSE,naive=FALSE,verbose=TRUE) PLS_lm_formula(formula,data=NULL,nt=2,limQ2set=.0975,dataPredictY=dataX, modele=\"pls\",family=NULL,typeVC=\"none\",EstimXNA=FALSE,scaleX=TRUE, scaleY=NULL,pvals.expli=FALSE,alpha.pvals.expli=.05,MClassed=FALSE, tol_Xi=10^(-12),weights,subset,contrasts=NULL,sparse=FALSE, sparseStop=FALSE,naive=FALSE,verbose=TRUE)"},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial least squares Regression models with leave one out cross validation — plsR","text":"object response (training) dataset object class \"formula\" (one can coerced class): symbolic description model fitted. details model specification given 'Details'. dataY response (training) dataset dataX predictor(s) (training) dataset formula object class \"formula\" (one can coerced class): symbolic description model fitted. details model specification given 'Details'. data optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found data, variables taken environment(formula), typically environment plsR called. nt number components extracted limQ2set limit value Q2 dataPredictY predictor(s) (testing) dataset modele name PLS model fitted, (\"pls\" available fonction. family present moment family argument ignored set thanks value modele. typeVC type leave one cross validation. Several procedures available. cross validation required, one needs selects way predicting response left observations. complete rows, without missing value, two different ways computing predictions. consequence, mixed datasets, complete incomplete rows, two ways computing prediction : either predicts row missing values (missingdata) selects prediction method accordingly completeness row (adaptative). none cross validation standard SIMCA datasets without missing value. datasets missing value, using missingdata missingdata values predicted missing values datasets missing values adaptative predict response value x missing value missing values x without missing value without missing values.  EstimXNA modele=\"pls\". Set whether missing X values estimated. scaleX scale predictor(s) : must set TRUE modele=\"pls\" glms pls. scaleY scale response : Yes/. Ignored since non always possible glm responses. pvals.expli individual p-values reported tune model selection ? alpha.pvals.expli level significance predictors pvals.expli=TRUE MClassed number missclassified cases, used binary responses tol_Xi minimal value Norm2(Xi) \\(\\mathrm{det}(pp' \\times pp)\\) missing value dataX. defaults \\(10^{-12}\\) weights optional vector 'prior weights' used fitting process. NULL numeric vector. subset optional vector specifying subset observations used fitting process. contrasts optional list. See contrasts.arg model.matrix.default. sparse coefficients non-significant predictors (<alpha.pvals.expli) set 0 sparseStop component extraction stop significant predictors (<alpha.pvals.expli) found naive Use naive estimates Degrees Freedom plsR? Default FALSE. verbose info messages displayed ? ... arguments pass plsRmodel.default plsRmodel.formula","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial least squares Regression models with leave one out cross validation — plsR","text":"several ways deal missing values leads different computations leave one cross validation criteria. typical predictor form response ~ terms response (numeric) response vector terms series terms specifies linear predictor response. terms specification form first + second indicates terms first together terms second duplicates removed. specification form first:second indicates set terms obtained taking interactions terms first terms second. specification first*second indicates cross first second. first + second + first:second. terms formula re-ordered main effects come first, followed interactions, second-order, third-order : avoid pass terms object formula. Non-NULL weights can used indicate different observations different dispersions (values weights inversely proportional dispersions); equivalently, elements weights positive integers w_i, response y_i mean w_i unit-weight observations. default estimator Degrees Freedom Kramer Sugiyama's one. Information criteria computed accordingly estimations. Naive Degrees Freedom Information Criteria also provided comparison purposes. details, see N. Kraemer M. Sugiyama. (2011). Degrees Freedom Partial Least Squares Regression. Journal American Statistical Association, 106(494), 697-705, 2011.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial least squares Regression models with leave one out cross validation — plsR","text":"nr Number observations nc Number predictors nt Number requested components ww raw weights (L2-normalization) wwnorm L2 normed weights (used deflated matrices predictor variables) wwetoile modified weights (used original matrix predictor variables) tt PLS components pp loadings predictor variables CoeffC coefficients PLS components uscores scores response variable YChapeau predicted response values dataX set residYChapeau residuals deflated response standardized scale RepY scaled response vector na.miss.Y NA value response vector YNA indicatrix vector missing values RepY residY deflated scaled response vector ExpliX scaled matrix predictors na.miss.X NA value predictor matrix XXNA indicator non-NA values predictor matrix residXX deflated predictor matrix PredictY response values NA replaced 0 press.ind individual PRESS value observation (scaled scale) press.tot total PRESS value observations (scaled scale) family glm family used fit PLSGLR model ttPredictY PLS components dataset prediction requested typeVC type leave one cross-validation used dataX predictor values dataY response values computed_nt number components computed CoeffCFull matrix coefficients predictors CoeffConstante value intercept (scaled scale) Std.Coeffs Vector standardized regression coefficients press.ind2 individual PRESS value observation (original scale) RSSresidY residual sum squares (scaled scale) Coeffs Vector regression coefficients (used original data scale) Yresidus residuals PLS model RSS residual sum squares (original scale) residusY residuals deflated response standardized scale AIC.std AIC.std vs number components (AIC computed standardized model AIC AIC vs number components optional response assumed binary:         .e. MClassed=TRUE. MissClassed Number miss classed results Probs \"Probability\" predicted model. true probabilities since may lay outside [0,1] Probs.trc Probability predicted model constrained belong [0,1]  ttPredictFittedMissingY Description 'comp2' optional cross validation requested:         .e. typeVC=\"standard\", typeVC=\"missingdata\" typeVC=\"adaptative\". R2residY R2 coefficient value standardized scale R2 R2 coefficient value original scale press.tot2 total PRESS value observations (original scale) Q2 Q2 value (standardized scale) limQ2 limit Q2 value Q2_2 Q2 value (original scale) Q2cum cumulated Q2 (standardized scale) Q2cum_2 cumulated Q2 (original scale)  InfCrit table Information Criteria Std.ValsPredictY predicted response values supplementary dataset (standardized scale) ValsPredictY predicted response values supplementary dataset (original scale) Std.XChapeau estimated values missing values predictor matrix (standardized scale) XXwotNA predictor matrix missing values replaced 0","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partial least squares Regression models with leave one out cross validation — plsR","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frederic Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Partial least squares Regression models with leave one out cross validation — plsR","text":"Frederic Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Partial least squares Regression models with leave one out cross validation — plsR","text":"Use cv.plsR cross-validate plsRglm models bootpls bootstrap .","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/plsR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial least squares Regression models with leave one out cross validation — plsR","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8]  #maximum 6 components could be extracted from this dataset #trying 10 to trigger automatic stopping criterion modpls10<-plsR(yCornell,XCornell,10) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  modpls10 #> Number of required components: #> [1] 10 #> Number of successfully computed components: #> [1] 6 #> Coefficients: #>                  [,1] #> Intercept  88.7107982 #> X1        -54.3905712 #> X2         -2.7879678 #> X3         52.5411315 #> X4        -11.5306977 #> X5         -0.9605822 #> X6         11.5900307 #> X7         28.2104803 #> Information criteria and Fit statistics: #>                AIC      RSS_Y      R2_Y R2_residY  RSS_residY    AIC.std #> Nb_Comp_0 82.01205 467.796667        NA        NA 11.00000000  37.010388 #> Nb_Comp_1 53.15173  35.742486 0.9235940 0.9235940  0.84046633   8.150064 #> Nb_Comp_2 41.08283  11.066606 0.9763431 0.9763431  0.26022559  -3.918831 #> Nb_Comp_3 32.06411   4.418081 0.9905556 0.9905556  0.10388893 -12.937550 #> Nb_Comp_4 33.76477   4.309235 0.9907882 0.9907882  0.10132947 -11.236891 #> Nb_Comp_5 33.34373   3.521924 0.9924713 0.9924713  0.08281624 -11.657929 #> Nb_Comp_6 35.25533   3.496074 0.9925265 0.9925265  0.08220840  -9.746328 #>            DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof DoF.naive #> Nb_Comp_0 1.000000    6.5212706 46.0708838 47.7893514 27.59461         1 #> Nb_Comp_1 2.740749    1.8665281  4.5699686  4.9558156 21.34020         2 #> Nb_Comp_2 5.085967    1.1825195  2.1075461  2.3949331 27.40202         3 #> Nb_Comp_3 5.121086    0.7488308  0.8467795  0.9628191 24.40842         4 #> Nb_Comp_4 5.103312    0.7387162  0.8232505  0.9357846 24.23105         5 #> Nb_Comp_5 6.006316    0.7096382  0.7976101  0.9198348 28.21184         6 #> Nb_Comp_6 7.000002    0.7633343  0.9711322  1.1359502 33.18348         7 #>           sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4      0.7846050  0.8721072  0.9964867   24.16510 #> Nb_Comp_5      0.7661509  0.8804809  1.0227979   28.64206 #> Nb_Comp_6      0.8361907  1.1070902  1.3048716   33.63927  #With iterated leave one out CV PRESS modpls6cv<-plsR(Y~.,data=Cornell,6,typeVC=\"standard\") #> ____************************************************____ #> ____TypeVC____ standard ____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  modpls6cv #> Number of required components: #> [1] 6 #> Number of successfully computed components: #> [1] 6 #> Coefficients: #>                  [,1] #> Intercept  88.7107982 #> X1        -54.3905712 #> X2         -2.7879678 #> X3         52.5411315 #> X4        -11.5306977 #> X5         -0.9605822 #> X6         11.5900307 #> X7         28.2104803 #> Leave one out cross validated PRESS, Information criteria and Fit statistics: #>                AIC   Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y      RSS_Y      R2_Y #> Nb_Comp_0 82.01205        NA      NA          NA        NA 467.796667        NA #> Nb_Comp_1 53.15173 0.8966556  0.0975  0.89665563 48.344150  35.742486 0.9235940 #> Nb_Comp_2 41.08283 0.9175426  0.0975  0.20210989 28.518576  11.066606 0.9763431 #> Nb_Comp_3 32.06411 0.9399676  0.0975  0.27195907  8.056942   4.418081 0.9905556 #> Nb_Comp_4 33.76477 0.9197009  0.0975 -0.33759604  5.909608   4.309235 0.9907882 #> Nb_Comp_5 33.34373 0.9281373  0.0975  0.10506161  3.856500   3.521924 0.9924713 #> Nb_Comp_6 35.25533 0.9232562  0.0975 -0.06792167  3.761138   3.496074 0.9925265 #>           R2_residY  RSS_residY PRESS_residY   Q2_residY  LimQ2 Q2cum_residY #> Nb_Comp_0        NA 11.00000000           NA          NA     NA           NA #> Nb_Comp_1 0.9235940  0.84046633   1.13678803  0.89665563 0.0975    0.8966556 #> Nb_Comp_2 0.9763431  0.26022559   0.67059977  0.20210989 0.0975    0.9175426 #> Nb_Comp_3 0.9905556  0.10388893   0.18945488  0.27195907 0.0975    0.9399676 #> Nb_Comp_4 0.9907882  0.10132947   0.13896142 -0.33759604 0.0975    0.9197009 #> Nb_Comp_5 0.9924713  0.08281624   0.09068364  0.10506161 0.0975    0.9281373 #> Nb_Comp_6 0.9925265  0.08220840   0.08844125 -0.06792167 0.0975    0.9232562 #>              AIC.std  DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof #> Nb_Comp_0  37.010388 1.000000    6.5212706 46.0708838 47.7893514 27.59461 #> Nb_Comp_1   8.150064 2.740749    1.8665281  4.5699686  4.9558156 21.34020 #> Nb_Comp_2  -3.918831 5.085967    1.1825195  2.1075461  2.3949331 27.40202 #> Nb_Comp_3 -12.937550 5.121086    0.7488308  0.8467795  0.9628191 24.40842 #> Nb_Comp_4 -11.236891 5.103312    0.7387162  0.8232505  0.9357846 24.23105 #> Nb_Comp_5 -11.657929 6.006316    0.7096382  0.7976101  0.9198348 28.21184 #> Nb_Comp_6  -9.746328 7.000002    0.7633343  0.9711322  1.1359502 33.18348 #>           DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0         1      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1         2      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2         3      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3         4      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4         5      0.7846050  0.8721072  0.9964867   24.16510 #> Nb_Comp_5         6      0.7661509  0.8804809  1.0227979   28.64206 #> Nb_Comp_6         7      0.8361907  1.1070902  1.3048716   33.63927 cv.modpls<-cv.plsR(Y~.,data=Cornell,6,NK=100, verbose=FALSE) res.cv.modpls<-cvtable(summary(cv.modpls)) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1,  2,  3,  4,  5,  6,  7,  8,  9,  10 #> NK: 11,  12,  13,  14,  15,  16,  17,  18,  19,  20 #> NK: 21,  22,  23,  24,  25,  26,  27,  28,  29,  30 #> NK: 31,  32,  33,  34,  35,  36,  37,  38,  39,  40 #> NK: 41,  42,  43,  44,  45,  46,  47,  48,  49,  50 #> NK: 51,  52,  53,  54,  55,  56,  57,  58,  59,  60 #> NK: 61,  62,  63,  64,  65,  66,  67,  68,  69,  70 #> NK: 71,  72,  73,  74,  75,  76,  77,  78,  79,  80 #> NK: 81,  82,  83,  84,  85,  86,  87,  88,  89,  90 #> NK: 91,  92,  93,  94,  95,  96,  97,  98,  99,  100 #>  #> CV Q2 criterion: #>  0  1  2  #>  0 86 14  #>  #> CV Press criterion: #>  1  2  3  4  5  #>  0  1 31 52 16  plot(res.cv.modpls)   rm(list=c(\"XCornell\",\"yCornell\",\"modpls10\",\"modpls6cv\"))  # \\donttest{ #A binary response example data(aze_compl) Xaze_compl<-aze_compl[,2:34] yaze_compl<-aze_compl$y modpls.aze <- plsR(yaze_compl,Xaze_compl,10,MClassed=TRUE,typeVC=\"standard\") #> ____************************************************____ #> ____TypeVC____ standard ____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  modpls.aze #> Number of required components: #> [1] 10 #> Number of successfully computed components: #> [1] 10 #> Coefficients: #>                   [,1] #> Intercept  0.308019808 #> D2S138    -0.131218617 #> D18S61     0.450219840 #> D16S422   -0.183848373 #> D17S794    0.269084083 #> D6S264     0.105061098 #> D14S65    -0.052837918 #> D18S53     0.008489326 #> D17S790   -0.213122117 #> D1S225     0.046277290 #> D3S1282   -0.095666162 #> D9S179     0.054547887 #> D5S430    -0.126491043 #> D8S283     0.106373432 #> D11S916    0.111623381 #> D2S159     0.056759714 #> D16S408    0.010288859 #> D5S346     0.233674850 #> D10S191    0.010715856 #> D13S173    0.074148740 #> D6S275    -0.123145693 #> D15S127    0.064566148 #> D1S305     0.190500469 #> D4S394    -0.142585807 #> D20S107   -0.184483600 #> D1S197    -0.284373695 #> D1S207     0.186728597 #> D10S192    0.195516079 #> D3S1283   -0.096309755 #> D4S414     0.017960975 #> D8S264     0.121051206 #> D22S928   -0.049091794 #> TP53      -0.391965015 #> D9S171    -0.012315197 #> Leave one out cross validated PRESS, Information criteria and Fit statistics: #>                 AIC      Q2cum_Y LimQ2_Y        Q2_Y  PRESS_Y    RSS_Y #> Nb_Comp_0  154.6179           NA      NA          NA       NA 25.91346 #> Nb_Comp_1  126.4083  -0.09840016  0.0975 -0.09840016 28.46335 19.38086 #> Nb_Comp_2  119.3375  -0.19018163  0.0975 -0.08355923 21.00031 17.76209 #> Nb_Comp_3  114.2313  -0.77332918  0.0975 -0.48996518 26.46489 16.58896 #> Nb_Comp_4  112.3463  -1.64635954  0.0975 -0.49231150 24.75590 15.98071 #> Nb_Comp_5  113.2362  -2.74242209  0.0975 -0.41417749 22.59955 15.81104 #> Nb_Comp_6  114.7620  -4.46009228  0.0975 -0.45897286 23.06788 15.73910 #> Nb_Comp_7  116.5264  -7.36664482  0.0975 -0.53232663 24.11744 15.70350 #> Nb_Comp_8  118.4601 -11.80011367  0.0975 -0.52989806 24.02475 15.69348 #> Nb_Comp_9  120.4452 -17.90787273  0.0975 -0.47716444 23.18185 15.69123 #> Nb_Comp_10 122.4395 -26.50536212  0.0975 -0.45470421 22.82610 15.69037 #>                 R2_Y MissClassed R2_residY RSS_residY PRESS_residY   Q2_residY #> Nb_Comp_0         NA          49        NA  103.00000           NA          NA #> Nb_Comp_1  0.2520929          27 0.2520929   77.03443    113.13522 -0.09840016 #> Nb_Comp_2  0.3145613          25 0.3145613   70.60018     83.47137 -0.08355923 #> Nb_Comp_3  0.3598323          27 0.3598323   65.93728    105.19181 -0.48996518 #> Nb_Comp_4  0.3833049          23 0.3833049   63.51960     98.39895 -0.49231150 #> Nb_Comp_5  0.3898523          22 0.3898523   62.84522     89.82798 -0.41417749 #> Nb_Comp_6  0.3926285          21 0.3926285   62.55927     91.68947 -0.45897286 #> Nb_Comp_7  0.3940024          20 0.3940024   62.41775     95.86123 -0.53232663 #> Nb_Comp_8  0.3943888          20 0.3943888   62.37795     95.49280 -0.52989806 #> Nb_Comp_9  0.3944758          19 0.3944758   62.36900     92.14249 -0.47716444 #> Nb_Comp_10 0.3945088          19 0.3945088   62.36560     90.72844 -0.45470421 #>             LimQ2 Q2cum_residY  AIC.std  DoF.dof sigmahat.dof   AIC.dof #> Nb_Comp_0      NA           NA 298.1344  1.00000    0.5015845 0.2540061 #> Nb_Comp_1  0.0975  -0.09840016 269.9248 22.55372    0.4848429 0.2883114 #> Nb_Comp_2  0.0975  -0.19018163 262.8540 27.31542    0.4781670 0.2908950 #> Nb_Comp_3  0.0975  -0.77332918 257.7478 30.52370    0.4719550 0.2902572 #> Nb_Comp_4  0.0975  -1.64635954 255.8628 34.00000    0.4744263 0.3008285 #> Nb_Comp_5  0.0975  -2.74242209 256.7527 34.00000    0.4719012 0.2976347 #> Nb_Comp_6  0.0975  -4.46009228 258.2785 34.00000    0.4708264 0.2962804 #> Nb_Comp_7  0.0975  -7.36664482 260.0429 33.71066    0.4693382 0.2937976 #> Nb_Comp_8  0.0975 -11.80011367 261.9766 34.00000    0.4701436 0.2954217 #> Nb_Comp_9  0.0975 -17.90787273 263.9617 33.87284    0.4696894 0.2945815 #> Nb_Comp_10 0.0975 -26.50536212 265.9560 34.00000    0.4700970 0.2953632 #>              BIC.dof  GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive #> Nb_Comp_0  0.2604032 -67.17645         1      0.5015845 0.2540061 0.2604032 #> Nb_Comp_1  0.4231184 -53.56607         2      0.4358996 0.1936625 0.2033251 #> Nb_Comp_2  0.4496983 -52.42272         3      0.4193593 0.1809352 0.1943501 #> Nb_Comp_3  0.4631316 -51.93343         4      0.4072955 0.1722700 0.1891422 #> Nb_Comp_4  0.4954133 -50.37079         5      0.4017727 0.1691819 0.1897041 #> Nb_Comp_5  0.4901536 -50.65724         6      0.4016679 0.1706451 0.1952588 #> Nb_Comp_6  0.4879234 -50.78005         7      0.4028135 0.1731800 0.2020601 #> Nb_Comp_7  0.4826103 -51.05525         8      0.4044479 0.1761610 0.2094352 #> Nb_Comp_8  0.4865092 -50.85833         9      0.4064413 0.1794902 0.2172936 #> Nb_Comp_9  0.4845867 -50.95616        10      0.4085682 0.1829787 0.2254232 #> Nb_Comp_10 0.4864128 -50.86368        11      0.4107477 0.1865584 0.2337468 #>            GMDL.naive #> Nb_Comp_0   -67.17645 #> Nb_Comp_1   -79.67755 #> Nb_Comp_2   -81.93501 #> Nb_Comp_3   -83.31503 #> Nb_Comp_4   -83.23369 #> Nb_Comp_5   -81.93513 #> Nb_Comp_6   -80.42345 #> Nb_Comp_7   -78.87607 #> Nb_Comp_8   -77.31942 #> Nb_Comp_9   -75.80069 #> Nb_Comp_10  -74.33325  #Direct access to not cross-validated values modpls.aze$AIC #>          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]    [,7]     [,8] #> [1,] 154.6179 126.4083 119.3375 114.2313 112.3463 113.2362 114.762 116.5264 #>          [,9]    [,10]    [,11] #> [1,] 118.4601 120.4452 122.4395 modpls.aze$AIC.std #>          [,1]     [,2]    [,3]     [,4]     [,5]     [,6]     [,7]     [,8] #> [1,] 298.1344 269.9248 262.854 257.7478 255.8628 256.7527 258.2785 260.0429 #>          [,9]    [,10]   [,11] #> [1,] 261.9766 263.9617 265.956 modpls.aze$MissClassed #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] #> [1,]   49   27   25   27   23   22   21   20   20    19    19  #Raw predicted values (not really probabily since not constrained in [0,1] modpls.aze$Probs #>          [,1]        [,2]        [,3]        [,4]        [,5]        [,6] #> 1   0.4711538  0.46105744  0.63458141  0.67961627  0.69452246  0.64534767 #> 2   0.4711538  0.26911816  0.26581497  0.16989268  0.11760783  0.18096700 #> 3   0.4711538 -0.09080494 -0.05104846 -0.17166916 -0.21455242 -0.21725391 #> 4   0.4711538  0.36370490  0.54112657  0.50724821  0.55508565  0.57773785 #> 5   0.4711538 -0.04408124  0.07399231 -0.07129909 -0.24018962 -0.23445282 #> 6   0.4711538 -0.03776963  0.17275288  0.01806190 -0.02597539 -0.06284454 #> 7   0.4711538 -0.06930728 -0.19928456 -0.09137261  0.01116043  0.06506517 #> 8   0.4711538  0.27158233  0.24933653  0.11611522  0.12804487  0.04118115 #> 9   0.4711538  0.76949497  0.60296556  0.47237794  0.51581382  0.49885092 #> 10  0.4711538  0.22096539  0.34482052  0.34660816  0.38580378  0.43528451 #> 11  0.4711538  0.87147914  0.84865348  0.76372713  0.73582307  0.76725258 #> 12  0.4711538  0.79792975  0.67828859  0.73747065  0.67844373  0.67908585 #> 13  0.4711538  0.09432664 -0.04344681  0.10780023  0.22488457  0.26144110 #> 14  0.4711538  0.28543133  0.29293086  0.37385135  0.37961001  0.30207755 #> 15  0.4711538  0.30637401  0.27816310  0.18074751  0.01510565  0.05074255 #> 16  0.4711538  0.12893721 -0.07276258 -0.05146556 -0.09988241 -0.06790398 #> 17  0.4711538  0.59910292  0.41302582  0.40055026  0.32477692  0.32429673 #> 18  0.4711538  0.60665328  0.51461671  0.70351041  0.63093215  0.60232625 #> 19  0.4711538  0.18381206  0.36596047  0.33591603  0.25289460  0.21859872 #> 20  0.4711538  0.28422822  0.15202852  0.29980632  0.42075827  0.43463142 #> 21  0.4711538  0.35982960  0.40300075  0.63220247  0.58056075  0.55273462 #> 22  0.4711538  0.31574837  0.28422517  0.37116719  0.27156145  0.25529246 #> 23  0.4711538  0.41682757  0.36900849  0.23791176  0.25730930  0.24221472 #> 24  0.4711538  0.30288056  0.15972272  0.19362318  0.07194768  0.07250435 #> 25  0.4711538  0.29650015  0.48867070  0.61025747  0.59737342  0.67704212 #> 26  0.4711538  0.23008536  0.32001822  0.15862645  0.26312675  0.22513847 #> 27  0.4711538  0.67526360  0.68123526  0.58796740  0.51309143  0.44381568 #> 28  0.4711538  0.15222775  0.13544964  0.15605402  0.15868232  0.10574096 #> 29  0.4711538  0.43138914  0.29576924  0.29706087  0.35294305  0.40257625 #> 30  0.4711538  0.13910581  0.26763382  0.10182481  0.12169881  0.13543560 #> 31  0.4711538  0.40295972  0.43810789  0.28684877  0.41632594  0.45388666 #> 32  0.4711538  0.58422149  0.44366239  0.16615851  0.15367980  0.18291151 #> 33  0.4711538  0.69889100  0.72592310  0.57845537  0.50185886  0.51841164 #> 34  0.4711538  0.35960908  0.24234167  0.09364940  0.08428214  0.10528276 #> 35  0.4711538  0.27914959  0.03731133 -0.08896074 -0.06232370 -0.08231459 #> 36  0.4711538  0.38865989  0.39024480  0.44138316  0.47508801  0.42329842 #> 37  0.4711538  0.62200134  0.42145828  0.38142396  0.29675933  0.28947211 #> 38  0.4711538  0.41311694  0.19970983  0.16702613  0.17059545  0.17073272 #> 39  0.4711538  0.31755422  0.28395547  0.17609314  0.23875966  0.25763504 #> 40  0.4711538  0.62628933  0.51627261  0.52025889  0.47789760  0.47304606 #> 41  0.4711538  0.14894845  0.14069540  0.13906223  0.05976750  0.13670893 #> 42  0.4711538  0.64041121  0.49727655  0.49380105  0.53239359  0.51394469 #> 43  0.4711538  0.38696544  0.54930653  0.62650411  0.65244562  0.56755351 #> 44  0.4711538  0.24204195  0.05825611  0.02230584 -0.01790809 -0.03785626 #> 45  0.4711538  0.10349021  0.14957660  0.16304594  0.15564790  0.17065395 #> 46  0.4711538  0.63322787  0.64625855  0.55541948  0.65203351  0.63670168 #> 47  0.4711538  0.20557889  0.23864853  0.24328712  0.13063078  0.09743813 #> 48  0.4711538  0.32352238  0.34894312  0.21162810  0.20487572  0.16461876 #> 49  0.4711538  0.64888519  0.52290405  0.50926772  0.62061797  0.59597941 #> 50  0.4711538  0.44153005  0.49754241  0.32749149  0.24840605  0.32456388 #> 51  0.4711538  0.32562433  0.23887414  0.26764033  0.24950898  0.30432045 #> 52  0.4711538 -0.23250098 -0.28713647 -0.09216174 -0.12709475 -0.18324647 #> 53  0.4711538  0.53388610  0.47710127  0.60836140  0.48273912  0.43334108 #> 54  0.4711538  0.64191356  0.44931093  0.46371798  0.45275305  0.46653696 #> 55  0.4711538  0.05279255  0.06829351  0.15306458  0.25200214  0.21249173 #> 56  0.4711538  0.59808020  0.64333345  0.53741245  0.64108173  0.57876914 #> 57  0.4711538  0.53093147  0.62138656  0.92046148  0.93004391  0.95130430 #> 58  0.4711538  0.64943097  0.57141374  0.66800038  0.64835800  0.65566321 #> 59  0.4711538  0.42541400  0.43027409  0.30117492  0.36183156  0.29992796 #> 60  0.4711538  0.24537249  0.29963849  0.42931558  0.51048830  0.58927966 #> 61  0.4711538  0.64269314  0.62785202  0.75163561  0.68045267  0.67000184 #> 62  0.4711538  0.51277761  0.60877778  0.75493489  0.66735142  0.63862193 #> 63  0.4711538  0.53377378  0.53228159  0.56245626  0.58414332  0.61176055 #> 64  0.4711538  0.79099666  0.90572246  0.92244949  0.93001276  0.93454809 #> 65  0.4711538  0.73768777  0.61339931  0.72362105  0.70536287  0.69970096 #> 66  0.4711538  0.70767466  0.53408924  0.50675818  0.52181506  0.54559559 #> 67  0.4711538  0.96312042  1.17012215  1.08116795  1.22497425  1.21728258 #> 68  0.4711538  0.31575995  0.57179559  0.77297374  0.78532935  0.78484987 #> 69  0.4711538  0.69505872  0.78176548  0.74300700  0.72711033  0.70750770 #> 70  0.4711538  0.72276362  0.90232185  0.89364576  0.84428623  0.92659977 #> 71  0.4711538  0.50950893  0.39503961  0.45591683  0.38297596  0.35086204 #> 72  0.4711538  0.14720074  0.13538571 -0.04473829 -0.05529233  0.02748516 #> 73  0.4711538  0.49275110  0.44937896  0.41856171  0.62470016  0.61654596 #> 74  0.4711538  0.65674324  0.69439259  0.75479685  0.88511667  0.92560996 #> 75  0.4711538  0.68716407  0.57541914  0.59945962  0.54581071  0.55228791 #> 76  0.4711538  0.54839542  0.50508123  0.52627725  0.55765709  0.52543838 #> 77  0.4711538  0.77317727  0.79812663  0.93073165  1.10301473  1.08723742 #> 78  0.4711538  0.85322027  0.76128342  0.81061207  0.85796753  0.87947603 #> 79  0.4711538  0.81659194  0.90228252  0.80744839  0.70383361  0.68468090 #> 80  0.4711538  0.55964651  0.44326524  0.39507689  0.36149039  0.32071350 #> 81  0.4711538  0.87105473  0.86695796  0.89177640  0.74816339  0.69831750 #> 82  0.4711538  0.47715869  0.68930595  0.71280202  0.73606020  0.78321326 #> 83  0.4711538  0.80974821  0.87138779  0.97466313  0.93082943  0.95560886 #> 84  0.4711538  0.67739807  0.85743609  0.98894432  0.96011041  0.90800271 #> 85  0.4711538  0.57131444  0.34250950  0.33855791  0.31118498  0.31383288 #> 86  0.4711538  0.84958765  0.97611051  0.93090902  0.91560248  0.86222031 #> 87  0.4711538  0.57644613  0.41449248  0.48714466  0.54811918  0.57041511 #> 88  0.4711538  0.75932310  0.71214369  0.52234742  0.59011684  0.59023780 #> 89  0.4711538  0.53031516  0.47090892  0.42433053  0.38847912  0.39218094 #> 90  0.4711538  0.76770402  1.07649866  1.00864429  1.06363018  1.09017457 #> 91  0.4711538  0.38643842  0.37696993  0.44452861  0.49450298  0.46628856 #> 92  0.4711538  0.92591633  1.03707888  0.96084369  0.95688931  0.93400393 #> 93  0.4711538  0.66726042  0.89247800  0.87390628  0.87335977  0.95801535 #> 94  0.4711538  0.32634752  0.41373057  0.48066349  0.67273089  0.62115180 #> 95  0.4711538  0.50472276  0.77159222  0.71730564  0.62350221  0.64335334 #> 96  0.4711538  0.34622269  0.33150717  0.49412629  0.44574013  0.46889514 #> 97  0.4711538  0.55805257  0.50280611  0.58541977  0.52239953  0.53556273 #> 98  0.4711538  0.78090964  0.73429355  0.79385683  0.86651416  0.88151677 #> 99  0.4711538  0.21116352  0.10917861  0.02565398  0.18342015  0.15222876 #> 100 0.4711538  0.66672702  0.78264411  0.86306662  0.75733969  0.77632472 #> 101 0.4711538  0.45317545  0.50149615  0.62617428  0.70904267  0.78134354 #> 102 0.4711538  0.74435376  0.66135006  0.72568147  0.70203564  0.77593538 #> 103 0.4711538  0.34690226  0.56605434  0.52782336  0.50951738  0.46795757 #> 104 0.4711538  0.69496014  0.80515138  0.78871059  0.78008789  0.78042831 #>            [,7]         [,8]         [,9]       [,10]       [,11] #> 1    0.64037279  0.627340571  0.651243676  0.65354280  0.65838797 #> 2    0.21304385  0.202666528  0.206463548  0.21046038  0.20470356 #> 3   -0.22444089 -0.193652144 -0.201652437 -0.20167289 -0.20081532 #> 4    0.58413761  0.600377920  0.608768219  0.60784745  0.60193905 #> 5   -0.26327049 -0.311781941 -0.310765976 -0.31066830 -0.31401382 #> 6   -0.10341096 -0.076840858 -0.080016598 -0.08436785 -0.08777135 #> 7    0.10261786  0.132750517  0.144750243  0.13944940  0.14173177 #> 8    0.04809780  0.063736599  0.063261540  0.07570783  0.07715150 #> 9    0.44543808  0.444943670  0.447021225  0.44582742  0.44748513 #> 10   0.43490588  0.407005593  0.413663760  0.41349216  0.41350336 #> 11   0.78695284  0.777623618  0.783734315  0.78262765  0.77949531 #> 12   0.65654818  0.642154505  0.633436560  0.63197252  0.62875264 #> 13   0.21708341  0.187509114  0.186533541  0.17822088  0.17842513 #> 14   0.28651410  0.260501290  0.279081223  0.27196942  0.26996735 #> 15   0.05784774  0.095949877  0.090894676  0.08865039  0.09080522 #> 16  -0.06239212 -0.039505632 -0.023469898 -0.02045198 -0.02715190 #> 17   0.33482409  0.336193547  0.335468481  0.33501592  0.33670840 #> 18   0.59257402  0.580678556  0.581449676  0.58013547  0.57927640 #> 19   0.24272344  0.246701307  0.240991178  0.23822863  0.23157123 #> 20   0.40555564  0.386074751  0.400419290  0.40843493  0.40860630 #> 21   0.53582205  0.549336181  0.539598759  0.54139679  0.54098845 #> 22   0.27214775  0.265323031  0.262889367  0.27124503  0.27372049 #> 23   0.26310951  0.254264842  0.244111736  0.24044626  0.24169731 #> 24   0.10789143  0.136298989  0.142908568  0.14863967  0.15404679 #> 25   0.62754156  0.650367844  0.644944061  0.64644697  0.64416177 #> 26   0.18477380  0.190402191  0.199245619  0.20152378  0.20582432 #> 27   0.44358238  0.454283166  0.446210009  0.43311399  0.43568840 #> 28   0.13769251  0.118081488  0.117589648  0.11048814  0.11155803 #> 29   0.42759376  0.424018002  0.417256036  0.42362830  0.42160066 #> 30   0.10952676  0.168692282  0.174041713  0.17387211  0.17480429 #> 31   0.45876287  0.432435790  0.425259491  0.43329412  0.43856907 #> 32   0.11742399  0.116981896  0.108778824  0.10636129  0.10689920 #> 33   0.47697376  0.450738829  0.452062165  0.44881973  0.44992624 #> 34   0.09863470  0.095862956  0.092253997  0.09980718  0.10084230 #> 35  -0.08390506 -0.085155814 -0.086690885 -0.08262604 -0.08272575 #> 36   0.45381739  0.433667887  0.449594388  0.44854107  0.44960414 #> 37   0.30022320  0.311627620  0.315020647  0.31958491  0.32067580 #> 38   0.15959719  0.160997289  0.151222415  0.15079738  0.14817778 #> 39   0.27800144  0.253643110  0.255071837  0.25875102  0.25674198 #> 40   0.51555833  0.530347073  0.528402618  0.52790558  0.52538704 #> 41   0.09275154  0.101869980  0.090604733  0.09445259  0.09150467 #> 42   0.50207194  0.483136866  0.487491071  0.48860245  0.49212211 #> 43   0.57336835  0.573091866  0.546609274  0.54001848  0.54366888 #> 44  -0.01451487 -0.004369241 -0.002647953 -0.00844687 -0.01073887 #> 45   0.19657318  0.164988597  0.170522098  0.16781405  0.16715155 #> 46   0.65287559  0.645084587  0.651535848  0.65177845  0.65178893 #> 47   0.12452036  0.119913760  0.117053912  0.11873700  0.11591426 #> 48   0.18275993  0.166998459  0.160605969  0.16869180  0.16855238 #> 49   0.58006784  0.613009102  0.608873759  0.60785525  0.61021103 #> 50   0.33208894  0.314978063  0.311974842  0.30517646  0.31174053 #> 51   0.32816749  0.318321881  0.320797741  0.31281691  0.31540371 #> 52  -0.19584259 -0.184768370 -0.177691131 -0.18225253 -0.18172040 #> 53   0.40794213  0.415136651  0.416044038  0.42408314  0.42075636 #> 54   0.46480524  0.479688395  0.471302624  0.46613648  0.46656474 #> 55   0.23097197  0.213772954  0.189358085  0.18930563  0.19050731 #> 56   0.57331393  0.574558380  0.579775660  0.57922184  0.57800858 #> 57   0.96183872  0.975414458  0.968855613  0.96385549  0.96028958 #> 58   0.64361788  0.631632631  0.641013340  0.63785489  0.64045306 #> 59   0.28643229  0.289148607  0.278791345  0.28784917  0.28782462 #> 60   0.55978204  0.559023840  0.561630138  0.55671889  0.55726966 #> 61   0.65787202  0.659412106  0.650588243  0.64930310  0.65091617 #> 62   0.60705201  0.603977438  0.589826600  0.58812271  0.58793743 #> 63   0.63813827  0.617717657  0.614454772  0.61166047  0.60985403 #> 64   1.00166279  1.008968255  1.008852814  1.01022555  1.00666729 #> 65   0.69297263  0.697694744  0.689810628  0.69214943  0.69038662 #> 66   0.53663407  0.532369158  0.535934708  0.53171176  0.53102146 #> 67   1.22111150  1.202569147  1.194030443  1.19310867  1.19228184 #> 68   0.80071187  0.812462410  0.796883689  0.80360414  0.80689017 #> 69   0.74791867  0.774669023  0.764357440  0.76435231  0.76730276 #> 70   0.93952180  0.926356875  0.916496158  0.91637035  0.92383169 #> 71   0.31179970  0.319584982  0.342996678  0.34334588  0.34349096 #> 72   0.08069763  0.064883087  0.053282640  0.04500807  0.04571864 #> 73   0.63914960  0.656024336  0.647841400  0.64971036  0.64930911 #> 74   0.94540783  0.945531101  0.947433351  0.95548576  0.95086945 #> 75   0.56609663  0.581051527  0.586510546  0.58350518  0.58195688 #> 76   0.49807985  0.507124137  0.503700114  0.50352891  0.50289031 #> 77   1.06463806  1.090636226  1.099163425  1.09692704  1.09684987 #> 78   0.88947890  0.914074686  0.921993535  0.92611779  0.92473772 #> 79   0.70672170  0.689699520  0.693322761  0.69306283  0.69031633 #> 80   0.30181332  0.296560012  0.282907508  0.28672758  0.28334638 #> 81   0.69871492  0.692603330  0.692711040  0.69448149  0.69353087 #> 82   0.73754433  0.755515607  0.753806256  0.76075515  0.76006115 #> 83   0.95554583  0.981114506  0.967899112  0.96789876  0.97167928 #> 84   0.92460814  0.928255751  0.934569121  0.93157477  0.93560641 #> 85   0.31932547  0.326702214  0.334191767  0.33780085  0.33863677 #> 86   0.82950069  0.806588554  0.823792983  0.82202715  0.81981455 #> 87   0.56750119  0.560439488  0.549720853  0.54609905  0.54656224 #> 88   0.57484476  0.588841816  0.582284530  0.57334028  0.57098492 #> 89   0.44028895  0.455790854  0.462215323  0.46149391  0.46635298 #> 90   1.08703587  1.113909884  1.123382027  1.12669615  1.12559691 #> 91   0.50591629  0.528734399  0.542033081  0.53789411  0.54025902 #> 92   0.95078882  0.944122848  0.933909143  0.93429933  0.92818920 #> 93   0.95048831  0.984993815  0.999870929  0.99916201  0.99970721 #> 94   0.63222931  0.617803323  0.604620965  0.60316670  0.59998131 #> 95   0.60173453  0.598838861  0.615665753  0.61062288  0.61003734 #> 96   0.42461082  0.393735123  0.382307431  0.38698306  0.38928062 #> 97   0.55493331  0.545341350  0.548945997  0.55196226  0.55110104 #> 98   0.84875293  0.849088124  0.833445596  0.82896512  0.82882885 #> 99   0.12817884  0.125184677  0.142524174  0.14250387  0.14467219 #> 100  0.76010896  0.740234308  0.744642249  0.75159300  0.75722807 #> 101  0.80270481  0.778624924  0.777761525  0.78102072  0.77766043 #> 102  0.77647730  0.755860583  0.764875857  0.76840548  0.77181270 #> 103  0.50588630  0.488855008  0.495423757  0.50188675  0.50526664 #> 104  0.81071639  0.804180721  0.825464815  0.81861016  0.81635531 #Truncated to [0;1] predicted values (true probabilities) modpls.aze$Probs.trc #>          [,1]       [,2]       [,3]       [,4]       [,5]       [,6]       [,7] #> 1   0.4711538 0.46105744 0.63458141 0.67961627 0.69452246 0.64534767 0.64037279 #> 2   0.4711538 0.26911816 0.26581497 0.16989268 0.11760783 0.18096700 0.21304385 #> 3   0.4711538 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 #> 4   0.4711538 0.36370490 0.54112657 0.50724821 0.55508565 0.57773785 0.58413761 #> 5   0.4711538 0.00000000 0.07399231 0.00000000 0.00000000 0.00000000 0.00000000 #> 6   0.4711538 0.00000000 0.17275288 0.01806190 0.00000000 0.00000000 0.00000000 #> 7   0.4711538 0.00000000 0.00000000 0.00000000 0.01116043 0.06506517 0.10261786 #> 8   0.4711538 0.27158233 0.24933653 0.11611522 0.12804487 0.04118115 0.04809780 #> 9   0.4711538 0.76949497 0.60296556 0.47237794 0.51581382 0.49885092 0.44543808 #> 10  0.4711538 0.22096539 0.34482052 0.34660816 0.38580378 0.43528451 0.43490588 #> 11  0.4711538 0.87147914 0.84865348 0.76372713 0.73582307 0.76725258 0.78695284 #> 12  0.4711538 0.79792975 0.67828859 0.73747065 0.67844373 0.67908585 0.65654818 #> 13  0.4711538 0.09432664 0.00000000 0.10780023 0.22488457 0.26144110 0.21708341 #> 14  0.4711538 0.28543133 0.29293086 0.37385135 0.37961001 0.30207755 0.28651410 #> 15  0.4711538 0.30637401 0.27816310 0.18074751 0.01510565 0.05074255 0.05784774 #> 16  0.4711538 0.12893721 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 #> 17  0.4711538 0.59910292 0.41302582 0.40055026 0.32477692 0.32429673 0.33482409 #> 18  0.4711538 0.60665328 0.51461671 0.70351041 0.63093215 0.60232625 0.59257402 #> 19  0.4711538 0.18381206 0.36596047 0.33591603 0.25289460 0.21859872 0.24272344 #> 20  0.4711538 0.28422822 0.15202852 0.29980632 0.42075827 0.43463142 0.40555564 #> 21  0.4711538 0.35982960 0.40300075 0.63220247 0.58056075 0.55273462 0.53582205 #> 22  0.4711538 0.31574837 0.28422517 0.37116719 0.27156145 0.25529246 0.27214775 #> 23  0.4711538 0.41682757 0.36900849 0.23791176 0.25730930 0.24221472 0.26310951 #> 24  0.4711538 0.30288056 0.15972272 0.19362318 0.07194768 0.07250435 0.10789143 #> 25  0.4711538 0.29650015 0.48867070 0.61025747 0.59737342 0.67704212 0.62754156 #> 26  0.4711538 0.23008536 0.32001822 0.15862645 0.26312675 0.22513847 0.18477380 #> 27  0.4711538 0.67526360 0.68123526 0.58796740 0.51309143 0.44381568 0.44358238 #> 28  0.4711538 0.15222775 0.13544964 0.15605402 0.15868232 0.10574096 0.13769251 #> 29  0.4711538 0.43138914 0.29576924 0.29706087 0.35294305 0.40257625 0.42759376 #> 30  0.4711538 0.13910581 0.26763382 0.10182481 0.12169881 0.13543560 0.10952676 #> 31  0.4711538 0.40295972 0.43810789 0.28684877 0.41632594 0.45388666 0.45876287 #> 32  0.4711538 0.58422149 0.44366239 0.16615851 0.15367980 0.18291151 0.11742399 #> 33  0.4711538 0.69889100 0.72592310 0.57845537 0.50185886 0.51841164 0.47697376 #> 34  0.4711538 0.35960908 0.24234167 0.09364940 0.08428214 0.10528276 0.09863470 #> 35  0.4711538 0.27914959 0.03731133 0.00000000 0.00000000 0.00000000 0.00000000 #> 36  0.4711538 0.38865989 0.39024480 0.44138316 0.47508801 0.42329842 0.45381739 #> 37  0.4711538 0.62200134 0.42145828 0.38142396 0.29675933 0.28947211 0.30022320 #> 38  0.4711538 0.41311694 0.19970983 0.16702613 0.17059545 0.17073272 0.15959719 #> 39  0.4711538 0.31755422 0.28395547 0.17609314 0.23875966 0.25763504 0.27800144 #> 40  0.4711538 0.62628933 0.51627261 0.52025889 0.47789760 0.47304606 0.51555833 #> 41  0.4711538 0.14894845 0.14069540 0.13906223 0.05976750 0.13670893 0.09275154 #> 42  0.4711538 0.64041121 0.49727655 0.49380105 0.53239359 0.51394469 0.50207194 #> 43  0.4711538 0.38696544 0.54930653 0.62650411 0.65244562 0.56755351 0.57336835 #> 44  0.4711538 0.24204195 0.05825611 0.02230584 0.00000000 0.00000000 0.00000000 #> 45  0.4711538 0.10349021 0.14957660 0.16304594 0.15564790 0.17065395 0.19657318 #> 46  0.4711538 0.63322787 0.64625855 0.55541948 0.65203351 0.63670168 0.65287559 #> 47  0.4711538 0.20557889 0.23864853 0.24328712 0.13063078 0.09743813 0.12452036 #> 48  0.4711538 0.32352238 0.34894312 0.21162810 0.20487572 0.16461876 0.18275993 #> 49  0.4711538 0.64888519 0.52290405 0.50926772 0.62061797 0.59597941 0.58006784 #> 50  0.4711538 0.44153005 0.49754241 0.32749149 0.24840605 0.32456388 0.33208894 #> 51  0.4711538 0.32562433 0.23887414 0.26764033 0.24950898 0.30432045 0.32816749 #> 52  0.4711538 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 #> 53  0.4711538 0.53388610 0.47710127 0.60836140 0.48273912 0.43334108 0.40794213 #> 54  0.4711538 0.64191356 0.44931093 0.46371798 0.45275305 0.46653696 0.46480524 #> 55  0.4711538 0.05279255 0.06829351 0.15306458 0.25200214 0.21249173 0.23097197 #> 56  0.4711538 0.59808020 0.64333345 0.53741245 0.64108173 0.57876914 0.57331393 #> 57  0.4711538 0.53093147 0.62138656 0.92046148 0.93004391 0.95130430 0.96183872 #> 58  0.4711538 0.64943097 0.57141374 0.66800038 0.64835800 0.65566321 0.64361788 #> 59  0.4711538 0.42541400 0.43027409 0.30117492 0.36183156 0.29992796 0.28643229 #> 60  0.4711538 0.24537249 0.29963849 0.42931558 0.51048830 0.58927966 0.55978204 #> 61  0.4711538 0.64269314 0.62785202 0.75163561 0.68045267 0.67000184 0.65787202 #> 62  0.4711538 0.51277761 0.60877778 0.75493489 0.66735142 0.63862193 0.60705201 #> 63  0.4711538 0.53377378 0.53228159 0.56245626 0.58414332 0.61176055 0.63813827 #> 64  0.4711538 0.79099666 0.90572246 0.92244949 0.93001276 0.93454809 1.00000000 #> 65  0.4711538 0.73768777 0.61339931 0.72362105 0.70536287 0.69970096 0.69297263 #> 66  0.4711538 0.70767466 0.53408924 0.50675818 0.52181506 0.54559559 0.53663407 #> 67  0.4711538 0.96312042 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000 #> 68  0.4711538 0.31575995 0.57179559 0.77297374 0.78532935 0.78484987 0.80071187 #> 69  0.4711538 0.69505872 0.78176548 0.74300700 0.72711033 0.70750770 0.74791867 #> 70  0.4711538 0.72276362 0.90232185 0.89364576 0.84428623 0.92659977 0.93952180 #> 71  0.4711538 0.50950893 0.39503961 0.45591683 0.38297596 0.35086204 0.31179970 #> 72  0.4711538 0.14720074 0.13538571 0.00000000 0.00000000 0.02748516 0.08069763 #> 73  0.4711538 0.49275110 0.44937896 0.41856171 0.62470016 0.61654596 0.63914960 #> 74  0.4711538 0.65674324 0.69439259 0.75479685 0.88511667 0.92560996 0.94540783 #> 75  0.4711538 0.68716407 0.57541914 0.59945962 0.54581071 0.55228791 0.56609663 #> 76  0.4711538 0.54839542 0.50508123 0.52627725 0.55765709 0.52543838 0.49807985 #> 77  0.4711538 0.77317727 0.79812663 0.93073165 1.00000000 1.00000000 1.00000000 #> 78  0.4711538 0.85322027 0.76128342 0.81061207 0.85796753 0.87947603 0.88947890 #> 79  0.4711538 0.81659194 0.90228252 0.80744839 0.70383361 0.68468090 0.70672170 #> 80  0.4711538 0.55964651 0.44326524 0.39507689 0.36149039 0.32071350 0.30181332 #> 81  0.4711538 0.87105473 0.86695796 0.89177640 0.74816339 0.69831750 0.69871492 #> 82  0.4711538 0.47715869 0.68930595 0.71280202 0.73606020 0.78321326 0.73754433 #> 83  0.4711538 0.80974821 0.87138779 0.97466313 0.93082943 0.95560886 0.95554583 #> 84  0.4711538 0.67739807 0.85743609 0.98894432 0.96011041 0.90800271 0.92460814 #> 85  0.4711538 0.57131444 0.34250950 0.33855791 0.31118498 0.31383288 0.31932547 #> 86  0.4711538 0.84958765 0.97611051 0.93090902 0.91560248 0.86222031 0.82950069 #> 87  0.4711538 0.57644613 0.41449248 0.48714466 0.54811918 0.57041511 0.56750119 #> 88  0.4711538 0.75932310 0.71214369 0.52234742 0.59011684 0.59023780 0.57484476 #> 89  0.4711538 0.53031516 0.47090892 0.42433053 0.38847912 0.39218094 0.44028895 #> 90  0.4711538 0.76770402 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000 #> 91  0.4711538 0.38643842 0.37696993 0.44452861 0.49450298 0.46628856 0.50591629 #> 92  0.4711538 0.92591633 1.00000000 0.96084369 0.95688931 0.93400393 0.95078882 #> 93  0.4711538 0.66726042 0.89247800 0.87390628 0.87335977 0.95801535 0.95048831 #> 94  0.4711538 0.32634752 0.41373057 0.48066349 0.67273089 0.62115180 0.63222931 #> 95  0.4711538 0.50472276 0.77159222 0.71730564 0.62350221 0.64335334 0.60173453 #> 96  0.4711538 0.34622269 0.33150717 0.49412629 0.44574013 0.46889514 0.42461082 #> 97  0.4711538 0.55805257 0.50280611 0.58541977 0.52239953 0.53556273 0.55493331 #> 98  0.4711538 0.78090964 0.73429355 0.79385683 0.86651416 0.88151677 0.84875293 #> 99  0.4711538 0.21116352 0.10917861 0.02565398 0.18342015 0.15222876 0.12817884 #> 100 0.4711538 0.66672702 0.78264411 0.86306662 0.75733969 0.77632472 0.76010896 #> 101 0.4711538 0.45317545 0.50149615 0.62617428 0.70904267 0.78134354 0.80270481 #> 102 0.4711538 0.74435376 0.66135006 0.72568147 0.70203564 0.77593538 0.77647730 #> 103 0.4711538 0.34690226 0.56605434 0.52782336 0.50951738 0.46795757 0.50588630 #> 104 0.4711538 0.69496014 0.80515138 0.78871059 0.78008789 0.78042831 0.81071639 #>           [,8]       [,9]      [,10]      [,11] #> 1   0.62734057 0.65124368 0.65354280 0.65838797 #> 2   0.20266653 0.20646355 0.21046038 0.20470356 #> 3   0.00000000 0.00000000 0.00000000 0.00000000 #> 4   0.60037792 0.60876822 0.60784745 0.60193905 #> 5   0.00000000 0.00000000 0.00000000 0.00000000 #> 6   0.00000000 0.00000000 0.00000000 0.00000000 #> 7   0.13275052 0.14475024 0.13944940 0.14173177 #> 8   0.06373660 0.06326154 0.07570783 0.07715150 #> 9   0.44494367 0.44702123 0.44582742 0.44748513 #> 10  0.40700559 0.41366376 0.41349216 0.41350336 #> 11  0.77762362 0.78373432 0.78262765 0.77949531 #> 12  0.64215450 0.63343656 0.63197252 0.62875264 #> 13  0.18750911 0.18653354 0.17822088 0.17842513 #> 14  0.26050129 0.27908122 0.27196942 0.26996735 #> 15  0.09594988 0.09089468 0.08865039 0.09080522 #> 16  0.00000000 0.00000000 0.00000000 0.00000000 #> 17  0.33619355 0.33546848 0.33501592 0.33670840 #> 18  0.58067856 0.58144968 0.58013547 0.57927640 #> 19  0.24670131 0.24099118 0.23822863 0.23157123 #> 20  0.38607475 0.40041929 0.40843493 0.40860630 #> 21  0.54933618 0.53959876 0.54139679 0.54098845 #> 22  0.26532303 0.26288937 0.27124503 0.27372049 #> 23  0.25426484 0.24411174 0.24044626 0.24169731 #> 24  0.13629899 0.14290857 0.14863967 0.15404679 #> 25  0.65036784 0.64494406 0.64644697 0.64416177 #> 26  0.19040219 0.19924562 0.20152378 0.20582432 #> 27  0.45428317 0.44621001 0.43311399 0.43568840 #> 28  0.11808149 0.11758965 0.11048814 0.11155803 #> 29  0.42401800 0.41725604 0.42362830 0.42160066 #> 30  0.16869228 0.17404171 0.17387211 0.17480429 #> 31  0.43243579 0.42525949 0.43329412 0.43856907 #> 32  0.11698190 0.10877882 0.10636129 0.10689920 #> 33  0.45073883 0.45206217 0.44881973 0.44992624 #> 34  0.09586296 0.09225400 0.09980718 0.10084230 #> 35  0.00000000 0.00000000 0.00000000 0.00000000 #> 36  0.43366789 0.44959439 0.44854107 0.44960414 #> 37  0.31162762 0.31502065 0.31958491 0.32067580 #> 38  0.16099729 0.15122241 0.15079738 0.14817778 #> 39  0.25364311 0.25507184 0.25875102 0.25674198 #> 40  0.53034707 0.52840262 0.52790558 0.52538704 #> 41  0.10186998 0.09060473 0.09445259 0.09150467 #> 42  0.48313687 0.48749107 0.48860245 0.49212211 #> 43  0.57309187 0.54660927 0.54001848 0.54366888 #> 44  0.00000000 0.00000000 0.00000000 0.00000000 #> 45  0.16498860 0.17052210 0.16781405 0.16715155 #> 46  0.64508459 0.65153585 0.65177845 0.65178893 #> 47  0.11991376 0.11705391 0.11873700 0.11591426 #> 48  0.16699846 0.16060597 0.16869180 0.16855238 #> 49  0.61300910 0.60887376 0.60785525 0.61021103 #> 50  0.31497806 0.31197484 0.30517646 0.31174053 #> 51  0.31832188 0.32079774 0.31281691 0.31540371 #> 52  0.00000000 0.00000000 0.00000000 0.00000000 #> 53  0.41513665 0.41604404 0.42408314 0.42075636 #> 54  0.47968839 0.47130262 0.46613648 0.46656474 #> 55  0.21377295 0.18935809 0.18930563 0.19050731 #> 56  0.57455838 0.57977566 0.57922184 0.57800858 #> 57  0.97541446 0.96885561 0.96385549 0.96028958 #> 58  0.63163263 0.64101334 0.63785489 0.64045306 #> 59  0.28914861 0.27879135 0.28784917 0.28782462 #> 60  0.55902384 0.56163014 0.55671889 0.55726966 #> 61  0.65941211 0.65058824 0.64930310 0.65091617 #> 62  0.60397744 0.58982660 0.58812271 0.58793743 #> 63  0.61771766 0.61445477 0.61166047 0.60985403 #> 64  1.00000000 1.00000000 1.00000000 1.00000000 #> 65  0.69769474 0.68981063 0.69214943 0.69038662 #> 66  0.53236916 0.53593471 0.53171176 0.53102146 #> 67  1.00000000 1.00000000 1.00000000 1.00000000 #> 68  0.81246241 0.79688369 0.80360414 0.80689017 #> 69  0.77466902 0.76435744 0.76435231 0.76730276 #> 70  0.92635688 0.91649616 0.91637035 0.92383169 #> 71  0.31958498 0.34299668 0.34334588 0.34349096 #> 72  0.06488309 0.05328264 0.04500807 0.04571864 #> 73  0.65602434 0.64784140 0.64971036 0.64930911 #> 74  0.94553110 0.94743335 0.95548576 0.95086945 #> 75  0.58105153 0.58651055 0.58350518 0.58195688 #> 76  0.50712414 0.50370011 0.50352891 0.50289031 #> 77  1.00000000 1.00000000 1.00000000 1.00000000 #> 78  0.91407469 0.92199353 0.92611779 0.92473772 #> 79  0.68969952 0.69332276 0.69306283 0.69031633 #> 80  0.29656001 0.28290751 0.28672758 0.28334638 #> 81  0.69260333 0.69271104 0.69448149 0.69353087 #> 82  0.75551561 0.75380626 0.76075515 0.76006115 #> 83  0.98111451 0.96789911 0.96789876 0.97167928 #> 84  0.92825575 0.93456912 0.93157477 0.93560641 #> 85  0.32670221 0.33419177 0.33780085 0.33863677 #> 86  0.80658855 0.82379298 0.82202715 0.81981455 #> 87  0.56043949 0.54972085 0.54609905 0.54656224 #> 88  0.58884182 0.58228453 0.57334028 0.57098492 #> 89  0.45579085 0.46221532 0.46149391 0.46635298 #> 90  1.00000000 1.00000000 1.00000000 1.00000000 #> 91  0.52873440 0.54203308 0.53789411 0.54025902 #> 92  0.94412285 0.93390914 0.93429933 0.92818920 #> 93  0.98499381 0.99987093 0.99916201 0.99970721 #> 94  0.61780332 0.60462097 0.60316670 0.59998131 #> 95  0.59883886 0.61566575 0.61062288 0.61003734 #> 96  0.39373512 0.38230743 0.38698306 0.38928062 #> 97  0.54534135 0.54894600 0.55196226 0.55110104 #> 98  0.84908812 0.83344560 0.82896512 0.82882885 #> 99  0.12518468 0.14252417 0.14250387 0.14467219 #> 100 0.74023431 0.74464225 0.75159300 0.75722807 #> 101 0.77862492 0.77776152 0.78102072 0.77766043 #> 102 0.75586058 0.76487586 0.76840548 0.77181270 #> 103 0.48885501 0.49542376 0.50188675 0.50526664 #> 104 0.80418072 0.82546481 0.81861016 0.81635531 modpls.aze$Probs-modpls.aze$Probs.trc #>     [,1]        [,2]        [,3]         [,4]        [,5]        [,6] #> 1      0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 2      0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 3      0 -0.09080494 -0.05104846 -0.171669164 -0.21455242 -0.21725391 #> 4      0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 5      0 -0.04408124  0.00000000 -0.071299085 -0.24018962 -0.23445282 #> 6      0 -0.03776963  0.00000000  0.000000000 -0.02597539 -0.06284454 #> 7      0 -0.06930728 -0.19928456 -0.091372612  0.00000000  0.00000000 #> 8      0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 9      0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 10     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 11     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 12     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 13     0  0.00000000 -0.04344681  0.000000000  0.00000000  0.00000000 #> 14     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 15     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 16     0  0.00000000 -0.07276258 -0.051465557 -0.09988241 -0.06790398 #> 17     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 18     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 19     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 20     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 21     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 22     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 23     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 24     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 25     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 26     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 27     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 28     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 29     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 30     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 31     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 32     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 33     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 34     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 35     0  0.00000000  0.00000000 -0.088960742 -0.06232370 -0.08231459 #> 36     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 37     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 38     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 39     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 40     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 41     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 42     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 43     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 44     0  0.00000000  0.00000000  0.000000000 -0.01790809 -0.03785626 #> 45     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 46     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 47     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 48     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 49     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 50     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 51     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 52     0 -0.23250098 -0.28713647 -0.092161735 -0.12709475 -0.18324647 #> 53     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 54     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 55     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 56     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 57     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 58     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 59     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 60     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 61     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 62     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 63     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 64     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 65     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 66     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 67     0  0.00000000  0.17012215  0.081167947  0.22497425  0.21728258 #> 68     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 69     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 70     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 71     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 72     0  0.00000000  0.00000000 -0.044738287 -0.05529233  0.00000000 #> 73     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 74     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 75     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 76     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 77     0  0.00000000  0.00000000  0.000000000  0.10301473  0.08723742 #> 78     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 79     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 80     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 81     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 82     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 83     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 84     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 85     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 86     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 87     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 88     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 89     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 90     0  0.00000000  0.07649866  0.008644293  0.06363018  0.09017457 #> 91     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 92     0  0.00000000  0.03707888  0.000000000  0.00000000  0.00000000 #> 93     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 94     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 95     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 96     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 97     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 98     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 99     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 100    0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 101    0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 102    0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 103    0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #> 104    0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000 #>             [,7]         [,8]         [,9]       [,10]        [,11] #> 1    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 2    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 3   -0.224440890 -0.193652144 -0.201652437 -0.20167289 -0.200815325 #> 4    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 5   -0.263270486 -0.311781941 -0.310765976 -0.31066830 -0.314013823 #> 6   -0.103410961 -0.076840858 -0.080016598 -0.08436785 -0.087771351 #> 7    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 8    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 9    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 10   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 11   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 12   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 13   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 14   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 15   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 16  -0.062392124 -0.039505632 -0.023469898 -0.02045198 -0.027151896 #> 17   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 18   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 19   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 20   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 21   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 22   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 23   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 24   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 25   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 26   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 27   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 28   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 29   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 30   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 31   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 32   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 33   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 34   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 35  -0.083905063 -0.085155814 -0.086690885 -0.08262604 -0.082725745 #> 36   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 37   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 38   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 39   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 40   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 41   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 42   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 43   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 44  -0.014514870 -0.004369241 -0.002647953 -0.00844687 -0.010738872 #> 45   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 46   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 47   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 48   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 49   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 50   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 51   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 52  -0.195842587 -0.184768370 -0.177691131 -0.18225253 -0.181720401 #> 53   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 54   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 55   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 56   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 57   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 58   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 59   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 60   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 61   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 62   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 63   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 64   0.001662791  0.008968255  0.008852814  0.01022555  0.006667285 #> 65   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 66   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 67   0.221111495  0.202569147  0.194030443  0.19310867  0.192281835 #> 68   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 69   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 70   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 71   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 72   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 73   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 74   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 75   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 76   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 77   0.064638063  0.090636226  0.099163425  0.09692704  0.096849873 #> 78   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 79   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 80   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 81   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 82   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 83   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 84   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 85   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 86   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 87   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 88   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 89   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 90   0.087035865  0.113909884  0.123382027  0.12669615  0.125596908 #> 91   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 92   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 93   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 94   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 95   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 96   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 97   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 98   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 99   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 100  0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 101  0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 102  0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 103  0.000000000  0.000000000  0.000000000  0.00000000  0.000000000 #> 104  0.000000000  0.000000000  0.000000000  0.00000000  0.000000000  #Repeated cross validation of the model (NK=100 times) cv.modpls.aze<-cv.plsR(y~.,data=aze_compl,10,NK=100, verbose=FALSE) res.cv.modpls.aze<-cvtable(summary(cv.modpls.aze,MClassed=TRUE)) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1,  2,  3,  4,  5,  6,  7,  8,  9,  10 #> NK: 11,  12,  13,  14,  15,  16,  17,  18,  19,  20 #> NK: 21,  22,  23,  24,  25,  26,  27,  28,  29,  30 #> NK: 31,  32,  33,  34,  35,  36,  37,  38,  39,  40 #> NK: 41,  42,  43,  44,  45,  46,  47,  48,  49,  50 #> NK: 51,  52,  53,  54,  55,  56,  57,  58,  59,  60 #> NK: 61,  62,  63,  64,  65,  66,  67,  68,  69,  70 #> NK: 71,  72,  73,  74,  75,  76,  77,  78,  79,  80 #> NK: 81,  82,  83,  84,  85,  86,  87,  88,  89,  90 #> NK: 91,  92,  93,  94,  95,  96,  97,  98,  99,  100 #>  #> CV MissClassed criterion: #>  1  2  3  4  5  6  7  8  9 10  #> 24 10 25 11  5  5  7  8  2  3  #>  #> CV Q2 criterion: #>   0  #> 100  #>  #> CV Press criterion: #>  1  2  #> 81 19  #High discrepancy in the number of component choice using repeated cross validation #and missclassed criterion plot(res.cv.modpls.aze)   rm(list=c(\"Xaze_compl\",\"yaze_compl\",\"modpls.aze\",\"cv.modpls.aze\",\"res.cv.modpls.aze\"))  #24 predictors dimX <- 24 #2 components Astar <- 2 simul_data_UniYX(dimX,Astar) #>          Y         X1         X2         X3         X4         X5         X6  #> 11.6445768  0.6175008  0.6056228  5.1301635  0.6107449  0.6138664  5.1302654  #>         X7         X8         X9        X10        X11        X12        X13  #>  0.6402793  0.6103912  5.1466522  0.6048168  0.6205430  5.1257361  0.6101874  #>        X14        X15        X16        X17        X18        X19        X20  #>  0.6103582  5.1152508  0.6286553  0.6139872  5.1205242  0.6145876  0.6165494  #>        X21        X22        X23        X24  #>  5.1176202  0.6228756  0.6110989  5.1274519  dataAstar2 <- data.frame(t(replicate(250,simul_data_UniYX(dimX,Astar)))) modpls.A2<- plsR(Y~.,data=dataAstar2,10,typeVC=\"standard\") #> ____************************************************____ #> ____TypeVC____ standard ____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> ____Component____ 9 ____ #> ____Component____ 10 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  modpls.A2 #> Number of required components: #> [1] 10 #> Number of successfully computed components: #> [1] 10 #> Coefficients: #>                   [,1] #> Intercept -0.009308745 #> X1        -1.252039537 #> X2         0.251769360 #> X3         1.069303144 #> X4        -1.523206574 #> X5         0.429339251 #> X6        -0.103727035 #> X7         0.514838746 #> X8        -0.008132813 #> X9        -1.109769998 #> X10        0.697707208 #> X11        0.110179634 #> X12        0.263432702 #> X13        0.048981023 #> X14        1.102957195 #> X15        2.998639072 #> X16       -1.030175931 #> X17        0.005090035 #> X18       -0.108388491 #> X19        1.071595090 #> X20        0.619985470 #> X21       -0.996526239 #> X22       -0.639107098 #> X23        0.152756799 #> X24        0.266087715 #> Leave one out cross validated PRESS, Information criteria and Fit statistics: #>                  AIC   Q2cum_Y LimQ2_Y        Q2_Y     PRESS_Y        RSS_Y #> Nb_Comp_0  1707.6611        NA      NA          NA          NA 13336.080111 #> Nb_Comp_1  1268.8401 0.8246912  0.0975  0.82469120 2337.932230  2286.881298 #> Nb_Comp_2  -202.5201 0.9995127  0.0975  0.99722014    6.357207     6.306012 #> Nb_Comp_3  -219.4997 0.9994751  0.0975 -0.07700506    6.791607     5.844991 #> Nb_Comp_4  -219.7889 0.9993831  0.0975 -0.17536483    6.869997     5.791713 #> Nb_Comp_5  -218.0111 0.9992724  0.0975 -0.17939626    6.830725     5.786567 #> Nb_Comp_6  -216.0264 0.9991613  0.0975 -0.15268975    6.670117     5.786214 #> Nb_Comp_7  -214.0278 0.9990390  0.0975 -0.14581108    6.629908     5.786181 #> Nb_Comp_8  -212.0280 0.9989079  0.0975 -0.13650388    6.576018     5.786178 #> Nb_Comp_9  -210.0280 0.9987662  0.0975 -0.12969385    6.536609     5.786177 #> Nb_Comp_10 -208.0280 0.9986200  0.0975 -0.11849061    6.471785     5.786177 #>                 R2_Y R2_residY  RSS_residY PRESS_residY   Q2_residY  LimQ2 #> Nb_Comp_0         NA        NA 249.0000000           NA          NA     NA #> Nb_Comp_1  0.8285192 0.8285192  42.6987119   43.6518917  0.82469120 0.0975 #> Nb_Comp_2  0.9995271 0.9995271   0.1177405    0.1186964  0.99722014 0.0975 #> Nb_Comp_3  0.9995617 0.9995617   0.1091327    0.1268071 -0.07700506 0.0975 #> Nb_Comp_4  0.9995657 0.9995657   0.1081380    0.1282708 -0.17536483 0.0975 #> Nb_Comp_5  0.9995661 0.9995661   0.1080419    0.1275375 -0.17939626 0.0975 #> Nb_Comp_6  0.9995661 0.9995661   0.1080353    0.1245388 -0.15268975 0.0975 #> Nb_Comp_7  0.9995661 0.9995661   0.1080347    0.1237880 -0.14581108 0.0975 #> Nb_Comp_8  0.9995661 0.9995661   0.1080346    0.1227818 -0.13650388 0.0975 #> Nb_Comp_9  0.9995661 0.9995661   0.1080346    0.1220460 -0.12969385 0.0975 #> Nb_Comp_10 0.9995661 0.9995661   0.1080346    0.1208357 -0.11849061 0.0975 #>            Q2cum_residY    AIC.std   DoF.dof sigmahat.dof     AIC.dof #> Nb_Comp_0            NA   712.4673  1.000000    7.3183710 53.77278888 #> Nb_Comp_1     0.8246912   273.6462  2.555426    3.0339405  9.33570257 #> Nb_Comp_2     0.9995127 -1197.7140  3.000068    0.1594599  0.02583432 #> Nb_Comp_3     0.9994751 -1214.6936 22.575083    0.1599632  0.02800122 #> Nb_Comp_4     0.9993831 -1214.9828 24.169579    0.1597912  0.02810387 #> Nb_Comp_5     0.9992724 -1213.2050 24.064193    0.1596831  0.02805511 #> Nb_Comp_6     0.9991613 -1211.2203 23.898718    0.1596200  0.02801609 #> Nb_Comp_7     0.9990390 -1209.2217 23.943396    0.1596353  0.02802600 #> Nb_Comp_8     0.9989079 -1207.2219 23.912174    0.1596243  0.02801895 #> Nb_Comp_9     0.9987662 -1205.2219 24.027467    0.1596648  0.02804494 #> Nb_Comp_10    0.9986200 -1203.2219 24.166857    0.1597139  0.02807639 #>                BIC.dof  GMDL.dof DoF.naive sigmahat.naive   AIC.naive #> Nb_Comp_0  54.52720631  499.7901         1      7.3183710 53.77278888 #> Nb_Comp_1   9.66703221  288.0890         2      3.0366586  9.29506592 #> Nb_Comp_2   0.02690885 -438.1210         3      0.1597824  0.02583678 #> Nb_Comp_3   0.03613800 -342.0265         4      0.1541432  0.02414029 #> Nb_Comp_4   0.03679663 -335.0836         5      0.1537519  0.02411244 #> Nb_Comp_5   0.03669827 -335.7098         6      0.1539982  0.02428461 #> Nb_Comp_6   0.03659303 -336.5430         7      0.1543100  0.02447830 #> Nb_Comp_7   0.03662062 -336.3205         8      0.1546281  0.02467496 #> Nb_Comp_8   0.03660118 -336.4765         9      0.1549485  0.02487336 #> Nb_Comp_9   0.03667292 -335.9008        10      0.1552710  0.02507344 #> Nb_Comp_10  0.03675976 -335.2051        11      0.1555955  0.02527518 #>              BIC.naive GMDL.naive #> Nb_Comp_0  54.52720631   499.7901 #> Nb_Comp_1   9.55484538   286.8472 #> Nb_Comp_2   0.02691563  -437.6224 #> Nb_Comp_3   0.02547901  -441.0025 #> Nb_Comp_4   0.02577736  -436.2568 #> Nb_Comp_5   0.02628892  -430.5960 #> Nb_Comp_6   0.02682615  -424.9195 #> Nb_Comp_7   0.02736928  -419.3100 #> Nb_Comp_8   0.02791705  -413.7646 #> Nb_Comp_9   0.02846940  -408.2768 #> Nb_Comp_10  0.02902638  -402.8412 cv.modpls.A2<-cv.plsR(Y~.,data=dataAstar2,10,NK=100, verbose=FALSE) res.cv.modpls.A2<-cvtable(summary(cv.modpls.A2,verbose=FALSE)) #> Error in eval(mf, parent.frame()): object 'dataAstar2' not found #Perfect choice for the Q2 criterion in PLSR plot(res.cv.modpls.A2) #> Error: object 'res.cv.modpls.A2' not found  #Binarized data.frame simbin1 <- data.frame(dicho(dataAstar2)) modpls.B2 <- plsR(Y~.,data=simbin1,10,typeVC=\"standard\",MClassed=TRUE, verbose=FALSE) modpls.B2 #> Number of required components: #> [1] 10 #> Number of successfully computed components: #> [1] 8 #> Coefficients: #>                    [,1] #> Intercept -2.232996e-02 #> X1        -2.564600e-04 #> X2         1.827582e-02 #> X3         3.200076e-01 #> X4         1.827582e-02 #> X5         8.548667e-05 #> X6        -7.441941e-02 #> X7         1.827582e-02 #> X8         8.548667e-05 #> X9         1.600038e-01 #> X10       -6.653264e-03 #> X11        1.794648e-02 #> X12        5.540587e-01 #> X13        1.794648e-02 #> X14       -6.307629e-03 #> X15       -7.441941e-02 #> X16        1.827582e-02 #> X17        1.827582e-02 #> X18       -7.441941e-02 #> X19       -1.961416e-02 #> X20       -6.653264e-03 #> X21       -7.441941e-02 #> X22        8.548667e-05 #> X23        1.827582e-02 #> X24        1.600038e-01 #> Leave one out cross validated PRESS, Information criteria and Fit statistics: #>                 AIC   Q2cum_Y LimQ2_Y          Q2_Y   PRESS_Y     RSS_Y #> Nb_Comp_0 366.87968        NA      NA            NA        NA 62.496000 #> Nb_Comp_1  26.83779 0.7381855  0.0975  0.7381855034 16.362359 15.909796 #> Nb_Comp_2 -76.52049 0.8252118  0.0975  0.3323966613 10.621433 10.438510 #> Nb_Comp_3 -91.51975 0.8283713  0.0975  0.0180764406 10.249819  9.752317 #> Nb_Comp_4 -89.75294 0.8284216  0.0975  0.0002930630  9.749459  9.743224 #> Nb_Comp_5 -87.81866 0.8284417  0.0975  0.0001171978  9.742083  9.740663 #> Nb_Comp_6 -85.82121 0.8284216  0.0975 -0.0001170090  9.741803  9.740564 #> Nb_Comp_7 -83.82127 0.8283970  0.0975 -0.0001436374  9.741963  9.740562 #> Nb_Comp_8 -81.82127 0.8283740  0.0975 -0.0001343106  9.741870  9.740562 #>                R2_Y MissClassed R2_residY RSS_residY PRESS_residY     Q2_residY #> Nb_Comp_0        NA         124        NA  249.00000           NA            NA #> Nb_Comp_1 0.7454270          11 0.7454270   63.38868     65.19181  0.7381855034 #> Nb_Comp_2 0.8329731          13 0.8329731   41.58969     42.31850  0.3323966613 #> Nb_Comp_3 0.8439529          11 0.8439529   38.85572     40.83789  0.0180764406 #> Nb_Comp_4 0.8440984          11 0.8440984   38.81949     38.84433  0.0002930630 #> Nb_Comp_5 0.8441394          11 0.8441394   38.80929     38.81494  0.0001171978 #> Nb_Comp_6 0.8441410          11 0.8441410   38.80889     38.81383 -0.0001170090 #> Nb_Comp_7 0.8441410          11 0.8441410   38.80888     38.81447 -0.0001436374 #> Nb_Comp_8 0.8441410          11 0.8441410   38.80888     38.81409 -0.0001343106 #>            LimQ2 Q2cum_residY  AIC.std   DoF.dof sigmahat.dof    AIC.dof #> Nb_Comp_0     NA           NA 712.4673  1.000000    0.5009870 0.25199190 #> Nb_Comp_1 0.0975    0.7381855 372.4254  3.112471    0.2533407 0.06523729 #> Nb_Comp_2 0.0975    0.8252118 269.0671  3.041696    0.2051776 0.04277843 #> Nb_Comp_3 0.0975    0.8283713 254.0678 10.053091    0.2011839 0.04226445 #> Nb_Comp_4 0.0975    0.8284216 255.8346  8.294626    0.2003603 0.04163675 #> Nb_Comp_5 0.0975    0.8284417 257.7689  8.533342    0.2004326 0.04170515 #> Nb_Comp_6 0.0975    0.8284216 259.7664  8.818006    0.2005493 0.04179954 #> Nb_Comp_7 0.0975    0.8283970 261.7663  8.983410    0.2006178 0.04185473 #> Nb_Comp_8 0.0975    0.8283740 263.7663  8.999382    0.2006244 0.04186006 #>              BIC.dof  GMDL.dof DoF.naive sigmahat.naive  AIC.naive  BIC.naive #> Nb_Comp_0 0.25552728 -167.2823         1      0.5009870 0.25199190 0.25552728 #> Nb_Comp_1 0.06805112 -330.7000         2      0.2532832 0.06466562 0.06647290 #> Nb_Comp_2 0.04458211 -382.8861         3      0.2055752 0.04276831 0.04455416 #> Nb_Comp_3 0.04799596 -369.7858         4      0.1991069 0.04027786 0.04251151 #> Nb_Comp_4 0.04632708 -374.9363         5      0.1994198 0.04056363 0.04336448 #> Nb_Comp_5 0.04653394 -374.2734         6      0.1998018 0.04087885 0.04425275 #> Nb_Comp_6 0.04679523 -373.4508         7      0.2002115 0.04120700 0.04515938 #> Nb_Comp_7 0.04694760 -372.9744         8      0.2006247 0.04153826 0.04607393 #> Nb_Comp_8 0.04696232 -372.9284         9      0.2010405 0.04187229 0.04699609 #>           GMDL.naive #> Nb_Comp_0  -167.2823 #> Nb_Comp_1  -333.8147 #> Nb_Comp_2  -382.5286 #> Nb_Comp_3  -387.5578 #> Nb_Comp_4  -384.4408 #> Nb_Comp_5  -381.3439 #> Nb_Comp_6  -378.3019 #> Nb_Comp_7  -375.3325 #> Nb_Comp_8  -372.4277 modpls.B2$Probs #>      [,1]        [,2]         [,3]          [,4]        [,5]         [,6] #> 1   0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 2   0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 3   0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 4   0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 5   0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 6   0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 7   0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 8   0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 9   0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 10  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 11  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 12  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 13  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 14  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 15  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 16  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 17  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 18  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 19  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 20  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 21  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 22  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 23  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 24  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 25  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 26  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 27  0.496  0.03606045  0.002955833  0.0001432602 -0.01599899  0.007925162 #> 28  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 29  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 30  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 31  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 32  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 33  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 34  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 35  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 36  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 37  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 38  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 39  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 40  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 41  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 42  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 43  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 44  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 45  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 46  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 47  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 48  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 49  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 50  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 51  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 52  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 53  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 54  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 55  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 56  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 57  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 58  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 59  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 60  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 61  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 62  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 63  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 64  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 65  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 66  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 67  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 68  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 69  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 70  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 71  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 72  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 73  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 74  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 75  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 76  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 77  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 78  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 79  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 80  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 81  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 82  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 83  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 84  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 85  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 86  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 87  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 88  0.496  1.00500492  0.973254333  1.0029362526  0.99021061  0.997293320 #> 89  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 90  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 91  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 92  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 93  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 94  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 95  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 96  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 97  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 98  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 99  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 100 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 101 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 102 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 103 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 104 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 105 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 106 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 107 0.496  0.90947840  0.945577585  1.0369797504  0.97619695  0.995322751 #> 108 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 109 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 110 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 111 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 112 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 113 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 114 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 115 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 116 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 117 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 118 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 119 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 120 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 121 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 122 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 123 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 124 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 125 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 126 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 127 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 128 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 129 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 130 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 131 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 132 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 133 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 134 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 135 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 136 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 137 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 138 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 139 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 140 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 141 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 142 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 143 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 144 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 145 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 146 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 147 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 148 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 149 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 150 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 151 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 152 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 153 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 154 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 155 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 156 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 157 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 158 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 159 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 160 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 161 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 162 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 163 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 164 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 165 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 166 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 167 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 168 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 169 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 170 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 171 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 172 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 173 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 174 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 175 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 176 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 177 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 178 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 179 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 180 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 181 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 182 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 183 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 184 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 185 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 186 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 187 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 188 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 189 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 190 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 191 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 192 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 193 0.496  0.45907245  0.636656724  0.0755600483  0.02597481  0.001514519 #> 194 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 195 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 196 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 197 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 198 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 199 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 200 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 201 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 202 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 203 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 204 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 205 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 206 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 207 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 208 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 209 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 210 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 211 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 212 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 213 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 214 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 215 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 216 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 217 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 218 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 219 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 220 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 221 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 222 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 223 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 224 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 225 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 226 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 227 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 228 0.496  0.95759591  0.959727077  0.9862193637  1.01721602  0.999177807 #> 229 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 230 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 231 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 232 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 233 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 234 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 235 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 236 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 237 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 238 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 239 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 240 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 241 0.496  0.36839434  0.524751547 -0.0668244029 -0.02771783 -0.002376501 #> 242 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455 #> 243 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 244 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #> 245 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 246 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 247 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 248 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110 #> 249 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640 #> 250 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075 #>              [,7]          [,8]          [,9] #> 1    8.740665e-01  8.740690e-01  8.740663e-01 #> 2    9.803926e-01  9.803899e-01  9.803858e-01 #> 3    9.803926e-01  9.803899e-01  9.803858e-01 #> 4    8.740665e-01  8.740690e-01  8.740663e-01 #> 5    9.803926e-01  9.803899e-01  9.803858e-01 #> 6    9.803926e-01  9.803899e-01  9.803858e-01 #> 7    8.740665e-01  8.740690e-01  8.740663e-01 #> 8   -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 9   -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 10   9.803926e-01  9.803899e-01  9.803858e-01 #> 11  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 12   9.803926e-01  9.803899e-01  9.803858e-01 #> 13  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 14   8.740665e-01  8.740690e-01  8.740663e-01 #> 15  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 16   8.399153e-02  8.399119e-02  8.398958e-02 #> 17   9.803926e-01  9.803899e-01  9.803858e-01 #> 18  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 19   8.399153e-02  8.399119e-02  8.398958e-02 #> 20   8.399153e-02  8.399119e-02  8.398958e-02 #> 21   9.803926e-01  9.803899e-01  9.803858e-01 #> 22   8.399153e-02  8.399119e-02  8.398958e-02 #> 23   8.399153e-02  8.399119e-02  8.398958e-02 #> 24  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 25   9.803926e-01  9.803899e-01  9.803858e-01 #> 26   9.803926e-01  9.803899e-01  9.803858e-01 #> 27   1.814101e-04 -9.424424e-05  1.665335e-16 #> 28   8.740665e-01  8.740690e-01  8.740663e-01 #> 29   9.803926e-01  9.803899e-01  9.803858e-01 #> 30  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 31   9.803926e-01  9.803899e-01  9.803858e-01 #> 32   9.803926e-01  9.803899e-01  9.803858e-01 #> 33   8.740665e-01  8.740690e-01  8.740663e-01 #> 34  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 35   8.740665e-01  8.740690e-01  8.740663e-01 #> 36   9.803926e-01  9.803899e-01  9.803858e-01 #> 37   9.803926e-01  9.803899e-01  9.803858e-01 #> 38  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 39  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 40  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 41   8.740665e-01  8.740690e-01  8.740663e-01 #> 42   8.399153e-02  8.399119e-02  8.398958e-02 #> 43   8.740665e-01  8.740690e-01  8.740663e-01 #> 44   8.399153e-02  8.399119e-02  8.398958e-02 #> 45   8.740665e-01  8.740690e-01  8.740663e-01 #> 46  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 47   9.803926e-01  9.803899e-01  9.803858e-01 #> 48   8.740665e-01  8.740690e-01  8.740663e-01 #> 49   8.740665e-01  8.740690e-01  8.740663e-01 #> 50   8.399153e-02  8.399119e-02  8.398958e-02 #> 51   8.399153e-02  8.399119e-02  8.398958e-02 #> 52  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 53   9.803926e-01  9.803899e-01  9.803858e-01 #> 54   8.740665e-01  8.740690e-01  8.740663e-01 #> 55   9.803926e-01  9.803899e-01  9.803858e-01 #> 56   9.803926e-01  9.803899e-01  9.803858e-01 #> 57   9.803926e-01  9.803899e-01  9.803858e-01 #> 58   8.399153e-02  8.399119e-02  8.398958e-02 #> 59  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 60   9.803926e-01  9.803899e-01  9.803858e-01 #> 61   8.740665e-01  8.740690e-01  8.740663e-01 #> 62   8.740665e-01  8.740690e-01  8.740663e-01 #> 63  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 64  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 65   9.803926e-01  9.803899e-01  9.803858e-01 #> 66   9.803926e-01  9.803899e-01  9.803858e-01 #> 67   9.803926e-01  9.803899e-01  9.803858e-01 #> 68  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 69   8.399153e-02  8.399119e-02  8.398958e-02 #> 70  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 71   8.399153e-02  8.399119e-02  8.398958e-02 #> 72   8.399153e-02  8.399119e-02  8.398958e-02 #> 73  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 74   8.399153e-02  8.399119e-02  8.398958e-02 #> 75  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 76   8.740665e-01  8.740690e-01  8.740663e-01 #> 77   8.399153e-02  8.399119e-02  8.398958e-02 #> 78   8.399153e-02  8.399119e-02  8.398958e-02 #> 79   9.803926e-01  9.803899e-01  9.803858e-01 #> 80   8.740665e-01  8.740690e-01  8.740663e-01 #> 81   8.740665e-01  8.740690e-01  8.740663e-01 #> 82   8.740665e-01  8.740690e-01  8.740663e-01 #> 83   8.399153e-02  8.399119e-02  8.398958e-02 #> 84   8.740665e-01  8.740690e-01  8.740663e-01 #> 85   8.399153e-02  8.399119e-02  8.398958e-02 #> 86   8.399153e-02  8.399119e-02  8.398958e-02 #> 87   9.803926e-01  9.803899e-01  9.803858e-01 #> 88   9.986012e-01  9.998504e-01  1.000000e+00 #> 89   9.803926e-01  9.803899e-01  9.803858e-01 #> 90   8.740665e-01  8.740690e-01  8.740663e-01 #> 91   8.399153e-02  8.399119e-02  8.398958e-02 #> 92  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 93  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 94  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 95   9.803926e-01  9.803899e-01  9.803858e-01 #> 96   8.399153e-02  8.399119e-02  8.398958e-02 #> 97  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 98  -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 99   9.803926e-01  9.803899e-01  9.803858e-01 #> 100  8.740665e-01  8.740690e-01  8.740663e-01 #> 101  9.803926e-01  9.803899e-01  9.803858e-01 #> 102  8.399153e-02  8.399119e-02  8.398958e-02 #> 103  9.803926e-01  9.803899e-01  9.803858e-01 #> 104 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 105  9.803926e-01  9.803899e-01  9.803858e-01 #> 106 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 107  1.000509e+00  9.999525e-01  1.000000e+00 #> 108  8.740665e-01  8.740690e-01  8.740663e-01 #> 109  8.399153e-02  8.399119e-02  8.398958e-02 #> 110 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 111  9.803926e-01  9.803899e-01  9.803858e-01 #> 112  9.803926e-01  9.803899e-01  9.803858e-01 #> 113  8.740665e-01  8.740690e-01  8.740663e-01 #> 114  8.399153e-02  8.399119e-02  8.398958e-02 #> 115  9.803926e-01  9.803899e-01  9.803858e-01 #> 116  8.740665e-01  8.740690e-01  8.740663e-01 #> 117  8.740665e-01  8.740690e-01  8.740663e-01 #> 118 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 119  8.399153e-02  8.399119e-02  8.398958e-02 #> 120  9.803926e-01  9.803899e-01  9.803858e-01 #> 121 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 122  8.740665e-01  8.740690e-01  8.740663e-01 #> 123 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 124  8.399153e-02  8.399119e-02  8.398958e-02 #> 125  8.399153e-02  8.399119e-02  8.398958e-02 #> 126  9.803926e-01  9.803899e-01  9.803858e-01 #> 127  9.803926e-01  9.803899e-01  9.803858e-01 #> 128  9.803926e-01  9.803899e-01  9.803858e-01 #> 129  9.803926e-01  9.803899e-01  9.803858e-01 #> 130  8.399153e-02  8.399119e-02  8.398958e-02 #> 131  9.803926e-01  9.803899e-01  9.803858e-01 #> 132  8.399153e-02  8.399119e-02  8.398958e-02 #> 133  9.803926e-01  9.803899e-01  9.803858e-01 #> 134  8.740665e-01  8.740690e-01  8.740663e-01 #> 135  9.803926e-01  9.803899e-01  9.803858e-01 #> 136  8.740665e-01  8.740690e-01  8.740663e-01 #> 137  9.803926e-01  9.803899e-01  9.803858e-01 #> 138  8.740665e-01  8.740690e-01  8.740663e-01 #> 139  8.399153e-02  8.399119e-02  8.398958e-02 #> 140 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 141 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 142 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 143  8.740665e-01  8.740690e-01  8.740663e-01 #> 144  8.740665e-01  8.740690e-01  8.740663e-01 #> 145  8.740665e-01  8.740690e-01  8.740663e-01 #> 146  8.399153e-02  8.399119e-02  8.398958e-02 #> 147  8.740665e-01  8.740690e-01  8.740663e-01 #> 148  9.803926e-01  9.803899e-01  9.803858e-01 #> 149 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 150  8.740665e-01  8.740690e-01  8.740663e-01 #> 151 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 152 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 153 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 154  9.803926e-01  9.803899e-01  9.803858e-01 #> 155  9.803926e-01  9.803899e-01  9.803858e-01 #> 156  9.803926e-01  9.803899e-01  9.803858e-01 #> 157 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 158  8.399153e-02  8.399119e-02  8.398958e-02 #> 159 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 160 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 161  8.399153e-02  8.399119e-02  8.398958e-02 #> 162 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 163 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 164  9.803926e-01  9.803899e-01  9.803858e-01 #> 165  8.399153e-02  8.399119e-02  8.398958e-02 #> 166  8.740665e-01  8.740690e-01  8.740663e-01 #> 167 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 168  8.740665e-01  8.740690e-01  8.740663e-01 #> 169  8.399153e-02  8.399119e-02  8.398958e-02 #> 170  9.803926e-01  9.803899e-01  9.803858e-01 #> 171  8.399153e-02  8.399119e-02  8.398958e-02 #> 172  8.740665e-01  8.740690e-01  8.740663e-01 #> 173  8.399153e-02  8.399119e-02  8.398958e-02 #> 174  9.803926e-01  9.803899e-01  9.803858e-01 #> 175  9.803926e-01  9.803899e-01  9.803858e-01 #> 176 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 177  9.803926e-01  9.803899e-01  9.803858e-01 #> 178  8.740665e-01  8.740690e-01  8.740663e-01 #> 179 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 180 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 181  8.399153e-02  8.399119e-02  8.398958e-02 #> 182  9.803926e-01  9.803899e-01  9.803858e-01 #> 183  8.399153e-02  8.399119e-02  8.398958e-02 #> 184  9.803926e-01  9.803899e-01  9.803858e-01 #> 185 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 186  9.803926e-01  9.803899e-01  9.803858e-01 #> 187  8.740665e-01  8.740690e-01  8.740663e-01 #> 188  8.740665e-01  8.740690e-01  8.740663e-01 #> 189  9.803926e-01  9.803899e-01  9.803858e-01 #> 190 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 191  9.803926e-01  9.803899e-01  9.803858e-01 #> 192 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 193 -4.099320e-05 -1.534115e-05 -1.110223e-16 #> 194  8.740665e-01  8.740690e-01  8.740663e-01 #> 195  8.399153e-02  8.399119e-02  8.398958e-02 #> 196  9.803926e-01  9.803899e-01  9.803858e-01 #> 197  8.740665e-01  8.740690e-01  8.740663e-01 #> 198  9.803926e-01  9.803899e-01  9.803858e-01 #> 199  8.740665e-01  8.740690e-01  8.740663e-01 #> 200 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 201  8.740665e-01  8.740690e-01  8.740663e-01 #> 202  8.399153e-02  8.399119e-02  8.398958e-02 #> 203  8.740665e-01  8.740690e-01  8.740663e-01 #> 204  8.740665e-01  8.740690e-01  8.740663e-01 #> 205  8.399153e-02  8.399119e-02  8.398958e-02 #> 206 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 207  9.803926e-01  9.803899e-01  9.803858e-01 #> 208  8.399153e-02  8.399119e-02  8.398958e-02 #> 209 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 210  9.803926e-01  9.803899e-01  9.803858e-01 #> 211  8.399153e-02  8.399119e-02  8.398958e-02 #> 212 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 213  9.803926e-01  9.803899e-01  9.803858e-01 #> 214  9.803926e-01  9.803899e-01  9.803858e-01 #> 215  9.803926e-01  9.803899e-01  9.803858e-01 #> 216  8.399153e-02  8.399119e-02  8.398958e-02 #> 217  8.399153e-02  8.399119e-02  8.398958e-02 #> 218  9.803926e-01  9.803899e-01  9.803858e-01 #> 219 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 220  8.399153e-02  8.399119e-02  8.398958e-02 #> 221 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 222  8.399153e-02  8.399119e-02  8.398958e-02 #> 223  8.740665e-01  8.740690e-01  8.740663e-01 #> 224 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 225  8.740665e-01  8.740690e-01  8.740663e-01 #> 226  8.740665e-01  8.740690e-01  8.740663e-01 #> 227 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 228  1.000372e+00  9.997744e-01  1.000000e+00 #> 229  9.803926e-01  9.803899e-01  9.803858e-01 #> 230  9.803926e-01  9.803899e-01  9.803858e-01 #> 231 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 232  9.803926e-01  9.803899e-01  9.803858e-01 #> 233 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 234  9.803926e-01  9.803899e-01  9.803858e-01 #> 235 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 236 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 237  8.399153e-02  8.399119e-02  8.398958e-02 #> 238  9.803926e-01  9.803899e-01  9.803858e-01 #> 239  9.803926e-01  9.803899e-01  9.803858e-01 #> 240  8.740665e-01  8.740690e-01  8.740663e-01 #> 241  5.931236e-05 -7.182277e-06 -2.775558e-16 #> 242  8.740665e-01  8.740690e-01  8.740663e-01 #> 243  9.803926e-01  9.803899e-01  9.803858e-01 #> 244 -2.233453e-02 -2.232974e-02 -2.232996e-02 #> 245  8.399153e-02  8.399119e-02  8.398958e-02 #> 246  8.399153e-02  8.399119e-02  8.398958e-02 #> 247  8.399153e-02  8.399119e-02  8.398958e-02 #> 248  8.399153e-02  8.399119e-02  8.398958e-02 #> 249  9.803926e-01  9.803899e-01  9.803858e-01 #> 250 -2.233453e-02 -2.232974e-02 -2.232996e-02 modpls.B2$Probs.trc #>      [,1]       [,2]        [,3]         [,4]       [,5]        [,6] #> 1   0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 2   0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 3   0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 4   0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 5   0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 6   0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 7   0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 8   0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 9   0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 10  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 11  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 12  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 13  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 14  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 15  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 16  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 17  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 18  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 19  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 20  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 21  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 22  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 23  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 24  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 25  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 26  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 27  0.496 0.03606045 0.002955833 0.0001432602 0.00000000 0.007925162 #> 28  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 29  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 30  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 31  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 32  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 33  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 34  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 35  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 36  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 37  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 38  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 39  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 40  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 41  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 42  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 43  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 44  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 45  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 46  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 47  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 48  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 49  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 50  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 51  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 52  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 53  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 54  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 55  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 56  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 57  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 58  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 59  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 60  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 61  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 62  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 63  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 64  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 65  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 66  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 67  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 68  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 69  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 70  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 71  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 72  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 73  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 74  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 75  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 76  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 77  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 78  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 79  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 80  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 81  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 82  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 83  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 84  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 85  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 86  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 87  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 88  0.496 1.00000000 0.973254333 1.0000000000 0.99021061 0.997293320 #> 89  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 90  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 91  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 92  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 93  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 94  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 95  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 96  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 97  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 98  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 99  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 100 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 101 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 102 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 103 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 104 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 105 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 106 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 107 0.496 0.90947840 0.945577585 1.0000000000 0.97619695 0.995322751 #> 108 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 109 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 110 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 111 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 112 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 113 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 114 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 115 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 116 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 117 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 118 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 119 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 120 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 121 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 122 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 123 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 124 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 125 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 126 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 127 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 128 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 129 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 130 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 131 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 132 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 133 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 134 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 135 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 136 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 137 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 138 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 139 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 140 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 141 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 142 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 143 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 144 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 145 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 146 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 147 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 148 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 149 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 150 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 151 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 152 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 153 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 154 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 155 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 156 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 157 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 158 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 159 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 160 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 161 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 162 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 163 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 164 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 165 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 166 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 167 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 168 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 169 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 170 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 171 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 172 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 173 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 174 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 175 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 176 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 177 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 178 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 179 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 180 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 181 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 182 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 183 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 184 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 185 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 186 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 187 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 188 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 189 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 190 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 191 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 192 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 193 0.496 0.45907245 0.636656724 0.0755600483 0.02597481 0.001514519 #> 194 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 195 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 196 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 197 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 198 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 199 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 200 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 201 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 202 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 203 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 204 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 205 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 206 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 207 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 208 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 209 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 210 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 211 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 212 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 213 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 214 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 215 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 216 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 217 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 218 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 219 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 220 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 221 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 222 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 223 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 224 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 225 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 226 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 227 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 228 0.496 0.95759591 0.959727077 0.9862193637 1.00000000 0.999177807 #> 229 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 230 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 231 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 232 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 233 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 234 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 235 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 236 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 237 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 238 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 239 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 240 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 241 0.496 0.36839434 0.524751547 0.0000000000 0.00000000 0.000000000 #> 242 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455 #> 243 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 244 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #> 245 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 246 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 247 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 248 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110 #> 249 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640 #> 250 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000 #>             [,7]       [,8]         [,9] #> 1   8.740665e-01 0.87406897 8.740663e-01 #> 2   9.803926e-01 0.98038990 9.803858e-01 #> 3   9.803926e-01 0.98038990 9.803858e-01 #> 4   8.740665e-01 0.87406897 8.740663e-01 #> 5   9.803926e-01 0.98038990 9.803858e-01 #> 6   9.803926e-01 0.98038990 9.803858e-01 #> 7   8.740665e-01 0.87406897 8.740663e-01 #> 8   0.000000e+00 0.00000000 0.000000e+00 #> 9   0.000000e+00 0.00000000 0.000000e+00 #> 10  9.803926e-01 0.98038990 9.803858e-01 #> 11  0.000000e+00 0.00000000 0.000000e+00 #> 12  9.803926e-01 0.98038990 9.803858e-01 #> 13  0.000000e+00 0.00000000 0.000000e+00 #> 14  8.740665e-01 0.87406897 8.740663e-01 #> 15  0.000000e+00 0.00000000 0.000000e+00 #> 16  8.399153e-02 0.08399119 8.398958e-02 #> 17  9.803926e-01 0.98038990 9.803858e-01 #> 18  0.000000e+00 0.00000000 0.000000e+00 #> 19  8.399153e-02 0.08399119 8.398958e-02 #> 20  8.399153e-02 0.08399119 8.398958e-02 #> 21  9.803926e-01 0.98038990 9.803858e-01 #> 22  8.399153e-02 0.08399119 8.398958e-02 #> 23  8.399153e-02 0.08399119 8.398958e-02 #> 24  0.000000e+00 0.00000000 0.000000e+00 #> 25  9.803926e-01 0.98038990 9.803858e-01 #> 26  9.803926e-01 0.98038990 9.803858e-01 #> 27  1.814101e-04 0.00000000 1.665335e-16 #> 28  8.740665e-01 0.87406897 8.740663e-01 #> 29  9.803926e-01 0.98038990 9.803858e-01 #> 30  0.000000e+00 0.00000000 0.000000e+00 #> 31  9.803926e-01 0.98038990 9.803858e-01 #> 32  9.803926e-01 0.98038990 9.803858e-01 #> 33  8.740665e-01 0.87406897 8.740663e-01 #> 34  0.000000e+00 0.00000000 0.000000e+00 #> 35  8.740665e-01 0.87406897 8.740663e-01 #> 36  9.803926e-01 0.98038990 9.803858e-01 #> 37  9.803926e-01 0.98038990 9.803858e-01 #> 38  0.000000e+00 0.00000000 0.000000e+00 #> 39  0.000000e+00 0.00000000 0.000000e+00 #> 40  0.000000e+00 0.00000000 0.000000e+00 #> 41  8.740665e-01 0.87406897 8.740663e-01 #> 42  8.399153e-02 0.08399119 8.398958e-02 #> 43  8.740665e-01 0.87406897 8.740663e-01 #> 44  8.399153e-02 0.08399119 8.398958e-02 #> 45  8.740665e-01 0.87406897 8.740663e-01 #> 46  0.000000e+00 0.00000000 0.000000e+00 #> 47  9.803926e-01 0.98038990 9.803858e-01 #> 48  8.740665e-01 0.87406897 8.740663e-01 #> 49  8.740665e-01 0.87406897 8.740663e-01 #> 50  8.399153e-02 0.08399119 8.398958e-02 #> 51  8.399153e-02 0.08399119 8.398958e-02 #> 52  0.000000e+00 0.00000000 0.000000e+00 #> 53  9.803926e-01 0.98038990 9.803858e-01 #> 54  8.740665e-01 0.87406897 8.740663e-01 #> 55  9.803926e-01 0.98038990 9.803858e-01 #> 56  9.803926e-01 0.98038990 9.803858e-01 #> 57  9.803926e-01 0.98038990 9.803858e-01 #> 58  8.399153e-02 0.08399119 8.398958e-02 #> 59  0.000000e+00 0.00000000 0.000000e+00 #> 60  9.803926e-01 0.98038990 9.803858e-01 #> 61  8.740665e-01 0.87406897 8.740663e-01 #> 62  8.740665e-01 0.87406897 8.740663e-01 #> 63  0.000000e+00 0.00000000 0.000000e+00 #> 64  0.000000e+00 0.00000000 0.000000e+00 #> 65  9.803926e-01 0.98038990 9.803858e-01 #> 66  9.803926e-01 0.98038990 9.803858e-01 #> 67  9.803926e-01 0.98038990 9.803858e-01 #> 68  0.000000e+00 0.00000000 0.000000e+00 #> 69  8.399153e-02 0.08399119 8.398958e-02 #> 70  0.000000e+00 0.00000000 0.000000e+00 #> 71  8.399153e-02 0.08399119 8.398958e-02 #> 72  8.399153e-02 0.08399119 8.398958e-02 #> 73  0.000000e+00 0.00000000 0.000000e+00 #> 74  8.399153e-02 0.08399119 8.398958e-02 #> 75  0.000000e+00 0.00000000 0.000000e+00 #> 76  8.740665e-01 0.87406897 8.740663e-01 #> 77  8.399153e-02 0.08399119 8.398958e-02 #> 78  8.399153e-02 0.08399119 8.398958e-02 #> 79  9.803926e-01 0.98038990 9.803858e-01 #> 80  8.740665e-01 0.87406897 8.740663e-01 #> 81  8.740665e-01 0.87406897 8.740663e-01 #> 82  8.740665e-01 0.87406897 8.740663e-01 #> 83  8.399153e-02 0.08399119 8.398958e-02 #> 84  8.740665e-01 0.87406897 8.740663e-01 #> 85  8.399153e-02 0.08399119 8.398958e-02 #> 86  8.399153e-02 0.08399119 8.398958e-02 #> 87  9.803926e-01 0.98038990 9.803858e-01 #> 88  9.986012e-01 0.99985040 1.000000e+00 #> 89  9.803926e-01 0.98038990 9.803858e-01 #> 90  8.740665e-01 0.87406897 8.740663e-01 #> 91  8.399153e-02 0.08399119 8.398958e-02 #> 92  0.000000e+00 0.00000000 0.000000e+00 #> 93  0.000000e+00 0.00000000 0.000000e+00 #> 94  0.000000e+00 0.00000000 0.000000e+00 #> 95  9.803926e-01 0.98038990 9.803858e-01 #> 96  8.399153e-02 0.08399119 8.398958e-02 #> 97  0.000000e+00 0.00000000 0.000000e+00 #> 98  0.000000e+00 0.00000000 0.000000e+00 #> 99  9.803926e-01 0.98038990 9.803858e-01 #> 100 8.740665e-01 0.87406897 8.740663e-01 #> 101 9.803926e-01 0.98038990 9.803858e-01 #> 102 8.399153e-02 0.08399119 8.398958e-02 #> 103 9.803926e-01 0.98038990 9.803858e-01 #> 104 0.000000e+00 0.00000000 0.000000e+00 #> 105 9.803926e-01 0.98038990 9.803858e-01 #> 106 0.000000e+00 0.00000000 0.000000e+00 #> 107 1.000000e+00 0.99995246 1.000000e+00 #> 108 8.740665e-01 0.87406897 8.740663e-01 #> 109 8.399153e-02 0.08399119 8.398958e-02 #> 110 0.000000e+00 0.00000000 0.000000e+00 #> 111 9.803926e-01 0.98038990 9.803858e-01 #> 112 9.803926e-01 0.98038990 9.803858e-01 #> 113 8.740665e-01 0.87406897 8.740663e-01 #> 114 8.399153e-02 0.08399119 8.398958e-02 #> 115 9.803926e-01 0.98038990 9.803858e-01 #> 116 8.740665e-01 0.87406897 8.740663e-01 #> 117 8.740665e-01 0.87406897 8.740663e-01 #> 118 0.000000e+00 0.00000000 0.000000e+00 #> 119 8.399153e-02 0.08399119 8.398958e-02 #> 120 9.803926e-01 0.98038990 9.803858e-01 #> 121 0.000000e+00 0.00000000 0.000000e+00 #> 122 8.740665e-01 0.87406897 8.740663e-01 #> 123 0.000000e+00 0.00000000 0.000000e+00 #> 124 8.399153e-02 0.08399119 8.398958e-02 #> 125 8.399153e-02 0.08399119 8.398958e-02 #> 126 9.803926e-01 0.98038990 9.803858e-01 #> 127 9.803926e-01 0.98038990 9.803858e-01 #> 128 9.803926e-01 0.98038990 9.803858e-01 #> 129 9.803926e-01 0.98038990 9.803858e-01 #> 130 8.399153e-02 0.08399119 8.398958e-02 #> 131 9.803926e-01 0.98038990 9.803858e-01 #> 132 8.399153e-02 0.08399119 8.398958e-02 #> 133 9.803926e-01 0.98038990 9.803858e-01 #> 134 8.740665e-01 0.87406897 8.740663e-01 #> 135 9.803926e-01 0.98038990 9.803858e-01 #> 136 8.740665e-01 0.87406897 8.740663e-01 #> 137 9.803926e-01 0.98038990 9.803858e-01 #> 138 8.740665e-01 0.87406897 8.740663e-01 #> 139 8.399153e-02 0.08399119 8.398958e-02 #> 140 0.000000e+00 0.00000000 0.000000e+00 #> 141 0.000000e+00 0.00000000 0.000000e+00 #> 142 0.000000e+00 0.00000000 0.000000e+00 #> 143 8.740665e-01 0.87406897 8.740663e-01 #> 144 8.740665e-01 0.87406897 8.740663e-01 #> 145 8.740665e-01 0.87406897 8.740663e-01 #> 146 8.399153e-02 0.08399119 8.398958e-02 #> 147 8.740665e-01 0.87406897 8.740663e-01 #> 148 9.803926e-01 0.98038990 9.803858e-01 #> 149 0.000000e+00 0.00000000 0.000000e+00 #> 150 8.740665e-01 0.87406897 8.740663e-01 #> 151 0.000000e+00 0.00000000 0.000000e+00 #> 152 0.000000e+00 0.00000000 0.000000e+00 #> 153 0.000000e+00 0.00000000 0.000000e+00 #> 154 9.803926e-01 0.98038990 9.803858e-01 #> 155 9.803926e-01 0.98038990 9.803858e-01 #> 156 9.803926e-01 0.98038990 9.803858e-01 #> 157 0.000000e+00 0.00000000 0.000000e+00 #> 158 8.399153e-02 0.08399119 8.398958e-02 #> 159 0.000000e+00 0.00000000 0.000000e+00 #> 160 0.000000e+00 0.00000000 0.000000e+00 #> 161 8.399153e-02 0.08399119 8.398958e-02 #> 162 0.000000e+00 0.00000000 0.000000e+00 #> 163 0.000000e+00 0.00000000 0.000000e+00 #> 164 9.803926e-01 0.98038990 9.803858e-01 #> 165 8.399153e-02 0.08399119 8.398958e-02 #> 166 8.740665e-01 0.87406897 8.740663e-01 #> 167 0.000000e+00 0.00000000 0.000000e+00 #> 168 8.740665e-01 0.87406897 8.740663e-01 #> 169 8.399153e-02 0.08399119 8.398958e-02 #> 170 9.803926e-01 0.98038990 9.803858e-01 #> 171 8.399153e-02 0.08399119 8.398958e-02 #> 172 8.740665e-01 0.87406897 8.740663e-01 #> 173 8.399153e-02 0.08399119 8.398958e-02 #> 174 9.803926e-01 0.98038990 9.803858e-01 #> 175 9.803926e-01 0.98038990 9.803858e-01 #> 176 0.000000e+00 0.00000000 0.000000e+00 #> 177 9.803926e-01 0.98038990 9.803858e-01 #> 178 8.740665e-01 0.87406897 8.740663e-01 #> 179 0.000000e+00 0.00000000 0.000000e+00 #> 180 0.000000e+00 0.00000000 0.000000e+00 #> 181 8.399153e-02 0.08399119 8.398958e-02 #> 182 9.803926e-01 0.98038990 9.803858e-01 #> 183 8.399153e-02 0.08399119 8.398958e-02 #> 184 9.803926e-01 0.98038990 9.803858e-01 #> 185 0.000000e+00 0.00000000 0.000000e+00 #> 186 9.803926e-01 0.98038990 9.803858e-01 #> 187 8.740665e-01 0.87406897 8.740663e-01 #> 188 8.740665e-01 0.87406897 8.740663e-01 #> 189 9.803926e-01 0.98038990 9.803858e-01 #> 190 0.000000e+00 0.00000000 0.000000e+00 #> 191 9.803926e-01 0.98038990 9.803858e-01 #> 192 0.000000e+00 0.00000000 0.000000e+00 #> 193 0.000000e+00 0.00000000 0.000000e+00 #> 194 8.740665e-01 0.87406897 8.740663e-01 #> 195 8.399153e-02 0.08399119 8.398958e-02 #> 196 9.803926e-01 0.98038990 9.803858e-01 #> 197 8.740665e-01 0.87406897 8.740663e-01 #> 198 9.803926e-01 0.98038990 9.803858e-01 #> 199 8.740665e-01 0.87406897 8.740663e-01 #> 200 0.000000e+00 0.00000000 0.000000e+00 #> 201 8.740665e-01 0.87406897 8.740663e-01 #> 202 8.399153e-02 0.08399119 8.398958e-02 #> 203 8.740665e-01 0.87406897 8.740663e-01 #> 204 8.740665e-01 0.87406897 8.740663e-01 #> 205 8.399153e-02 0.08399119 8.398958e-02 #> 206 0.000000e+00 0.00000000 0.000000e+00 #> 207 9.803926e-01 0.98038990 9.803858e-01 #> 208 8.399153e-02 0.08399119 8.398958e-02 #> 209 0.000000e+00 0.00000000 0.000000e+00 #> 210 9.803926e-01 0.98038990 9.803858e-01 #> 211 8.399153e-02 0.08399119 8.398958e-02 #> 212 0.000000e+00 0.00000000 0.000000e+00 #> 213 9.803926e-01 0.98038990 9.803858e-01 #> 214 9.803926e-01 0.98038990 9.803858e-01 #> 215 9.803926e-01 0.98038990 9.803858e-01 #> 216 8.399153e-02 0.08399119 8.398958e-02 #> 217 8.399153e-02 0.08399119 8.398958e-02 #> 218 9.803926e-01 0.98038990 9.803858e-01 #> 219 0.000000e+00 0.00000000 0.000000e+00 #> 220 8.399153e-02 0.08399119 8.398958e-02 #> 221 0.000000e+00 0.00000000 0.000000e+00 #> 222 8.399153e-02 0.08399119 8.398958e-02 #> 223 8.740665e-01 0.87406897 8.740663e-01 #> 224 0.000000e+00 0.00000000 0.000000e+00 #> 225 8.740665e-01 0.87406897 8.740663e-01 #> 226 8.740665e-01 0.87406897 8.740663e-01 #> 227 0.000000e+00 0.00000000 0.000000e+00 #> 228 1.000000e+00 0.99977443 1.000000e+00 #> 229 9.803926e-01 0.98038990 9.803858e-01 #> 230 9.803926e-01 0.98038990 9.803858e-01 #> 231 0.000000e+00 0.00000000 0.000000e+00 #> 232 9.803926e-01 0.98038990 9.803858e-01 #> 233 0.000000e+00 0.00000000 0.000000e+00 #> 234 9.803926e-01 0.98038990 9.803858e-01 #> 235 0.000000e+00 0.00000000 0.000000e+00 #> 236 0.000000e+00 0.00000000 0.000000e+00 #> 237 8.399153e-02 0.08399119 8.398958e-02 #> 238 9.803926e-01 0.98038990 9.803858e-01 #> 239 9.803926e-01 0.98038990 9.803858e-01 #> 240 8.740665e-01 0.87406897 8.740663e-01 #> 241 5.931236e-05 0.00000000 0.000000e+00 #> 242 8.740665e-01 0.87406897 8.740663e-01 #> 243 9.803926e-01 0.98038990 9.803858e-01 #> 244 0.000000e+00 0.00000000 0.000000e+00 #> 245 8.399153e-02 0.08399119 8.398958e-02 #> 246 8.399153e-02 0.08399119 8.398958e-02 #> 247 8.399153e-02 0.08399119 8.398958e-02 #> 248 8.399153e-02 0.08399119 8.398958e-02 #> 249 9.803926e-01 0.98038990 9.803858e-01 #> 250 0.000000e+00 0.00000000 0.000000e+00 modpls.B2$MissClassed #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] #> [1,]  124   11   13   11   11   11   11   11   11 plsR(simbin1$Y,dataAstar2[,-1],10,typeVC=\"standard\",MClassed=TRUE,verbose=FALSE)$InfCrit #>                  AIC     Q2cum_Y LimQ2_Y        Q2_Y  PRESS_Y    RSS_Y #> Nb_Comp_0  366.87968          NA      NA          NA       NA 62.49600 #> Nb_Comp_1  179.27607  0.52469907  0.0975  0.52469907 29.70441 29.27366 #> Nb_Comp_2  111.50920  0.63784869  0.0975  0.23805890 22.30480 22.14520 #> Nb_Comp_3   92.19471  0.61461931  0.0975 -0.06414274 23.56565 20.33539 #> Nb_Comp_4   92.80958  0.54850120  0.0975 -0.17156571 23.82425 20.22303 #> Nb_Comp_5   94.61150  0.46505988  0.0975 -0.18480962 23.96044 20.20702 #> Nb_Comp_6   96.58935  0.37811037  0.0975 -0.16254065 23.49148 20.20523 #> Nb_Comp_7   98.58715  0.28547861  0.0975 -0.14895208 23.21484 20.20505 #> Nb_Comp_8  100.58707  0.18505584  0.0975 -0.14054551 23.04478 20.20504 #> Nb_Comp_9  102.58707  0.07664463  0.0975 -0.13302900 22.89290 20.20504 #> Nb_Comp_10 104.58707 -0.03839400  0.0975 -0.12458760 22.72234 20.20504 #>                 R2_Y MissClassed R2_residY RSS_residY PRESS_residY   Q2_residY #> Nb_Comp_0         NA         124        NA  249.00000           NA          NA #> Nb_Comp_1  0.5315915          30 0.5315915  116.63372    118.34993  0.52469907 #> Nb_Comp_2  0.6456542           6 0.6456542   88.23211     88.86803  0.23805890 #> Nb_Comp_3  0.6746129           8 0.6746129   81.02138     93.89156 -0.06414274 #> Nb_Comp_4  0.6764108          11 0.6764108   80.57372     94.92187 -0.17156571 #> Nb_Comp_5  0.6766671          10 0.6766671   80.50990     95.46452 -0.18480962 #> Nb_Comp_6  0.6766957          10 0.6766957   80.50277     93.59604 -0.16254065 #> Nb_Comp_7  0.6766985          10 0.6766985   80.50206     92.49383 -0.14895208 #> Nb_Comp_8  0.6766986          10 0.6766986   80.50204     91.81627 -0.14054551 #> Nb_Comp_9  0.6766987          10 0.6766987   80.50203     91.21114 -0.13302900 #> Nb_Comp_10 0.6766987          10 0.6766987   80.50203     90.53159 -0.12458760 #>             LimQ2 Q2cum_residY  AIC.std   DoF.dof sigmahat.dof    AIC.dof #> Nb_Comp_0      NA           NA 712.4673  1.000000    0.5009870 0.25199190 #> Nb_Comp_1  0.0975   0.52469907 524.8637  2.621153    0.3433059 0.11956605 #> Nb_Comp_2  0.0975   0.63784869 457.0968  3.000068    0.2988230 0.09072392 #> Nb_Comp_3  0.0975   0.61461931 437.7823 21.497037    0.2976680 0.09657973 #> Nb_Comp_4  0.0975   0.54850120 438.3972 17.017307    0.2939891 0.09265852 #> Nb_Comp_5  0.0975   0.46505988 440.1991 17.406608    0.2941175 0.09287414 #> Nb_Comp_6  0.0975   0.37811037 442.1769 17.993023    0.2944743 0.09330304 #> Nb_Comp_7  0.0975   0.28547861 444.1747 18.501957    0.2947951 0.09368337 #> Nb_Comp_8  0.0975   0.18505584 446.1747 18.936590    0.2950710 0.09401017 #> Nb_Comp_9  0.0975   0.07664463 448.1747 19.634828    0.2955159 0.09453778 #> Nb_Comp_10 0.0975  -0.03839400 450.1747 19.983460    0.2957388 0.09480242 #>              BIC.dof  GMDL.dof DoF.naive sigmahat.naive  AIC.naive  BIC.naive #> Nb_Comp_0  0.2555273 -167.2823         1      0.5009870 0.25199190 0.25552728 #> Nb_Comp_1  0.1239175 -257.0188         2      0.3435680 0.11898326 0.12230862 #> Nb_Comp_2  0.0944974 -290.3040         3      0.2994272 0.09073255 0.09452122 #> Nb_Comp_3  0.1234100 -257.2238         4      0.2875138 0.08398681 0.08864439 #> Nb_Comp_4  0.1133760 -267.0758         5      0.2873030 0.08419385 0.09000729 #> Nb_Comp_5  0.1140840 -266.3413         6      0.2877771 0.08480321 0.09180238 #> Nb_Comp_6  0.1152807 -265.1168         7      0.2883558 0.08547725 0.09367583 #> Nb_Comp_7  0.1163320 -264.0546         8      0.2889497 0.08616367 0.09557211 #> Nb_Comp_8  0.1172342 -263.1526         9      0.2895485 0.08685653 0.09748493 #> Nb_Comp_9  0.1186908 -261.7148        10      0.2901511 0.08755518 0.09941372 #> Nb_Comp_10 0.1194214 -261.0020        11      0.2907575 0.08825968 0.10135865 #>            GMDL.naive #> Nb_Comp_0   -167.2823 #> Nb_Comp_1   -258.3373 #> Nb_Comp_2   -289.8052 #> Nb_Comp_3   -297.3647 #> Nb_Comp_4   -295.2257 #> Nb_Comp_5   -292.6062 #> Nb_Comp_6   -289.9866 #> Nb_Comp_7   -287.4310 #> Nb_Comp_8   -284.9391 #> Nb_Comp_9   -282.5049 #> Nb_Comp_10  -280.1229 cv.modpls.B2<-cv.plsR(Y~.,data=simbin1,2,NK=100,verbose=FALSE) res.cv.modpls.B2<-cvtable(summary(cv.modpls.B2,MClassed=TRUE)) #> ____************************************************____ #> Error in eval(mf, parent.frame()): object 'simbin1' not found #Only one component found by repeated CV missclassed criterion plot(res.cv.modpls.B2) #> Error: object 'res.cv.modpls.B2' not found  rm(list=c(\"dimX\",\"Astar\",\"dataAstar2\",\"modpls.A2\",\"cv.modpls.A2\", \"res.cv.modpls.A2\",\"simbin1\",\"modpls.B2\",\"cv.modpls.B2\",\"res.cv.modpls.B2\")) #> Warning: object 'res.cv.modpls.A2' not found #> Warning: object 'res.cv.modpls.B2' not found # }"},{"path":"https://fbertran.github.io/plsRglm/reference/plsRglm-package.html","id":null,"dir":"Reference","previous_headings":"","what":"plsRglm: Partial Least Squares Regression for Generalized Linear Models — plsRglm-package","title":"plsRglm: Partial Least Squares Regression for Generalized Linear Models — plsRglm-package","text":"Provides (weighted) Partial least squares Regression generalized linear models repeated k-fold cross-validation models using various criteria doi:10.48550/arXiv.1810.01005 . allows missing data explanatory variables. Bootstrap confidence intervals constructions also available.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsRglm-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"plsRglm: Partial Least Squares Regression for Generalized Linear Models — plsRglm-package","text":"short paper sums features package available https://arxiv.org/, Frédéric Bertrand Myriam Maumy-Bertrand (2018), \"plsRglm: Partial least squares linear generalized linear regression processing incomplete datasets cross-validation bootstrap techniques R\", *arxiv*, https://arxiv.org/abs/1810.01005, https://github.com/fbertran/plsRglm/ et https://fbertran.github.io/plsRglm/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/plsRglm-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"plsRglm: Partial Least Squares Regression for Generalized Linear Models — plsRglm-package","text":"Maintainer: Frederic Bertrand frederic.bertrand@lecnam.net (ORCID) Authors: Myriam Maumy-Bertrand myriam.maumy@ehesp.fr (ORCID)","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsRglm-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"plsRglm: Partial Least Squares Regression for Generalized Linear Models — plsRglm-package","text":"","code":"set.seed(314) library(plsRglm) data(Cornell) cv.modpls<-cv.plsR(Y~.,data=Cornell,nt=6,K=6) #> NK: 1  #> Number of groups : 6  #> 1  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 2  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 3  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 4  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 5 components could thus be extracted #> ****________________________________________________**** #>  #> 5  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  #> 6  #> ____************************************************____ #> ____Predicting X without NA neither in X nor in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ****________________________________________________**** #>  res.cv.modpls<-cvtable(summary(cv.modpls)) #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #>  #> CV Q2 criterion: #> 0 1  #> 0 1  #>  #> CV Press criterion: #> 1 2 3  #> 0 0 1"},{"path":"https://fbertran.github.io/plsRglm/reference/plsRglm.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial least squares Regression generalized linear models — plsRglm","title":"Partial least squares Regression generalized linear models — plsRglm","text":"function implements Partial least squares Regression generalized linear models complete incomplete datasets.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsRglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial least squares Regression generalized linear models — plsRglm","text":"","code":"plsRglm(object, ...) # Default S3 method plsRglmmodel(object,dataX,nt=2,limQ2set=.0975, dataPredictY=dataX,modele=\"pls\",family=NULL,typeVC=\"none\", EstimXNA=FALSE,scaleX=TRUE,scaleY=NULL,pvals.expli=FALSE, alpha.pvals.expli=.05,MClassed=FALSE,tol_Xi=10^(-12),weights, sparse=FALSE,sparseStop=TRUE,naive=FALSE,verbose=TRUE,...) # S3 method for class 'formula' plsRglmmodel(object,data=NULL,nt=2,limQ2set=.0975, dataPredictY,modele=\"pls\",family=NULL,typeVC=\"none\", EstimXNA=FALSE,scaleX=TRUE,scaleY=NULL,pvals.expli=FALSE, alpha.pvals.expli=.05,MClassed=FALSE,tol_Xi=10^(-12),weights,subset, start=NULL,etastart,mustart,offset,method=\"glm.fit\",control= list(), contrasts=NULL,sparse=FALSE,sparseStop=TRUE,naive=FALSE,verbose=TRUE,...) PLS_glm(dataY, dataX, nt = 2, limQ2set = 0.0975, dataPredictY = dataX,  modele = \"pls\", family = NULL, typeVC = \"none\", EstimXNA = FALSE,  scaleX = TRUE, scaleY = NULL, pvals.expli = FALSE,  alpha.pvals.expli = 0.05, MClassed = FALSE, tol_Xi = 10^(-12), weights,  method, sparse = FALSE, sparseStop=FALSE, naive=FALSE,verbose=TRUE) PLS_glm_formula(formula,data=NULL,nt=2,limQ2set=.0975,dataPredictY=dataX, modele=\"pls\",family=NULL,typeVC=\"none\",EstimXNA=FALSE,scaleX=TRUE, scaleY=NULL,pvals.expli=FALSE,alpha.pvals.expli=.05,MClassed=FALSE, tol_Xi=10^(-12),weights,subset,start=NULL,etastart,mustart,offset,method, control= list(),contrasts=NULL,sparse=FALSE,sparseStop=FALSE,naive=FALSE,verbose=TRUE)"},{"path":"https://fbertran.github.io/plsRglm/reference/plsRglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial least squares Regression generalized linear models — plsRglm","text":"object response (training) dataset object class \"formula\" (one can coerced class): symbolic description model fitted. details model specification given 'Details'. dataY response (training) dataset dataX predictor(s) (training) dataset formula object class \"formula\" (one can coerced class): symbolic description model fitted. details model specification given 'Details'. data optional data frame, list environment (object coercible .data.frame data frame) containing variables model. found data, variables taken environment(formula), typically environment plsRglm called. nt number components extracted limQ2set limit value Q2 dataPredictY predictor(s) (testing) dataset modele name PLS glm model fitted (\"pls\", \"pls-glm-Gamma\", \"pls-glm-gaussian\", \"pls-glm-inverse.gaussian\", \"pls-glm-logistic\", \"pls-glm-poisson\", \"pls-glm-polr\"). Use \"modele=pls-glm-family\" enable family option. family description error distribution link function used model. can character string naming family function, family function result call family function. (See family details family functions.) use family option, please set modele=\"pls-glm-family\". User defined families can also defined. See details. typeVC type leave one cross validation. back compatibility purpose. none cross validation  EstimXNA modele=\"pls\". Set whether missing X values estimated. scaleX scale predictor(s) : must set TRUE modele=\"pls\" glms pls. scaleY scale response : Yes/. Ignored since non always possible glm responses. pvals.expli individual p-values reported tune model selection ? alpha.pvals.expli level significance predictors pvals.expli=TRUE MClassed number missclassified cases, used binary responses tol_Xi minimal value Norm2(Xi) \\(\\mathrm{det}(pp' \\times pp)\\) missing value dataX. defaults \\(10^{-12}\\) weights optional vector 'prior weights' used fitting process. NULL numeric vector. subset optional vector specifying subset observations used fitting process. start starting values parameters linear predictor. etastart starting values linear predictor. mustart starting values vector means. offset can used specify priori known component included linear predictor fitting. NULL numeric vector length equal number cases. One offset terms can included formula instead well, one specified sum used. See model.offset. method glm model (modele=\"pls-glm-family\"), method used fitting model. default method \"glm.fit\" uses iteratively reweighted least squares (IWLS). User-supplied fitting functions can supplied either function character string naming function, function takes arguments glm.fit.   polr model (modele=\"pls-glm-polr\"), logistic probit (complementary) log-log (loglog cloglog) cauchit (corresponding Cauchy latent variable). control list parameters controlling fitting process. glm.fit passed glm.control. contrasts optional list. See contrasts.arg model.matrix.default. sparse coefficients non-significant predictors (<alpha.pvals.expli) set 0 sparseStop component extraction stop significant predictors (<alpha.pvals.expli) found naive Use naive estimates Degrees Freedom plsR? Default FALSE. verbose details displayed ? ... arguments pass plsRmodel.default plsRmodel.formula","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsRglm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial least squares Regression generalized linear models — plsRglm","text":"seven different predefined models predefined link functions available : \"pls\" ordinary pls models \"pls-glm-Gamma\" glm gaussian inverse link pls models \"pls-glm-gaussian\" glm gaussian identity link pls models \"pls-glm-inverse-gamma\" glm binomial square inverse link pls models \"pls-glm-logistic\" glm binomial logit link pls models \"pls-glm-poisson\" glm poisson log link pls models \"pls-glm-polr\" glm polr logit link pls models Using \"family=\" option setting \"modele=pls-glm-family\" allows changing family link function way glm function. consequence user-specified families can also used. gaussian family accepts links (names) identity, log inverse. binomial family accepts links logit, probit, cauchit, (corresponding logistic, normal Cauchy CDFs respectively) log cloglog (complementary log-log). Gamma family accepts links inverse, identity log. poisson family accepts links log, identity, sqrt. inverse.gaussian family accepts links 1/mu^2, inverse, identity log. quasi family accepts links logit, probit, cloglog, identity, inverse, log, 1/mu^2 sqrt. function power can used create power link function. typical predictor form response ~ terms response (numeric) response vector terms series terms specifies linear predictor response. terms specification form first + second indicates terms first together terms second duplicates removed. specification form first:second indicates set terms obtained taking interactions terms first terms second. specification first*second indicates cross first second. first + second + first:second. terms formula re-ordered main effects come first, followed interactions, second-order, third-order : avoid pass terms object formula. Non-NULL weights can used indicate different observations different dispersions (values weights inversely proportional dispersions); equivalently, elements weights positive integers w_i, response y_i mean w_i unit-weight observations. default estimator Degrees Freedom Kramer Sugiyama's one works classical plsR models. models, Information criteria computed accordingly estimations. Naive Degrees Freedom Information Criteria also provided comparison purposes. details, see N. Kraemer M. Sugiyama. (2011). Degrees Freedom Partial Least Squares Regression. Journal American Statistical Association, 106(494), 697-705, 2011.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsRglm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial least squares Regression generalized linear models — plsRglm","text":"Depends model used fit model. can generally least find items. nr Number observations nc Number predictors nt Number requested components ww raw weights (L2-normalization) wwnorm L2 normed weights (used deflated matrices predictor variables) wwetoile modified weights (used original matrix predictor variables) tt PLS components pp loadings predictor variables CoeffC coefficients PLS components uscores scores response variable YChapeau predicted response values dataX set residYChapeau residuals deflated response standardized scale RepY scaled response vector na.miss.Y NA value response vector YNA indicatrix vector missing values RepY residY deflated scaled response vector ExpliX scaled matrix predictors na.miss.X NA value predictor matrix XXNA indicator non-NA values predictor matrix residXX deflated predictor matrix PredictY response values NA replaced 0 RSS residual sum squares (original scale) RSSresidY residual sum squares (scaled scale) R2residY R2 coefficient value standardized scale R2 R2 coefficient value original scale press.ind individual PRESS value observation (scaled scale) press.tot total PRESS value observations (scaled scale) Q2cum cumulated Q2 (standardized scale) family glm family used fit PLSGLR model ttPredictY PLS components dataset prediction requested typeVC type leave one cross-validation used dataX predictor values dataY response values weights weights observations computed_nt number components computed AIC AIC vs number components BIC BIC vs number components Coeffsmodel_vals  ChisqPearson  CoeffCFull matrix coefficients predictors CoeffConstante value intercept (scaled scale) Std.Coeffs Vector standardized regression coefficients Coeffs Vector regression coefficients (used original data scale) Yresidus residuals PLS model residusY residuals deflated response standardized scale InfCrit table Information Criteria: AIC AIC vs number components BIC BIC vs number components MissClassed Number miss classed results Chi2_Pearson_Y Q2 value (standardized scale) RSS residual sum squares (original scale) R2 R2 coefficient value original scale R2residY R2 coefficient value standardized scale RSSresidY residual sum squares (scaled scale)  Std.ValsPredictY predicted response values supplementary dataset (standardized scale) ValsPredictY predicted response values supplementary dataset (original scale) Std.XChapeau estimated values missing values predictor matrix (standardized scale) FinalModel final GLR model PLS components XXwotNA predictor matrix missing values replaced 0 call call AIC.std AIC.std vs number components (AIC computed standardized model","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsRglm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partial least squares Regression generalized linear models — plsRglm","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frederic Bertrand (2010). Comparaison de la regression PLS et de la regression logistique PLS : application aux donnees d'allelotypage. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsRglm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Partial least squares Regression generalized linear models — plsRglm","text":"Frederic Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/plsRglm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Partial least squares Regression generalized linear models — plsRglm","text":"Use cv.plsRglm cross-validate plsRglm models bootplsglm bootstrap .","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/plsRglm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial least squares Regression generalized linear models — plsRglm","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8]  modplsglm <- plsRglm(yCornell,XCornell,10,modele=\"pls-glm-gaussian\") #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>   #To retrieve the final GLR model on the PLS components finalmod <- modplsglm$FinalModel #It is a glm object. plot(finalmod) #> Warning: not plotting observations with leverage one: #>   11      # \\donttest{ #Cross validation cv.modplsglm<-cv.plsRglm(Y~.,data=Cornell,6,NK=100,modele=\"pls-glm-gaussian\", verbose=FALSE) res.cv.modplsglm<-cvtable(summary(cv.modplsglm)) #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1,  2,  3,  4,  5,  6,  7,  8,  9,  10 #> NK: 11,  12,  13,  14,  15,  16,  17,  18,  19,  20 #> NK: 21,  22,  23,  24,  25,  26,  27,  28,  29,  30 #> NK: 31,  32,  33,  34,  35,  36,  37,  38,  39,  40 #> NK: 41,  42,  43,  44,  45,  46,  47,  48,  49,  50 #> NK: 51,  52,  53,  54,  55,  56,  57,  58,  59,  60 #> NK: 61,  62,  63,  64,  65,  66,  67,  68,  69,  70 #> NK: 71,  72,  73,  74,  75,  76,  77,  78,  79,  80 #> NK: 81,  82,  83,  84,  85,  86,  87,  88,  89,  90 #> NK: 91,  92,  93,  94,  95,  96,  97,  98,  99,  100 #>  #> CV Q2Chi2 criterion: #>  0  1  2  #>  0 28 72  #>  #> CV PreChi2 criterion: #>  1  2  3  4  5  #>  1 30 47 19  3  plot(res.cv.modplsglm)   #If no model specified, classic PLSR model modpls <- plsRglm(Y~.,data=Cornell,6) #> ____************************************************____ #>  #> Model: pls  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  modpls #> Number of required components: #> [1] 6 #> Number of successfully computed components: #> [1] 6 #> Coefficients: #>                  [,1] #> Intercept  88.7107982 #> X1        -54.3905712 #> X2         -2.7879678 #> X3         52.5411315 #> X4        -11.5306977 #> X5         -0.9605822 #> X6         11.5900307 #> X7         28.2104803 #> Information criteria and Fit statistics: #>                AIC      RSS_Y      R2_Y R2_residY  RSS_residY    AIC.std #> Nb_Comp_0 82.01205 467.796667        NA        NA 11.00000000  37.010388 #> Nb_Comp_1 53.15173  35.742486 0.9235940 0.9235940  0.84046633   8.150064 #> Nb_Comp_2 41.08283  11.066606 0.9763431 0.9763431  0.26022559  -3.918831 #> Nb_Comp_3 32.06411   4.418081 0.9905556 0.9905556  0.10388893 -12.937550 #> Nb_Comp_4 33.76477   4.309235 0.9907882 0.9907882  0.10132947 -11.236891 #> Nb_Comp_5 33.34373   3.521924 0.9924713 0.9924713  0.08281624 -11.657929 #> Nb_Comp_6 35.25533   3.496074 0.9925265 0.9925265  0.08220840  -9.746328 #>            DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof DoF.naive #> Nb_Comp_0 1.000000    6.5212706 46.0708838 47.7893514 27.59461         1 #> Nb_Comp_1 2.740749    1.8665281  4.5699686  4.9558156 21.34020         2 #> Nb_Comp_2 5.085967    1.1825195  2.1075461  2.3949331 27.40202         3 #> Nb_Comp_3 5.121086    0.7488308  0.8467795  0.9628191 24.40842         4 #> Nb_Comp_4 5.103312    0.7387162  0.8232505  0.9357846 24.23105         5 #> Nb_Comp_5 6.006316    0.7096382  0.7976101  0.9198348 28.21184         6 #> Nb_Comp_6 7.000002    0.7633343  0.9711322  1.1359502 33.18348         7 #>           sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4      0.7846050  0.8721072  0.9964867   24.16510 #> Nb_Comp_5      0.7661509  0.8804809  1.0227979   28.64206 #> Nb_Comp_6      0.8361907  1.1070902  1.3048716   33.63927 modpls$tt #>         Comp_1     Comp_2     Comp_3      Comp_4      Comp_5        Comp_6 #> 1   2.05131893  0.8217956  1.5820453 -0.61853330  0.01484108 -0.0004847062 #> 2   2.47466082  0.6488170  0.1093962  0.86769742  0.17352091 -0.0102365260 #> 3   2.33108430  0.9267035 -0.1729233  0.62591457 -0.21889565  0.0099484391 #> 4   2.03715457 -1.5957365 -0.5015374  0.52325099  0.10077311 -0.0020048043 #> 5  -0.06810714 -0.2178157 -2.9559035 -0.16013960 -0.08723778 -0.0005266324 #> 6   1.61381268 -1.4227579  0.9711117 -0.96297973 -0.05790672  0.0077470155 #> 7  -2.20425338 -0.1781166  0.2375256  0.05862843  0.16192611  0.0009678124 #> 8  -1.99354688  0.1006045  0.1184228  0.29283911  0.04069929  0.0069439383 #> 9  -2.08759464  0.1485897  0.3546081  0.06867502  0.06838481  0.0055358177 #> 10 -1.91577439  0.3184087  0.1964777  0.29953683 -0.02166158  0.0099892751 #> 11 -2.07628408 -0.4606368  1.0311837  0.30917216 -0.23179633 -0.0192401473 #> 12 -0.16247078  0.9101447 -0.9704071 -1.30406190  0.05735276 -0.0086394819 modpls$uscores #>          [,1]        [,2]       [,3]       [,4]        [,5]        [,6] #> 1   3.2182907  2.05967331  3.2801365  7.5269739  0.60581642  0.22391305 #> 2   2.9319848  0.80716434  0.4195899  1.3749676  0.03772786 -0.05145026 #> 3   2.5502436  0.38681011 -1.4306130 -5.5748469 -0.46117731 -0.09179745 #> 4   1.0869021 -1.67716952 -0.2157816  1.2666436  0.05528931 -0.01723324 #> 5  -0.6309334 -0.99337301 -2.0550769  3.9930120  0.30888775  0.15008693 #> 6   0.8324080 -1.37915791  0.1155316 -3.7924524 -0.21044006 -0.05779295 #> 7  -2.1260866  0.13796217  0.8375477  2.6596630  0.19345013  0.01194405 #> 8  -1.7443454  0.43983381  0.8988921  3.4595151  0.23551932  0.07381483 #> 9  -1.9670278  0.21279720  0.1701376 -0.8176856 -0.06592246 -0.05088731 #> 10 -1.7125336  0.35871439  0.1068023 -0.3974961 -0.05184134 -0.01143473 #> 11 -2.2851455 -0.36863467  0.2437879 -3.4902180 -0.28257699 -0.01924015 #> 12 -0.1537569  0.01537978 -2.3709538 -6.2080761 -0.36473264 -0.15992279 modpls$pp #>         Comp_1      Comp_2     Comp_3       Comp_4      Comp_5       Comp_6 #> X1 -0.45356016 -0.04251297  0.2729702  0.428653916 -0.35971989 -0.681738989 #> X2  0.03168571 -1.00322825  0.4493175 -0.166401110  0.36073990  0.004457454 #> X3 -0.45436193 -0.03899701  0.2707321  0.428071834 -0.28257532  0.725647289 #> X4 -0.35604722  0.27807191 -0.5331693 -0.375162994 -0.17744550  0.062078406 #> X5  0.29430620 -0.04543850 -0.4952981  0.868097080 -0.31806417  0.006305311 #> X6  0.46197139  0.43955413  0.1054092  0.018156887  0.05700168  0.034656940 #> X7 -0.41254369  0.47679210 -0.3389256  0.007896449  0.72448143 -0.059611275 modpls$Coeffs #>                  [,1] #> Intercept  88.7107982 #> X1        -54.3905712 #> X2         -2.7879678 #> X3         52.5411315 #> X4        -11.5306977 #> X5         -0.9605822 #> X6         11.5900307 #> X7         28.2104803  #rm(list=c(\"XCornell\",\"yCornell\",modpls,cv.modplsglm,res.cv.modplsglm)) # }  data(aze_compl) Xaze_compl<-aze_compl[,2:34] yaze_compl<-aze_compl$y plsRglm(yaze_compl,Xaze_compl,nt=10,modele=\"pls\",MClassed=TRUE, verbose=FALSE)$InfCrit #>                 AIC    RSS_Y      R2_Y MissClassed R2_residY RSS_residY #> Nb_Comp_0  154.6179 25.91346        NA          49        NA  103.00000 #> Nb_Comp_1  126.4083 19.38086 0.2520929          27 0.2520929   77.03443 #> Nb_Comp_2  119.3375 17.76209 0.3145613          25 0.3145613   70.60018 #> Nb_Comp_3  114.2313 16.58896 0.3598323          27 0.3598323   65.93728 #> Nb_Comp_4  112.3463 15.98071 0.3833049          23 0.3833049   63.51960 #> Nb_Comp_5  113.2362 15.81104 0.3898523          22 0.3898523   62.84522 #> Nb_Comp_6  114.7620 15.73910 0.3926285          21 0.3926285   62.55927 #> Nb_Comp_7  116.5264 15.70350 0.3940024          20 0.3940024   62.41775 #> Nb_Comp_8  118.4601 15.69348 0.3943888          20 0.3943888   62.37795 #> Nb_Comp_9  120.4452 15.69123 0.3944758          19 0.3944758   62.36900 #> Nb_Comp_10 122.4395 15.69037 0.3945088          19 0.3945088   62.36560 #>             AIC.std  DoF.dof sigmahat.dof   AIC.dof   BIC.dof  GMDL.dof #> Nb_Comp_0  298.1344  1.00000    0.5015845 0.2540061 0.2604032 -67.17645 #> Nb_Comp_1  269.9248 22.55372    0.4848429 0.2883114 0.4231184 -53.56607 #> Nb_Comp_2  262.8540 27.31542    0.4781670 0.2908950 0.4496983 -52.42272 #> Nb_Comp_3  257.7478 30.52370    0.4719550 0.2902572 0.4631316 -51.93343 #> Nb_Comp_4  255.8628 34.00000    0.4744263 0.3008285 0.4954133 -50.37079 #> Nb_Comp_5  256.7527 34.00000    0.4719012 0.2976347 0.4901536 -50.65724 #> Nb_Comp_6  258.2785 34.00000    0.4708264 0.2962804 0.4879234 -50.78005 #> Nb_Comp_7  260.0429 33.71066    0.4693382 0.2937976 0.4826103 -51.05525 #> Nb_Comp_8  261.9766 34.00000    0.4701436 0.2954217 0.4865092 -50.85833 #> Nb_Comp_9  263.9617 33.87284    0.4696894 0.2945815 0.4845867 -50.95616 #> Nb_Comp_10 265.9560 34.00000    0.4700970 0.2953632 0.4864128 -50.86368 #>            DoF.naive sigmahat.naive AIC.naive BIC.naive GMDL.naive #> Nb_Comp_0          1      0.5015845 0.2540061 0.2604032  -67.17645 #> Nb_Comp_1          2      0.4358996 0.1936625 0.2033251  -79.67755 #> Nb_Comp_2          3      0.4193593 0.1809352 0.1943501  -81.93501 #> Nb_Comp_3          4      0.4072955 0.1722700 0.1891422  -83.31503 #> Nb_Comp_4          5      0.4017727 0.1691819 0.1897041  -83.23369 #> Nb_Comp_5          6      0.4016679 0.1706451 0.1952588  -81.93513 #> Nb_Comp_6          7      0.4028135 0.1731800 0.2020601  -80.42345 #> Nb_Comp_7          8      0.4044479 0.1761610 0.2094352  -78.87607 #> Nb_Comp_8          9      0.4064413 0.1794902 0.2172936  -77.31942 #> Nb_Comp_9         10      0.4085682 0.1829787 0.2254232  -75.80069 #> Nb_Comp_10        11      0.4107477 0.1865584 0.2337468  -74.33325 modpls <- plsRglm(yaze_compl,Xaze_compl,nt=10,modele=\"pls-glm-logistic\", MClassed=TRUE,pvals.expli=TRUE, verbose=FALSE) modpls #> Number of required components: #> [1] 10 #> Number of successfully computed components: #> [1] 10 #> Coefficients: #>                   [,1] #> Intercept -2.276982302 #> D2S138    -1.068275295 #> D18S61     3.509231595 #> D16S422   -1.651869135 #> D17S794    2.207538418 #> D6S264     0.568523938 #> D14S65    -0.059691869 #> D18S53    -0.214529856 #> D17S790   -1.405223273 #> D1S225     0.396973880 #> D3S1282   -0.782167532 #> D9S179     0.677591817 #> D5S430    -0.972259676 #> D8S283     0.650745841 #> D11S916    0.723667343 #> D2S159     0.477540145 #> D16S408    0.638755948 #> D5S346     1.666070158 #> D10S191   -0.005938234 #> D13S173    0.482766293 #> D6S275    -0.904425334 #> D15S127    0.300460249 #> D1S305     1.367992779 #> D4S394    -1.201977825 #> D20S107   -1.536120691 #> D1S197    -1.983144986 #> D1S207     1.544435411 #> D10S192    1.410302156 #> D3S1283   -0.495400138 #> D4S414     0.454129717 #> D8S264     1.240250301 #> D22S928   -0.222933455 #> TP53      -2.822712745 #> D9S171     0.026369914 #> Information criteria and Fit statistics: #>                 AIC      BIC Missclassed Chi2_Pearson_Y    RSS_Y      R2_Y #> Nb_Comp_0  145.8283 148.4727          49      104.00000 25.91346        NA #> Nb_Comp_1  118.1398 123.4285          28      100.53823 19.32272 0.2543365 #> Nb_Comp_2  109.9553 117.8885          26       99.17955 17.33735 0.3309519 #> Nb_Comp_3  105.1591 115.7366          22      123.37836 15.58198 0.3986915 #> Nb_Comp_4  103.8382 117.0601          21      114.77551 15.14046 0.4157299 #> Nb_Comp_5  104.7338 120.6001          21      105.35382 15.08411 0.4179043 #> Nb_Comp_6  105.6770 124.1878          21       98.87767 14.93200 0.4237744 #> Nb_Comp_7  107.2828 128.4380          20       97.04072 14.87506 0.4259715 #> Nb_Comp_8  109.0172 132.8167          22       98.90110 14.84925 0.4269676 #> Nb_Comp_9  110.9354 137.3793          21      100.35563 14.84317 0.4272022 #> Nb_Comp_10 112.9021 141.9904          20      102.85214 14.79133 0.4292027 #>             R2_residY RSS_residY #> Nb_Comp_0          NA   25.91346 #> Nb_Comp_1   -6.004879  181.52066 #> Nb_Comp_2   -9.617595  275.13865 #> Nb_Comp_3  -12.332217  345.48389 #> Nb_Comp_4  -15.496383  427.47839 #> Nb_Comp_5  -15.937183  438.90105 #> Nb_Comp_6  -16.700929  458.69233 #> Nb_Comp_7  -16.908851  464.08033 #> Nb_Comp_8  -17.555867  480.84675 #> Nb_Comp_9  -17.834439  488.06552 #> Nb_Comp_10 -17.999267  492.33678 #> Model with all the required components: #>  #> Call:  glm(formula = YwotNA ~ ., family = family, data = tttrain) #>  #> Coefficients: #> (Intercept)         tt.1         tt.2         tt.3         tt.4         tt.5   #>    -0.24597      1.54105      0.47489      0.89142      0.51153      0.33475   #>        tt.6         tt.7         tt.8         tt.9        tt.10   #>     0.35595      0.23350      0.21274      0.09192      0.06302   #>  #> Degrees of Freedom: 103 Total (i.e. Null);  93 Residual #> Null Deviance:\t    143.8  #> Residual Deviance: 90.9 \tAIC: 112.9 colSums(modpls$pvalstep) #> temppvalstep temppvalstep temppvalstep temppvalstep temppvalstep temppvalstep  #>            2            1            0            0            0            0  #> temppvalstep temppvalstep temppvalstep temppvalstep  #>            0            0            0            0  modpls$Coeffsmodel_vals #>               Estimate Std. Error    z value  Pr(>|z|)   Estimate Std. Error #> (Intercept) -0.1155129  0.1964432 -0.5880218 0.5565177 -0.1916697  0.2303635 #>                     NA         NA         NA        NA  1.0860661  0.2374093 #>                     NA         NA         NA        NA         NA         NA #>                     NA         NA         NA        NA         NA         NA #>                     NA         NA         NA        NA         NA         NA #>                     NA         NA         NA        NA         NA         NA #>                     NA         NA         NA        NA         NA         NA #>                     NA         NA         NA        NA         NA         NA #>                     NA         NA         NA        NA         NA         NA #>                     NA         NA         NA        NA         NA         NA #>                     NA         NA         NA        NA         NA         NA #>                z value     Pr(>|z|)   Estimate Std. Error    z value #> (Intercept) -0.8320314 4.053912e-01 -0.1780926  0.2422018 -0.7353066 #>              4.5746567 4.770016e-06  1.2611189  0.2751714  4.5830296 #>                     NA           NA  0.4491918  0.1525562  2.9444352 #>                     NA           NA         NA         NA         NA #>                     NA           NA         NA         NA         NA #>                     NA           NA         NA         NA         NA #>                     NA           NA         NA         NA         NA #>                     NA           NA         NA         NA         NA #>                     NA           NA         NA         NA         NA #>                     NA           NA         NA         NA         NA #>                     NA           NA         NA         NA         NA #>                 Pr(>|z|)   Estimate Std. Error    z value     Pr(>|z|) #> (Intercept) 4.621528e-01 -0.2296856  0.2551324 -0.9002602 3.679818e-01 #>             4.582872e-06  1.3603921  0.2991217  4.5479546 5.416983e-06 #>             3.235447e-03  0.4513946  0.1577291  2.8618340 4.211975e-03 #>                       NA  0.7351530  0.2969651  2.4755532 1.330299e-02 #>                       NA         NA         NA         NA           NA #>                       NA         NA         NA         NA           NA #>                       NA         NA         NA         NA           NA #>                       NA         NA         NA         NA           NA #>                       NA         NA         NA         NA           NA #>                       NA         NA         NA         NA           NA #>                       NA         NA         NA         NA           NA #>               Estimate Std. Error   z value     Pr(>|z|)   Estimate Std. Error #> (Intercept) -0.2631783  0.2622355 -1.003595 3.155738e-01 -0.2598139  0.2644378 #>              1.4806072  0.3244631  4.563253 5.036706e-06  1.4929412  0.3299548 #>              0.4747033  0.1624087  2.922894 3.467946e-03  0.4774613  0.1631709 #>              0.8168174  0.3055562  2.673215 7.512815e-03  0.8198024  0.3065426 #>              0.4468736  0.2530751  1.765775 7.743367e-02  0.4534822  0.2507909 #>                     NA         NA        NA           NA  0.2427411  0.2336729 #>                     NA         NA        NA           NA         NA         NA #>                     NA         NA        NA           NA         NA         NA #>                     NA         NA        NA           NA         NA         NA #>                     NA         NA        NA           NA         NA         NA #>                     NA         NA        NA           NA         NA         NA #>                z value     Pr(>|z|)   Estimate Std. Error    z value #> (Intercept) -0.9825141 3.258466e-01 -0.2591151  0.2659184 -0.9744157 #>              4.5246846 6.048563e-06  1.5079215  0.3316435  4.5468147 #>              2.9261429 3.431933e-03  0.4740832  0.1639150  2.8922506 #>              2.6743507 7.487410e-03  0.8488272  0.3138940  2.7041841 #>              1.8082086 7.057404e-02  0.4750095  0.2529611  1.8777963 #>              1.0388072 2.988944e-01  0.2926709  0.2405633  1.2166065 #>                     NA           NA  0.3152581  0.3086154  1.0215244 #>                     NA           NA         NA         NA         NA #>                     NA           NA         NA         NA         NA #>                     NA           NA         NA         NA         NA #>                     NA           NA         NA         NA         NA #>                 Pr(>|z|)   Estimate Std. Error    z value     Pr(>|z|) #> (Intercept) 3.298502e-01 -0.2511020  0.2665107 -0.9421836 3.460986e-01 #>             5.446390e-06  1.5066928  0.3286117  4.5850242 4.539339e-06 #>             3.824927e-03  0.4695250  0.1636168  2.8696632 4.109093e-03 #>             6.847234e-03  0.8655113  0.3167212  2.7327230 6.281313e-03 #>             6.040904e-02  0.4869181  0.2569742  1.8948132 5.811715e-02 #>             2.237540e-01  0.3127604  0.2432912  1.2855395 1.986038e-01 #>             3.070060e-01  0.3414775  0.3071860  1.1116313 2.662967e-01 #>                       NA  0.1759267  0.2823982  0.6229738 5.333017e-01 #>                       NA         NA         NA         NA           NA #>                       NA         NA         NA         NA           NA #>                       NA         NA         NA         NA           NA #>               Estimate Std. Error    z value     Pr(>|z|)    Estimate #> (Intercept) -0.2384005  0.2677851 -0.8902678 3.733221e-01 -0.24302353 #>              1.5260550  0.3332262  4.5796371 4.657834e-06  1.53551302 #>              0.4751856  0.1647356  2.8845352 3.919920e-03  0.47435732 #>              0.8833506  0.3211506  2.7505809 5.948970e-03  0.88832250 #>              0.5051588  0.2602702  1.9409013 5.227026e-02  0.51143914 #>              0.3266900  0.2457243  1.3294979 1.836838e-01  0.33288203 #>              0.3553735  0.3066020  1.1590710 2.464272e-01  0.35367508 #>              0.2190251  0.2960578  0.7398053 4.594182e-01  0.22974545 #>              0.1958595  0.3804306  0.5148364 6.066673e-01  0.20542758 #>                     NA         NA         NA           NA  0.08025328 #>                     NA         NA         NA           NA          NA #>             Std. Error    z value     Pr(>|z|)    Estimate Std. Error #> (Intercept)  0.2687971 -0.9041150 3.659344e-01 -0.24597264  0.2694749 #>              0.3374570  4.5502475 5.358285e-06  1.54105173  0.3404396 #>              0.1649223  2.8762474 4.024342e-03  0.47489173  0.1650133 #>              0.3223046  2.7561583 5.848469e-03  0.89142494  0.3238360 #>              0.2617010  1.9542883 5.066714e-02  0.51152578  0.2616836 #>              0.2471900  1.3466648 1.780882e-01  0.33475232  0.2480448 #>              0.3066587  1.1533184 2.487797e-01  0.35595360  0.3067304 #>              0.2980235  0.7708970 4.407680e-01  0.23349638  0.2986792 #>              0.3822961  0.5373521 5.910244e-01  0.21273736  0.3839796 #>              0.2813259  0.2852680 7.754388e-01  0.09192325  0.2880633 #>                     NA         NA           NA  0.06301759  0.3456878 #>                z value     Pr(>|z|) #> (Intercept) -0.9127851 3.613556e-01 #>              4.5266528 5.992528e-06 #>              2.8779001 4.003319e-03 #>              2.7527047 5.910518e-03 #>              1.9547488 5.061273e-02 #>              1.3495639 1.771559e-01 #>              1.1604769 2.458547e-01 #>              0.7817631 4.343538e-01 #>              0.5540330 5.795563e-01 #>              0.3191079 7.496447e-01 #>              0.1822962 8.553502e-01  plot(plsRglm(yaze_compl,Xaze_compl,4,modele=\"pls-glm-logistic\")$FinalModel) #> ____************************************************____ #>  #> Family: binomial  #> Link function: logit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>      plsRglm(yaze_compl[-c(99,72)],Xaze_compl[-c(99,72),],4, modele=\"pls-glm-logistic\",pvals.expli=TRUE)$pvalstep #> ____************************************************____ #>  #> Family: binomial  #> Link function: logit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>       temppvalstep temppvalstep temppvalstep temppvalstep #>  [1,]            0            0            0            0 #>  [2,]            1            0            0            0 #>  [3,]            0            0            0            0 #>  [4,]            0            0            0            0 #>  [5,]            0            0            0            0 #>  [6,]            0            0            0            0 #>  [7,]            0            0            0            0 #>  [8,]            0            0            0            0 #>  [9,]            0            0            0            0 #> [10,]            0            0            0            0 #> [11,]            0            0            0            0 #> [12,]            0            0            0            0 #> [13,]            0            0            0            0 #> [14,]            1            0            0            0 #> [15,]            0            0            0            0 #> [16,]            0            0            0            0 #> [17,]            1            0            0            0 #> [18,]            0            0            0            0 #> [19,]            0            0            0            0 #> [20,]            0            0            0            0 #> [21,]            0            0            0            0 #> [22,]            0            0            0            0 #> [23,]            0            0            0            0 #> [24,]            0            0            0            0 #> [25,]            0            1            0            0 #> [26,]            0            0            0            0 #> [27,]            0            0            0            0 #> [28,]            0            0            0            0 #> [29,]            0            0            0            0 #> [30,]            0            0            0            0 #> [31,]            0            0            0            0 #> [32,]            0            1            0            0 #> [33,]            0            0            0            0 plot(plsRglm(yaze_compl[-c(99,72)],Xaze_compl[-c(99,72),],4, modele=\"pls-glm-logistic\",pvals.expli=TRUE)$FinalModel) #> ____************************************************____ #>  #> Family: binomial  #> Link function: logit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>      rm(list=c(\"Xaze_compl\",\"yaze_compl\",\"modpls\"))   data(bordeaux) Xbordeaux<-bordeaux[,1:4] ybordeaux<-factor(bordeaux$Quality,ordered=TRUE) modpls <- plsRglm(ybordeaux,Xbordeaux,10,modele=\"pls-glm-polr\",pvals.expli=TRUE) #> ____************************************************____ #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> Warning : 1 2 3 4 < 10^{-12} #> Warning only 4 components could thus be extracted #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  modpls #> Number of required components: #> [1] 10 #> Number of successfully computed components: #> [1] 4 #> Coefficients: #>                     [,1] #> 1|2         -85.50956454 #> 2|3         -80.55155990 #> Temperature   0.02427235 #> Sunshine      0.01379029 #> Heat         -0.08876364 #> Rain         -0.02589509 #> Information criteria and Fit statistics: #>                AIC      BIC Missclassed Chi2_Pearson_Y #> Nb_Comp_0 78.64736 81.70009          22      62.333333 #> Nb_Comp_1 36.50286 41.08194           6       9.356521 #> Nb_Comp_2 35.58058 41.68602           6       8.568956 #> Nb_Comp_3 36.26588 43.89768           7       8.281011 #> Nb_Comp_4 38.15799 47.31616           7       8.321689 colSums(modpls$pvalstep) #> temppvalstep temppvalstep temppvalstep temppvalstep  #>            4            0            0            0    XbordeauxNA<-Xbordeaux XbordeauxNA[1,1] <- NA modplsNA <- plsRglm(ybordeaux,XbordeauxNA,10,modele=\"pls-glm-polr\",pvals.expli=TRUE) #> ____************************************************____ #> Only naive DoF can be used with missing data #>  #> Model: pls-glm-polr  #> Method: logistic  #>  #> ____There are some NAs in X but not in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> Warning : reciprocal condition number of t(cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE])%*%cbind(res$pp,temppp)[XXNA[1,],,drop=FALSE] < 10^{-12} #> Warning only 3 components could thus be extracted #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  modpls #> Number of required components: #> [1] 10 #> Number of successfully computed components: #> [1] 4 #> Coefficients: #>                     [,1] #> 1|2         -85.50956454 #> 2|3         -80.55155990 #> Temperature   0.02427235 #> Sunshine      0.01379029 #> Heat         -0.08876364 #> Rain         -0.02589509 #> Information criteria and Fit statistics: #>                AIC      BIC Missclassed Chi2_Pearson_Y #> Nb_Comp_0 78.64736 81.70009          22      62.333333 #> Nb_Comp_1 36.50286 41.08194           6       9.356521 #> Nb_Comp_2 35.58058 41.68602           6       8.568956 #> Nb_Comp_3 36.26588 43.89768           7       8.281011 #> Nb_Comp_4 38.15799 47.31616           7       8.321689 colSums(modpls$pvalstep) #> temppvalstep temppvalstep temppvalstep temppvalstep  #>            4            0            0            0  rm(list=c(\"Xbordeaux\",\"XbordeauxNA\",\"ybordeaux\",\"modplsNA\"))  # \\donttest{ data(pine) Xpine<-pine[,1:10] ypine<-pine[,11] modpls1 <- plsRglm(ypine,Xpine,1) #> ____************************************************____ #>  #> Model: pls  #>  #> ____Component____ 1 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  modpls1$Std.Coeffs #>                  [,1] #> Intercept  0.00000000 #> x1        -0.12075822 #> x2        -0.10373136 #> x3        -0.12842935 #> x4        -0.08151265 #> x5        -0.03593266 #> x6        -0.12987323 #> x7        -0.04822603 #> x8        -0.12552116 #> x9        -0.14482083 #> x10       -0.02820877 modpls1$Coeffs #>                    [,1] #> Intercept  4.1382956708 #> x1        -0.0007545026 #> x2        -0.0114506575 #> x3        -0.0108576908 #> x4        -0.0631435196 #> x5        -0.0067331994 #> x6        -0.1459627512 #> x7        -0.2077725998 #> x8        -0.0430293759 #> x9        -0.2061096267 #> x10       -0.0887273019 modpls4 <- plsRglm(ypine,Xpine,4) #> ____************************************************____ #>  #> Model: pls  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  modpls4$Std.Coeffs #>                 [,1] #> Intercept  0.0000000 #> x1        -0.4420109 #> x2        -0.3440382 #> x3         0.2638393 #> x4        -0.2948914 #> x5         0.3931541 #> x6         0.2227973 #> x7        -0.1176200 #> x8        -0.2582013 #> x9        -0.5091120 #> x10       -0.1219269 modpls4$Coeffs #>                   [,1] #> Intercept  8.350613628 #> x1        -0.002761704 #> x2        -0.037977559 #> x3         0.022305538 #> x4        -0.228436678 #> x5         0.073670736 #> x6         0.250398830 #> x7        -0.506743287 #> x8        -0.088512880 #> x9        -0.724570373 #> x10       -0.383506358 modpls4$PredictY[1,] #>         x1         x2         x3         x4         x5         x6         x7  #> -0.8938006 -0.9625784 -1.0962764 -0.4338283 -0.1049413 -1.1025308 -2.9795617  #>         x8         x9        x10  #> -0.6970648 -1.0270611 -1.3713833  plsRglm(ypine,Xpine,4,dataPredictY=Xpine[1,])$PredictY[1,] #> ____************************************************____ #>  #> Model: pls  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  #>         x1         x2         x3         x4         x5         x6         x7  #> -0.8938006 -0.9625784 -1.0962764 -0.4338283 -0.1049413 -1.1025308 -2.9795617  #>         x8         x9        x10  #> -0.6970648 -1.0270611 -1.3713833   XpineNAX21 <- Xpine XpineNAX21[1,2] <- NA modpls4NA <- plsRglm(ypine,XpineNAX21,4) #> ____************************************************____ #> Only naive DoF can be used with missing data #>  #> Model: pls  #>  #> ____There are some NAs in X but not in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  modpls4NA$Std.Coeffs #>                 [,1] #> Intercept  0.0000000 #> x1        -0.4482129 #> x2        -0.3419468 #> x3         0.2639767 #> x4        -0.2976908 #> x5         0.3980568 #> x6         0.2227265 #> x7        -0.1003291 #> x8        -0.2630762 #> x9        -0.5134822 #> x10       -0.1155765 modpls4NA$YChapeau[1,] #>        1  #> 2.063442  modpls4$YChapeau[1,] #>        1  #> 2.019396  modpls4NA$CoeffC #> Coeff_Comp_Reg 1 Coeff_Comp_Reg 2 Coeff_Comp_Reg 3 Coeff_Comp_Reg 4  #>        0.3259018        0.3206317        0.2795367        0.3837106  plsRglm(ypine,XpineNAX21,4,EstimXNA=TRUE)$XChapeau #> ____************************************************____ #> Only naive DoF can be used with missing data #>  #> Model: pls  #>  #> ____There are some NAs in X but not in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  #>          x1       x2          x3       x4        x5        x6       x7 #> 1  1134.926 17.71027 -1.55494586 4.617652 17.305716 0.8486361 1.478701 #> 2  1289.388 28.04038  7.90829874 4.624402 17.149156 1.5219847 1.602875 #> 3  1249.652 28.26614  4.04605095 2.766712  9.769908 1.1702877 1.691789 #> 4  1302.534 27.62757 17.52125611 3.253130 10.847486 2.1870969 1.736890 #> 5  1348.106 34.85765  5.39129800 3.929641 12.914210 1.3214368 1.704204 #> 6  1266.414 28.96388  0.65947289 4.266220 15.814114 0.9760181 1.594253 #> 7  1432.714 36.98512 23.67253140 3.129351  8.217668 2.6460431 1.876249 #> 8  1404.730 37.58134  5.32566106 5.727770 20.722755 1.3677455 1.611431 #> 9  1180.796 21.81141  2.88848941 3.335411 11.169400 1.1333238 1.619553 #> 10 1275.948 27.24037  9.65604429 3.771598 11.989421 1.6470259 1.681580 #> 11 1259.564 20.94764 16.48622739 5.667959 18.533231 2.2445475 1.575084 #> 12 1394.964 27.98596 31.86797620 5.563379 21.664911 3.2946812 1.650637 #> 13 1135.520 19.18086  0.32731180 3.036465 11.266662 0.9204965 1.584646 #> 14 1238.978 25.77450  1.37695304 4.752455 19.126468 1.0315111 1.524638 #> 15 1247.316 26.42985  3.58143639 4.146871 15.175624 1.1926480 1.598700 #> 16 1501.750 38.06874 29.19896489 5.556556 18.392884 3.1295468 1.764202 #> 17 1450.581 35.94538 22.31619700 5.619470 20.182786 2.6095860 1.687935 #> 18 1252.985 25.62811  5.23193278 4.605906 14.947795 1.3637731 1.606747 #> 19 1327.516 32.77904  9.61237796 3.044450  9.806764 1.5946018 1.752730 #> 20 1429.839 36.31945 18.92696106 4.738709 15.290167 2.3501708 1.746581 #> 21 1377.533 27.81569 29.35999846 5.107524 18.668226 3.1133147 1.682007 #> 22 1318.284 28.04601 16.03323018 4.365471 14.743435 2.1271150 1.677908 #> 23 1325.821 31.50718  5.58479450 4.966866 17.261144 1.3774365 1.617724 #> 24 1383.070 31.25375 21.66717959 4.793301 16.260553 2.5508573 1.707051 #> 25 1463.234 42.03186 10.45349969 4.878436 16.759389 1.7107863 1.726395 #> 26 1301.669 29.43958  6.08840693 4.752488 15.708156 1.4213115 1.627982 #> 27 1390.268 30.07541 19.80133275 6.653309 23.022739 2.4959599 1.593548 #> 28 1236.133 28.52827  0.08033458 2.566106  6.654150 0.9086939 1.722742 #> 29 1196.392 23.15203  3.03238784 3.307398 10.802144 1.1440582 1.635806 #> 30 1265.126 24.40645 14.03965248 3.978220 11.110834 2.0069974 1.696349 #> 31 1293.488 27.99940  7.51088152 5.069256 19.457843 1.5011917 1.566879 #> 32 1250.314 22.52645 10.77971133 5.291157 16.422781 1.8201013 1.590744 #> 33 1407.143 33.66167 19.58235996 5.058855 16.210758 2.4207837 1.717287 #>           x8       x9      x10 #> 1   6.105504 1.326767 1.647842 #> 2   6.882002 1.660718 1.629429 #> 3   3.757650 1.284641 1.725048 #> 4   6.421039 2.062960 1.892126 #> 5   5.987267 1.652982 1.682369 #> 6   5.454892 1.287215 1.567051 #> 7   7.544949 2.574739 2.006478 #> 8   8.157027 1.715136 1.468098 #> 9   5.082501 1.505169 1.812920 #> 10  6.686354 1.941424 1.849234 #> 11 10.892806 2.672310 1.925674 #> 12 10.645052 2.659727 1.738274 #> 13  3.883547 1.174771 1.746730 #> 14  5.741519 1.174675 1.475078 #> 15  5.794444 1.450750 1.647027 #> 16 11.388213 2.984510 1.830369 #> 17 10.075867 2.462894 1.670380 #> 18  7.598409 1.921157 1.790273 #> 19  5.100449 1.686284 1.783541 #> 20  9.030929 2.446771 1.799899 #> 21 10.240385 2.699833 1.836498 #> 22  8.066347 2.207112 1.829440 #> 23  7.530488 1.773139 1.631801 #> 24  9.286715 2.494618 1.828172 #> 25  7.617564 1.892788 1.570558 #> 26  7.677432 1.907246 1.728978 #> 27 12.072562 2.739598 1.733802 #> 28  4.043894 1.474978 1.868514 #> 29  5.121026 1.537486 1.819119 #> 30  8.364931 2.461724 2.036300 #> 31  7.233594 1.604288 1.553519 #> 32  9.906396 2.472563 1.923566 #> 33  9.829378 2.595127 1.840669 plsRglm(ypine,XpineNAX21,4,EstimXNA=TRUE)$XChapeauNA #> ____************************************************____ #> Only naive DoF can be used with missing data #>  #> Model: pls  #>  #> ____There are some NAs in X but not in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  #>    [,1]     [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] #> 1     0 17.71027    0    0    0    0    0    0    0     0 #> 2     0  0.00000    0    0    0    0    0    0    0     0 #> 3     0  0.00000    0    0    0    0    0    0    0     0 #> 4     0  0.00000    0    0    0    0    0    0    0     0 #> 5     0  0.00000    0    0    0    0    0    0    0     0 #> 6     0  0.00000    0    0    0    0    0    0    0     0 #> 7     0  0.00000    0    0    0    0    0    0    0     0 #> 8     0  0.00000    0    0    0    0    0    0    0     0 #> 9     0  0.00000    0    0    0    0    0    0    0     0 #> 10    0  0.00000    0    0    0    0    0    0    0     0 #> 11    0  0.00000    0    0    0    0    0    0    0     0 #> 12    0  0.00000    0    0    0    0    0    0    0     0 #> 13    0  0.00000    0    0    0    0    0    0    0     0 #> 14    0  0.00000    0    0    0    0    0    0    0     0 #> 15    0  0.00000    0    0    0    0    0    0    0     0 #> 16    0  0.00000    0    0    0    0    0    0    0     0 #> 17    0  0.00000    0    0    0    0    0    0    0     0 #> 18    0  0.00000    0    0    0    0    0    0    0     0 #> 19    0  0.00000    0    0    0    0    0    0    0     0 #> 20    0  0.00000    0    0    0    0    0    0    0     0 #> 21    0  0.00000    0    0    0    0    0    0    0     0 #> 22    0  0.00000    0    0    0    0    0    0    0     0 #> 23    0  0.00000    0    0    0    0    0    0    0     0 #> 24    0  0.00000    0    0    0    0    0    0    0     0 #> 25    0  0.00000    0    0    0    0    0    0    0     0 #> 26    0  0.00000    0    0    0    0    0    0    0     0 #> 27    0  0.00000    0    0    0    0    0    0    0     0 #> 28    0  0.00000    0    0    0    0    0    0    0     0 #> 29    0  0.00000    0    0    0    0    0    0    0     0 #> 30    0  0.00000    0    0    0    0    0    0    0     0 #> 31    0  0.00000    0    0    0    0    0    0    0     0 #> 32    0  0.00000    0    0    0    0    0    0    0     0 #> 33    0  0.00000    0    0    0    0    0    0    0     0  # compare pls-glm-gaussian with classic plsR modplsglm4 <- plsRglm(ypine,Xpine,4,modele=\"pls-glm-gaussian\") #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  cbind(modpls4$Std.Coeffs,modplsglm4$Std.Coeffs) #>                 [,1]        [,2] #> Intercept  0.0000000  0.81121212 #> x1        -0.4420109 -0.34178559 #> x2        -0.3440382 -0.26828907 #> x3         0.2638393  0.19051737 #> x4        -0.2948914 -0.09571119 #> x5         0.3931541  0.17792633 #> x6         0.2227973  0.24017232 #> x7        -0.1176200 -0.12049491 #> x8        -0.2582013 -0.11958412 #> x9        -0.5091120 -0.58148650 #> x10       -0.1219269 -0.04519212  # without missing data cbind(ypine,modpls4$ValsPredictY,modplsglm4$ValsPredictY) #>    ypine                          #> 1   2.37  2.01939633  2.025720690 #> 2   1.47  1.24570213  1.188171412 #> 3   1.13  1.53585542  1.417980819 #> 4   0.85  1.04161870  0.901257566 #> 5   0.24  0.58902449  0.539466433 #> 6   1.49  1.37731103  1.394223504 #> 7   0.30 -0.17938500 -0.181775915 #> 8   0.07  0.39516648  0.513587769 #> 9   3.00  1.60139990  1.576666292 #> 10  1.21  0.86352520  0.915171230 #> 11  0.38  0.64182858  0.636399772 #> 12  0.70  0.92157715  0.906678742 #> 13  2.64  2.19169300  2.197201851 #> 14  2.05  1.84688715  1.849649772 #> 15  1.75  1.43462512  1.475461977 #> 16  0.06 -0.48552205 -0.373068343 #> 17  0.13  0.15763382 -0.036909766 #> 18  1.00  0.88458167  0.805974957 #> 19  0.41  0.82968208  0.811023094 #> 20  0.72 -0.06160100 -0.009618538 #> 21  0.67  0.71563687  0.690072944 #> 22  0.12  0.76705111  0.734843252 #> 23  0.97  0.68206508  0.723928013 #> 24  0.07  0.36607751  0.409261632 #> 25  0.10 -0.01161858 -0.049135741 #> 26  0.68  0.64060202  0.676658656 #> 27  0.13  0.07976920  0.142983517 #> 28  0.20  0.98446655  1.067690338 #> 29  1.09  1.46033916  1.566714783 #> 30  0.18  0.49408354  0.348494547 #> 31  0.35  1.31718138  1.348938103 #> 32  0.21  0.50456716  0.644006458 #> 33  0.03 -0.08122119 -0.087719821  # with missing data modplsglm4NA <- plsRglm(ypine,XpineNAX21,4,modele=\"pls-glm-gaussian\") #> ____************************************************____ #> Only naive DoF can be used with missing data #>  #> Family: gaussian  #> Link function: identity  #>  #> ____There are some NAs in X but not in Y____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X with NA in X and not in Y____ #> ****________________________________________________**** #>  cbind((ypine),modpls4NA$ValsPredictY,modplsglm4NA$ValsPredictY) #>    [,1]        [,2]        [,3] #> 1  2.37  2.59632584  2.65655978 #> 2  1.47  1.29283727  1.28488164 #> 3  1.13  1.75173093  1.15999892 #> 4  0.85  1.18716395  0.63676710 #> 5  0.24  0.86910609  0.48002572 #> 6  1.49  1.46921709  1.35213181 #> 7  0.30 -0.21535819 -0.40312929 #> 8  0.07  0.23933510  0.06547790 #> 9  3.00  1.40568878  1.59073347 #> 10 1.21  0.50211746  0.51995031 #> 11 0.38  0.66223983  0.59109134 #> 12 0.70  0.44282335  0.02503985 #> 13 2.64  2.36396443  2.30673885 #> 14 2.05  1.90161042  1.99562658 #> 15 1.75  1.29947548  1.50028142 #> 16 0.06 -0.46871207 -0.45217350 #> 17 0.13  0.57159705  0.38572317 #> 18 1.00  0.91390716  0.93127818 #> 19 0.41  0.66724660  0.69975186 #> 20 0.72 -0.11983245 -0.17511644 #> 21 0.67  1.05066865  1.10740476 #> 22 0.12  0.92111414  0.88988795 #> 23 0.97  0.56876142  1.08147288 #> 24 0.07  0.57008862  0.95768372 #> 25 0.10  0.04444106 -0.37407716 #> 26 0.68  0.55151878  1.09037413 #> 27 0.13  0.33919018  0.37286685 #> 28 0.20  1.24427797  1.30885327 #> 29 1.09  1.34241091  1.60355751 #> 30 0.18  0.49663099  0.45727580 #> 31 0.35  0.97474814  1.27926735 #> 32 0.21  0.41013362  0.97635769 #> 33 0.03 -0.37518880 -0.15328541 rm(list=c(\"Xpine\",\"ypine\",\"modpls4\",\"modpls4NA\",\"modplsglm4\",\"modplsglm4NA\"))  data(fowlkes) Xfowlkes <- fowlkes[,2:13] yfowlkes <- fowlkes[,1] modpls <- plsRglm(yfowlkes,Xfowlkes,4,modele=\"pls-glm-logistic\",pvals.expli=TRUE) #> ____************************************************____ #>  #> Family: binomial  #> Link function: logit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  modpls #> Number of required components: #> [1] 4 #> Number of successfully computed components: #> [1] 4 #> Coefficients: #>                   [,1] #> Intercept -0.651543987 #> MA        -0.267881403 #> MW         0.086198351 #> NE         0.169434730 #> NW         0.036691503 #> PA        -0.257673339 #> SO        -0.009023316 #> SW        -0.126008946 #> color      0.006227693 #> age1       0.148377241 #> age2       0.026777188 #> age3      -0.214447902 #> sexe       0.177928904 #> Information criteria and Fit statistics: #>                AIC      BIC Missclassed Chi2_Pearson_Y    RSS_Y       R2_Y #> Nb_Comp_0 12989.10 12996.31        3569       9949.000 2288.694         NA #> Nb_Comp_1 12890.53 12904.94        3569       9951.203 2265.506 0.01013155 #> Nb_Comp_2 12886.80 12908.42        3569       9951.831 2264.195 0.01070437 #> Nb_Comp_3 12888.51 12917.34        3569       9951.623 2264.140 0.01072862 #> Nb_Comp_4 12890.48 12926.51        3569       9951.646 2264.133 0.01073170 #>           R2_residY RSS_residY #> Nb_Comp_0        NA   2288.694 #> Nb_Comp_1 -3.997724  11438.263 #> Nb_Comp_2 -4.008537  11463.011 #> Nb_Comp_3 -4.008640  11463.246 #> Nb_Comp_4 -4.008764  11463.529 #> Model with all the required components: #>  #> Call:  glm(formula = YwotNA ~ ., family = family, data = tttrain) #>  #> Coefficients: #> (Intercept)         tt.1         tt.2         tt.3         tt.4   #>   -0.587799     0.177512     0.045112     0.013739     0.007043   #>  #> Degrees of Freedom: 9948 Total (i.e. Null);  9944 Residual #> Null Deviance:\t    12990  #> Residual Deviance: 12880 \tAIC: 12890 colSums(modpls$pvalstep) #> temppvalstep temppvalstep temppvalstep temppvalstep  #>            7            0            0            0  rm(list=c(\"Xfowlkes\",\"yfowlkes\",\"modpls\"))   if(require(chemometrics)){ data(hyptis) yhyptis <- factor(hyptis$Group,ordered=TRUE) Xhyptis <- as.data.frame(hyptis[,c(1:6)]) options(contrasts = c(\"contr.treatment\", \"contr.poly\")) modpls2 <- plsRglm(yhyptis,Xhyptis,6,modele=\"pls-glm-polr\") modpls2$Coeffsmodel_vals modpls2$InfCrit modpls2$Coeffs modpls2$Std.Coeffs  table(yhyptis,predict(modpls2$FinalModel,type=\"class\")) rm(list=c(\"yhyptis\",\"Xhyptis\",\"modpls2\")) } #> Loading required package: chemometrics #> Warning: there is no package called ‘chemometrics’  dimX <- 24 Astar <- 6 dataAstar6 <- t(replicate(250,simul_data_UniYX(dimX,Astar))) ysimbin1 <- dicho(dataAstar6)[,1] Xsimbin1 <- dicho(dataAstar6)[,2:(dimX+1)] modplsglm <- plsRglm(ysimbin1,Xsimbin1,10,modele=\"pls-glm-logistic\") #> ____************************************************____ #>  #> Family: binomial  #> Link function: logit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> ____Component____ 7 ____ #> ____Component____ 8 ____ #> Warning : 1 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 < 10^{-12} #> Warning only 8 components could thus be extracted #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  modplsglm #> Number of required components: #> [1] 10 #> Number of successfully computed components: #> [1] 8 #> Coefficients: #>                   [,1] #> Intercept  -4.94026470 #> X1          0.03575405 #> X2        -10.55974940 #> X3          1.15593464 #> X4         -0.42925052 #> X5          0.57136104 #> X6          0.43677191 #> X7          0.03575405 #> X8         24.04985196 #> X9          1.15593464 #> X10        -0.42925052 #> X11         0.57136104 #> X12         0.43677191 #> X13         0.03575405 #> X14        -5.31290178 #> X15         1.15593464 #> X16        -0.42925052 #> X17         0.57136104 #> X18         0.43677191 #> X19         0.03575405 #> X20        -5.31290178 #> X21         1.15593464 #> X22        -0.42925052 #> X23         0.57136104 #> X24         0.43677191 #> Information criteria and Fit statistics: #>                AIC      BIC Missclassed Chi2_Pearson_Y    RSS_Y      R2_Y #> Nb_Comp_0 348.5096 352.0310         123       250.0000 62.48400        NA #> Nb_Comp_1 159.4885 166.5314          34       222.0787 24.68882 0.6048778 #> Nb_Comp_2 138.8774 149.4418          31       275.2727 20.90597 0.6654188 #> Nb_Comp_3 140.0717 154.1576          28       245.8402 20.83078 0.6666222 #> Nb_Comp_4 141.5817 159.1890          32       272.8925 20.86649 0.6660506 #> Nb_Comp_5 143.4258 164.5546          32       268.9579 20.85505 0.6662337 #> Nb_Comp_6 145.4206 170.0708          32       268.3603 20.85285 0.6662690 #> Nb_Comp_7 147.3365 175.5082          32       264.5888 20.84915 0.6663282 #> Nb_Comp_8 149.3365 181.0297          32       264.5888 20.84915 0.6663282 #>             R2_residY RSS_residY #> Nb_Comp_0          NA     62.484 #> Nb_Comp_1   -25.72379   1669.809 #> Nb_Comp_2   -50.67938   3229.134 #> Nb_Comp_3   -48.58458   3098.243 #> Nb_Comp_4   -51.75556   3296.378 #> Nb_Comp_5   -51.51036   3281.058 #> Nb_Comp_6   -51.42983   3276.026 #> Nb_Comp_7 -1196.70669  74837.505 #> Nb_Comp_8   -57.88193   3679.178 #> Model with all the required components: #>  #> Call:  glm(formula = YwotNA ~ ., family = family, data = tttrain) #>  #> Coefficients: #> (Intercept)         tt.1         tt.2         tt.3         tt.4         tt.5   #>   -0.001574     1.434029     0.519441     0.069985     0.153924     0.130296   #>        tt.6         tt.7         tt.8   #>   -0.029721   106.340171   671.157882   #>  #> Degrees of Freedom: 249 Total (i.e. Null);  241 Residual #> Null Deviance:\t    346.5  #> Residual Deviance: 131.3 \tAIC: 149.3  simbin=data.frame(dicho(dataAstar6)) cv.modplsglm <- suppressWarnings(cv.plsRglm(Y~.,data=simbin,nt=10, modele=\"pls-glm-logistic\",NK=100, verbose=FALSE)) res.cv.modplsglm <- cvtable(summary(cv.modplsglm,MClassed=TRUE, verbose=FALSE)) #> Error in eval(mf, parent.frame()): object 'simbin' not found plot(res.cv.modplsglm) #defaults to type=\"CVMC\"   rm(list=c(\"dimX\",\"Astar\",\"dataAstar6\",\"ysimbin1\",\"Xsimbin1\",\"modplsglm\",\"cv.modplsglm\", \"res.cv.modplsglm\")) # }"},{"path":"https://fbertran.github.io/plsRglm/reference/predict.plsRglmmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for plsRglm models — predict.plsRglmmodel","title":"Print method for plsRglm models — predict.plsRglmmodel","text":"function provides predict method class \"plsRglmmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/predict.plsRglmmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for plsRglm models — predict.plsRglmmodel","text":"","code":"# S3 method for class 'plsRglmmodel' predict(   object,   newdata,   comps = object$computed_nt,   type = c(\"link\", \"response\", \"terms\", \"scores\", \"class\", \"probs\"),   se.fit = FALSE,   weights,   dispersion = NULL,   methodNA = \"adaptative\",   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/plsRglm/reference/predict.plsRglmmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for plsRglm models — predict.plsRglmmodel","text":"object object class \"plsRmodel\". newdata optional data frame look variables predict. omitted, fitted values used. comps value single value component use prediction. type Type predicted value. Available choices glms ones (\"link\", \"response\", \"terms\"), polr ones (\"class\", \"probs\") scores (\"scores\"). se.fit TRUE, pointwise standard errors produced predictions using Cox model. weights Vector case weights. weights vector integers, estimated coefficients equivalent estimating model data individual cases replicated many times indicated weights. dispersion dispersion GLM fit assumed computing standard errors. omitted, returned summary applied object used. methodNA Selects way predicting response scores new data. complete rows, without missing value, two different ways computing prediction. consequence, mixed datasets, complete incomplete rows, two ways computing prediction : either predicts row missing values (missingdata) selects prediction method accordingly completeness row (adaptative). verbose info messages displayed ? ... Arguments passed stats::glm plsRglm::plsRglm.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/predict.plsRglmmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for plsRglm models — predict.plsRglmmodel","text":"type \"response\", matrix predicted response values returned. type \"scores\", score matrix returned.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/predict.plsRglmmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print method for plsRglm models — predict.plsRglmmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/predict.plsRglmmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for plsRglm models — predict.plsRglmmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/predict.plsRglmmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for plsRglm models — predict.plsRglmmodel","text":"","code":"data(pine) Xpine<-pine[,1:10] ypine<-pine[,11] data(pine_sup) Xpine_sup<-pine_sup[,1:10] Xpine_supNA<-Xpine_sup Xpine_supNA[1,1]<-NA  modpls=plsRglm(object=ypine,dataX=Xpine,nt=6,modele=\"pls-glm-family\",family=\"gaussian\", verbose=FALSE) modplsform=plsRglm(x11~.,data=pine,nt=6,modele=\"pls-glm-family\",family=\"gaussian\", verbose=FALSE) modpls2=plsRglm(object=ypine,dataX=Xpine,nt=6,modele=\"pls-glm-family\", dataPredictY=Xpine_sup,family=\"gaussian\", verbose=FALSE) modpls2NA=plsRglm(object=ypine,dataX=Xpine,nt=6,modele=\"pls-glm-family\", dataPredictY=Xpine_supNA,family=\"gaussian\", verbose=FALSE)  #Identical to predict(modpls,type=\"link\") or modpls$Std.ValsPredictY cbind(modpls$Std.ValsPredictY,modplsform$Std.ValsPredictY, predict(modpls),predict(modplsform)) #>             [,1]          [,2]          [,3]          [,4] #> 1   1.9833376732  1.9833376732  1.9833376732  1.9833376732 #> 2   1.2424038010  1.2424038010  1.2424038010  1.2424038010 #> 3   1.4982947689  1.4982947689  1.4982947689  1.4982947689 #> 4   0.9909505955  0.9909505955  0.9909505955  0.9909505955 #> 5   0.5188201727  0.5188201727  0.5188201727  0.5188201727 #> 6   1.3306250748  1.3306250748  1.3306250748  1.3306250748 #> 7  -0.0207190905 -0.0207190905 -0.0207190905 -0.0207190905 #> 8   0.3578640505  0.3578640505  0.3578640505  0.3578640505 #> 9   1.6121834444  1.6121834444  1.6121834444  1.6121834444 #> 10  0.8174125637  0.8174125637  0.8174125637  0.8174125637 #> 11  0.6245784031  0.6245784031  0.6245784031  0.6245784031 #> 12  1.0296261669  1.0296261669  1.0296261669  1.0296261669 #> 13  2.1697925483  2.1697925483  2.1697925483  2.1697925483 #> 14  1.8135307368  1.8135307368  1.8135307368  1.8135307368 #> 15  1.5668160958  1.5668160958  1.5668160958  1.5668160958 #> 16 -0.4913222929 -0.4913222929 -0.4913222929 -0.4913222929 #> 17  0.0003648119  0.0003648119  0.0003648119  0.0003648119 #> 18  0.9670404542  0.9670404542  0.9670404542  0.9670404542 #> 19  0.9155210110  0.9155210110  0.9155210110  0.9155210110 #> 20  0.0147427279  0.0147427279  0.0147427279  0.0147427279 #> 21  0.5787557488  0.5787557488  0.5787557488  0.5787557488 #> 22  0.7677772238  0.7677772238  0.7677772238  0.7677772238 #> 23  0.6902564661  0.6902564661  0.6902564661  0.6902564661 #> 24  0.2269039458  0.2269039458  0.2269039458  0.2269039458 #> 25 -0.1262912840 -0.1262912840 -0.1262912840 -0.1262912840 #> 26  0.7620516870  0.7620516870  0.7620516870  0.7620516870 #> 27  0.2265845367  0.2265845367  0.2265845367  0.2265845367 #> 28  0.9429046207  0.9429046207  0.9429046207  0.9429046207 #> 29  1.5828522058  1.5828522058  1.5828522058  1.5828522058 #> 30  0.3072993447  0.3072993447  0.3072993447  0.3072993447 #> 31  1.3622819484  1.3622819484  1.3622819484  1.3622819484 #> 32  0.4779691553  0.4779691553  0.4779691553  0.4779691553 #> 33  0.0287906836  0.0287906836  0.0287906836  0.0287906836  #Identical to predict(modpls,type=\"response\") or modpls$ValsPredictY cbind(modpls$ValsPredictY,modplsform$ValsPredictY, predict(modpls,type=\"response\"),predict(modplsform,type=\"response\")) #>             [,1]          [,2]          [,3]          [,4] #> 1   1.9833376732  1.9833376732  1.9833376732  1.9833376732 #> 2   1.2424038010  1.2424038010  1.2424038010  1.2424038010 #> 3   1.4982947689  1.4982947689  1.4982947689  1.4982947689 #> 4   0.9909505955  0.9909505955  0.9909505955  0.9909505955 #> 5   0.5188201727  0.5188201727  0.5188201727  0.5188201727 #> 6   1.3306250748  1.3306250748  1.3306250748  1.3306250748 #> 7  -0.0207190905 -0.0207190905 -0.0207190905 -0.0207190905 #> 8   0.3578640505  0.3578640505  0.3578640505  0.3578640505 #> 9   1.6121834444  1.6121834444  1.6121834444  1.6121834444 #> 10  0.8174125637  0.8174125637  0.8174125637  0.8174125637 #> 11  0.6245784031  0.6245784031  0.6245784031  0.6245784031 #> 12  1.0296261669  1.0296261669  1.0296261669  1.0296261669 #> 13  2.1697925483  2.1697925483  2.1697925483  2.1697925483 #> 14  1.8135307368  1.8135307368  1.8135307368  1.8135307368 #> 15  1.5668160958  1.5668160958  1.5668160958  1.5668160958 #> 16 -0.4913222929 -0.4913222929 -0.4913222929 -0.4913222929 #> 17  0.0003648119  0.0003648119  0.0003648119  0.0003648119 #> 18  0.9670404542  0.9670404542  0.9670404542  0.9670404542 #> 19  0.9155210110  0.9155210110  0.9155210110  0.9155210110 #> 20  0.0147427279  0.0147427279  0.0147427279  0.0147427279 #> 21  0.5787557488  0.5787557488  0.5787557488  0.5787557488 #> 22  0.7677772238  0.7677772238  0.7677772238  0.7677772238 #> 23  0.6902564661  0.6902564661  0.6902564661  0.6902564661 #> 24  0.2269039458  0.2269039458  0.2269039458  0.2269039458 #> 25 -0.1262912840 -0.1262912840 -0.1262912840 -0.1262912840 #> 26  0.7620516870  0.7620516870  0.7620516870  0.7620516870 #> 27  0.2265845367  0.2265845367  0.2265845367  0.2265845367 #> 28  0.9429046207  0.9429046207  0.9429046207  0.9429046207 #> 29  1.5828522058  1.5828522058  1.5828522058  1.5828522058 #> 30  0.3072993447  0.3072993447  0.3072993447  0.3072993447 #> 31  1.3622819484  1.3622819484  1.3622819484  1.3622819484 #> 32  0.4779691553  0.4779691553  0.4779691553  0.4779691553 #> 33  0.0287906836  0.0287906836  0.0287906836  0.0287906836  #Identical to modpls$ttPredictY predict(modpls,type=\"scores\") #>        Comp_1      Comp_2      Comp_3       Comp_4       Comp_5      Comp_6 #> 1   2.9096976  1.00710122 -0.24592387 -0.160828305 -0.176676852 -0.04612186 #> 2   0.7632932  0.15976639  0.27373619  0.140033799 -0.211959106  0.23748516 #> 3   2.5797729 -0.15255047  0.29850835 -0.463288186  0.395641948  0.06260773 #> 4   0.0443116  0.18393139  0.35088163 -0.751984567  0.503753361  0.04469555 #> 5   0.8636609 -0.71278066 -0.37239336 -0.161000543  0.039381404 -0.07357890 #> 6   2.0735510  0.01335370 -0.07197122  0.334437598 -0.101229035 -0.13598146 #> 7  -1.8665241 -0.99415606  0.33015396 -0.396546167  0.785963932  0.12857825 #> 8  -0.3528084 -0.47395114 -0.24214142  0.751121043 -0.169208869 -0.36500370 #> 9   2.5760644  0.16552577  0.04928545 -0.089535122  0.167729285  0.03063475 #> 10  0.7101307 -0.07990096 -0.15351493 -0.005071190  0.409378779 -0.43921245 #> 11 -1.4335481  1.07257765 -1.18074795 -0.436193501  0.158685019 -0.09759548 #> 12 -3.3502270  1.30698624  0.87144711  0.386088832  0.978624443 -0.05611513 #> 13  3.6223851  0.68753187  0.40988945 -0.264421225 -0.030412303 -0.06398871 #> 14  2.1481736  0.57279554  0.28246967  0.653041463 -0.327686046  0.03285982 #> 15  1.8241923  0.13197474  0.13629418  0.539338767  0.189873538  0.17720966 #> 16 -4.2769308 -0.28783227  0.30482521  0.105860327 -0.057241843 -0.30620830 #> 17 -2.7842661 -0.16567944  0.07256901 -0.315395828 -0.707648649  0.39219062 #> 18  0.8485036 -0.05290953 -0.61740825 -0.280346593 -0.011117608  0.45336039 #> 19  1.0268524 -0.80640496  0.57912902  0.064174398  0.354166437  0.14689814 #> 20 -2.0252326 -0.58395494  0.04522859  0.075864802  0.204673403 -0.01550492 #> 21 -2.9034527  0.78107186  1.11976594 -0.422652246 -0.632696644 -0.05241835 #> 22 -0.6130182  0.13878788  0.24414686 -0.354981337 -0.127986504  0.14392098 #> 23  0.3973956 -0.47715993 -0.08672426  0.577352623 -0.498808259  0.10940105 #> 24 -1.9919455 -0.11392902  0.83986464 -0.231967944 -0.889717260 -0.14566335 #> 25 -0.9692387 -1.09175820 -0.24633375  0.268105315 -0.001492138 -0.21439636 #> 26  0.4320999 -0.42853732 -0.32668909  0.438180905 -0.212606195  0.32458213 #> 27 -3.0186366  0.68892697 -1.13558954  0.357517970  0.068179402  0.20518691 #> 28  2.7834585 -0.79904726  0.11258827 -0.544298344 -0.268790892 -0.23821771 #> 29  2.4348733  0.11286629  0.15459790  0.102159012  0.238308194 -0.05212571 #> 30 -0.3039968 -0.10418524 -0.64875748 -1.092874683 -0.151109635 -0.05322880 #> 31  0.6490525  0.29413661  0.31920770  0.875287429 -0.027498146  0.04838810 #> 32 -0.5424034  0.43591326 -0.99283694 -0.002253209 -0.288501338 -0.34514010 #> 33 -2.2552401 -0.42850996 -0.47355708  0.305074707  0.398028177  0.16250207 predict(modplsform,type=\"scores\") #>        Comp_1      Comp_2      Comp_3       Comp_4       Comp_5      Comp_6 #> 1   2.9096976  1.00710122 -0.24592387 -0.160828305 -0.176676852 -0.04612186 #> 2   0.7632932  0.15976639  0.27373619  0.140033799 -0.211959106  0.23748516 #> 3   2.5797729 -0.15255047  0.29850835 -0.463288186  0.395641948  0.06260773 #> 4   0.0443116  0.18393139  0.35088163 -0.751984567  0.503753361  0.04469555 #> 5   0.8636609 -0.71278066 -0.37239336 -0.161000543  0.039381404 -0.07357890 #> 6   2.0735510  0.01335370 -0.07197122  0.334437598 -0.101229035 -0.13598146 #> 7  -1.8665241 -0.99415606  0.33015396 -0.396546167  0.785963932  0.12857825 #> 8  -0.3528084 -0.47395114 -0.24214142  0.751121043 -0.169208869 -0.36500370 #> 9   2.5760644  0.16552577  0.04928545 -0.089535122  0.167729285  0.03063475 #> 10  0.7101307 -0.07990096 -0.15351493 -0.005071190  0.409378779 -0.43921245 #> 11 -1.4335481  1.07257765 -1.18074795 -0.436193501  0.158685019 -0.09759548 #> 12 -3.3502270  1.30698624  0.87144711  0.386088832  0.978624443 -0.05611513 #> 13  3.6223851  0.68753187  0.40988945 -0.264421225 -0.030412303 -0.06398871 #> 14  2.1481736  0.57279554  0.28246967  0.653041463 -0.327686046  0.03285982 #> 15  1.8241923  0.13197474  0.13629418  0.539338767  0.189873538  0.17720966 #> 16 -4.2769308 -0.28783227  0.30482521  0.105860327 -0.057241843 -0.30620830 #> 17 -2.7842661 -0.16567944  0.07256901 -0.315395828 -0.707648649  0.39219062 #> 18  0.8485036 -0.05290953 -0.61740825 -0.280346593 -0.011117608  0.45336039 #> 19  1.0268524 -0.80640496  0.57912902  0.064174398  0.354166437  0.14689814 #> 20 -2.0252326 -0.58395494  0.04522859  0.075864802  0.204673403 -0.01550492 #> 21 -2.9034527  0.78107186  1.11976594 -0.422652246 -0.632696644 -0.05241835 #> 22 -0.6130182  0.13878788  0.24414686 -0.354981337 -0.127986504  0.14392098 #> 23  0.3973956 -0.47715993 -0.08672426  0.577352623 -0.498808259  0.10940105 #> 24 -1.9919455 -0.11392902  0.83986464 -0.231967944 -0.889717260 -0.14566335 #> 25 -0.9692387 -1.09175820 -0.24633375  0.268105315 -0.001492138 -0.21439636 #> 26  0.4320999 -0.42853732 -0.32668909  0.438180905 -0.212606195  0.32458213 #> 27 -3.0186366  0.68892697 -1.13558954  0.357517970  0.068179402  0.20518691 #> 28  2.7834585 -0.79904726  0.11258827 -0.544298344 -0.268790892 -0.23821771 #> 29  2.4348733  0.11286629  0.15459790  0.102159012  0.238308194 -0.05212571 #> 30 -0.3039968 -0.10418524 -0.64875748 -1.092874683 -0.151109635 -0.05322880 #> 31  0.6490525  0.29413661  0.31920770  0.875287429 -0.027498146  0.04838810 #> 32 -0.5424034  0.43591326 -0.99283694 -0.002253209 -0.288501338 -0.34514010 #> 33 -2.2552401 -0.42850996 -0.47355708  0.305074707  0.398028177  0.16250207  # \\donttest{ #Identical to modpls2$ValsPredictY cbind(predict(modpls,newdata=Xpine_sup,type=\"response\"), predict(modplsform,newdata=Xpine_sup,type=\"response\")) #>         [,1]      [,2] #> 1  1.1097381 1.1097381 #> 2  1.6368638 1.6368638 #> 3  1.4742716 1.4742716 #> 4  1.7447487 1.7447487 #> 5  1.4156388 1.4156388 #> 6  2.9500255 2.9500255 #> 7  2.0414347 2.0414347 #> 8  1.8312096 1.8312096 #> 9  1.5718912 1.5718912 #> 10 2.0025140 2.0025140 #> 11 2.0487486 2.0487486 #> 12 2.0535109 2.0535109 #> 13 1.0628496 1.0628496 #> 14 0.8116580 0.8116580 #> 15 0.1798506 0.1798506 #> 16 0.3632888 0.3632888 #> 17 0.9930354 0.9930354 #> 18 1.0399233 1.0399233 #> 19 0.2747613 0.2747613 #> 20 0.7296300 0.7296300 #> 21 1.2241840 1.2241840 #> 22 0.3757749 0.3757749 #> 23 1.2966168 1.2966168 #> 24 0.3423249 0.3423249 #> 25 0.3425252 0.3425252  #Select the number of components to use to derive the prediction predict(modpls,newdata=Xpine_sup,type=\"response\",comps=1)     #>         1         2         3         4         5         6         7         8  #> 0.4529386 1.5275250 0.8653393 1.2623019 1.2181767 0.5365724 1.8005533 1.4130804  #>         9        10        11        12        13        14        15        16  #> 1.3482246 0.8525246 1.4451515 1.0083162 0.1933256 0.4868117 0.2004471 0.1145533  #>        17        18        19        20        21        22        23        24  #> 0.6559225 1.0049792 0.4994408 0.4326020 0.8987432 0.4734407 1.0680659 0.1914079  #>        25  #> 0.6558292  predict(modpls,newdata=Xpine_sup,type=\"response\",comps=3)     #>         1         2         3         4         5         6         7         8  #> 1.4182116 1.6412293 1.6692276 1.8131310 1.4721576 2.4824189 2.3952957 1.9883342  #>         9        10        11        12        13        14        15        16  #> 1.5249653 1.8631319 2.3120849 1.6636405 1.0800241 0.9203430 1.0943056 0.6916340  #>        17        18        19        20        21        22        23        24  #> 1.3022034 1.2067980 0.1706657 0.7408545 1.3858670 0.2923245 1.4945633 0.4191331  #>        25  #> 0.4186188  predict(modpls,newdata=Xpine_sup,type=\"response\",comps=6)     #>         1         2         3         4         5         6         7         8  #> 1.1097381 1.6368638 1.4742716 1.7447487 1.4156388 2.9500255 2.0414347 1.8312096  #>         9        10        11        12        13        14        15        16  #> 1.5718912 2.0025140 2.0487486 2.0535109 1.0628496 0.8116580 0.1798506 0.3632888  #>        17        18        19        20        21        22        23        24  #> 0.9930354 1.0399233 0.2747613 0.7296300 1.2241840 0.3757749 1.2966168 0.3423249  #>        25  #> 0.3425252  try(predict(modpls,newdata=Xpine_sup,type=\"response\",comps=8)) #> Error in predict.plsRglmmodel(modpls, newdata = Xpine_sup, type = \"response\",  :  #>   Cannot predict using more components than extracted.  #Identical to modpls2$ttValsPredictY predict(modpls,newdata=Xpine_sup,type=\"scores\")     #>           Comp_1      Comp_2      Comp_3      Comp_4      Comp_5      Comp_6 #>  [1,] -1.3617679  1.84853757 -0.07167989 -0.78643051 -0.55491628 -0.31285630 #>  [2,]  2.7226457 -0.18222256  0.81656680  0.02721720  0.86067342 -0.37393001 #>  [3,]  0.2057330  0.81889037  1.42664508 -0.15485978  0.43372368 -0.65684336 #>  [4,]  1.7145547  0.87851109  0.32284764  0.37343500  0.23900014 -0.44019550 #>  [5,]  1.5468388  0.06396562  0.85245128 -0.16192486  0.59815956 -0.33518539 #>  [6,] -1.0438828  2.94178014  1.47387097  1.08467443 -0.02394675  0.87054622 #>  [7,]  3.7604036  1.20512548 -0.18065028 -0.40642515 -0.37373716 -0.66809476 #>  [8,]  2.2876515  0.79101480  0.59799022 -0.32260550  0.35381984 -0.45046964 #>  [9,]  2.0411399  0.23491526  0.20046643  0.46551988  0.41574301 -0.22843097 #> [10,]  0.1570251  1.48472812  0.85445008  0.03281035  0.58589348  0.13631629 #> [11,]  2.4095509  1.50815475  0.24927003 -1.08425752  0.08663564 -0.32703134 #> [12,]  0.7491762  1.04259904  0.38939526  1.71739480 -0.33430079  0.52239057 #> [13,] -2.3485356  1.25475466  0.84855868 -0.87653694  0.94681725 -0.07623013 #> [14,] -1.2330191  0.69650062  0.24364744  0.35221831  1.00517071 -0.85601738 #> [15,] -2.3214673  0.90707702  1.59345546 -0.33982651 -0.51746875 -2.19885874 #> [16,] -2.6479422  0.70541253  0.78164085 -0.12218988  0.26382110 -0.97264696 #> [17,] -0.5902429  1.20133709  0.02691916 -0.45526058 -0.38894004 -0.51744565 #> [18,]  0.7364927  0.46852245 -0.18419048 -0.45872544 -0.30400190 -0.15411996 #> [19,] -1.1850170  0.09703486 -1.47443389 -0.31309733  0.46295088  0.22911528 #> [20,] -1.4390656  0.52556741  0.11066551 -0.46711508  0.70135198 -0.12657426 #> [21,]  0.3326983  1.15647992 -0.49742370 -0.49751150  0.03075929 -0.26023128 #> [22,] -1.2838413 -0.23799459 -0.21107354  0.50469061  0.13088191 -0.02655946 #> [23,]  0.9762797  0.70172088  0.20561742 -0.60785236 -0.37714270 -0.15010150 #> [24,] -2.3558246  0.03526826  0.80988172 -0.01076392  0.79025721 -0.53162513 #> [25,] -0.5905978 -0.27969847 -0.34246431  0.49615203  0.23346261 -0.50946404  #Select the number of components in the scores matrix predict(modpls,newdata=Xpine_sup,type=\"scores\",comps=1)     #>           Comp_1 #>  [1,] -1.3617679 #>  [2,]  2.7226457 #>  [3,]  0.2057330 #>  [4,]  1.7145547 #>  [5,]  1.5468388 #>  [6,] -1.0438828 #>  [7,]  3.7604036 #>  [8,]  2.2876515 #>  [9,]  2.0411399 #> [10,]  0.1570251 #> [11,]  2.4095509 #> [12,]  0.7491762 #> [13,] -2.3485356 #> [14,] -1.2330191 #> [15,] -2.3214673 #> [16,] -2.6479422 #> [17,] -0.5902429 #> [18,]  0.7364927 #> [19,] -1.1850170 #> [20,] -1.4390656 #> [21,]  0.3326983 #> [22,] -1.2838413 #> [23,]  0.9762797 #> [24,] -2.3558246 #> [25,] -0.5905978 predict(modpls,newdata=Xpine_sup,type=\"scores\",comps=3)     #>           Comp_1      Comp_2      Comp_3 #>  [1,] -1.3617679  1.84853757 -0.07167989 #>  [2,]  2.7226457 -0.18222256  0.81656680 #>  [3,]  0.2057330  0.81889037  1.42664508 #>  [4,]  1.7145547  0.87851109  0.32284764 #>  [5,]  1.5468388  0.06396562  0.85245128 #>  [6,] -1.0438828  2.94178014  1.47387097 #>  [7,]  3.7604036  1.20512548 -0.18065028 #>  [8,]  2.2876515  0.79101480  0.59799022 #>  [9,]  2.0411399  0.23491526  0.20046643 #> [10,]  0.1570251  1.48472812  0.85445008 #> [11,]  2.4095509  1.50815475  0.24927003 #> [12,]  0.7491762  1.04259904  0.38939526 #> [13,] -2.3485356  1.25475466  0.84855868 #> [14,] -1.2330191  0.69650062  0.24364744 #> [15,] -2.3214673  0.90707702  1.59345546 #> [16,] -2.6479422  0.70541253  0.78164085 #> [17,] -0.5902429  1.20133709  0.02691916 #> [18,]  0.7364927  0.46852245 -0.18419048 #> [19,] -1.1850170  0.09703486 -1.47443389 #> [20,] -1.4390656  0.52556741  0.11066551 #> [21,]  0.3326983  1.15647992 -0.49742370 #> [22,] -1.2838413 -0.23799459 -0.21107354 #> [23,]  0.9762797  0.70172088  0.20561742 #> [24,] -2.3558246  0.03526826  0.80988172 #> [25,] -0.5905978 -0.27969847 -0.34246431 predict(modpls,newdata=Xpine_sup,type=\"scores\",comps=6)     #>           Comp_1      Comp_2      Comp_3      Comp_4      Comp_5      Comp_6 #>  [1,] -1.3617679  1.84853757 -0.07167989 -0.78643051 -0.55491628 -0.31285630 #>  [2,]  2.7226457 -0.18222256  0.81656680  0.02721720  0.86067342 -0.37393001 #>  [3,]  0.2057330  0.81889037  1.42664508 -0.15485978  0.43372368 -0.65684336 #>  [4,]  1.7145547  0.87851109  0.32284764  0.37343500  0.23900014 -0.44019550 #>  [5,]  1.5468388  0.06396562  0.85245128 -0.16192486  0.59815956 -0.33518539 #>  [6,] -1.0438828  2.94178014  1.47387097  1.08467443 -0.02394675  0.87054622 #>  [7,]  3.7604036  1.20512548 -0.18065028 -0.40642515 -0.37373716 -0.66809476 #>  [8,]  2.2876515  0.79101480  0.59799022 -0.32260550  0.35381984 -0.45046964 #>  [9,]  2.0411399  0.23491526  0.20046643  0.46551988  0.41574301 -0.22843097 #> [10,]  0.1570251  1.48472812  0.85445008  0.03281035  0.58589348  0.13631629 #> [11,]  2.4095509  1.50815475  0.24927003 -1.08425752  0.08663564 -0.32703134 #> [12,]  0.7491762  1.04259904  0.38939526  1.71739480 -0.33430079  0.52239057 #> [13,] -2.3485356  1.25475466  0.84855868 -0.87653694  0.94681725 -0.07623013 #> [14,] -1.2330191  0.69650062  0.24364744  0.35221831  1.00517071 -0.85601738 #> [15,] -2.3214673  0.90707702  1.59345546 -0.33982651 -0.51746875 -2.19885874 #> [16,] -2.6479422  0.70541253  0.78164085 -0.12218988  0.26382110 -0.97264696 #> [17,] -0.5902429  1.20133709  0.02691916 -0.45526058 -0.38894004 -0.51744565 #> [18,]  0.7364927  0.46852245 -0.18419048 -0.45872544 -0.30400190 -0.15411996 #> [19,] -1.1850170  0.09703486 -1.47443389 -0.31309733  0.46295088  0.22911528 #> [20,] -1.4390656  0.52556741  0.11066551 -0.46711508  0.70135198 -0.12657426 #> [21,]  0.3326983  1.15647992 -0.49742370 -0.49751150  0.03075929 -0.26023128 #> [22,] -1.2838413 -0.23799459 -0.21107354  0.50469061  0.13088191 -0.02655946 #> [23,]  0.9762797  0.70172088  0.20561742 -0.60785236 -0.37714270 -0.15010150 #> [24,] -2.3558246  0.03526826  0.80988172 -0.01076392  0.79025721 -0.53162513 #> [25,] -0.5905978 -0.27969847 -0.34246431  0.49615203  0.23346261 -0.50946404 try(predict(modpls,newdata=Xpine_sup,type=\"scores\",comps=8)) #> Error in predict.plsRglmmodel(modpls, newdata = Xpine_sup, type = \"scores\",  :  #>   Cannot predict using more components than extracted.  #Identical to modpls2NA$ValsPredictY predict(modpls,newdata=Xpine_supNA,type=\"response\",methodNA=\"missingdata\")     #> Prediction as if missing values in every row. #>          1          2          3          4          5          6          7  #>  2.6822545  1.1863259  1.1158440  1.3838529  0.9095165  3.0886290  1.4840306  #>          8          9         10         11         12         13         14  #>  1.3932964  1.5820746  1.7099538  1.7180268  1.7661632  0.8530780  0.4951882  #>         15         16         17         18         19         20         21  #>  0.3444462  0.4816824  0.8115274  1.0833567  0.3552001  0.4309125  1.2581587  #>         22         23         24         25  #>  0.7244769  1.3761161 -0.0205930  0.1081691   cbind(predict(modpls,newdata=Xpine_supNA,type=\"response\"), predict(modplsform,newdata=Xpine_supNA,type=\"response\")) #> Missing value in row  1 . #> Missing value in row  1 . #>         [,1]      [,2] #> 1  2.6822545 2.6822545 #> 2  1.6368638 1.6368638 #> 3  1.4742716 1.4742716 #> 4  1.7447487 1.7447487 #> 5  1.4156388 1.4156388 #> 6  2.9500255 2.9500255 #> 7  2.0414347 2.0414347 #> 8  1.8312096 1.8312096 #> 9  1.5718912 1.5718912 #> 10 2.0025140 2.0025140 #> 11 2.0487486 2.0487486 #> 12 2.0535109 2.0535109 #> 13 1.0628496 1.0628496 #> 14 0.8116580 0.8116580 #> 15 0.1798506 0.1798506 #> 16 0.3632888 0.3632888 #> 17 0.9930354 0.9930354 #> 18 1.0399233 1.0399233 #> 19 0.2747613 0.2747613 #> 20 0.7296300 0.7296300 #> 21 1.2241840 1.2241840 #> 22 0.3757749 0.3757749 #> 23 1.2966168 1.2966168 #> 24 0.3423249 0.3423249 #> 25 0.3425252 0.3425252  predict(modpls,newdata=Xpine_supNA,type=\"response\",comps=1)     #> Missing value in row  1 . #>         1         2         3         4         5         6         7         8  #> 0.7935852 1.5275250 0.8653393 1.2623019 1.2181767 0.5365724 1.8005533 1.4130804  #>         9        10        11        12        13        14        15        16  #> 1.3482246 0.8525246 1.4451515 1.0083162 0.1933256 0.4868117 0.2004471 0.1145533  #>        17        18        19        20        21        22        23        24  #> 0.6559225 1.0049792 0.4994408 0.4326020 0.8987432 0.4734407 1.0680659 0.1914079  #>        25  #> 0.6558292  predict(modpls,newdata=Xpine_supNA,type=\"response\",comps=3)     #> Missing value in row  1 . #>         1         2         3         4         5         6         7         8  #> 2.6350800 1.6412293 1.6692276 1.8131310 1.4721576 2.4824189 2.3952957 1.9883342  #>         9        10        11        12        13        14        15        16  #> 1.5249653 1.8631319 2.3120849 1.6636405 1.0800241 0.9203430 1.0943056 0.6916340  #>        17        18        19        20        21        22        23        24  #> 1.3022034 1.2067980 0.1706657 0.7408545 1.3858670 0.2923245 1.4945633 0.4191331  #>        25  #> 0.4186188  predict(modpls,newdata=Xpine_supNA,type=\"response\",comps=6)     #> Missing value in row  1 . #>         1         2         3         4         5         6         7         8  #> 2.6822545 1.6368638 1.4742716 1.7447487 1.4156388 2.9500255 2.0414347 1.8312096  #>         9        10        11        12        13        14        15        16  #> 1.5718912 2.0025140 2.0487486 2.0535109 1.0628496 0.8116580 0.1798506 0.3632888  #>        17        18        19        20        21        22        23        24  #> 0.9930354 1.0399233 0.2747613 0.7296300 1.2241840 0.3757749 1.2966168 0.3423249  #>        25  #> 0.3425252  try(predict(modpls,newdata=Xpine_supNA,type=\"response\",comps=8)) #> Error in predict.plsRglmmodel(modpls, newdata = Xpine_supNA, type = \"response\",  :  #>   Cannot predict using more components than extracted.  #Identical to modpls2NA$ttPredictY predict(modpls,newdata=Xpine_supNA,type=\"scores\",methodNA=\"missingdata\") #> Prediction as if missing values in every row. #>            Comp_1      Comp_2      Comp_3      Comp_4      Comp_5      Comp_6 #>  [1,] -0.06699854  3.66196285 -0.41608333  0.45187568  1.59546224 -0.70283222 #>  [2,]  2.70687391 -0.58366935  0.27090780 -0.23268469  0.41783324 -0.34378821 #>  [3,]  0.19202296  0.49815234  0.85544720 -0.24904846  0.19019882 -0.62164030 #>  [4,]  1.70925990  0.55904242 -0.30881117  0.25656004  0.01838154 -0.37653562 #>  [5,]  1.52593733 -0.38881272  0.06295091 -0.28629453  0.25482060 -0.30053699 #>  [6,] -1.05490144  3.06326417  1.16226073  1.75918466  0.63562354  0.76498730 #>  [7,]  3.76970759  0.71212677 -0.93264756 -1.01046463 -1.05410585 -0.43291609 #>  [8,]  2.27575778  0.40145391 -0.07597958 -0.49309936  0.02646672 -0.39687347 #>  [9,]  2.05501340  0.24531251 -0.02869079  0.50618778  0.53512630 -0.12610842 #> [10,]  0.14426832  1.22229503  0.30409563  0.03954890  0.46422395  0.16211651 #> [11,]  2.42011239  1.21572929 -0.52692173 -1.23349885 -0.07511353 -0.13789070 #> [12,]  0.71325904  0.78138784 -0.22320815  2.05984947 -0.23708707  0.39657611 #> [13,] -2.36496665  1.06490787  0.67009104 -0.97605714  0.71251859 -0.10284336 #> [14,] -1.24656968  0.41305228  0.07580642  0.00245363  0.50871863 -0.84205602 #> [15,] -2.30296146  1.06483113  1.46884767  0.00434439 -0.02752066 -2.23807126 #> [16,] -2.64053336  0.81365140  0.52481842  0.27545183  0.73661798 -0.97879522 #> [17,] -0.60476055  1.04011407 -0.29486241 -0.35457355 -0.40072127 -0.57840396 #> [18,]  0.72843736  0.50469321 -0.16432560 -0.30879645 -0.18587858 -0.20436368 #> [19,] -1.18710588  0.16576762 -1.16075056 -0.42137277  0.35583549  0.21512882 #> [20,] -1.45582497  0.26069143 -0.29422583 -0.49842200  0.51864437 -0.17557750 #> [21,]  0.32934702  1.18545904 -0.32589387 -0.54271388 -0.02733918 -0.28729932 #> [22,] -1.27473171  0.07149663 -0.08468023  0.98077026  0.73852299 -0.05307274 #> [23,]  0.99076234  0.77336043  0.10840383 -0.54965195 -0.22267535 -0.06219731 #> [24,] -2.37627373 -0.28604262  0.49260588 -0.18770162  0.42544962 -0.60255367 #> [25,] -0.60942177 -0.48739596 -0.69025348  0.57675181  0.16727880 -0.59655697 predict(modplsform,newdata=Xpine_supNA,type=\"scores\",methodNA=\"missingdata\") #> Prediction as if missing values in every row. #>            Comp_1      Comp_2      Comp_3      Comp_4      Comp_5      Comp_6 #>  [1,] -0.06699854  3.66196285 -0.41608333  0.45187568  1.59546224 -0.70283222 #>  [2,]  2.70687391 -0.58366935  0.27090780 -0.23268469  0.41783324 -0.34378821 #>  [3,]  0.19202296  0.49815234  0.85544720 -0.24904846  0.19019882 -0.62164030 #>  [4,]  1.70925990  0.55904242 -0.30881117  0.25656004  0.01838154 -0.37653562 #>  [5,]  1.52593733 -0.38881272  0.06295091 -0.28629453  0.25482060 -0.30053699 #>  [6,] -1.05490144  3.06326417  1.16226073  1.75918466  0.63562354  0.76498730 #>  [7,]  3.76970759  0.71212677 -0.93264756 -1.01046463 -1.05410585 -0.43291609 #>  [8,]  2.27575778  0.40145391 -0.07597958 -0.49309936  0.02646672 -0.39687347 #>  [9,]  2.05501340  0.24531251 -0.02869079  0.50618778  0.53512630 -0.12610842 #> [10,]  0.14426832  1.22229503  0.30409563  0.03954890  0.46422395  0.16211651 #> [11,]  2.42011239  1.21572929 -0.52692173 -1.23349885 -0.07511353 -0.13789070 #> [12,]  0.71325904  0.78138784 -0.22320815  2.05984947 -0.23708707  0.39657611 #> [13,] -2.36496665  1.06490787  0.67009104 -0.97605714  0.71251859 -0.10284336 #> [14,] -1.24656968  0.41305228  0.07580642  0.00245363  0.50871863 -0.84205602 #> [15,] -2.30296146  1.06483113  1.46884767  0.00434439 -0.02752066 -2.23807126 #> [16,] -2.64053336  0.81365140  0.52481842  0.27545183  0.73661798 -0.97879522 #> [17,] -0.60476055  1.04011407 -0.29486241 -0.35457355 -0.40072127 -0.57840396 #> [18,]  0.72843736  0.50469321 -0.16432560 -0.30879645 -0.18587858 -0.20436368 #> [19,] -1.18710588  0.16576762 -1.16075056 -0.42137277  0.35583549  0.21512882 #> [20,] -1.45582497  0.26069143 -0.29422583 -0.49842200  0.51864437 -0.17557750 #> [21,]  0.32934702  1.18545904 -0.32589387 -0.54271388 -0.02733918 -0.28729932 #> [22,] -1.27473171  0.07149663 -0.08468023  0.98077026  0.73852299 -0.05307274 #> [23,]  0.99076234  0.77336043  0.10840383 -0.54965195 -0.22267535 -0.06219731 #> [24,] -2.37627373 -0.28604262  0.49260588 -0.18770162  0.42544962 -0.60255367 #> [25,] -0.60942177 -0.48739596 -0.69025348  0.57675181  0.16727880 -0.59655697  predict(modpls,newdata=Xpine_supNA,type=\"scores\")     #> Missing value in row  1 . #>            Comp_1      Comp_2      Comp_3      Comp_4      Comp_5      Comp_6 #>  [1,] -0.06699854  3.66196285 -0.41608333  0.45187568  1.59546224 -0.70283222 #>  [2,]  2.72264571 -0.18222256  0.81656680  0.02721720  0.86067342 -0.37393001 #>  [3,]  0.20573296  0.81889037  1.42664508 -0.15485978  0.43372368 -0.65684336 #>  [4,]  1.71455473  0.87851109  0.32284764  0.37343500  0.23900014 -0.44019550 #>  [5,]  1.54683876  0.06396562  0.85245128 -0.16192486  0.59815956 -0.33518539 #>  [6,] -1.04388279  2.94178014  1.47387097  1.08467443 -0.02394675  0.87054622 #>  [7,]  3.76040357  1.20512548 -0.18065028 -0.40642515 -0.37373716 -0.66809476 #>  [8,]  2.28765145  0.79101480  0.59799022 -0.32260550  0.35381984 -0.45046964 #>  [9,]  2.04113990  0.23491526  0.20046643  0.46551988  0.41574301 -0.22843097 #> [10,]  0.15702512  1.48472812  0.85445008  0.03281035  0.58589348  0.13631629 #> [11,]  2.40955090  1.50815475  0.24927003 -1.08425752  0.08663564 -0.32703134 #> [12,]  0.74917624  1.04259904  0.38939526  1.71739480 -0.33430079  0.52239057 #> [13,] -2.34853556  1.25475466  0.84855868 -0.87653694  0.94681725 -0.07623013 #> [14,] -1.23301912  0.69650062  0.24364744  0.35221831  1.00517071 -0.85601738 #> [15,] -2.32146728  0.90707702  1.59345546 -0.33982651 -0.51746875 -2.19885874 #> [16,] -2.64794221  0.70541253  0.78164085 -0.12218988  0.26382110 -0.97264696 #> [17,] -0.59024285  1.20133709  0.02691916 -0.45526058 -0.38894004 -0.51744565 #> [18,]  0.73649265  0.46852245 -0.18419048 -0.45872544 -0.30400190 -0.15411996 #> [19,] -1.18501704  0.09703486 -1.47443389 -0.31309733  0.46295088  0.22911528 #> [20,] -1.43906556  0.52556741  0.11066551 -0.46711508  0.70135198 -0.12657426 #> [21,]  0.33269832  1.15647992 -0.49742370 -0.49751150  0.03075929 -0.26023128 #> [22,] -1.28384132 -0.23799459 -0.21107354  0.50469061  0.13088191 -0.02655946 #> [23,]  0.97627971  0.70172088  0.20561742 -0.60785236 -0.37714270 -0.15010150 #> [24,] -2.35582456  0.03526826  0.80988172 -0.01076392  0.79025721 -0.53162513 #> [25,] -0.59059777 -0.27969847 -0.34246431  0.49615203  0.23346261 -0.50946404 predict(modplsform,newdata=Xpine_supNA,type=\"scores\")     #> Missing value in row  1 . #>            Comp_1      Comp_2      Comp_3      Comp_4      Comp_5      Comp_6 #>  [1,] -0.06699854  3.66196285 -0.41608333  0.45187568  1.59546224 -0.70283222 #>  [2,]  2.72264571 -0.18222256  0.81656680  0.02721720  0.86067342 -0.37393001 #>  [3,]  0.20573296  0.81889037  1.42664508 -0.15485978  0.43372368 -0.65684336 #>  [4,]  1.71455473  0.87851109  0.32284764  0.37343500  0.23900014 -0.44019550 #>  [5,]  1.54683876  0.06396562  0.85245128 -0.16192486  0.59815956 -0.33518539 #>  [6,] -1.04388279  2.94178014  1.47387097  1.08467443 -0.02394675  0.87054622 #>  [7,]  3.76040357  1.20512548 -0.18065028 -0.40642515 -0.37373716 -0.66809476 #>  [8,]  2.28765145  0.79101480  0.59799022 -0.32260550  0.35381984 -0.45046964 #>  [9,]  2.04113990  0.23491526  0.20046643  0.46551988  0.41574301 -0.22843097 #> [10,]  0.15702512  1.48472812  0.85445008  0.03281035  0.58589348  0.13631629 #> [11,]  2.40955090  1.50815475  0.24927003 -1.08425752  0.08663564 -0.32703134 #> [12,]  0.74917624  1.04259904  0.38939526  1.71739480 -0.33430079  0.52239057 #> [13,] -2.34853556  1.25475466  0.84855868 -0.87653694  0.94681725 -0.07623013 #> [14,] -1.23301912  0.69650062  0.24364744  0.35221831  1.00517071 -0.85601738 #> [15,] -2.32146728  0.90707702  1.59345546 -0.33982651 -0.51746875 -2.19885874 #> [16,] -2.64794221  0.70541253  0.78164085 -0.12218988  0.26382110 -0.97264696 #> [17,] -0.59024285  1.20133709  0.02691916 -0.45526058 -0.38894004 -0.51744565 #> [18,]  0.73649265  0.46852245 -0.18419048 -0.45872544 -0.30400190 -0.15411996 #> [19,] -1.18501704  0.09703486 -1.47443389 -0.31309733  0.46295088  0.22911528 #> [20,] -1.43906556  0.52556741  0.11066551 -0.46711508  0.70135198 -0.12657426 #> [21,]  0.33269832  1.15647992 -0.49742370 -0.49751150  0.03075929 -0.26023128 #> [22,] -1.28384132 -0.23799459 -0.21107354  0.50469061  0.13088191 -0.02655946 #> [23,]  0.97627971  0.70172088  0.20561742 -0.60785236 -0.37714270 -0.15010150 #> [24,] -2.35582456  0.03526826  0.80988172 -0.01076392  0.79025721 -0.53162513 #> [25,] -0.59059777 -0.27969847 -0.34246431  0.49615203  0.23346261 -0.50946404 predict(modpls,newdata=Xpine_supNA,type=\"scores\",comps=1)     #> Missing value in row  1 . #>            Comp_1 #>  [1,] -0.06699854 #>  [2,]  2.72264571 #>  [3,]  0.20573296 #>  [4,]  1.71455473 #>  [5,]  1.54683876 #>  [6,] -1.04388279 #>  [7,]  3.76040357 #>  [8,]  2.28765145 #>  [9,]  2.04113990 #> [10,]  0.15702512 #> [11,]  2.40955090 #> [12,]  0.74917624 #> [13,] -2.34853556 #> [14,] -1.23301912 #> [15,] -2.32146728 #> [16,] -2.64794221 #> [17,] -0.59024285 #> [18,]  0.73649265 #> [19,] -1.18501704 #> [20,] -1.43906556 #> [21,]  0.33269832 #> [22,] -1.28384132 #> [23,]  0.97627971 #> [24,] -2.35582456 #> [25,] -0.59059777 predict(modpls,newdata=Xpine_supNA,type=\"scores\",comps=3)     #> Missing value in row  1 . #>            Comp_1      Comp_2      Comp_3 #>  [1,] -0.06699854  3.66196285 -0.41608333 #>  [2,]  2.72264571 -0.18222256  0.81656680 #>  [3,]  0.20573296  0.81889037  1.42664508 #>  [4,]  1.71455473  0.87851109  0.32284764 #>  [5,]  1.54683876  0.06396562  0.85245128 #>  [6,] -1.04388279  2.94178014  1.47387097 #>  [7,]  3.76040357  1.20512548 -0.18065028 #>  [8,]  2.28765145  0.79101480  0.59799022 #>  [9,]  2.04113990  0.23491526  0.20046643 #> [10,]  0.15702512  1.48472812  0.85445008 #> [11,]  2.40955090  1.50815475  0.24927003 #> [12,]  0.74917624  1.04259904  0.38939526 #> [13,] -2.34853556  1.25475466  0.84855868 #> [14,] -1.23301912  0.69650062  0.24364744 #> [15,] -2.32146728  0.90707702  1.59345546 #> [16,] -2.64794221  0.70541253  0.78164085 #> [17,] -0.59024285  1.20133709  0.02691916 #> [18,]  0.73649265  0.46852245 -0.18419048 #> [19,] -1.18501704  0.09703486 -1.47443389 #> [20,] -1.43906556  0.52556741  0.11066551 #> [21,]  0.33269832  1.15647992 -0.49742370 #> [22,] -1.28384132 -0.23799459 -0.21107354 #> [23,]  0.97627971  0.70172088  0.20561742 #> [24,] -2.35582456  0.03526826  0.80988172 #> [25,] -0.59059777 -0.27969847 -0.34246431 predict(modpls,newdata=Xpine_supNA,type=\"scores\",comps=6)     #> Missing value in row  1 . #>            Comp_1      Comp_2      Comp_3      Comp_4      Comp_5      Comp_6 #>  [1,] -0.06699854  3.66196285 -0.41608333  0.45187568  1.59546224 -0.70283222 #>  [2,]  2.72264571 -0.18222256  0.81656680  0.02721720  0.86067342 -0.37393001 #>  [3,]  0.20573296  0.81889037  1.42664508 -0.15485978  0.43372368 -0.65684336 #>  [4,]  1.71455473  0.87851109  0.32284764  0.37343500  0.23900014 -0.44019550 #>  [5,]  1.54683876  0.06396562  0.85245128 -0.16192486  0.59815956 -0.33518539 #>  [6,] -1.04388279  2.94178014  1.47387097  1.08467443 -0.02394675  0.87054622 #>  [7,]  3.76040357  1.20512548 -0.18065028 -0.40642515 -0.37373716 -0.66809476 #>  [8,]  2.28765145  0.79101480  0.59799022 -0.32260550  0.35381984 -0.45046964 #>  [9,]  2.04113990  0.23491526  0.20046643  0.46551988  0.41574301 -0.22843097 #> [10,]  0.15702512  1.48472812  0.85445008  0.03281035  0.58589348  0.13631629 #> [11,]  2.40955090  1.50815475  0.24927003 -1.08425752  0.08663564 -0.32703134 #> [12,]  0.74917624  1.04259904  0.38939526  1.71739480 -0.33430079  0.52239057 #> [13,] -2.34853556  1.25475466  0.84855868 -0.87653694  0.94681725 -0.07623013 #> [14,] -1.23301912  0.69650062  0.24364744  0.35221831  1.00517071 -0.85601738 #> [15,] -2.32146728  0.90707702  1.59345546 -0.33982651 -0.51746875 -2.19885874 #> [16,] -2.64794221  0.70541253  0.78164085 -0.12218988  0.26382110 -0.97264696 #> [17,] -0.59024285  1.20133709  0.02691916 -0.45526058 -0.38894004 -0.51744565 #> [18,]  0.73649265  0.46852245 -0.18419048 -0.45872544 -0.30400190 -0.15411996 #> [19,] -1.18501704  0.09703486 -1.47443389 -0.31309733  0.46295088  0.22911528 #> [20,] -1.43906556  0.52556741  0.11066551 -0.46711508  0.70135198 -0.12657426 #> [21,]  0.33269832  1.15647992 -0.49742370 -0.49751150  0.03075929 -0.26023128 #> [22,] -1.28384132 -0.23799459 -0.21107354  0.50469061  0.13088191 -0.02655946 #> [23,]  0.97627971  0.70172088  0.20561742 -0.60785236 -0.37714270 -0.15010150 #> [24,] -2.35582456  0.03526826  0.80988172 -0.01076392  0.79025721 -0.53162513 #> [25,] -0.59059777 -0.27969847 -0.34246431  0.49615203  0.23346261 -0.50946404 try(predict(modpls,newdata=Xpine_supNA,type=\"scores\",comps=8)) #> Error in predict.plsRglmmodel(modpls, newdata = Xpine_supNA, type = \"scores\",  :  #>   Cannot predict using more components than extracted. # }"},{"path":"https://fbertran.github.io/plsRglm/reference/predict.plsRmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for plsR models — predict.plsRmodel","title":"Print method for plsR models — predict.plsRmodel","text":"function provides predict method class \"plsRmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/predict.plsRmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for plsR models — predict.plsRmodel","text":"","code":"# S3 method for class 'plsRmodel' predict(   object,   newdata,   comps = object$computed_nt,   type = c(\"response\", \"scores\"),   weights,   methodNA = \"adaptative\",   verbose = TRUE,   ... )"},{"path":"https://fbertran.github.io/plsRglm/reference/predict.plsRmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for plsR models — predict.plsRmodel","text":"object object class \"plsRmodel\". newdata optional data frame look variables predict. omitted, fitted values used. comps value single value component use prediction. type Type predicted value. Available choices response values (\"response\") scores (\"scores\"). weights Vector case weights. weights vector integers, estimated coefficients equivalent estimating model data individual cases replicated many times indicated weights. methodNA Selects way predicting response scores new data. complete rows, without missing value, two different ways computing prediction. consequence, mixed datasets, complete incomplete rows, two ways computing prediction : either predicts row missing values (missingdata) selects prediction method accordingly completeness row (adaptative). verbose info messages displayed ? ... Arguments passed plsRglm::plsR.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/predict.plsRmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for plsR models — predict.plsRmodel","text":"type \"response\", matrix predicted response values returned. type \"scores\", score matrix returned.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/predict.plsRmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print method for plsR models — predict.plsRmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/predict.plsRmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for plsR models — predict.plsRmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/predict.plsRmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for plsR models — predict.plsRmodel","text":"","code":"data(pine) Xpine<-pine[,1:10] ypine<-pine[,11] data(pine_sup) Xpine_sup<-pine_sup[,1:10] Xpine_supNA<-Xpine_sup Xpine_supNA[1,1]<-NA  modpls=plsR(object=ypine,dataX=Xpine,nt=6,modele=\"pls\", verbose=FALSE) modplsform=plsR(x11~.,data=pine,nt=6,modele=\"pls\", verbose=FALSE) modpls2=plsR(object=ypine,dataX=Xpine,nt=6,modele=\"pls\",dataPredictY=Xpine_sup, verbose=FALSE) modpls2NA=plsR(object=ypine,dataX=Xpine,nt=6,modele=\"pls\",dataPredictY=Xpine_supNA, verbose=FALSE)  #Identical to predict(modpls,type=\"response\") or modpls$ValsPredictY cbind(predict(modpls),predict(modplsform)) #>           [,1]        [,2] #> 1   1.88550891  1.88550891 #> 2   1.20179188  1.20179188 #> 3   1.51671911  1.51671911 #> 4   1.04125064  1.04125064 #> 5   0.57134580  0.57134580 #> 6   1.39997555  1.39997555 #> 7  -0.11535438 -0.11535438 #> 8   0.32418945  0.32418945 #> 9   1.65007715  1.65007715 #> 10  0.94847153  0.94847153 #> 11  0.63882421  0.63882421 #> 12  0.98380367  0.98380367 #> 13  2.19486369  2.19486369 #> 14  1.90455582  1.90455582 #> 15  1.51027552  1.51027552 #> 16 -0.51351160 -0.51351160 #> 17  0.10574381  0.10574381 #> 18  0.78377367  0.78377367 #> 19  0.88040097  0.88040097 #> 20 -0.07763891 -0.07763891 #> 21  0.61594736  0.61594736 #> 22  0.71165796  0.71165796 #> 23  0.71111241  0.71111241 #> 24  0.27266379  0.27266379 #> 25 -0.04249364 -0.04249364 #> 26  0.67364464  0.67364464 #> 27  0.15754257  0.15754257 #> 28  0.90956750  0.90956750 #> 29  1.51049933  1.51049933 #> 30  0.42326984  0.42326984 #> 31  1.39942166  1.39942166 #> 32  0.55048739  0.55048739 #> 33  0.04161271  0.04161271  #Identical to modpls$ttPredictY predict(modpls,type=\"scores\") #>        Comp_1      Comp_2       Comp_3       Comp_4      Comp_5       Comp_6 #> 1   2.9096976  1.64928263 -0.009483345  0.057956125 -1.46934378 -0.489598560 #> 2   0.7632932  0.53986261 -0.159129490  0.437277302 -0.17706329 -0.321853358 #> 3   2.5797729 -0.95827084  0.555733674  0.564062003 -0.87910500  0.284035643 #> 4   0.0443116 -0.73426297  1.346922821  0.343331779 -0.61503115  0.321925722 #> 5   0.8636609 -1.16804390 -0.764622885  0.093269712 -1.08357804  0.406014752 #> 6   2.0735510  0.19497416 -0.670208952  0.413100157 -0.18688067  0.313358700 #> 7  -1.8665241 -2.48962433  0.797691352 -0.120816072  0.24965976  0.473848359 #> 8  -0.3528084  0.04861907 -1.852562297  0.290984465  0.31452397 -0.838090240 #> 9   2.5760644  0.15055738  0.648675543 -0.250529134  0.91785586 -0.024983347 #> 10  0.7101307 -0.41831551  0.377690029 -0.377341589  1.50934893  0.005287361 #> 11 -1.4335481  1.66638440  0.456378669 -1.104406098 -0.44664111  0.207883485 #> 12 -3.3502270  1.31224504  1.417402888  1.104955312  1.55029102 -0.231379510 #> 13  3.6223851  0.52711545  0.931982918  0.263506207 -0.45209584  0.269206095 #> 14  2.1481736  1.27179987 -0.531059123  0.880856701  0.19746452  0.441259500 #> 15  1.8241923  0.37179819 -0.148615856  0.272375958  0.74396025  0.322278940 #> 16 -4.2769308 -0.60364703 -0.145483587  0.061124443 -0.07065661 -0.227489941 #> 17 -2.7842661  0.07795936 -0.502459829  0.582930183 -1.32991074  0.212595330 #> 18  0.8485036  0.40742891 -0.193547055 -0.711084310 -0.56678414 -0.654095817 #> 19  1.0268524 -1.55540630  0.267743180  0.304546989  0.88466538  0.011898270 #> 20 -2.0252326 -0.95493184 -0.296655275 -0.083369174  0.12999791 -0.220552715 #> 21 -2.9034527  0.76785147  1.198603055  0.659329630 -1.11470720 -0.353608888 #> 22 -0.6130182  0.01002519  0.509344060 -0.005358532 -0.61128002 -0.200778587 #> 23  0.3973956  0.13794708 -1.064862116 -0.089851072  0.79543645 -0.145976068 #> 24 -1.9919455 -0.11442060  0.306396644  0.130362294 -0.45181618 -0.644950290 #> 25 -0.9692387 -1.33933413 -1.514216201  0.419166401 -0.31389894 -0.126098495 #> 26  0.4320999  0.08330600 -0.734286784 -0.465917039  0.54059199  0.026669076 #> 27 -3.0186366  1.40703110 -0.783174430 -0.415481000 -1.00237524  1.266343581 #> 28  2.7834585 -1.59488217  0.077656351 -0.549262658 -0.86934018 -0.248831094 #> 29  2.4348733 -0.09247079  0.513378875 -0.284383041  0.63256561  0.139995140 #> 30 -0.3039968 -0.25883732  0.796456033 -1.182848400 -0.21148979 -0.558234302 #> 31  0.6490525  1.01235432 -0.442700445  0.584228984  1.60266786 -0.069695249 #> 32 -0.5424034  1.07847208 -0.113667400 -1.404961066  0.47606589  0.182674243 #> 33 -2.2552401 -0.43256657 -0.275321019 -0.417755460  1.30690250  0.470942265 predict(modplsform,type=\"scores\") #>        Comp_1      Comp_2       Comp_3       Comp_4      Comp_5       Comp_6 #> 1   2.9096976  1.64928263 -0.009483345  0.057956125 -1.46934378 -0.489598560 #> 2   0.7632932  0.53986261 -0.159129490  0.437277302 -0.17706329 -0.321853358 #> 3   2.5797729 -0.95827084  0.555733674  0.564062003 -0.87910500  0.284035643 #> 4   0.0443116 -0.73426297  1.346922821  0.343331779 -0.61503115  0.321925722 #> 5   0.8636609 -1.16804390 -0.764622885  0.093269712 -1.08357804  0.406014752 #> 6   2.0735510  0.19497416 -0.670208952  0.413100157 -0.18688067  0.313358700 #> 7  -1.8665241 -2.48962433  0.797691352 -0.120816072  0.24965976  0.473848359 #> 8  -0.3528084  0.04861907 -1.852562297  0.290984465  0.31452397 -0.838090240 #> 9   2.5760644  0.15055738  0.648675543 -0.250529134  0.91785586 -0.024983347 #> 10  0.7101307 -0.41831551  0.377690029 -0.377341589  1.50934893  0.005287361 #> 11 -1.4335481  1.66638440  0.456378669 -1.104406098 -0.44664111  0.207883485 #> 12 -3.3502270  1.31224504  1.417402888  1.104955312  1.55029102 -0.231379510 #> 13  3.6223851  0.52711545  0.931982918  0.263506207 -0.45209584  0.269206095 #> 14  2.1481736  1.27179987 -0.531059123  0.880856701  0.19746452  0.441259500 #> 15  1.8241923  0.37179819 -0.148615856  0.272375958  0.74396025  0.322278940 #> 16 -4.2769308 -0.60364703 -0.145483587  0.061124443 -0.07065661 -0.227489941 #> 17 -2.7842661  0.07795936 -0.502459829  0.582930183 -1.32991074  0.212595330 #> 18  0.8485036  0.40742891 -0.193547055 -0.711084310 -0.56678414 -0.654095817 #> 19  1.0268524 -1.55540630  0.267743180  0.304546989  0.88466538  0.011898270 #> 20 -2.0252326 -0.95493184 -0.296655275 -0.083369174  0.12999791 -0.220552715 #> 21 -2.9034527  0.76785147  1.198603055  0.659329630 -1.11470720 -0.353608888 #> 22 -0.6130182  0.01002519  0.509344060 -0.005358532 -0.61128002 -0.200778587 #> 23  0.3973956  0.13794708 -1.064862116 -0.089851072  0.79543645 -0.145976068 #> 24 -1.9919455 -0.11442060  0.306396644  0.130362294 -0.45181618 -0.644950290 #> 25 -0.9692387 -1.33933413 -1.514216201  0.419166401 -0.31389894 -0.126098495 #> 26  0.4320999  0.08330600 -0.734286784 -0.465917039  0.54059199  0.026669076 #> 27 -3.0186366  1.40703110 -0.783174430 -0.415481000 -1.00237524  1.266343581 #> 28  2.7834585 -1.59488217  0.077656351 -0.549262658 -0.86934018 -0.248831094 #> 29  2.4348733 -0.09247079  0.513378875 -0.284383041  0.63256561  0.139995140 #> 30 -0.3039968 -0.25883732  0.796456033 -1.182848400 -0.21148979 -0.558234302 #> 31  0.6490525  1.01235432 -0.442700445  0.584228984  1.60266786 -0.069695249 #> 32 -0.5424034  1.07847208 -0.113667400 -1.404961066  0.47606589  0.182674243 #> 33 -2.2552401 -0.43256657 -0.275321019 -0.417755460  1.30690250  0.470942265  # \\donttest{ #Identical to modpls2$ValsPredictY cbind(predict(modpls,newdata=Xpine_sup,type=\"response\"), predict(modplsform,newdata=Xpine_sup,type=\"response\")) #>            [,1]      [,2] #>  [1,] 1.3129638 1.3129638 #>  [2,] 1.7388475 1.7388475 #>  [3,] 1.6763518 1.6763518 #>  [4,] 1.8099257 1.8099257 #>  [5,] 1.6200619 1.6200619 #>  [6,] 3.0575985 3.0575985 #>  [7,] 1.9649911 1.9649911 #>  [8,] 1.9619642 1.9619642 #>  [9,] 1.4752241 1.4752241 #> [10,] 2.0924149 2.0924149 #> [11,] 2.0100323 2.0100323 #> [12,] 2.3735435 2.3735435 #> [13,] 1.1905470 1.1905470 #> [14,] 0.9390483 0.9390483 #> [15,] 0.3599746 0.3599746 #> [16,] 0.5024583 0.5024583 #> [17,] 1.2330826 1.2330826 #> [18,] 1.2011370 1.2011370 #> [19,] 0.2350173 0.2350173 #> [20,] 0.8460029 0.8460029 #> [21,] 1.2946902 1.2946902 #> [22,] 0.3957882 0.3957882 #> [23,] 1.2468234 1.2468234 #> [24,] 0.4951827 0.4951827 #> [25,] 0.5538154 0.5538154  #Select the number of components to use to derive the prediction predict(modpls,newdata=Xpine_sup,type=\"response\",comps=1)     #>            [,1] #>  [1,] 0.4529386 #>  [2,] 1.5275250 #>  [3,] 0.8653393 #>  [4,] 1.2623019 #>  [5,] 1.2181767 #>  [6,] 0.5365724 #>  [7,] 1.8005533 #>  [8,] 1.4130804 #>  [9,] 1.3482246 #> [10,] 0.8525246 #> [11,] 1.4451515 #> [12,] 1.0083162 #> [13,] 0.1933256 #> [14,] 0.4868117 #> [15,] 0.2004471 #> [16,] 0.1145533 #> [17,] 0.6559225 #> [18,] 1.0049792 #> [19,] 0.4994408 #> [20,] 0.4326020 #> [21,] 0.8987432 #> [22,] 0.4734407 #> [23,] 1.0680659 #> [24,] 0.1914079 #> [25,] 0.6558292 predict(modpls,newdata=Xpine_sup,type=\"response\",comps=3)     #>            [,1] #>  [1,] 1.3964152 #>  [2,] 1.3235411 #>  [3,] 1.1864009 #>  [4,] 1.5145135 #>  [5,] 1.1423259 #>  [6,] 2.1104660 #>  [7,] 2.1399449 #>  [8,] 1.6900978 #>  [9,] 1.3301024 #> [10,] 1.5686734 #> [11,] 2.0696493 #> [12,] 1.4845725 #> [13,] 0.9158598 #> [14,] 0.6998484 #> [15,] 0.4447477 #> [16,] 0.3612035 #> [17,] 1.2314589 #> [18,] 1.3030724 #> [19,] 0.6100443 #> [20,] 0.6747087 #> [21,] 1.5231209 #> [22,] 0.3475253 #> [23,] 1.4135977 #> [24,] 0.1426153 #> [25,] 0.3905439 predict(modpls,newdata=Xpine_sup,type=\"response\",comps=6)     #>            [,1] #>  [1,] 1.3129638 #>  [2,] 1.7388475 #>  [3,] 1.6763518 #>  [4,] 1.8099257 #>  [5,] 1.6200619 #>  [6,] 3.0575985 #>  [7,] 1.9649911 #>  [8,] 1.9619642 #>  [9,] 1.4752241 #> [10,] 2.0924149 #> [11,] 2.0100323 #> [12,] 2.3735435 #> [13,] 1.1905470 #> [14,] 0.9390483 #> [15,] 0.3599746 #> [16,] 0.5024583 #> [17,] 1.2330826 #> [18,] 1.2011370 #> [19,] 0.2350173 #> [20,] 0.8460029 #> [21,] 1.2946902 #> [22,] 0.3957882 #> [23,] 1.2468234 #> [24,] 0.4951827 #> [25,] 0.5538154 try(predict(modpls,newdata=Xpine_sup,type=\"response\",comps=8)) #> Error in predict.plsRmodel(modpls, newdata = Xpine_sup, type = \"response\",  :  #>   Cannot predict using more components than extracted.  #Identical to modpls2$ttValsPredictY predict(modpls,newdata=Xpine_sup,type=\"scores\")     #>           Comp_1       Comp_2      Comp_3       Comp_4      Comp_5       Comp_6 #>  [1,] -1.3617679  2.993459769  0.73427739  0.452953573 -1.11579015 -1.473542293 #>  [2,]  2.7226457 -1.448207417  0.75220272  1.097297569  0.53631331  0.559682133 #>  [3,]  0.2057330 -0.065699548  1.48307730  1.608813107  0.19908226  0.005584384 #>  [4,]  1.7145547  0.999997451 -0.03091563  0.968262496 -0.09309405  0.121080636 #>  [5,]  1.5468388 -0.962223763  0.76157621  1.426096569  0.06539057  0.474713635 #>  [6,] -1.0438828  5.067110560  1.14136095  2.864592446  1.68207458  0.014847912 #>  [7,]  3.7604036  1.284021688  0.02849577  0.004909657 -3.03776558 -0.062192479 #>  [8,]  2.2876515  0.199824399  0.98790364  0.944924320 -0.59601659  0.230003786 #>  [9,]  2.0411399  0.238406080 -0.35062475  0.558516943  0.19675157 -0.301893947 #> [10,]  0.1570251  1.504717841  1.43017861  1.564536266  0.14708601  0.477418245 #> [11,]  2.4095509  1.155533043  1.42525994  0.452142174 -2.83846498 -0.334252057 #> [12,]  0.7491762  3.052072375 -1.38187603  2.282056699  2.18543478  0.836814768 #> [13,] -2.3485356  0.216703031  2.92300006  0.685183103  0.15356406  0.590760027 #> [14,] -1.2330191  0.008574545  0.92474943  0.312313976  1.39640033  0.646248390 #> [15,] -2.3214673  0.108405764  0.94835654  0.484159548  0.27324060 -2.308760250 #> [16,] -2.6479422  0.291815002  0.75007834  0.717778190  0.67224455 -1.038074446 #> [17,] -0.5902429  1.554635840  0.75660189  0.131428359 -0.44100984 -0.121010721 #> [18,]  0.7364927  0.699547511  0.51203773 -0.265761130 -0.22924277 -0.095761547 #> [19,] -1.1850170  0.300466200  0.14346126 -1.526977483  0.06869875  0.710089752 #> [20,] -1.4390656 -0.147557539  1.22983008  0.341807486  0.21492515  0.545779712 #> [21,]  0.3326983  1.459383292  1.07917521 -0.766536942 -0.26974278  0.137300450 #> [22,] -1.2838413  0.228232572 -0.81189728  0.112113284  1.24971859 -0.519868578 #> [23,]  0.9762797  0.792728055  0.61416007 -0.026280577 -1.58598821 -0.665173114 #> [24,] -2.3558246 -1.146802277  1.09018353  0.784478257  1.20560305  0.491817441 #> [25,] -0.5905978 -0.284407470 -0.84024689  0.182976076  1.35912630  0.311267458  #Select the number of components in the scores matrix predict(modpls,newdata=Xpine_sup,type=\"scores\",comps=1)     #>           Comp_1 #>  [1,] -1.3617679 #>  [2,]  2.7226457 #>  [3,]  0.2057330 #>  [4,]  1.7145547 #>  [5,]  1.5468388 #>  [6,] -1.0438828 #>  [7,]  3.7604036 #>  [8,]  2.2876515 #>  [9,]  2.0411399 #> [10,]  0.1570251 #> [11,]  2.4095509 #> [12,]  0.7491762 #> [13,] -2.3485356 #> [14,] -1.2330191 #> [15,] -2.3214673 #> [16,] -2.6479422 #> [17,] -0.5902429 #> [18,]  0.7364927 #> [19,] -1.1850170 #> [20,] -1.4390656 #> [21,]  0.3326983 #> [22,] -1.2838413 #> [23,]  0.9762797 #> [24,] -2.3558246 #> [25,] -0.5905978 predict(modpls,newdata=Xpine_sup,type=\"scores\",comps=3)     #>           Comp_1       Comp_2      Comp_3 #>  [1,] -1.3617679  2.993459769  0.73427739 #>  [2,]  2.7226457 -1.448207417  0.75220272 #>  [3,]  0.2057330 -0.065699548  1.48307730 #>  [4,]  1.7145547  0.999997451 -0.03091563 #>  [5,]  1.5468388 -0.962223763  0.76157621 #>  [6,] -1.0438828  5.067110560  1.14136095 #>  [7,]  3.7604036  1.284021688  0.02849577 #>  [8,]  2.2876515  0.199824399  0.98790364 #>  [9,]  2.0411399  0.238406080 -0.35062475 #> [10,]  0.1570251  1.504717841  1.43017861 #> [11,]  2.4095509  1.155533043  1.42525994 #> [12,]  0.7491762  3.052072375 -1.38187603 #> [13,] -2.3485356  0.216703031  2.92300006 #> [14,] -1.2330191  0.008574545  0.92474943 #> [15,] -2.3214673  0.108405764  0.94835654 #> [16,] -2.6479422  0.291815002  0.75007834 #> [17,] -0.5902429  1.554635840  0.75660189 #> [18,]  0.7364927  0.699547511  0.51203773 #> [19,] -1.1850170  0.300466200  0.14346126 #> [20,] -1.4390656 -0.147557539  1.22983008 #> [21,]  0.3326983  1.459383292  1.07917521 #> [22,] -1.2838413  0.228232572 -0.81189728 #> [23,]  0.9762797  0.792728055  0.61416007 #> [24,] -2.3558246 -1.146802277  1.09018353 #> [25,] -0.5905978 -0.284407470 -0.84024689 predict(modpls,newdata=Xpine_sup,type=\"scores\",comps=6)     #>           Comp_1       Comp_2      Comp_3       Comp_4      Comp_5       Comp_6 #>  [1,] -1.3617679  2.993459769  0.73427739  0.452953573 -1.11579015 -1.473542293 #>  [2,]  2.7226457 -1.448207417  0.75220272  1.097297569  0.53631331  0.559682133 #>  [3,]  0.2057330 -0.065699548  1.48307730  1.608813107  0.19908226  0.005584384 #>  [4,]  1.7145547  0.999997451 -0.03091563  0.968262496 -0.09309405  0.121080636 #>  [5,]  1.5468388 -0.962223763  0.76157621  1.426096569  0.06539057  0.474713635 #>  [6,] -1.0438828  5.067110560  1.14136095  2.864592446  1.68207458  0.014847912 #>  [7,]  3.7604036  1.284021688  0.02849577  0.004909657 -3.03776558 -0.062192479 #>  [8,]  2.2876515  0.199824399  0.98790364  0.944924320 -0.59601659  0.230003786 #>  [9,]  2.0411399  0.238406080 -0.35062475  0.558516943  0.19675157 -0.301893947 #> [10,]  0.1570251  1.504717841  1.43017861  1.564536266  0.14708601  0.477418245 #> [11,]  2.4095509  1.155533043  1.42525994  0.452142174 -2.83846498 -0.334252057 #> [12,]  0.7491762  3.052072375 -1.38187603  2.282056699  2.18543478  0.836814768 #> [13,] -2.3485356  0.216703031  2.92300006  0.685183103  0.15356406  0.590760027 #> [14,] -1.2330191  0.008574545  0.92474943  0.312313976  1.39640033  0.646248390 #> [15,] -2.3214673  0.108405764  0.94835654  0.484159548  0.27324060 -2.308760250 #> [16,] -2.6479422  0.291815002  0.75007834  0.717778190  0.67224455 -1.038074446 #> [17,] -0.5902429  1.554635840  0.75660189  0.131428359 -0.44100984 -0.121010721 #> [18,]  0.7364927  0.699547511  0.51203773 -0.265761130 -0.22924277 -0.095761547 #> [19,] -1.1850170  0.300466200  0.14346126 -1.526977483  0.06869875  0.710089752 #> [20,] -1.4390656 -0.147557539  1.22983008  0.341807486  0.21492515  0.545779712 #> [21,]  0.3326983  1.459383292  1.07917521 -0.766536942 -0.26974278  0.137300450 #> [22,] -1.2838413  0.228232572 -0.81189728  0.112113284  1.24971859 -0.519868578 #> [23,]  0.9762797  0.792728055  0.61416007 -0.026280577 -1.58598821 -0.665173114 #> [24,] -2.3558246 -1.146802277  1.09018353  0.784478257  1.20560305  0.491817441 #> [25,] -0.5905978 -0.284407470 -0.84024689  0.182976076  1.35912630  0.311267458 try(predict(modpls,newdata=Xpine_sup,type=\"scores\",comps=8)) #> Error in predict.plsRmodel(modpls, newdata = Xpine_sup, type = \"scores\",  :  #>   Cannot predict using more components than extracted.  #Identical to modpls2NA$ValsPredictY predict(modpls,newdata=Xpine_supNA,type=\"response\",methodNA=\"missingdata\")     #> Prediction as if missing values in every row. #>             [,1] #>  [1,] -0.4380246 #>  [2,]  1.7274179 #>  [3,]  1.7531622 #>  [4,]  1.8064674 #>  [5,]  1.6641257 #>  [6,]  3.1037177 #>  [7,]  1.8996680 #>  [8,]  1.9915726 #>  [9,]  1.3431573 #> [10,]  2.0567726 #> [11,]  1.9113526 #> [12,]  2.5555213 #> [13,]  1.1747931 #> [14,]  0.9143911 #> [15,]  0.6401136 #> [16,]  0.5709883 #> [17,]  1.4171363 #> [18,]  1.3099823 #> [19,]  0.1209765 #> [20,]  0.8630320 #> [21,]  1.3182253 #> [22,]  0.3658273 #> [23,]  1.2252369 #> [24,]  0.5737034 #> [25,]  0.6736099  cbind(predict(modpls,newdata=Xpine_supNA,type=\"response\"), predict(modplsform,newdata=Xpine_supNA,type=\"response\")) #> Missing value in row  1 . #> Missing value in row  1 . #>             [,1]       [,2] #>  [1,] -0.4380246 -0.4380246 #>  [2,]  1.7388475  1.7388475 #>  [3,]  1.6763518  1.6763518 #>  [4,]  1.8099257  1.8099257 #>  [5,]  1.6200619  1.6200619 #>  [6,]  3.0575985  3.0575985 #>  [7,]  1.9649911  1.9649911 #>  [8,]  1.9619642  1.9619642 #>  [9,]  1.4752241  1.4752241 #> [10,]  2.0924149  2.0924149 #> [11,]  2.0100323  2.0100323 #> [12,]  2.3735435  2.3735435 #> [13,]  1.1905470  1.1905470 #> [14,]  0.9390483  0.9390483 #> [15,]  0.3599746  0.3599746 #> [16,]  0.5024583  0.5024583 #> [17,]  1.2330826  1.2330826 #> [18,]  1.2011370  1.2011370 #> [19,]  0.2350173  0.2350173 #> [20,]  0.8460029  0.8460029 #> [21,]  1.2946902  1.2946902 #> [22,]  0.3957882  0.3957882 #> [23,]  1.2468234  1.2468234 #> [24,]  0.4951827  0.4951827 #> [25,]  0.5538154  0.5538154  predict(modpls,newdata=Xpine_supNA,type=\"response\",comps=1)     #> Missing value in row  1 . #>             [,1] #>  [1,] 0.01262359 #>  [2,] 1.52752498 #>  [3,] 0.86533931 #>  [4,] 1.26230188 #>  [5,] 1.21817675 #>  [6,] 0.53657240 #>  [7,] 1.80055327 #>  [8,] 1.41308042 #>  [9,] 1.34822461 #> [10,] 0.85252455 #> [11,] 1.44515149 #> [12,] 1.00831620 #> [13,] 0.19332555 #> [14,] 0.48681169 #> [15,] 0.20044706 #> [16,] 0.11455334 #> [17,] 0.65592253 #> [18,] 1.00497922 #> [19,] 0.49944077 #> [20,] 0.43260202 #> [21,] 0.89874319 #> [22,] 0.47344065 #> [23,] 1.06806585 #> [24,] 0.19140786 #> [25,] 0.65582915 predict(modpls,newdata=Xpine_supNA,type=\"response\",comps=3)     #> Missing value in row  1 . #>                [,1] #>  [1,] -0.0001503207 #>  [2,]  1.3235411249 #>  [3,]  1.1864008651 #>  [4,]  1.5145134877 #>  [5,]  1.1423259016 #>  [6,]  2.1104660488 #>  [7,]  2.1399449414 #>  [8,]  1.6900977631 #>  [9,]  1.3301024082 #> [10,]  1.5686733743 #> [11,]  2.0696493364 #> [12,]  1.4845725327 #> [13,]  0.9158597617 #> [14,]  0.6998484111 #> [15,]  0.4447477116 #> [16,]  0.3612034996 #> [17,]  1.2314588588 #> [18,]  1.3030723893 #> [19,]  0.6100442895 #> [20,]  0.6747086944 #> [21,]  1.5231208749 #> [22,]  0.3475252821 #> [23,]  1.4135976883 #> [24,]  0.1426152740 #> [25,]  0.3905438807 predict(modpls,newdata=Xpine_supNA,type=\"response\",comps=6)     #> Missing value in row  1 . #>             [,1] #>  [1,] -0.4380246 #>  [2,]  1.7388475 #>  [3,]  1.6763518 #>  [4,]  1.8099257 #>  [5,]  1.6200619 #>  [6,]  3.0575985 #>  [7,]  1.9649911 #>  [8,]  1.9619642 #>  [9,]  1.4752241 #> [10,]  2.0924149 #> [11,]  2.0100323 #> [12,]  2.3735435 #> [13,]  1.1905470 #> [14,]  0.9390483 #> [15,]  0.3599746 #> [16,]  0.5024583 #> [17,]  1.2330826 #> [18,]  1.2011370 #> [19,]  0.2350173 #> [20,]  0.8460029 #> [21,]  1.2946902 #> [22,]  0.3957882 #> [23,]  1.2468234 #> [24,]  0.4951827 #> [25,]  0.5538154 try(predict(modpls,newdata=Xpine_supNA,type=\"response\",comps=8)) #> Error in predict.plsRmodel(modpls, newdata = Xpine_supNA, type = \"response\",  :  #>   Cannot predict using more components than extracted.  #Identical to modpls2NA$ttPredictY predict(modpls,newdata=Xpine_supNA,type=\"scores\",methodNA=\"missingdata\") #> Prediction as if missing values in every row. #>           Comp_1       Comp_2       Comp_3      Comp_4      Comp_5     Comp_6 #>  [1,] -3.0353687  0.987755634 -1.179371542 -0.19743715 -3.30898182 -1.8375844 #>  [2,]  2.7220756 -1.450870839  0.745991000  1.08616889  0.51576986  0.5150498 #>  [3,]  0.2095646 -0.047800552  1.524821925  1.68360118  0.33714044  0.3055271 #>  [4,]  1.7143822  0.999191584 -0.032795102  0.96489531 -0.09930985  0.1075763 #>  [5,]  1.5490368 -0.951955668  0.785523797  1.46900015  0.14459023  0.6467814 #>  [6,] -1.0415822  5.077857636  1.166425636  2.90949737  1.76496872  0.1949422 #>  [7,]  3.7571450  1.268799569 -0.007005749 -0.05869351 -3.15517652 -0.3172774 #>  [8,]  2.2891284  0.206724001  1.003995120  0.97375319 -0.54279872  0.3456240 #>  [9,]  2.0345518  0.207630787 -0.422399890  0.42992734 -0.04062381 -0.8176114 #> [10,]  0.1552471  1.496412167  1.410807841  1.52983235  0.08302285  0.3382358 #> [11,]  2.4046283  1.132537890  1.371629890  0.35606063 -3.01583074 -0.7195937 #> [12,]  0.7582541  3.094478343 -1.282975446  2.45924320  2.51251965  1.5474334 #> [13,] -2.3493214  0.213031935  2.914438207  0.66984402  0.12524823  0.5292416 #> [14,] -1.2342491  0.002828718  0.911348819  0.28830596  1.35208173  0.5499626 #> [15,] -2.3074928  0.173686077  1.100605419  0.75692282  0.77675941 -1.2148245 #> [16,] -2.6445236  0.307784429  0.787322756  0.78450387  0.79541961 -0.7704665 #> [17,] -0.5810615  1.597525542  0.856630655  0.31063607 -0.11019384  0.5977141 #> [18,]  0.7419223  0.724911543  0.571192552 -0.15978161 -0.03360542  0.3292766 #> [19,] -1.1907059  0.273891474  0.081482816 -1.63801569 -0.13627690  0.2647634 #> [20,] -1.4382161 -0.143589272  1.239085007  0.35838825  0.24553311  0.6122780 #> [21,]  0.3338724  1.464867644  1.091965992 -0.74362146 -0.22744099  0.2292046 #> [22,] -1.2853359  0.221250834 -0.828180315  0.08294122  1.19586719 -0.6368651 #> [23,]  0.9752029  0.787697790  0.602428320 -0.04729873 -1.62478755 -0.7494679 #> [24,] -2.3519076 -1.128504742  1.132857643  0.86093156  1.34673523  0.7984386 #> [25,] -0.5846219 -0.256491971 -0.775141451  0.29961649  1.57444357  0.7790618 predict(modplsform,newdata=Xpine_supNA,type=\"scores\",methodNA=\"missingdata\") #> Prediction as if missing values in every row. #>           Comp_1       Comp_2       Comp_3      Comp_4      Comp_5     Comp_6 #>  [1,] -3.0353687  0.987755634 -1.179371542 -0.19743715 -3.30898182 -1.8375844 #>  [2,]  2.7220756 -1.450870839  0.745991000  1.08616889  0.51576986  0.5150498 #>  [3,]  0.2095646 -0.047800552  1.524821925  1.68360118  0.33714044  0.3055271 #>  [4,]  1.7143822  0.999191584 -0.032795102  0.96489531 -0.09930985  0.1075763 #>  [5,]  1.5490368 -0.951955668  0.785523797  1.46900015  0.14459023  0.6467814 #>  [6,] -1.0415822  5.077857636  1.166425636  2.90949737  1.76496872  0.1949422 #>  [7,]  3.7571450  1.268799569 -0.007005749 -0.05869351 -3.15517652 -0.3172774 #>  [8,]  2.2891284  0.206724001  1.003995120  0.97375319 -0.54279872  0.3456240 #>  [9,]  2.0345518  0.207630787 -0.422399890  0.42992734 -0.04062381 -0.8176114 #> [10,]  0.1552471  1.496412167  1.410807841  1.52983235  0.08302285  0.3382358 #> [11,]  2.4046283  1.132537890  1.371629890  0.35606063 -3.01583074 -0.7195937 #> [12,]  0.7582541  3.094478343 -1.282975446  2.45924320  2.51251965  1.5474334 #> [13,] -2.3493214  0.213031935  2.914438207  0.66984402  0.12524823  0.5292416 #> [14,] -1.2342491  0.002828718  0.911348819  0.28830596  1.35208173  0.5499626 #> [15,] -2.3074928  0.173686077  1.100605419  0.75692282  0.77675941 -1.2148245 #> [16,] -2.6445236  0.307784429  0.787322756  0.78450387  0.79541961 -0.7704665 #> [17,] -0.5810615  1.597525542  0.856630655  0.31063607 -0.11019384  0.5977141 #> [18,]  0.7419223  0.724911543  0.571192552 -0.15978161 -0.03360542  0.3292766 #> [19,] -1.1907059  0.273891474  0.081482816 -1.63801569 -0.13627690  0.2647634 #> [20,] -1.4382161 -0.143589272  1.239085007  0.35838825  0.24553311  0.6122780 #> [21,]  0.3338724  1.464867644  1.091965992 -0.74362146 -0.22744099  0.2292046 #> [22,] -1.2853359  0.221250834 -0.828180315  0.08294122  1.19586719 -0.6368651 #> [23,]  0.9752029  0.787697790  0.602428320 -0.04729873 -1.62478755 -0.7494679 #> [24,] -2.3519076 -1.128504742  1.132857643  0.86093156  1.34673523  0.7984386 #> [25,] -0.5846219 -0.256491971 -0.775141451  0.29961649  1.57444357  0.7790618  predict(modpls,newdata=Xpine_supNA,type=\"scores\")     #> Missing value in row  1 . #>           Comp_1       Comp_2      Comp_3       Comp_4      Comp_5       Comp_6 #>  [1,] -3.0353687  0.987755634 -1.17937154 -0.197437151 -3.30898182 -1.837584434 #>  [2,]  2.7226457 -1.448207417  0.75220272  1.097297569  0.53631331  0.559682133 #>  [3,]  0.2057330 -0.065699548  1.48307730  1.608813107  0.19908226  0.005584384 #>  [4,]  1.7145547  0.999997451 -0.03091563  0.968262496 -0.09309405  0.121080636 #>  [5,]  1.5468388 -0.962223763  0.76157621  1.426096569  0.06539057  0.474713635 #>  [6,] -1.0438828  5.067110560  1.14136095  2.864592446  1.68207458  0.014847912 #>  [7,]  3.7604036  1.284021688  0.02849577  0.004909657 -3.03776558 -0.062192479 #>  [8,]  2.2876515  0.199824399  0.98790364  0.944924320 -0.59601659  0.230003786 #>  [9,]  2.0411399  0.238406080 -0.35062475  0.558516943  0.19675157 -0.301893947 #> [10,]  0.1570251  1.504717841  1.43017861  1.564536266  0.14708601  0.477418245 #> [11,]  2.4095509  1.155533043  1.42525994  0.452142174 -2.83846498 -0.334252057 #> [12,]  0.7491762  3.052072375 -1.38187603  2.282056699  2.18543478  0.836814768 #> [13,] -2.3485356  0.216703031  2.92300006  0.685183103  0.15356406  0.590760027 #> [14,] -1.2330191  0.008574545  0.92474943  0.312313976  1.39640033  0.646248390 #> [15,] -2.3214673  0.108405764  0.94835654  0.484159548  0.27324060 -2.308760250 #> [16,] -2.6479422  0.291815002  0.75007834  0.717778190  0.67224455 -1.038074446 #> [17,] -0.5902429  1.554635840  0.75660189  0.131428359 -0.44100984 -0.121010721 #> [18,]  0.7364927  0.699547511  0.51203773 -0.265761130 -0.22924277 -0.095761547 #> [19,] -1.1850170  0.300466200  0.14346126 -1.526977483  0.06869875  0.710089752 #> [20,] -1.4390656 -0.147557539  1.22983008  0.341807486  0.21492515  0.545779712 #> [21,]  0.3326983  1.459383292  1.07917521 -0.766536942 -0.26974278  0.137300450 #> [22,] -1.2838413  0.228232572 -0.81189728  0.112113284  1.24971859 -0.519868578 #> [23,]  0.9762797  0.792728055  0.61416007 -0.026280577 -1.58598821 -0.665173114 #> [24,] -2.3558246 -1.146802277  1.09018353  0.784478257  1.20560305  0.491817441 #> [25,] -0.5905978 -0.284407470 -0.84024689  0.182976076  1.35912630  0.311267458 predict(modplsform,newdata=Xpine_supNA,type=\"scores\")     #> Missing value in row  1 . #>           Comp_1       Comp_2      Comp_3       Comp_4      Comp_5       Comp_6 #>  [1,] -3.0353687  0.987755634 -1.17937154 -0.197437151 -3.30898182 -1.837584434 #>  [2,]  2.7226457 -1.448207417  0.75220272  1.097297569  0.53631331  0.559682133 #>  [3,]  0.2057330 -0.065699548  1.48307730  1.608813107  0.19908226  0.005584384 #>  [4,]  1.7145547  0.999997451 -0.03091563  0.968262496 -0.09309405  0.121080636 #>  [5,]  1.5468388 -0.962223763  0.76157621  1.426096569  0.06539057  0.474713635 #>  [6,] -1.0438828  5.067110560  1.14136095  2.864592446  1.68207458  0.014847912 #>  [7,]  3.7604036  1.284021688  0.02849577  0.004909657 -3.03776558 -0.062192479 #>  [8,]  2.2876515  0.199824399  0.98790364  0.944924320 -0.59601659  0.230003786 #>  [9,]  2.0411399  0.238406080 -0.35062475  0.558516943  0.19675157 -0.301893947 #> [10,]  0.1570251  1.504717841  1.43017861  1.564536266  0.14708601  0.477418245 #> [11,]  2.4095509  1.155533043  1.42525994  0.452142174 -2.83846498 -0.334252057 #> [12,]  0.7491762  3.052072375 -1.38187603  2.282056699  2.18543478  0.836814768 #> [13,] -2.3485356  0.216703031  2.92300006  0.685183103  0.15356406  0.590760027 #> [14,] -1.2330191  0.008574545  0.92474943  0.312313976  1.39640033  0.646248390 #> [15,] -2.3214673  0.108405764  0.94835654  0.484159548  0.27324060 -2.308760250 #> [16,] -2.6479422  0.291815002  0.75007834  0.717778190  0.67224455 -1.038074446 #> [17,] -0.5902429  1.554635840  0.75660189  0.131428359 -0.44100984 -0.121010721 #> [18,]  0.7364927  0.699547511  0.51203773 -0.265761130 -0.22924277 -0.095761547 #> [19,] -1.1850170  0.300466200  0.14346126 -1.526977483  0.06869875  0.710089752 #> [20,] -1.4390656 -0.147557539  1.22983008  0.341807486  0.21492515  0.545779712 #> [21,]  0.3326983  1.459383292  1.07917521 -0.766536942 -0.26974278  0.137300450 #> [22,] -1.2838413  0.228232572 -0.81189728  0.112113284  1.24971859 -0.519868578 #> [23,]  0.9762797  0.792728055  0.61416007 -0.026280577 -1.58598821 -0.665173114 #> [24,] -2.3558246 -1.146802277  1.09018353  0.784478257  1.20560305  0.491817441 #> [25,] -0.5905978 -0.284407470 -0.84024689  0.182976076  1.35912630  0.311267458 predict(modpls,newdata=Xpine_supNA,type=\"scores\",comps=1)     #> Missing value in row  1 . #>           Comp_1 #>  [1,] -3.0353687 #>  [2,]  2.7226457 #>  [3,]  0.2057330 #>  [4,]  1.7145547 #>  [5,]  1.5468388 #>  [6,] -1.0438828 #>  [7,]  3.7604036 #>  [8,]  2.2876515 #>  [9,]  2.0411399 #> [10,]  0.1570251 #> [11,]  2.4095509 #> [12,]  0.7491762 #> [13,] -2.3485356 #> [14,] -1.2330191 #> [15,] -2.3214673 #> [16,] -2.6479422 #> [17,] -0.5902429 #> [18,]  0.7364927 #> [19,] -1.1850170 #> [20,] -1.4390656 #> [21,]  0.3326983 #> [22,] -1.2838413 #> [23,]  0.9762797 #> [24,] -2.3558246 #> [25,] -0.5905978 predict(modpls,newdata=Xpine_supNA,type=\"scores\",comps=3)     #> Missing value in row  1 . #>           Comp_1       Comp_2      Comp_3 #>  [1,] -3.0353687  0.987755634 -1.17937154 #>  [2,]  2.7226457 -1.448207417  0.75220272 #>  [3,]  0.2057330 -0.065699548  1.48307730 #>  [4,]  1.7145547  0.999997451 -0.03091563 #>  [5,]  1.5468388 -0.962223763  0.76157621 #>  [6,] -1.0438828  5.067110560  1.14136095 #>  [7,]  3.7604036  1.284021688  0.02849577 #>  [8,]  2.2876515  0.199824399  0.98790364 #>  [9,]  2.0411399  0.238406080 -0.35062475 #> [10,]  0.1570251  1.504717841  1.43017861 #> [11,]  2.4095509  1.155533043  1.42525994 #> [12,]  0.7491762  3.052072375 -1.38187603 #> [13,] -2.3485356  0.216703031  2.92300006 #> [14,] -1.2330191  0.008574545  0.92474943 #> [15,] -2.3214673  0.108405764  0.94835654 #> [16,] -2.6479422  0.291815002  0.75007834 #> [17,] -0.5902429  1.554635840  0.75660189 #> [18,]  0.7364927  0.699547511  0.51203773 #> [19,] -1.1850170  0.300466200  0.14346126 #> [20,] -1.4390656 -0.147557539  1.22983008 #> [21,]  0.3326983  1.459383292  1.07917521 #> [22,] -1.2838413  0.228232572 -0.81189728 #> [23,]  0.9762797  0.792728055  0.61416007 #> [24,] -2.3558246 -1.146802277  1.09018353 #> [25,] -0.5905978 -0.284407470 -0.84024689 predict(modpls,newdata=Xpine_supNA,type=\"scores\",comps=6)     #> Missing value in row  1 . #>           Comp_1       Comp_2      Comp_3       Comp_4      Comp_5       Comp_6 #>  [1,] -3.0353687  0.987755634 -1.17937154 -0.197437151 -3.30898182 -1.837584434 #>  [2,]  2.7226457 -1.448207417  0.75220272  1.097297569  0.53631331  0.559682133 #>  [3,]  0.2057330 -0.065699548  1.48307730  1.608813107  0.19908226  0.005584384 #>  [4,]  1.7145547  0.999997451 -0.03091563  0.968262496 -0.09309405  0.121080636 #>  [5,]  1.5468388 -0.962223763  0.76157621  1.426096569  0.06539057  0.474713635 #>  [6,] -1.0438828  5.067110560  1.14136095  2.864592446  1.68207458  0.014847912 #>  [7,]  3.7604036  1.284021688  0.02849577  0.004909657 -3.03776558 -0.062192479 #>  [8,]  2.2876515  0.199824399  0.98790364  0.944924320 -0.59601659  0.230003786 #>  [9,]  2.0411399  0.238406080 -0.35062475  0.558516943  0.19675157 -0.301893947 #> [10,]  0.1570251  1.504717841  1.43017861  1.564536266  0.14708601  0.477418245 #> [11,]  2.4095509  1.155533043  1.42525994  0.452142174 -2.83846498 -0.334252057 #> [12,]  0.7491762  3.052072375 -1.38187603  2.282056699  2.18543478  0.836814768 #> [13,] -2.3485356  0.216703031  2.92300006  0.685183103  0.15356406  0.590760027 #> [14,] -1.2330191  0.008574545  0.92474943  0.312313976  1.39640033  0.646248390 #> [15,] -2.3214673  0.108405764  0.94835654  0.484159548  0.27324060 -2.308760250 #> [16,] -2.6479422  0.291815002  0.75007834  0.717778190  0.67224455 -1.038074446 #> [17,] -0.5902429  1.554635840  0.75660189  0.131428359 -0.44100984 -0.121010721 #> [18,]  0.7364927  0.699547511  0.51203773 -0.265761130 -0.22924277 -0.095761547 #> [19,] -1.1850170  0.300466200  0.14346126 -1.526977483  0.06869875  0.710089752 #> [20,] -1.4390656 -0.147557539  1.22983008  0.341807486  0.21492515  0.545779712 #> [21,]  0.3326983  1.459383292  1.07917521 -0.766536942 -0.26974278  0.137300450 #> [22,] -1.2838413  0.228232572 -0.81189728  0.112113284  1.24971859 -0.519868578 #> [23,]  0.9762797  0.792728055  0.61416007 -0.026280577 -1.58598821 -0.665173114 #> [24,] -2.3558246 -1.146802277  1.09018353  0.784478257  1.20560305  0.491817441 #> [25,] -0.5905978 -0.284407470 -0.84024689  0.182976076  1.35912630  0.311267458 try(predict(modpls,newdata=Xpine_supNA,type=\"scores\",comps=8)) #> Error in predict.plsRmodel(modpls, newdata = Xpine_supNA, type = \"scores\",  :  #>   Cannot predict using more components than extracted. # }"},{"path":"https://fbertran.github.io/plsRglm/reference/print.coef.plsRglmmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for plsRglm models — print.coef.plsRglmmodel","title":"Print method for plsRglm models — print.coef.plsRglmmodel","text":"function provides print method class \"coef.plsRglmmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.coef.plsRglmmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for plsRglm models — print.coef.plsRglmmodel","text":"","code":"# S3 method for class 'coef.plsRglmmodel' print(x, ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/print.coef.plsRglmmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for plsRglm models — print.coef.plsRglmmodel","text":"x object class \"coef.plsRglmmodel\" ... used","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.coef.plsRglmmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for plsRglm models — print.coef.plsRglmmodel","text":"NULL","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.coef.plsRglmmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print method for plsRglm models — print.coef.plsRglmmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/print.coef.plsRglmmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for plsRglm models — print.coef.plsRglmmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.coef.plsRglmmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for plsRglm models — print.coef.plsRglmmodel","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] modplsglm <- plsRglm(yCornell,XCornell,3,modele=\"pls-glm-family\",family=gaussian()) #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  class(modplsglm) #> [1] \"plsRglmmodel\" print(coef(modplsglm)) #> Coefficients of the components #> Coeff_Comp_Reg 1 Coeff_Comp_Reg 2 Coeff_Comp_Reg 3  #>        3.1434906        2.8745210        0.9766999  #> Coefficients of the predictors (original scale) #>                 [,1] #> Intercept  87.652763 #> X1         -5.930456 #> X2         -2.069198 #> X3         -9.607722 #> X4         -4.994568 #> X5          2.603934 #> X6         14.721801 #> X7        -20.912671 rm(list=c(\"XCornell\",\"yCornell\",\"modplsglm\"))"},{"path":"https://fbertran.github.io/plsRglm/reference/print.coef.plsRmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for plsR models — print.coef.plsRmodel","title":"Print method for plsR models — print.coef.plsRmodel","text":"function provides print method class \"coef.plsRmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.coef.plsRmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for plsR models — print.coef.plsRmodel","text":"","code":"# S3 method for class 'coef.plsRmodel' print(x, ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/print.coef.plsRmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for plsR models — print.coef.plsRmodel","text":"x object class \"coef.plsRmodel\" ... used","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.coef.plsRmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for plsR models — print.coef.plsRmodel","text":"NULL","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.coef.plsRmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print method for plsR models — print.coef.plsRmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/print.coef.plsRmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for plsR models — print.coef.plsRmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.coef.plsRmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for plsR models — print.coef.plsRmodel","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] modpls <- plsRglm(yCornell,XCornell,3,modele=\"pls\") #> ____************************************************____ #>  #> Model: pls  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  class(modpls) #> [1] \"plsRglmmodel\" print(coef(modpls)) #> Coefficients of the components #> Coeff_Comp_Reg 1 Coeff_Comp_Reg 2 Coeff_Comp_Reg 3  #>        0.4820365        0.2731127        0.1030689  #> Coefficients of the predictors (original scale) #>                 [,1] #> Intercept  92.675989 #> X1         -9.828318 #> X2         -6.960181 #> X3        -16.666239 #> X4         -8.421802 #> X5         -4.388934 #> X6         10.161304 #> X7        -34.528959 rm(list=c(\"XCornell\",\"yCornell\",\"modpls\"))"},{"path":"https://fbertran.github.io/plsRglm/reference/print.cv.plsRglmmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for plsRglm models — print.cv.plsRglmmodel","title":"Print method for plsRglm models — print.cv.plsRglmmodel","text":"function provides print method class \"cv.plsRglmmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.cv.plsRglmmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for plsRglm models — print.cv.plsRglmmodel","text":"","code":"# S3 method for class 'cv.plsRglmmodel' print(x, ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/print.cv.plsRglmmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for plsRglm models — print.cv.plsRglmmodel","text":"x object class \"cv.plsRglmmodel\" ... used","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.cv.plsRglmmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for plsRglm models — print.cv.plsRglmmodel","text":"NULL","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.cv.plsRglmmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print method for plsRglm models — print.cv.plsRglmmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparaison de la régression PLS et de la régression logistique PLS : application aux données d'allélotypage. Journal de la Société Française de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/print.cv.plsRglmmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for plsRglm models — print.cv.plsRglmmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.cv.plsRglmmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for plsRglm models — print.cv.plsRglmmodel","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] print(cv.plsRglm(object=yCornell,dataX=XCornell,nt=10,NK=1, modele=\"pls-glm-family\",family=gaussian(), verbose=FALSE)) #> Number of repeated crossvalidations: #> [1] 1 #> Number of folds for each crossvalidation: #> [1] 5 rm(list=c(\"XCornell\",\"yCornell\",\"bbb\")) #> Warning: object 'bbb' not found"},{"path":"https://fbertran.github.io/plsRglm/reference/print.cv.plsRmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for plsR models — print.cv.plsRmodel","title":"Print method for plsR models — print.cv.plsRmodel","text":"function provides print method class \"cv.plsRmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.cv.plsRmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for plsR models — print.cv.plsRmodel","text":"","code":"# S3 method for class 'cv.plsRmodel' print(x, ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/print.cv.plsRmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for plsR models — print.cv.plsRmodel","text":"x object class \"cv.plsRmodel\" ... used","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.cv.plsRmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for plsR models — print.cv.plsRmodel","text":"NULL","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.cv.plsRmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print method for plsR models — print.cv.plsRmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/print.cv.plsRmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for plsR models — print.cv.plsRmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.cv.plsRmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for plsR models — print.cv.plsRmodel","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] print(cv.plsR(object=yCornell,dataX=XCornell,nt=10,K=6, verbose=FALSE)) #> Number of repeated crossvalidations: #> [1] 1 #> Number of folds for each crossvalidation: #> [1] 6 rm(list=c(\"XCornell\",\"yCornell\",\"bbb\")) #> Warning: object 'bbb' not found"},{"path":"https://fbertran.github.io/plsRglm/reference/print.plsRglmmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for plsRglm models — print.plsRglmmodel","title":"Print method for plsRglm models — print.plsRglmmodel","text":"function provides print method class \"plsRglmmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.plsRglmmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for plsRglm models — print.plsRglmmodel","text":"","code":"# S3 method for class 'plsRglmmodel' print(x, ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/print.plsRglmmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for plsRglm models — print.plsRglmmodel","text":"x object class \"plsRglmmodel\" ... used","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.plsRglmmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for plsRglm models — print.plsRglmmodel","text":"NULL","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.plsRglmmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print method for plsRglm models — print.plsRglmmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparaison de la régression PLS et de la régression logistique PLS : application aux données d'allélotypage. Journal de la Société Française de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/print.plsRglmmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for plsRglm models — print.plsRglmmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.plsRglmmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for plsRglm models — print.plsRglmmodel","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] modplsglm <- plsRglm(yCornell,XCornell,3,modele=\"pls-glm-gaussian\") #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  class(modplsglm) #> [1] \"plsRglmmodel\" print(modplsglm) #> Number of required components: #> [1] 3 #> Number of successfully computed components: #> [1] 3 #> Coefficients: #>                 [,1] #> Intercept  87.652763 #> X1         -5.930456 #> X2         -2.069198 #> X3         -9.607722 #> X4         -4.994568 #> X5          2.603934 #> X6         14.721801 #> X7        -20.912671 #> Information criteria and Fit statistics: #>                AIC      BIC Chi2_Pearson_Y      RSS_Y      R2_Y R2_residY #> Nb_Comp_0 82.01205 82.98186     467.796667 467.796667        NA        NA #> Nb_Comp_1 53.15173 54.60645      35.742486  35.742486 0.9235940 0.9235940 #> Nb_Comp_2 31.46903 33.40866       4.966831   4.966831 0.9893825 0.9893825 #> Nb_Comp_3 31.54404 33.96857       4.230693   4.230693 0.9909561 0.9909561 #>           RSS_residY #> Nb_Comp_0 467.796667 #> Nb_Comp_1  35.742486 #> Nb_Comp_2   4.966831 #> Nb_Comp_3   4.230693 #> Model with all the required components: #>  #> Call:  glm(formula = YwotNA ~ ., family = family, data = tttrain) #>  #> Coefficients: #> (Intercept)         tt.1         tt.2         tt.3   #>     88.5833       3.1435       2.8745       0.9767   #>  #> Degrees of Freedom: 11 Total (i.e. Null);  8 Residual #> Null Deviance:\t    467.8  #> Residual Deviance: 4.231 \tAIC: 31.54 rm(list=c(\"XCornell\",\"yCornell\",\"modplsglm\"))"},{"path":"https://fbertran.github.io/plsRglm/reference/print.plsRmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for plsR models — print.plsRmodel","title":"Print method for plsR models — print.plsRmodel","text":"function provides print method class \"plsRmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.plsRmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for plsR models — print.plsRmodel","text":"","code":"# S3 method for class 'plsRmodel' print(x, ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/print.plsRmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for plsR models — print.plsRmodel","text":"x object class \"plsRmodel\" ... used","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.plsRmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for plsR models — print.plsRmodel","text":"NULL","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.plsRmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print method for plsR models — print.plsRmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparaison de la régression PLS et de la régression logistique PLS : application aux données d'allélotypage. Journal de la Société Française de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/print.plsRmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for plsR models — print.plsRmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.plsRmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for plsR models — print.plsRmodel","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] modpls <- plsRglm(yCornell,XCornell,3,modele=\"pls\") #> ____************************************************____ #>  #> Model: pls  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  class(modpls) #> [1] \"plsRglmmodel\" print(modpls) #> Number of required components: #> [1] 3 #> Number of successfully computed components: #> [1] 3 #> Coefficients: #>                 [,1] #> Intercept  92.675989 #> X1         -9.828318 #> X2         -6.960181 #> X3        -16.666239 #> X4         -8.421802 #> X5         -4.388934 #> X6         10.161304 #> X7        -34.528959 #> Information criteria and Fit statistics: #>                AIC      RSS_Y      R2_Y R2_residY RSS_residY    AIC.std #> Nb_Comp_0 82.01205 467.796667        NA        NA 11.0000000  37.010388 #> Nb_Comp_1 53.15173  35.742486 0.9235940 0.9235940  0.8404663   8.150064 #> Nb_Comp_2 41.08283  11.066606 0.9763431 0.9763431  0.2602256  -3.918831 #> Nb_Comp_3 32.06411   4.418081 0.9905556 0.9905556  0.1038889 -12.937550 #>            DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof DoF.naive #> Nb_Comp_0 1.000000    6.5212706 46.0708838 47.7893514 27.59461         1 #> Nb_Comp_1 2.740749    1.8665281  4.5699686  4.9558156 21.34020         2 #> Nb_Comp_2 5.085967    1.1825195  2.1075461  2.3949331 27.40202         3 #> Nb_Comp_3 5.121086    0.7488308  0.8467795  0.9628191 24.40842         4 #>           sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3      0.7431421  0.7363469  0.8256118   19.01033 rm(list=c(\"XCornell\",\"yCornell\",\"modpls\"))"},{"path":"https://fbertran.github.io/plsRglm/reference/print.summary.plsRglmmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for summaries of plsRglm models — print.summary.plsRglmmodel","title":"Print method for summaries of plsRglm models — print.summary.plsRglmmodel","text":"function provides print method class \"summary.plsRglmmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.summary.plsRglmmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for summaries of plsRglm models — print.summary.plsRglmmodel","text":"","code":"# S3 method for class 'summary.plsRglmmodel' print(x, ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/print.summary.plsRglmmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for summaries of plsRglm models — print.summary.plsRglmmodel","text":"x object class \"summary.plsRglmmodel\" ... used","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.summary.plsRglmmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for summaries of plsRglm models — print.summary.plsRglmmodel","text":"language call model","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.summary.plsRglmmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print method for summaries of plsRglm models — print.summary.plsRglmmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparaison de la régression PLS et de la régression logistique PLS : application aux données d'allélotypage. Journal de la Société Française de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/print.summary.plsRglmmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for summaries of plsRglm models — print.summary.plsRglmmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.summary.plsRglmmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for summaries of plsRglm models — print.summary.plsRglmmodel","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] modplsglm <- plsRglm(yCornell,XCornell,3,modele=\"pls-glm-gaussian\") #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  class(modplsglm) #> [1] \"plsRglmmodel\" print(summary(modplsglm)) #> Call: #> plsRglmmodel.default(dataX = XCornell, nt = 3, modele = \"pls-glm-gaussian\",  #>     dataY = yCornell) rm(list=c(\"XCornell\",\"yCornell\",\"modplsglm\"))"},{"path":"https://fbertran.github.io/plsRglm/reference/print.summary.plsRmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for summaries of plsR models — print.summary.plsRmodel","title":"Print method for summaries of plsR models — print.summary.plsRmodel","text":"function provides print method class \"summary.plsRmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.summary.plsRmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for summaries of plsR models — print.summary.plsRmodel","text":"","code":"# S3 method for class 'summary.plsRmodel' print(x, ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/print.summary.plsRmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for summaries of plsR models — print.summary.plsRmodel","text":"x object class \"summary.plsRmodel\" ... used","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.summary.plsRmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for summaries of plsR models — print.summary.plsRmodel","text":"language call model","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.summary.plsRmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Print method for summaries of plsR models — print.summary.plsRmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparaison de la régression PLS et de la régression logistique PLS : application aux données d'allélotypage. Journal de la Société Française de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/print.summary.plsRmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print method for summaries of plsR models — print.summary.plsRmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/print.summary.plsRmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for summaries of plsR models — print.summary.plsRmodel","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] modpls <- plsRglm(yCornell,XCornell,3,modele=\"pls\") #> ____************************************************____ #>  #> Model: pls  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  class(modpls) #> [1] \"plsRglmmodel\" print(summary(modpls)) #> Call: #> plsRglmmodel.default(dataX = XCornell, nt = 3, modele = \"pls\",  #>     dataY = yCornell) rm(list=c(\"XCornell\",\"yCornell\",\"modpls\"))"},{"path":"https://fbertran.github.io/plsRglm/reference/signpred.html","id":null,"dir":"Reference","previous_headings":"","what":"Graphical assessment of the stability of selected variables — signpred","title":"Graphical assessment of the stability of selected variables — signpred","text":"fonctions plots, model, ","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/signpred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graphical assessment of the stability of selected variables — signpred","text":"","code":"signpred(   matbin,   pred.lablength = max(sapply(rownames(matbin), nchar)),   labsize = 1,   plotsize = 12 )"},{"path":"https://fbertran.github.io/plsRglm/reference/signpred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graphical assessment of the stability of selected variables — signpred","text":"matbin Matrix 0 1 entries. row per predictor column every model. 0 means predictor significant model 1 , contrary, significant. pred.lablength Maximum length predictors labels. Defaults full label length. labsize Size predictors labels. plotsize Global size graph.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/signpred.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Graphical assessment of the stability of selected variables — signpred","text":"plot window.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/signpred.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Graphical assessment of the stability of selected variables — signpred","text":"function based visweb function bipartite package.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/signpred.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Graphical assessment of the stability of selected variables — signpred","text":"Vazquez, P.D., Chacoff, N.,P. Cagnolo, L. (2009) Evaluating multiple determinants structure plant-animal mutualistic networks. Ecology, 90:2039-2046.","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/signpred.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Graphical assessment of the stability of selected variables — signpred","text":"Bernd Gruber minor modifications Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/signpred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Graphical assessment of the stability of selected variables — signpred","text":"","code":"signpred(matrix(rbinom(160,1,.2),ncol=8,dimnames=list(as.character(1:20),as.character(1:8))))"},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX.html","id":null,"dir":"Reference","previous_headings":"","what":"Data generating function for univariate plsR models — simul_data_UniYX","title":"Data generating function for univariate plsR models — simul_data_UniYX","text":"function generates single univariate response value \\(Y\\) vector explanatory variables \\((X_1,\\ldots,X_{totdim})\\) drawn model given number latent components.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data generating function for univariate plsR models — simul_data_UniYX","text":"","code":"simul_data_UniYX(totdim, ncomp)"},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data generating function for univariate plsR models — simul_data_UniYX","text":"totdim Number columns X vector (ncomp hardware limits) ncomp Number latent components model (2 6)","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data generating function for univariate plsR models — simul_data_UniYX","text":"vector \\((Y,X_1,\\ldots,X_{totdim})\\)","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data generating function for univariate plsR models — simul_data_UniYX","text":"function combined replicate function give rise larger dataset. algorithm used port one described article Li multivariate generalization algorithm Naes Martens.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data generating function for univariate plsR models — simul_data_UniYX","text":"T. Naes, H. Martens, Comparison prediction methods multicollinear data, Commun. Stat., Simul. 14 (1985) 545-576. Morris, Elaine B. Martin, Model selection partial least squares regression, Chemometrics Intelligent Laboratory Systems 64 (2002) 79-89, doi:10.1016/S0169-7439(02)00051-5 .","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Data generating function for univariate plsR models — simul_data_UniYX","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data generating function for univariate plsR models — simul_data_UniYX","text":"","code":"simul_data_UniYX(20,6)                           #>           Y          X1          X2          X3          X4          X5  #>  5.37208159  2.61772471  1.98015086  2.73966905 -0.65033218  2.80462160  #>          X6          X7          X8          X9         X10         X11  #>  2.56459761  2.97305937 -0.07073625  0.09994084  1.52460131  1.87522259  #>         X12         X13         X14         X15         X16         X17  #>  1.47017902  2.54432359  3.69661409  0.10830547  1.51483474  1.89846468  #>         X18         X19         X20  #>  1.46503159  2.55933333  3.67439144   # \\donttest{ dimX <- 6 Astar <- 2 simul_data_UniYX(dimX,Astar) #>          Y         X1         X2         X3         X4         X5         X6  #> -13.907393   1.960788   1.972129 -12.548192   1.981423   1.972791 -12.529984  (dataAstar2 <- data.frame(t(replicate(50,simul_data_UniYX(dimX,Astar))))) #>              Y           X1          X2          X3           X4           X5 #> 1    3.8835021  -0.86101898  -0.8585292   3.5667795  -0.86396799  -0.85963034 #> 2    2.1036123  -4.23745332  -4.2451625   2.6827753  -4.23773593  -4.24655183 #> 3   -7.6334554   1.63488040   1.6198754  -7.0916115   1.62034004   1.62234791 #> 4    5.2684942   6.02266762   6.0035262   3.4444054   6.01491653   6.03774662 #> 5    5.3073841   3.43863801   3.4290896   3.8601260   3.44318025   3.42863295 #> 6   14.1292800   9.39403422   9.4096588  10.2487855   9.39540352   9.39415553 #> 7  -12.7078565  -4.99976673  -5.0027713 -10.0752803  -4.99043747  -4.99635204 #> 8   -8.3401731   2.64693430   2.6431057  -8.1373183   2.63832587   2.63936376 #> 9    2.6521257  -0.09433747  -0.1078118   2.2133681  -0.08936865  -0.09518355 #> 10   8.6763013  -9.88098128  -9.9042742  10.0556337  -9.89152604  -9.87553203 #> 11  -0.9632626   9.58474352   9.5887055  -3.2305931   9.60993068   9.56627937 #> 12 -16.8184852  -0.94634924  -0.9526492 -14.4230444  -0.93679857  -0.96541380 #> 13   1.0199900  -5.19862080  -5.1936552   2.1500019  -5.19912401  -5.19056624 #> 14  17.8291114  -1.34479290  -1.3492358  15.9098476  -1.34808293  -1.33920119 #> 15  -4.6104361  -6.71956191  -6.7168387  -2.2519049  -6.69500066  -6.71863827 #> 16   2.0552492   1.91474298   1.9273525   1.3234751   1.92965979   1.91400875 #> 17  -1.4873593  -0.32223625  -0.3259767  -1.1575482  -0.30600170  -0.30726717 #> 18  -5.0542769  -7.09269213  -7.1057334  -2.7318341  -7.09574924  -7.09831930 #> 19  11.2761574   3.47220734   3.4847111   9.0669754   3.47792371   3.48452409 #> 20 -11.6565941   3.09511377   3.1179164 -10.8131318   3.11844854   3.10927176 #> 21   9.3498807   7.58249010   7.5926645   6.3069149   7.58835745   7.58460974 #> 22  -2.8393309   4.40729402   4.4115625  -3.5618869   4.42013211   4.42532752 #> 23 -10.6205438   7.71139729   7.6919160 -10.9908654   7.70183762   7.70002745 #> 24 -18.4918386  -8.17862749  -8.1543959 -14.3323704  -8.17335733  -8.19547554 #> 25  -4.1456204   4.67818616   4.6700780  -4.9050637   4.65602956   4.67854494 #> 26   4.6904730  -1.20983931  -1.1910112   4.5526713  -1.18465815  -1.18363840 #> 27  -1.3481296  -5.20637717  -5.2207911   0.1423457  -5.19546166  -5.20366869 #> 28  -6.9649421 -10.51188564 -10.5142038  -3.5120759 -10.51934024 -10.53309255 #> 29  12.0024773   5.22529539   5.2446828   9.2860329   5.23587640   5.23076541 #> 30   1.0779628   9.01658176   9.0175611  -1.2955567   9.02725592   9.00860771 #> 31   1.0493864   1.05689427   1.0253789   0.7514018   1.02966186   1.04720388 #> 32  -5.0395468  -6.59996503  -6.5995401  -2.7773355  -6.59466791  -6.59926102 #> 33 -17.3292878  -6.74167486  -6.7699467 -13.3821982  -6.73789684  -6.73729467 #> 34  -5.5137724   5.51032179   5.5052749  -6.2023025   5.50789402   5.52668350 #> 35 -12.4978407  -1.49623562  -1.5004234 -10.7332391  -1.52810861  -1.52425007 #> 36  -3.8843655  -0.70012435  -0.7107067  -3.2533373  -0.70248578  -0.71553083 #> 37  -5.6005114   5.64539111   5.6497678  -6.1774716   5.64850876   5.64455227 #> 38  -2.6804103   2.42087271   2.4032030  -2.9265460   2.41376446   2.41339274 #> 39  11.6112195   1.47025923   1.4833565   9.9658942   1.48251834   1.47975745 #> 40   2.0287946  -2.78573085  -2.7772632   2.4840439  -2.78562442  -2.78234378 #> 41  -5.1830779  -0.70929950  -0.7211025  -4.3696184  -0.72363317  -0.73659370 #> 42 -15.3210544   0.95543343   0.9476569 -13.5879601   0.95379695   0.95064553 #> 43  -5.1145830   1.49915057   1.4852571  -4.6896349   1.50728777   1.48331294 #> 44   4.1997361  -2.68052500  -2.6882637   4.2251419  -2.68428888  -2.68853188 #> 45   8.6108449   1.53618973   1.5237747   7.2044338   1.50836988   1.52866652 #> 46  -5.0628676   2.00435225   1.9992170  -4.8958960   2.01722943   2.00301714 #> 47 -16.4823624  -6.30269172  -6.3001770 -12.8443507  -6.30296475  -6.29372646 #> 48 -16.5945227 -13.86088554 -13.8849554 -11.0957969 -13.87212632 -13.87673512 #> 49   6.1745872  -1.38215770  -1.3846519   5.7810565  -1.37898207  -1.39402422 #> 50  -7.9239998  -1.35914913  -1.3883223  -6.7668870  -1.38381653  -1.36855332 #>             X6 #> 1    3.5648792 #> 2    2.6722453 #> 3   -7.0861820 #> 4    3.4467972 #> 5    3.8727228 #> 6   10.2741243 #> 7  -10.0948566 #> 8   -8.1367866 #> 9    2.2250447 #> 10  10.0459464 #> 11  -3.2237765 #> 12 -14.4261306 #> 13   2.1469067 #> 14  15.8915027 #> 15  -2.2555525 #> 16   1.3162244 #> 17  -1.1894906 #> 18  -2.7349873 #> 19   9.0786301 #> 20 -10.8211611 #> 21   6.3180235 #> 22  -3.5412934 #> 23 -11.0057288 #> 24 -14.3207732 #> 25  -4.9146715 #> 26   4.5492355 #> 27   0.1613773 #> 28  -3.5319529 #> 29   9.3058474 #> 30  -1.2829327 #> 31   0.7383270 #> 32  -2.7550041 #> 33 -13.3664442 #> 34  -6.2054366 #> 35 -10.6931173 #> 36  -3.2291507 #> 37  -6.1657026 #> 38  -2.9261940 #> 39   9.9363752 #> 40   2.4753093 #> 41  -4.3433148 #> 42 -13.5772263 #> 43  -4.6896462 #> 44   4.2330389 #> 45   7.2106320 #> 46  -4.8978538 #> 47 -12.8548489 #> 48 -11.1004403 #> 49   5.7849515 #> 50  -6.7647212 cvtable(summary(cv.plsR(Y~.,data=dataAstar2,5,NK=100, verbose=FALSE))) #> ____************************************************____ #> Error in eval(mf, parent.frame()): object 'dataAstar2' not found  dimX <- 6 Astar <- 3 simul_data_UniYX(dimX,Astar) #>        Y       X1       X2       X3       X4       X5       X6  #> 5.147520 1.513335 4.440176 2.109769 1.526822 4.455568 2.118202  (dataAstar3 <- data.frame(t(replicate(50,simul_data_UniYX(dimX,Astar))))) #>               Y          X1           X2           X3          X4            X5 #> 1    1.61184288  -3.1453515   2.67245432  -1.38751871  -3.1335055  2.680796e+00 #> 2   -1.30671233   6.0789699  -0.01409086   1.05812766   6.0615349  5.139614e-05 #> 3    3.86404629   7.5471695   4.05847595   3.51592392   7.5450722  4.066135e+00 #> 4   -5.71544893   4.4169696  -2.06311192  -2.04103648   4.4280102 -2.057402e+00 #> 5   10.42782288   1.0612895  -2.39586723  11.10991373   1.0780188 -2.375335e+00 #> 6   15.74690681   3.5686973  10.31033359   8.89112771   3.5510225  1.032373e+01 #> 7   -6.25234893   0.7998805  -3.45696908  -2.74371941   0.8208916 -3.471445e+00 #> 8   15.50724918 -10.6852600  -0.88442192   9.76954475 -10.7019801 -9.106402e-01 #> 9    3.32925053   0.3733313  -0.94292185   3.71406374   0.3819483 -9.325856e-01 #> 10   9.16838763 -10.7052609  -5.89006748   7.67509096 -10.6965845 -5.883337e+00 #> 11 -21.22080041  -1.3537709  -7.17443071 -14.58477057  -1.3770165 -7.189509e+00 #> 12  -7.13605888  -2.0240266   0.13805329  -7.19593050  -2.0363195  1.543217e-01 #> 13   0.32544237   2.5910330   1.11652908   0.41826840   2.5940457  1.100608e+00 #> 14  -4.01863392   5.5147199   4.67585699  -4.23649047   5.5235122  4.652382e+00 #> 15   3.41492208   2.8135642   8.82793641  -1.65962845   2.8282798  8.828523e+00 #> 16  -2.71240209  -0.1181444   2.08747214  -3.85839105  -0.1222899  2.092057e+00 #> 17   5.64165464  -3.8922316  -3.56902390   5.60484620  -3.8951310 -3.557819e+00 #> 18  -8.74803187 -16.6573380 -14.86368112  -4.62858551 -16.6479412 -1.487390e+01 #> 19  16.64326611  -5.1423132   4.51826085   9.80288345  -5.1565371  4.539871e+00 #> 20   4.83944696  -5.4797383   4.98217762  -0.82966162  -5.4758555  4.986784e+00 #> 21  -2.37452366  -1.5272576  -6.69083286   1.47741360  -1.5264493 -6.678615e+00 #> 22  -0.46743870  -6.0470156  -4.74361450  -0.08959611  -6.0812672 -4.751834e+00 #> 23  -0.80190884   3.5343239   4.03116230  -2.04418975   3.5333668  4.019366e+00 #> 24 -15.11309472  -2.5697972  -2.13676919 -13.05862183  -2.5661690 -2.126380e+00 #> 25   7.73080317  -1.6197055   3.49750323   3.95377848  -1.6292029  3.496756e+00 #> 26   6.89997310 -14.7632822  -1.01305798   0.94643873 -14.7482680 -1.008190e+00 #> 27   4.33649122   2.2461857  -0.78315855   4.92004196   2.2632953 -7.794394e-01 #> 28  14.29956345  -3.1933515  -3.56095518  13.62003606  -3.1778156 -3.557107e+00 #> 29   0.23645067   0.3290622  -1.05430729   1.08159722   0.3289938 -1.044840e+00 #> 30  -0.41725081 -18.1209777 -12.04381295   0.03811136 -18.1039799 -1.204332e+01 #> 31 -11.91781638   2.4010988  -9.96809706  -3.23666283   2.4030743 -9.982433e+00 #> 32  -0.03276720   5.8873117   1.76116090   1.10291100   5.8850760  1.769101e+00 #> 33  -1.84971837  -0.7848941   1.40287358  -2.92722243  -0.7931282  1.393646e+00 #> 34   2.12820592 -10.0175419  -7.91879427   2.79155658 -10.0450615 -7.919383e+00 #> 35   7.56748431   5.9218802   8.78864118   3.59299874   5.9060197  8.769332e+00 #> 36  16.09577645   5.4569825   5.32502527  12.78369177   5.4296274  5.345703e+00 #> 37   0.19097685   9.1880168   6.89820547  -0.41668056   9.1931464  6.893767e+00 #> 38  -1.62614423  17.7220363   8.47289389  -0.04774728  17.7168731  8.475962e+00 #> 39 -10.74021974  -0.2053579  -0.13773318  -9.32781957  -0.2033117 -1.446842e-01 #> 40   3.06197407   1.5532651  -3.70648028   5.43621067   1.5366369 -3.709812e+00 #> 41   0.06081361   3.6684504   4.93578748  -1.67370886   3.6816702  4.896537e+00 #> 42   1.72664479  -1.6221266   0.21791156   0.79285769  -1.6082344  2.004612e-01 #> 43 -12.77548455   5.7172520  -6.49999945  -4.97376634   5.6843545 -6.511580e+00 #> 44   7.87577686   4.4654945   2.02644763   7.49516136   4.4560643  2.017758e+00 #> 45  -0.13041315  -5.1855721   8.36831532  -7.40532668  -5.1898595  8.383204e+00 #> 46  -5.35516241   7.0032044   1.89287812  -3.09609157   7.0132003  1.900229e+00 #> 47   7.51800821   0.8560249   5.63294764   3.39519055   0.8172378  5.641474e+00 #> 48  12.07280412 -20.0492593  -4.94393234   5.80418880 -20.0518943 -4.915580e+00 #> 49  -2.23649254   1.0247076   4.79627403  -4.48618152   1.0307158  4.791178e+00 #> 50  20.20569168   1.4178214  10.11621374  11.82872431   1.4087079  1.013776e+01 #>              X6 #> 1   -1.40858378 #> 2    1.07207982 #> 3    3.50041869 #> 4   -2.06255993 #> 5   11.09622926 #> 6    8.89227423 #> 7   -2.75335931 #> 8    9.78326885 #> 9    3.70934172 #> 10   7.69532509 #> 11 -14.57035737 #> 12  -7.20389554 #> 13   0.42151221 #> 14  -4.22599353 #> 15  -1.64441264 #> 16  -3.84831000 #> 17   5.60499342 #> 18  -4.62487007 #> 19   9.81102871 #> 20  -0.83920066 #> 21   1.50512520 #> 22  -0.08125450 #> 23  -2.02903098 #> 24 -13.05831424 #> 25   3.95899158 #> 26   0.93761627 #> 27   4.93596583 #> 28  13.60030540 #> 29   1.07604548 #> 30   0.03042669 #> 31  -3.25687586 #> 32   1.08729402 #> 33  -2.95200753 #> 34   2.79537222 #> 35   3.57952657 #> 36  12.79662174 #> 37  -0.41224688 #> 38  -0.03645503 #> 39  -9.31912428 #> 40   5.40963671 #> 41  -1.69099017 #> 42   0.77923864 #> 43  -5.00067229 #> 44   7.49760779 #> 45  -7.40554767 #> 46  -3.09519023 #> 47   3.37952371 #> 48   5.80402100 #> 49  -4.46498290 #> 50  11.84522252 cvtable(summary(cv.plsR(Y~.,data=dataAstar3,5,NK=100, verbose=FALSE))) #> ____************************************************____ #> Error in eval(mf, parent.frame()): object 'dataAstar3' not found  dimX <- 6 Astar <- 4 simul_data_UniYX(dimX,Astar) #>          Y         X1         X2         X3         X4         X5         X6  #>  4.1025014 -7.3463924 -1.8833438  2.7813756 -5.8684888 -0.4107439  4.2461270  (dataAstar4 <- data.frame(t(replicate(50,simul_data_UniYX(dimX,Astar))))) #>                Y           X1           X2          X3           X4 #> 1    0.966031019   4.50068200  -1.94061431   3.7402178   9.53705369 #> 2    3.495971538   8.02106104   3.22040249   4.8583732   4.71601175 #> 3   -1.670187656  -2.85123295  -1.28044149  -2.0228122  -7.45368695 #> 4    6.776411670  -1.65313773   2.03237970   4.9211335  -0.66178490 #> 5   -2.837133817   3.75149740   0.74930417  -2.1141171   6.76443657 #> 6   -3.090030903   1.85817645 -11.75887543   4.8730087  -0.73794398 #> 7    2.051109713   4.77718821   8.02323831  -0.9316928   0.03708379 #> 8    7.389664461  -4.75863834   3.69398209   3.1939522  -8.04082347 #> 9    9.627635282   3.32824120   1.33571275  10.0884911  -1.06203683 #> 10  -0.226408178   0.09123474   9.69438503  -6.0834229   1.83400953 #> 11  -1.896880639  -3.04452889  -3.01264925  -1.0823789  -2.26983188 #> 12  -2.232002377  -2.84021073   4.96370258  -6.5183381  -0.63463906 #> 13   4.361903283  -3.93227840  -3.10445698   5.0062563  -5.09856165 #> 14 -15.151074140  -2.07063564  -3.06376273 -14.5004611   0.86600345 #> 15  -5.150118268   0.46972134  -1.91339687  -3.6978604   2.14253078 #> 16   1.821468706  -5.85561856  -3.58035750   2.1570105   0.96659778 #> 17   5.354033787  14.10975378  15.55440141   1.2229256   9.94728332 #> 18  13.346756685  -6.37944723   3.62587755   8.8088506  -7.23265418 #> 19  -1.876444141  -4.08136765  -4.04430045  -1.1081081  -8.00201728 #> 20   0.286432025   5.25001628  -3.77857011   4.3487252   1.85623546 #> 21  -4.893634969  -6.84102266 -10.67132351  -0.9226245   0.88802679 #> 22 -17.479906863   0.86397862 -14.61131427  -8.1053448   5.28912109 #> 23  -5.970519904  -9.55824956  -8.70219368  -4.2830267 -13.79289519 #> 24  11.830100673  -4.56473566   5.88461719   6.4419748  -6.09922013 #> 25 -13.108851286  -4.36255329  -2.23245896 -13.4950822  -1.69063431 #> 26   0.766468795   4.93581420   2.34223122   0.8549509   4.29308605 #> 27 -13.445290428 -10.39174893  -8.73274916 -12.3041350 -10.19909712 #> 28  -6.887919309  -3.08610363  -5.74355344  -4.5215467  -5.27074432 #> 29   4.018200137   3.50896470  -3.30077486   7.4055212   2.49665829 #> 30   3.300228900   2.66367169   5.63768688   0.6643811  -2.55645973 #> 31  -5.116920292  -1.00378799  -0.05558991  -5.2346620   2.44113148 #> 32  -4.219609448   4.00960831   9.51248664  -8.6100331   2.04055413 #> 33  16.359444387   6.00761376   9.07118039  13.2718654   3.92092304 #> 34  15.228556033   0.87004344   8.09345624  10.7638992  -0.19726769 #> 35  -6.948448988  -7.15303402 -13.36909721  -1.7739551  -4.92127340 #> 36   0.408994809  -4.51098078   0.91030664  -2.0332454  -6.50986719 #> 37   0.744618591   0.04720849  -6.47685893   4.9257665   2.85202746 #> 38  -3.241210024  -9.21759590  -4.76961090  -3.9257373  -3.82689540 #> 39  11.114421886  -5.08209953  -2.93155309  11.2797439  -2.75695757 #> 40   6.550466610   5.00269866   8.22265149   3.4478487   2.46121647 #> 41  -4.617573850  -0.27947483  -1.30340522  -3.9362930  -3.29092805 #> 42  -0.006716945   5.90653668   0.38579251   1.9457905   6.15568801 #> 43  -9.981692586  -3.05601532   0.12834889 -11.3388541   4.36133430 #> 44  -2.430963824   7.42050044   8.61457109  -4.9584686   3.46372229 #> 45  12.471468862   8.19222227   1.03879541  15.0466501   7.95701556 #> 46   0.100983251  12.01505990   6.63291900   0.6671434   7.56202524 #> 47   4.990012231  -4.86603505   1.27598106   2.7874906   0.96174553 #> 48   5.060678322  -0.67182060  -0.36544881   4.8536096  -0.83716419 #> 49  13.599742755   6.99960766   6.85180475  12.1439564   7.16229107 #> 50  -3.262443935   7.73136191   3.36980553  -2.5844432   8.23744657 #>              X5           X6 #> 1    3.10546507   8.75943335 #> 2   -0.05796514   1.54075568 #> 3   -5.86028068  -6.59672126 #> 4    3.03007345   5.90012114 #> 5    3.77272826   0.89945667 #> 6  -14.36149135   2.25322462 #> 7    3.30444318  -5.67128645 #> 8    0.41780007  -0.08179084 #> 9   -3.03290303   5.69245773 #> 10  11.44183555  -4.31039378 #> 11  -2.23279419  -0.30564154 #> 12   7.16040442  -4.32085247 #> 13  -4.25593043   3.84711146 #> 14  -0.09342710 -11.55567798 #> 15  -0.23392278  -1.99863219 #> 16   3.25125657   9.01570694 #> 17  11.41630450  -2.91349902 #> 18   2.76513719   7.98415293 #> 19  -7.96694145  -5.01846735 #> 20  -7.15630305   0.95161804 #> 21  -2.92758431   6.82304833 #> 22 -10.18549421  -3.71102204 #> 23 -12.88557036  -8.49774958 #> 24   4.39218902   4.94449344 #> 25   0.40517274 -10.85014294 #> 26   1.68290564   0.23176969 #> 27  -8.55642976 -12.12425518 #> 28  -7.95598944  -6.71163939 #> 29  -4.31376896   6.39878120 #> 30   0.41085986  -4.57152587 #> 31   3.42085930  -1.80381199 #> 32   7.54634697 -10.58679208 #> 33   6.98597630  11.20854621 #> 34   7.00303727   9.66707478 #> 35 -11.08549523   0.49753277 #> 36  -1.11326943  -4.02839306 #> 37  -3.67568665   7.75985653 #> 38   0.66765200   1.47913194 #> 39  -0.58458609  13.62261220 #> 40   5.65703379   0.89087367 #> 41  -4.31533175  -6.93089191 #> 42   0.64110556   2.20665903 #> 43   7.56560199  -3.90385110 #> 44   4.64156162  -8.93464409 #> 45   0.81156501  14.80883364 #> 46   2.16760214  -3.81518298 #> 47   7.11068531   8.63438251 #> 48  -0.55846990   4.66900855 #> 49   6.99317228  12.29462297 #> 50   3.84947115  -2.09604189 cvtable(summary(cv.plsR(Y~.,data=dataAstar4,5,NK=100, verbose=FALSE))) #> ____************************************************____ #> Error in eval(mf, parent.frame()): object 'dataAstar4' not found  rm(list=c(\"dimX\",\"Astar\",\"dataAstar2\",\"dataAstar3\",\"dataAstar4\")) # }"},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX_binom.html","id":null,"dir":"Reference","previous_headings":"","what":"Data generating function for univariate binomial plsR models — simul_data_UniYX_binom","title":"Data generating function for univariate binomial plsR models — simul_data_UniYX_binom","text":"function generates single univariate binomial response value \\(Y\\) vector explanatory variables \\((X_1,\\ldots,X_{totdim})\\) drawn model given number latent components.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX_binom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data generating function for univariate binomial plsR models — simul_data_UniYX_binom","text":"","code":"simul_data_UniYX_binom(totdim, ncomp, link = \"logit\", offset = 0)"},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX_binom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data generating function for univariate binomial plsR models — simul_data_UniYX_binom","text":"totdim Number columns X vector (ncomp hardware limits) ncomp Number latent components model (2 6) link Character specification link function mean model (mu). Currently, \"logit\", \"probit\", \"cloglog\", \"cauchit\", \"log\", \"loglog\" supported. Alternatively, object class \"link-glm\" can supplied. offset Offset linear scale","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX_binom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data generating function for univariate binomial plsR models — simul_data_UniYX_binom","text":"vector \\((Y,X_1,\\ldots,X_{totdim})\\)","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX_binom.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data generating function for univariate binomial plsR models — simul_data_UniYX_binom","text":"function combined replicate function give rise larger dataset. algorithm used modification port one described article Li multivariate generalization algorithm Naes Martens.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX_binom.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data generating function for univariate binomial plsR models — simul_data_UniYX_binom","text":"T. Naes, H. Martens, Comparison prediction methods multicollinear data, Commun. Stat., Simul. 14 (1985) 545-576. Morris, Elaine B. Martin, Model selection partial least squares regression, Chemometrics Intelligent Laboratory Systems 64 (2002), 79-89, doi:10.1016/S0169-7439(02)00051-5 .","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX_binom.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Data generating function for univariate binomial plsR models — simul_data_UniYX_binom","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_UniYX_binom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data generating function for univariate binomial plsR models — simul_data_UniYX_binom","text":"","code":"# \\donttest{ layout(matrix(1:6,nrow=2)) # logit link hist(t(replicate(100,simul_data_UniYX_binom(4,4)))[,1]) # probit link hist(t(replicate(100,simul_data_UniYX_binom(4,4,link=\"probit\")))[,1]) # cloglog link hist(t(replicate(100,simul_data_UniYX_binom(4,4,link=\"cloglog\")))[,1]) # cauchit link hist(t(replicate(100,simul_data_UniYX_binom(4,4,link=\"cauchit\")))[,1]) # loglog link hist(t(replicate(100,simul_data_UniYX_binom(4,4,link=\"loglog\")))[,1]) # log link hist(t(replicate(100,simul_data_UniYX_binom(4,4,link=\"log\")))[,1]) #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced  layout(1)   layout(matrix(1:6,nrow=2)) # logit link hist(t(replicate(100,simul_data_UniYX_binom(4,4,offset=5)))[,1]) # probit link hist(t(replicate(100,simul_data_UniYX_binom(4,4,link=\"probit\",offset=5)))[,1]) # cloglog link hist(t(replicate(100,simul_data_UniYX_binom(4,4,link=\"cloglog\",offset=5)))[,1]) # cauchit link hist(t(replicate(100,simul_data_UniYX_binom(4,4,link=\"cauchit\",offset=5)))[,1]) # loglog link hist(t(replicate(100,simul_data_UniYX_binom(4,4,link=\"loglog\",offset=5)))[,1]) # log link hist(t(replicate(100,simul_data_UniYX_binom(4,4,link=\"log\",offset=5)))[,1]) #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced  layout(1)   layout(matrix(1:6,nrow=2)) # logit link hist(t(replicate(100,simul_data_UniYX_binom(4,4,offset=-5)))[,1]) # probit link hist(t(replicate(100,simul_data_UniYX_binom(4,4,link=\"probit\",offset=-5)))[,1]) # cloglog link hist(t(replicate(100,simul_data_UniYX_binom(4,4,link=\"cloglog\",offset=-5)))[,1]) # cauchit link hist(t(replicate(100,simul_data_UniYX_binom(4,4,link=\"cauchit\",offset=-5)))[,1]) # loglog link hist(t(replicate(100,simul_data_UniYX_binom(4,4,link=\"loglog\",offset=-5)))[,1]) # log link hist(t(replicate(100,simul_data_UniYX_binom(4,4,link=\"log\",offset=-5)))[,1]) #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced #> Warning: NAs produced  layout(1) # }"},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_YX.html","id":null,"dir":"Reference","previous_headings":"","what":"Data generating function for multivariate plsR models — simul_data_YX","title":"Data generating function for multivariate plsR models — simul_data_YX","text":"function generates single multivariate response value \\(\\boldsymbol{Y}\\) vector explinatory variables \\((X_1,\\ldots,X_{totdim})\\) drawn model given number latent components.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_YX.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data generating function for multivariate plsR models — simul_data_YX","text":"","code":"simul_data_YX(totdim, ncomp)"},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_YX.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data generating function for multivariate plsR models — simul_data_YX","text":"totdim Number column X vector (ncomp hardware limits) ncomp Number latent components model (2 6)","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_YX.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data generating function for multivariate plsR models — simul_data_YX","text":"vector \\((Y_1,\\ldots,Y_r,X_1,\\ldots,X_{totdim})\\)","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_YX.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data generating function for multivariate plsR models — simul_data_YX","text":"function combined replicate function give rise larger dataset. algorithm used port one described article Li multivariate generalization algorithm Naes Martens.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_YX.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Data generating function for multivariate plsR models — simul_data_YX","text":"value \\(r\\) depends value ncomp :","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_YX.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data generating function for multivariate plsR models — simul_data_YX","text":"T. Naes, H. Martens, Comparison prediction methods multicollinear data, Commun. Stat., Simul. 14 (1985) 545-576. Morris, Elaine B. Martin, Model selection partial least squares regression, Chemometrics Intelligent Laboratory Systems 64 (2002) 79-89, doi:10.1016/S0169-7439(02)00051-5 .","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_YX.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Data generating function for multivariate plsR models — simul_data_YX","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_YX.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data generating function for multivariate plsR models — simul_data_YX","text":"","code":"simul_data_YX(20,6)                           #>         Y 1         Y 2         Y 3         Y 4          X1          X2  #> -9.45176297 -9.47163207 -9.45084107 -9.45273015 -4.62074234  1.55320742  #>          X3          X4          X5          X6          X7          X8  #>  0.60935296  1.13612242 -4.91720188  0.58412558  0.32945918  0.17914794  #>          X9         X10         X11         X12         X13         X14  #> -0.06716894 -2.82980256 -3.25922979  2.71312870  0.63529298 -1.03698105  #>         X15         X16         X17         X18         X19         X20  #> -0.08041950 -2.83857700 -3.24731589  2.72213250  0.61117743 -1.05277089   # \\donttest{ if(require(plsdepot)){ dimX <- 6 Astar <- 2 (dataAstar2 <- t(replicate(50,simul_data_YX(dimX,Astar)))) library(plsdepot) resAstar2 <- plsreg2(dataAstar2[,4:9],dataAstar2[,1:3],comps=5) resAstar2$Q2 resAstar2$Q2[,4]>0.0975  dimX <- 6 Astar <- 3 (dataAstar3 <- t(replicate(50,simul_data_YX(dimX,Astar)))) library(plsdepot) resAstar3 <- plsreg2(dataAstar3[,4:9],dataAstar3[,1:3],comps=5) resAstar3$Q2 resAstar3$Q2[,4]>0.0975  dimX <- 6 Astar <- 4 (dataAstar4 <- t(replicate(50,simul_data_YX(dimX,Astar)))) library(plsdepot) resAstar4 <- plsreg2(dataAstar4[,5:10],dataAstar4[,1:4],comps=5) resAstar4$Q2 resAstar4$Q2[,5]>0.0975  rm(list=c(\"dimX\",\"Astar\")) } #> Loading required package: plsdepot #> Warning: there is no package called ‘plsdepot’ # }"},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_complete.html","id":null,"dir":"Reference","previous_headings":"","what":"Data generating detailed process for multivariate plsR models — simul_data_complete","title":"Data generating detailed process for multivariate plsR models — simul_data_complete","text":"function generates single multivariate response value \\(\\boldsymbol{Y}\\) vector explinatory variables \\((X_1,\\ldots,X_{totdim})\\) drawn model given number latent components.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_complete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data generating detailed process for multivariate plsR models — simul_data_complete","text":"","code":"simul_data_complete(totdim, ncomp)"},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_complete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data generating detailed process for multivariate plsR models — simul_data_complete","text":"totdim Number columns X vector (ncomp hardware limits) ncomp Number latent components model (2 6)","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_complete.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data generating detailed process for multivariate plsR models — simul_data_complete","text":"simX Vector explanatory variables HH Dimension response \\(\\boldsymbol{Y}\\) eta See Li et al. r See Li et al. epsilon See Li et al. ksi See Li et al. f See Li et al. z See Li et al. Y See Li et al.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_complete.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data generating detailed process for multivariate plsR models — simul_data_complete","text":"function combined replicate function give rise larger dataset. algorithm used port one described article Li multivariate generalization algorithm Naes Martens.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_complete.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Data generating detailed process for multivariate plsR models — simul_data_complete","text":"value \\(r\\) depends value ncomp :","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_complete.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data generating detailed process for multivariate plsR models — simul_data_complete","text":"T. Naes, H. Martens, Comparison prediction methods multicollinear data, Commun. Stat., Simul. 14 (1985) 545-576. Morris, Elaine B. Martin, Model selection partial least squares regression, Chemometrics Intelligent Laboratory Systems 64 (2002) 79-89, doi:10.1016/S0169-7439(02)00051-5 .","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_complete.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Data generating detailed process for multivariate plsR models — simul_data_complete","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/simul_data_complete.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data generating detailed process for multivariate plsR models — simul_data_complete","text":"","code":"simul_data_complete(20,6)                           #> $simX #>           [,1]      [,2]      [,3]     [,4]       [,5]      [,6]     [,7] #> [1,] -1.712616 -2.708999 0.5089005 1.805394 -0.5960683 -2.198365 1.651388 #>          [,8]     [,9]     [,10]    [,11]    [,12]     [,13]      [,14] #> [1,] 2.335166 2.484493 -1.239708 0.119169 0.616752 -2.469253 -0.2062345 #>         [,15]     [,16]     [,17]     [,18]     [,19]     [,20] #> [1,] 2.483004 -1.225264 0.1188616 0.5938215 -2.460134 -0.195174 #>  #> $HH #> [1] 4 #>  #> $eta #>      eta61 eta62 eta63 eta64 eta65 eta66 #> [1,]   0.5   0.5   0.5   0.5   0.5   0.5 #> [2,]   0.5   0.5   0.5   0.5   0.5   0.5 #> [3,]   0.5   0.5   0.5   0.5   0.5   0.5 #> [4,]   0.5   0.5   0.5   0.5   0.5   0.5 #>  #> $r #> [1] -0.5181719  0.2851329 -6.7860253  2.5495065 -1.5436408 -0.6119904 #>  #> $epsilon #>  [1]  0.0190179819  0.0092237542 -0.0123040978 -0.0095696117  0.0044599032 #>  [6]  0.0007421335 -0.0009226144  0.0010871323  0.0125932698 -0.0125990862 #> [11]  0.0012991337  0.0035771458  0.0045898592 -0.0090410580  0.0111044805 #> [16]  0.0018442834  0.0009917598 -0.0193532713  0.0137086949  0.0020194035 #>  #> $ksi #>            ksi1       ksi2  ksi3       ksi4       ksi5  ksi6 #>  [1,] 0.2236068  0.2672612  0.25  0.2236068  0.2672612  0.25 #>  [2,] 0.2236068 -0.2672612  0.25 -0.2236068  0.2672612 -0.25 #>  [3,] 0.2236068  0.2672612 -0.25 -0.2236068  0.2672612  0.25 #>  [4,] 0.2236068 -0.2672612 -0.25  0.2236068  0.2672612 -0.25 #>  [5,] 0.2236068  0.2672612  0.25  0.2236068 -0.2672612 -0.25 #>  [6,] 0.2236068 -0.2672612  0.25 -0.2236068 -0.2672612  0.25 #>  [7,] 0.2236068  0.2672612 -0.25 -0.2236068 -0.2672612 -0.25 #>  [8,] 0.2236068 -0.2672612 -0.25  0.2236068 -0.2672612  0.25 #>  [9,] 0.2236068 -0.1336306 -0.25  0.2236068 -0.1336306 -0.25 #> [10,] 0.2236068 -0.1336306  0.25  0.2236068 -0.1336306  0.25 #> [11,] 0.2236068  0.2672612  0.00  0.2236068  0.2672612  0.00 #> [12,] 0.2236068 -0.1336306 -0.25 -0.2236068  0.1336306  0.25 #> [13,] 0.2236068 -0.1336306  0.25 -0.2236068  0.1336306 -0.25 #> [14,] 0.2236068  0.2672612  0.00 -0.2236068 -0.2672612  0.00 #> [15,] 0.2236068 -0.1336306 -0.25  0.2236068 -0.1336306 -0.25 #> [16,] 0.2236068 -0.1336306  0.25  0.2236068 -0.1336306  0.25 #> [17,] 0.2236068  0.2672612  0.00  0.2236068  0.2672612  0.00 #> [18,] 0.2236068 -0.1336306 -0.25 -0.2236068  0.1336306  0.25 #> [19,] 0.2236068 -0.1336306  0.25 -0.2236068  0.1336306 -0.25 #> [20,] 0.2236068  0.2672612  0.00 -0.2236068 -0.2672612  0.00 #>  #> $crossksi #>               ksi1          ksi2 ksi3          ksi4          ksi5 ksi6 #> ksi1  1.000000e+00 -4.902020e-18    0 -1.574365e-18  1.184091e-17    0 #> ksi2 -4.902020e-18  1.000000e+00    0 -2.036874e-18 -1.030127e-17    0 #> ksi3  0.000000e+00  0.000000e+00    1  0.000000e+00  0.000000e+00    0 #> ksi4 -1.574365e-18 -2.036874e-18    0  1.000000e+00 -4.902020e-18    0 #> ksi5  1.184091e-17 -1.030127e-17    0 -4.902020e-18  1.000000e+00    0 #> ksi6  0.000000e+00  0.000000e+00    0  0.000000e+00  0.000000e+00    1 #>  #> $f #> [1] -0.3607455854 -0.1446953990 -0.0039547825 -0.0083423154  0.0001853034 #> [6]  0.0003924178 #>  #> $z #> [1] -0.8789175  0.1404376 -6.7899801  2.5411641 -1.5434554 -0.6115980 #>  #> $Y #>           [,1]      [,2]      [,3]      [,4] #> [1,] -3.619587 -3.634135 -3.622975 -3.575727 #>   dimX <- 6 Astar <- 2 simul_data_complete(dimX,Astar) #> $simX #>           [,1]      [,2]     [,3]      [,4]      [,5]     [,6] #> [1,] -4.423119 -4.431336 1.048331 -4.423496 -4.413834 1.045084 #>  #> $HH #> [1] 3 #>  #> $eta #>          eta21      eta22 #> [1,] 0.4082483  0.0000000 #> [2,] 0.8164966  0.4472136 #> [3,] 0.4082483 -0.8944272 #>  #> $r #> [1] -6.365877  6.310611 #>  #> $epsilon #> [1] -0.0025442301 -0.0107615820  0.0037565033 -0.0029208804  0.0067408226 #> [6]  0.0005094681 #>  #> $ksi #>           ksi1       ksi2 #> [1,] 0.4082483 -0.2886751 #> [2,] 0.4082483 -0.2886751 #> [3,] 0.4082483  0.5773503 #> [4,] 0.4082483 -0.2886751 #> [5,] 0.4082483 -0.2886751 #> [6,] 0.4082483  0.5773503 #>  #> $crossksi #>              ksi1         ksi2 #> ksi1 1.000000e+00 1.109716e-17 #> ksi2 1.109716e-17 1.000000e+00 #>  #> $f #> [1] 0.1493877 0.1110407 #>  #> $z #> [1] -6.216489  6.421651 #>  #> $Y #>          [,1]     [,2]      [,3] #> [1,] -2.52821 -2.18031 -8.268568 #>    dimX <- 6 Astar <- 3 simul_data_complete(dimX,Astar) #> $simX #>          [,1]      [,2]     [,3]     [,4]      [,5]     [,6] #> [1,] 5.786717 -3.365062 8.110312 5.793858 -3.356623 8.116651 #>  #> $HH #> [1] 3 #>  #> $eta #>          eta31      eta32      eta33 #> [1,] 0.4082483  0.0000000 -0.9128709 #> [2,] 0.8164966  0.4472136  0.3651484 #> [3,] 0.4082483 -0.8944272  0.1825742 #>  #> $r #> [1]  8.599434  7.975830 -9.162390 #>  #> $epsilon #> [1] -0.002758572  0.007852146 -0.005239954  0.004382694  0.016291245 #> [6]  0.001099254 #>  #> $ksi #>           ksi1       ksi2 ksi3 #> [1,] 0.4082483 -0.2886751 -0.5 #> [2,] 0.4082483 -0.2886751  0.5 #> [3,] 0.4082483  0.5773503  0.0 #> [4,] 0.4082483 -0.2886751 -0.5 #> [5,] 0.4082483 -0.2886751  0.5 #> [6,] 0.4082483  0.5773503  0.0 #>  #> $crossksi #>              ksi1         ksi2 ksi3 #> ksi1 1.000000e+00 1.109716e-17    0 #> ksi2 1.109716e-17 1.000000e+00    0 #> ksi3 0.000000e+00 0.000000e+00    1 #>  #> $f #> [1] -0.348428362 -0.264057480  0.006344453 #>  #> $z #> [1]  8.251006  7.711772 -9.156045 #>  #> $Y #>          [,1]     [,2]      [,3] #> [1,] 11.68288 6.844786 -5.222383 #>    dimX <- 6 Astar <- 4 simul_data_complete(dimX,Astar) #> $simX #>            [,1]     [,2]     [,3]       [,4]     [,5]     [,6] #> [1,] -0.4552968 5.430575 3.174759 -0.3671978 5.549447 3.267214 #>  #> $HH #> [1] 4 #>  #> $eta #>          eta41      eta42      eta43      eta44 #> [1,] 0.4082483  0.0000000  0.0000000 -0.9128709 #> [2,] 0.8164966  0.4472136  0.1825742  0.3651484 #> [3,] 0.4082483 -0.8944272 -0.3651484  0.1825742 #> [4,] 0.0000000  0.4472136 -0.9128709  0.0000000 #>  #> $r #> [1]  6.7774988  0.7782884  5.9034128 -0.1237278 #>  #> $epsilon #> [1]  0.004691429 -0.012849206  0.009023812 -0.008232835  0.004998913 #> [6]  0.000454679 #>  #> $ksi #>           ksi1       ksi2 ksi3       ksi4 #> [1,] 0.4082483 -0.2886751 -0.5  0.4082483 #> [2,] 0.4082483 -0.2886751  0.5  0.4082483 #> [3,] 0.4082483  0.5773503  0.0  0.4082483 #> [4,] 0.4082483 -0.2886751 -0.5 -0.4082483 #> [5,] 0.4082483 -0.2886751  0.5 -0.4082483 #> [6,] 0.4082483  0.5773503  0.0 -0.4082483 #>  #> $crossksi #>              ksi1         ksi2 ksi3         ksi4 #> ksi1 1.000000e+00 1.109716e-17    0 2.293169e-19 #> ksi2 1.109716e-17 1.000000e+00    0 1.665841e-17 #> ksi3 0.000000e+00 0.000000e+00    1 0.000000e+00 #> ksi4 2.293169e-19 1.665841e-17    0 1.000000e+00 #>  #> $f #> [1] 0.79068418 0.15805796 0.01084444 0.01590103 #>  #> $z #> [1]  7.5681830  0.9363463  5.9142573 -0.1078268 #>  #> $Y #>          [,1]     [,2]       [,3]      [,4] #> [1,] 3.159941 7.615641 0.02105927 -4.997839 #>   rm(list=c(\"dimX\",\"Astar\"))"},{"path":"https://fbertran.github.io/plsRglm/reference/summary.cv.plsRglmmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for plsRglm models — summary.cv.plsRglmmodel","title":"Summary method for plsRglm models — summary.cv.plsRglmmodel","text":"function provides summary method class \"cv.plsRglmmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.cv.plsRglmmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for plsRglm models — summary.cv.plsRglmmodel","text":"","code":"# S3 method for class 'cv.plsRglmmodel' summary(object, ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/summary.cv.plsRglmmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for plsRglm models — summary.cv.plsRglmmodel","text":"object object class \"cv.plsRglmmodel\" ... arguments passed methods.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.cv.plsRglmmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary method for plsRglm models — summary.cv.plsRglmmodel","text":"object class \"summary.cv.plsRmodel\" model missing model=\"pls\". Otherwise object class \"summary.cv.plsRglmmodel\".","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.cv.plsRglmmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summary method for plsRglm models — summary.cv.plsRglmmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/summary.cv.plsRglmmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary method for plsRglm models — summary.cv.plsRglmmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.cv.plsRglmmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary method for plsRglm models — summary.cv.plsRglmmodel","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] summary(cv.plsRglm(Y~.,data=Cornell,nt=10,NK=1, modele=\"pls-glm-family\",family=gaussian(), verbose=FALSE)) #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Component____ 4 ____ #> ____Component____ 5 ____ #> ____Component____ 6 ____ #> Warning : 1 2 3 4 5 6 7 < 10^{-12} #> Warning only 6 components could thus be extracted #> ____Predicting X without NA neither in X or Y____ #> ****________________________________________________**** #>  #>  #> NK: 1 #> [[1]] #>                AIC      BIC Q2Chisqcum_Y  limQ2  Q2Chisq_Y PREChi2_Pearson_Y #> Nb_Comp_0 82.01205 82.98186           NA     NA         NA                NA #> Nb_Comp_1 53.15173 54.60645    0.8768878 0.0975  0.8768878          57.59147 #> Nb_Comp_2 31.46903 33.40866    0.7420926 0.0975 -1.0948972          74.87683 #> Nb_Comp_3 31.54404 33.96857   -0.1274405 0.0975 -3.3714938          21.71247 #> Nb_Comp_4 33.20141 36.11085   -2.6516402 0.0975 -2.2388763          13.70269 #> Nb_Comp_5 33.25554 36.64989  -11.0163277 0.0975 -2.2906659          13.52993 #> Nb_Comp_6 35.25533 39.13459           NA 0.0975         NA                NA #>           Chi2_Pearson_Y      RSS_Y      R2_Y #> Nb_Comp_0     467.796667 467.796667        NA #> Nb_Comp_1      35.742486  35.742486 0.9235940 #> Nb_Comp_2       4.966831   4.966831 0.9893825 #> Nb_Comp_3       4.230693   4.230693 0.9909561 #> Nb_Comp_4       4.111608   4.111608 0.9912107 #> Nb_Comp_5       3.496135   3.496135 0.9925264 #> Nb_Comp_6       3.496074   3.496074 0.9925265 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRglmmodel\" rm(list=c(\"XCornell\",\"yCornell\",\"bbb\")) #> Warning: object 'bbb' not found"},{"path":"https://fbertran.github.io/plsRglm/reference/summary.cv.plsRmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for plsR models — summary.cv.plsRmodel","title":"Summary method for plsR models — summary.cv.plsRmodel","text":"function provides summary method class \"cv.plsRmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.cv.plsRmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for plsR models — summary.cv.plsRmodel","text":"","code":"# S3 method for class 'cv.plsRmodel' summary(object, ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/summary.cv.plsRmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for plsR models — summary.cv.plsRmodel","text":"object object class \"cv.plsRmodel\" ... arguments passed methods.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.cv.plsRmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary method for plsR models — summary.cv.plsRmodel","text":"object class \"summary.cv.plsRglmmodel\".","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.cv.plsRmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summary method for plsR models — summary.cv.plsRmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/summary.cv.plsRmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary method for plsR models — summary.cv.plsRmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.cv.plsRmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary method for plsR models — summary.cv.plsRmodel","text":"","code":"data(Cornell) summary(cv.plsR(Y~.,data=Cornell,nt=10,K=6, verbose=FALSE), verbose=FALSE) #> [[1]] #>                AIC     Q2cum_Y LimQ2_Y       Q2_Y  PRESS_Y      RSS_Y      R2_Y #> Nb_Comp_0 82.01205          NA      NA         NA       NA 467.796667        NA #> Nb_Comp_1 53.15173   0.8496596  0.0975  0.8496596 70.32872  35.742486 0.9235940 #> Nb_Comp_2 41.08283   0.7926079  0.0975 -0.3794841 49.30619  11.066606 0.9763431 #> Nb_Comp_3 32.06411   0.5788646  0.0975 -1.0306237 22.47211   4.418081 0.9905556 #> Nb_Comp_4 33.76477  -1.6107564  0.0975 -5.1993283 27.38914   4.309235 0.9907882 #> Nb_Comp_5 33.34373 -17.5479050  0.0975 -6.1044181 30.61461   3.521924 0.9924713 #> Nb_Comp_6 35.25533          NA  0.0975         NA       NA   3.496074 0.9925265 #>              AIC.std  DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof #> Nb_Comp_0  37.010388 1.000000    6.5212706 46.0708838 47.7893514 27.59461 #> Nb_Comp_1   8.150064 2.740749    1.8665281  4.5699686  4.9558156 21.34020 #> Nb_Comp_2  -3.918831 5.085967    1.1825195  2.1075461  2.3949331 27.40202 #> Nb_Comp_3 -12.937550 5.121086    0.7488308  0.8467795  0.9628191 24.40842 #> Nb_Comp_4 -11.236891 5.103312    0.7387162  0.8232505  0.9357846 24.23105 #> Nb_Comp_5 -11.657929 6.006316    0.7096382  0.7976101  0.9198348 28.21184 #> Nb_Comp_6  -9.746328 7.000002    0.7633343  0.9711322  1.1359502 33.18348 #>           DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive #> Nb_Comp_0         1      6.5212706 46.0708838 47.7893514   27.59461 #> Nb_Comp_1         2      1.8905683  4.1699567  4.4588195   18.37545 #> Nb_Comp_2         3      1.1088836  1.5370286  1.6860917   17.71117 #> Nb_Comp_3         4      0.7431421  0.7363469  0.8256118   19.01033 #> Nb_Comp_4         5      0.7846050  0.8721072  0.9964867   24.16510 #> Nb_Comp_5         6      0.7661509  0.8804809  1.0227979   28.64206 #> Nb_Comp_6         7      0.8361907  1.1070902  1.3048716   33.63927 #> attr(,\"computed_nt\") #> [1] 6 #>  #> attr(,\"class\") #> [1] \"summary.cv.plsRmodel\""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.plsRglmmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for plsRglm models — summary.plsRglmmodel","title":"Summary method for plsRglm models — summary.plsRglmmodel","text":"function provides summary method class \"plsRglmmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.plsRglmmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for plsRglm models — summary.plsRglmmodel","text":"","code":"# S3 method for class 'plsRglmmodel' summary(object, ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/summary.plsRglmmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for plsRglm models — summary.plsRglmmodel","text":"object object class \"plsRglmmodel\" ... arguments passed methods.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.plsRglmmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary method for plsRglm models — summary.plsRglmmodel","text":"call function call plsRglmmodel","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.plsRglmmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summary method for plsRglm models — summary.plsRglmmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/summary.plsRglmmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary method for plsRglm models — summary.plsRglmmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.plsRglmmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary method for plsRglm models — summary.plsRglmmodel","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] modplsglm <- plsRglm(yCornell,XCornell,3,modele=\"pls-glm-gaussian\") #> ____************************************************____ #>  #> Family: gaussian  #> Link function: identity  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  class(modplsglm) #> [1] \"plsRglmmodel\" summary(modplsglm) #> Call: #> plsRglmmodel.default(dataX = XCornell, nt = 3, modele = \"pls-glm-gaussian\",  #>     dataY = yCornell) rm(list=c(\"XCornell\",\"yCornell\",\"modplsglm\"))"},{"path":"https://fbertran.github.io/plsRglm/reference/summary.plsRmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for plsR models — summary.plsRmodel","title":"Summary method for plsR models — summary.plsRmodel","text":"function provides summary method class \"plsRmodel\"","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.plsRmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for plsR models — summary.plsRmodel","text":"","code":"# S3 method for class 'plsRmodel' summary(object, ...)"},{"path":"https://fbertran.github.io/plsRglm/reference/summary.plsRmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for plsR models — summary.plsRmodel","text":"object object class \"plsRmodel\" ... arguments passed methods.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.plsRmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary method for plsR models — summary.plsRmodel","text":"call function call plsRmodel","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.plsRmodel.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summary method for plsR models — summary.plsRmodel","text":"Nicolas Meyer, Myriam Maumy-Bertrand et Frédéric Bertrand (2010). Comparing linear logistic PLS regression qualitative predictors: application allelotyping data. Journal de la Societe Francaise de Statistique, 151(2), pages 1-18. https://www.numdam.org/item/JSFS_2010__151_2_1_0/","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/summary.plsRmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary method for plsR models — summary.plsRmodel","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/summary.plsRmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary method for plsR models — summary.plsRmodel","text":"","code":"data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8] modpls <- plsR(yCornell,XCornell,3,modele=\"pls\") #> ____************************************************____ #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  class(modpls) #> [1] \"plsRmodel\" summary(modpls) #> Call: #> plsRmodel.default(dataX = XCornell, nt = 3, modele = \"pls\", dataY = yCornell) rm(list=c(\"XCornell\",\"yCornell\",\"modpls\"))"},{"path":"https://fbertran.github.io/plsRglm/reference/tilt.bootpls.html","id":null,"dir":"Reference","previous_headings":"","what":"Non-parametric tilted bootstrap for PLS regression models — tilt.bootpls","title":"Non-parametric tilted bootstrap for PLS regression models — tilt.bootpls","text":"Provides wrapper bootstrap function tilt.boot boot R package. Implements non-parametric tilted bootstrap PLS regression models case resampling : tilt.boot function run initial bootstrap equal resampling probabilities (required) use output initial run find resampling probabilities put value statistic required values. runs importance resampling bootstrap using calculated probabilities resampling distribution.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/tilt.bootpls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Non-parametric tilted bootstrap for PLS regression models — tilt.bootpls","text":"","code":"tilt.bootpls(   object,   typeboot = \"plsmodel\",   statistic = coefs.plsR,   R = c(499, 250, 250),   alpha = c(0.025, 0.975),   sim = \"ordinary\",   stype = \"i\",   index = 1,   stabvalue = 1e+06,   ... )"},{"path":"https://fbertran.github.io/plsRglm/reference/tilt.bootpls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Non-parametric tilted bootstrap for PLS regression models — tilt.bootpls","text":"object object class plsRmodel bootstrap typeboot type bootstrap. Either (Y,X) boostrap (typeboot=\"plsmodel\") (Y,T) bootstrap (typeboot=\"fmodel_np\"). Defaults (Y,T) resampling. statistic function applied data returns vector containing statistic(s) interest. statistic must take least two arguments. first argument passed always original data. second vector indices, frequencies weights define bootstrap sample. , predictions required, third argument required vector random indices used generate bootstrap predictions. arguments can passed statistic ... argument. R number bootstrap replicates. Usually single positive integer. importance resampling, resamples may use one set weights others use different set weights. case R vector integers component gives number resamples rows weights. alpha alpha level tilting required. parameter ignored R[1] 0 theta supplied, otherwise used find values theta quantiles initial uniform bootstrap. case R[1] large enough min(c(alpha, 1-alpha))*R[1] > 5, case warning generated effect theta extreme values tilted output may unreliable. sim character string indicating type simulation required. Possible values \"ordinary\" (default), \"balanced\", \"permutation\", \"antithetic\". stype character string indicating second argument statistic represents. Possible values stype \"\" (indices - default), \"f\" (frequencies), \"w\" (weights). index index statistic interest output statistic. default first element output statistic used. stabvalue Upper bound absolute value coefficients. ... ny arguments can passed statistic.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/tilt.bootpls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Non-parametric tilted bootstrap for PLS regression models — tilt.bootpls","text":"object class \"boot\".","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/tilt.bootpls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Non-parametric tilted bootstrap for PLS regression models — tilt.bootpls","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/tilt.bootpls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Non-parametric tilted bootstrap for PLS regression models — tilt.bootpls","text":"","code":"if (FALSE) { # \\dontrun{ data(Cornell) XCornell<-Cornell[,1:7] yCornell<-Cornell[,8]  set.seed(1385) Cornell.tilt.boot <- tilt.bootpls(plsR(yCornell,XCornell,1), statistic=coefs.plsR,  typeboot=\"fmodel_np\", R=c(499, 100, 100), alpha=c(0.025, 0.975), sim=\"ordinary\",  stype=\"i\", index=1) Cornell.tilt.boot str(Cornell.tilt.boot)  boxplots.bootpls(Cornell.tilt.boot,indices=2:7)  rm(Cornell.tilt.boot) } # }"},{"path":"https://fbertran.github.io/plsRglm/reference/tilt.bootplsglm.html","id":null,"dir":"Reference","previous_headings":"","what":"Non-parametric tilted bootstrap for PLS generalized linear regression models — tilt.bootplsglm","title":"Non-parametric tilted bootstrap for PLS generalized linear regression models — tilt.bootplsglm","text":"Provides wrapper bootstrap function tilt.boot boot R package. Implements non-parametric tilted bootstrap PLS generalized linear regression models case resampling : tilt.boot function run initial bootstrap equal resampling probabilities (required) use output initial run find resampling probabilities put value statistic required values. runs importance resampling bootstrap using calculated probabilities resampling distribution.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/tilt.bootplsglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Non-parametric tilted bootstrap for PLS generalized linear regression models — tilt.bootplsglm","text":"","code":"tilt.bootplsglm(   object,   typeboot = \"fmodel_np\",   statistic = coefs.plsRglm,   R = c(499, 250, 250),   alpha = c(0.025, 0.975),   sim = \"ordinary\",   stype = \"i\",   index = 1,   stabvalue = 1e+06,   ... )"},{"path":"https://fbertran.github.io/plsRglm/reference/tilt.bootplsglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Non-parametric tilted bootstrap for PLS generalized linear regression models — tilt.bootplsglm","text":"object object class plsRbetamodel bootstrap typeboot type bootstrap. Either (Y,X) boostrap (typeboot=\"plsmodel\") (Y,T) bootstrap (typeboot=\"fmodel_np\"). Defaults (Y,T) resampling. statistic function applied data returns vector containing statistic(s) interest. statistic must take least two arguments. first argument passed always original data. second vector indices, frequencies weights define bootstrap sample. , predictions required, third argument required vector random indices used generate bootstrap predictions. arguments can passed statistic ... argument. R number bootstrap replicates. Usually single positive integer. importance resampling, resamples may use one set weights others use different set weights. case R vector integers component gives number resamples rows weights. alpha alpha level tilting required. parameter ignored R[1] 0 theta supplied, otherwise used find values theta quantiles initial uniform bootstrap. case R[1] large enough min(c(alpha, 1-alpha))*R[1] > 5, case warning generated effect theta extreme values tilted output may unreliable. sim character string indicating type simulation required. Possible values \"ordinary\" (default), \"balanced\", \"permutation\", \"antithetic\". stype character string indicating second argument statistic represents. Possible values stype \"\" (indices - default), \"f\" (frequencies), \"w\" (weights). index index statistic interest output statistic. default first element output statistic used. stabvalue Upper bound absolute value coefficients. ... ny arguments can passed statistic.","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/tilt.bootplsglm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Non-parametric tilted bootstrap for PLS generalized linear regression models — tilt.bootplsglm","text":"object class \"boot\".","code":""},{"path":[]},{"path":"https://fbertran.github.io/plsRglm/reference/tilt.bootplsglm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Non-parametric tilted bootstrap for PLS generalized linear regression models — tilt.bootplsglm","text":"Frédéric Bertrandfrederic.bertrand@lecnam.nethttps://fbertran.github.io/homepage/","code":""},{"path":"https://fbertran.github.io/plsRglm/reference/tilt.bootplsglm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Non-parametric tilted bootstrap for PLS generalized linear regression models — tilt.bootplsglm","text":"","code":"# \\donttest{ data(aze_compl) Xaze_compl<-aze_compl[,2:34] yaze_compl<-aze_compl$y  dataset <- cbind(y=yaze_compl,Xaze_compl)  # Lazraq-Cleroux PLS bootstrap Classic  aze_compl.tilt.boot <- tilt.bootplsglm(plsRglm(yaze_compl,Xaze_compl,3,  modele=\"pls-glm-logistic\", family=NULL), statistic=coefs.plsRglm, R=c(499, 100, 100),  alpha=c(0.025, 0.975), sim=\"ordinary\", stype=\"i\", index=1) #> ____************************************************____ #>  #> Family: binomial  #> Link function: logit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  boxplots.bootpls(aze_compl.tilt.boot,1:2)   aze_compl.tilt.boot2 <- tilt.bootplsglm(plsRglm(yaze_compl,Xaze_compl,3,  modele=\"pls-glm-logistic\"), statistic=coefs.plsRglm, R=c(499, 100, 100),  alpha=c(0.025, 0.975), sim=\"ordinary\", stype=\"i\", index=1) #> ____************************************************____ #>  #> Family: binomial  #> Link function: logit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  boxplots.bootpls(aze_compl.tilt.boot2,1:2)   aze_compl.tilt.boot3 <- tilt.bootplsglm(plsRglm(yaze_compl,Xaze_compl,3,  modele=\"pls-glm-family\", family=binomial), statistic=coefs.plsRglm, R=c(499, 100, 100),  alpha=c(0.025, 0.975), sim=\"ordinary\", stype=\"i\", index=1) #> ____************************************************____ #>  #> Family: binomial  #> Link function: logit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  boxplots.bootpls(aze_compl.tilt.boot3,1:2)    # PLS bootstrap balanced  aze_compl.tilt.boot4 <- tilt.bootplsglm(plsRglm(yaze_compl,Xaze_compl,3,  modele=\"pls-glm-logistic\"), statistic=coefs.plsRglm, R=c(499, 100, 100),  alpha=c(0.025, 0.975), sim=\"balanced\", stype=\"i\", index=1) #> ____************************************************____ #>  #> Family: binomial  #> Link function: logit  #>  #> ____Component____ 1 ____ #> ____Component____ 2 ____ #> ____Component____ 3 ____ #> ____Predicting X without NA neither in X nor in Y____ #> ****________________________________________________**** #>  boxplots.bootpls(aze_compl.tilt.boot4,1:2)  # }"},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-160","dir":"Changelog","previous_headings":"","what":"plsRglm 1.6.0","title":"plsRglm 1.6.0","text":"CRAN release: 2025-09-12 Maintainer email update. Added unit tests. Fix package get rid CRAN check notes","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-151","dir":"Changelog","previous_headings":"","what":"plsRglm 1.5.1","title":"plsRglm 1.5.1","text":"CRAN release: 2023-03-14 Fix methods requested CRAN remove escaped latex characters.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-150","dir":"Changelog","previous_headings":"","what":"plsRglm 1.5.0","title":"plsRglm 1.5.0","text":"CRAN release: 2022-05-02 Fixes requested CRAN.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-140","dir":"Changelog","previous_headings":"","what":"plsRglm 1.4.0","title":"plsRglm 1.4.0","text":"Added functions raw bootstrap. Added feature support custom bootstrap function.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-130","dir":"Changelog","previous_headings":"","what":"plsRglm 1.3.0","title":"plsRglm 1.3.0","text":"CRAN release: 2021-03-15 Github actions Roxygen package.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-125","dir":"Changelog","previous_headings":"","what":"plsRglm 1.2.5","title":"plsRglm 1.2.5","text":"CRAN release: 2019-02-02 Rewrote examples cope pkgdown requirements.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-124","dir":"Changelog","previous_headings":"","what":"plsRglm 1.2.4","title":"plsRglm 1.2.4","text":"Improve examples manual Bug fix signpred variable selected. Creating website package Github repository package now public Added NEWS.md file track changes package.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-123","dir":"Changelog","previous_headings":"","what":"plsRglm 1.2.3","title":"plsRglm 1.2.3","text":"CRAN release: 2018-06-11 Complete S3 methods pass CRAN checks.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-122","dir":"Changelog","previous_headings":"","what":"plsRglm 1.2.2","title":"plsRglm 1.2.2","text":"Sped examples pass CRAN checks.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-121","dir":"Changelog","previous_headings":"","what":"plsRglm 1.2.1","title":"plsRglm 1.2.1","text":"CRAN release: 2018-06-02 Updated code pass CRAN checks.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-120","dir":"Changelog","previous_headings":"","what":"plsRglm 1.2.0","title":"plsRglm 1.2.0","text":"Added naive AIC BIC output data missing values.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-111","dir":"Changelog","previous_headings":"","what":"plsRglm 1.1.1","title":"plsRglm 1.1.1","text":"CRAN release: 2014-12-17 donttest update requested CRAN.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-110","dir":"Changelog","previous_headings":"","what":"plsRglm 1.1.0","title":"plsRglm 1.1.0","text":"CRAN release: 2014-07-19 Verbose option (request Max Kuhn, caret package).","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-101","dir":"Changelog","previous_headings":"","what":"plsRglm 1.0.1","title":"plsRglm 1.0.1","text":"CRAN release: 2014-06-28 Fix sPLS like option.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-100","dir":"Changelog","previous_headings":"","what":"plsRglm 1.0.0","title":"plsRglm 1.0.0","text":"CRAN release: 2014-06-27 Major upgrade enhance generics support. Package vignette (130 p.) release. Help package completed.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-090","dir":"Changelog","previous_headings":"","what":"plsRglm 0.9.0","title":"plsRglm 0.9.0","text":"Tilted bootstrap demos fixed.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-083","dir":"Changelog","previous_headings":"","what":"plsRglm 0.8.3","title":"plsRglm 0.8.3","text":"CRAN release: 2014-03-10 Code upgrade requested R Core Team due change namespace policies.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-082","dir":"Changelog","previous_headings":"","what":"plsRglm 0.8.2","title":"plsRglm 0.8.2","text":"CRAN release: 2013-04-10 Improvement access T-np model based Bootstrap.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-081","dir":"Changelog","previous_headings":"","what":"plsRglm 0.8.1","title":"plsRglm 0.8.1","text":"Graphical assessment variable selection. Selection bootstap techniques CI plots.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-080","dir":"Changelog","previous_headings":"","what":"plsRglm 0.8.0","title":"plsRglm 0.8.0","text":"Improved bootstrap stability.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-079","dir":"Changelog","previous_headings":"","what":"plsRglm 0.7.9","title":"plsRglm 0.7.9","text":"CRAN release: 2012-08-27 polr demo fixed.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-078","dir":"Changelog","previous_headings":"","what":"plsRglm 0.7.8","title":"plsRglm 0.7.8","text":"Minor code enhancements.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-077","dir":"Changelog","previous_headings":"","what":"plsRglm 0.7.7","title":"plsRglm 0.7.7","text":"Minor code enhancements.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-076","dir":"Changelog","previous_headings":"","what":"plsRglm 0.7.6","title":"plsRglm 0.7.6","text":"CRAN release: 2011-11-23 Demos fixed.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-075","dir":"Changelog","previous_headings":"","what":"plsRglm 0.7.5","title":"plsRglm 0.7.5","text":"Minor code enhancements.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-074","dir":"Changelog","previous_headings":"","what":"plsRglm 0.7.4","title":"plsRglm 0.7.4","text":"CRAN release: 2011-04-11 Minor code enhancements.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-073","dir":"Changelog","previous_headings":"","what":"plsRglm 0.7.3","title":"plsRglm 0.7.3","text":"Minor code fixes.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-072","dir":"Changelog","previous_headings":"","what":"plsRglm 0.7.2","title":"plsRglm 0.7.2","text":"CRAN release: 2011-04-06 Cross-validation fully compatible weighted plsR plsRglm models.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-071","dir":"Changelog","previous_headings":"","what":"plsRglm 0.7.1","title":"plsRglm 0.7.1","text":"Minor code changes.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-070","dir":"Changelog","previous_headings":"","what":"plsRglm 0.7.0","title":"plsRglm 0.7.0","text":"CRAN release: 2011-03-29 Estimation Degrees Freedom plsR models.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-067","dir":"Changelog","previous_headings":"","what":"plsRglm 0.6.7","title":"plsRglm 0.6.7","text":"Weighted plsR models.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-065","dir":"Changelog","previous_headings":"","what":"plsRglm 0.6.5","title":"plsRglm 0.6.5","text":"CRAN release: 2011-01-15 Sparse option set 0 coefficients non-significant predictors select number components.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-063","dir":"Changelog","previous_headings":"","what":"plsRglm 0.6.3","title":"plsRglm 0.6.3","text":"CRAN release: 2011-01-09 Minor fixes cope upcoming changes R 2.13.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-062","dir":"Changelog","previous_headings":"","what":"plsRglm 0.6.2","title":"plsRglm 0.6.2","text":"Support logistic, probit, cloglog cauchit links cumulative link models.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-061","dir":"Changelog","previous_headings":"","what":"plsRglm 0.6.1","title":"plsRglm 0.6.1","text":"Support various glm polr options.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-060","dir":"Changelog","previous_headings":"","what":"plsRglm 0.6.0","title":"plsRglm 0.6.0","text":"Support formulas.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-051","dir":"Changelog","previous_headings":"","what":"plsRglm 0.5.1","title":"plsRglm 0.5.1","text":"Minor code changes.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-050","dir":"Changelog","previous_headings":"","what":"plsRglm 0.5.0","title":"plsRglm 0.5.0","text":"CRAN release: 2010-12-09 Support R user defined “family” definition glms added.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-040","dir":"Changelog","previous_headings":"","what":"plsRglm 0.4.0","title":"plsRglm 0.4.0","text":"Support Gamma(link = “inverse”), inverse.gaussian(link = “1/mu^2”) poisson(link = “log”) added.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-034","dir":"Changelog","previous_headings":"","what":"plsRglm 0.3.4","title":"plsRglm 0.3.4","text":"Minor code fixes.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-033","dir":"Changelog","previous_headings":"","what":"plsRglm 0.3.3","title":"plsRglm 0.3.3","text":"CRAN release: 2010-10-05 Boostrap functionnalities improvement. Bootstrap longer stops model fitting fails subsample.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-020-032","dir":"Changelog","previous_headings":"","what":"plsRglm 0.2.0-0.3.2","title":"plsRglm 0.2.0-0.3.2","text":"Support polr, crossvalidations bootstraps.","code":""},{"path":"https://fbertran.github.io/plsRglm/news/index.html","id":"plsrglm-012-015","dir":"Changelog","previous_headings":"","what":"plsRglm 0.1.2-0.1.5","title":"plsRglm 0.1.2-0.1.5","text":"Creating help files.","code":""}]
