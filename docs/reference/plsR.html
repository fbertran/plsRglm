<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Partial least squares Regression models with leave one out cross validation — plsR • plsRglm</title>

<!-- favicons -->
<link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png" />
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png" />
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png" />
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png" />

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous" />

<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="Partial least squares Regression models with leave one out cross validation — plsR" />
<meta property="og:description" content="This function implements Partial least squares Regression models with leave one out cross validation for complete or incomplete datasets." />
<meta property="og:image" content="/logo.png" />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">plsRglm</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.3.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa-home"></span>
     
  </a>
</li>
<li>
  <a href="https://cran.r-project.org/web/packages/plsRglm/vignettes/plsRglm.pdf">Vignette</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/fbertran/plsRglm">
    <span class="fas fa-github"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Partial least squares Regression models with leave one out cross validation</h1>
    
    <div class="hidden name"><code>plsR.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>This function implements Partial least squares Regression models with leave one out cross validation for complete or incomplete datasets.</p>
    </div>

    <pre class="usage"><span class='fu'>plsR</span><span class='op'>(</span><span class='va'>x</span>, <span class='va'>...</span><span class='op'>)</span>
<span class='co'># S3 method for default</span>
<span class='fu'>plsRmodel</span><span class='op'>(</span><span class='va'>dataY</span>, <span class='va'>dataX</span>, nt <span class='op'>=</span> <span class='fl'>2</span>, limQ2set <span class='op'>=</span> <span class='fl'>0.0975</span>, 
dataPredictY <span class='op'>=</span> <span class='va'>dataX</span>, modele <span class='op'>=</span> <span class='st'>"pls"</span>, family <span class='op'>=</span> <span class='cn'>NULL</span>, typeVC <span class='op'>=</span> <span class='st'>"none"</span>, 
EstimXNA <span class='op'>=</span> <span class='cn'>FALSE</span>, scaleX <span class='op'>=</span> <span class='cn'>TRUE</span>, scaleY <span class='op'>=</span> <span class='cn'>NULL</span>, pvals.expli <span class='op'>=</span> <span class='cn'>FALSE</span>, 
alpha.pvals.expli <span class='op'>=</span> <span class='fl'>0.05</span>, MClassed <span class='op'>=</span> <span class='cn'>FALSE</span>, tol_Xi <span class='op'>=</span> <span class='fl'>10</span><span class='op'>^</span><span class='op'>(</span><span class='op'>-</span><span class='fl'>12</span><span class='op'>)</span>, <span class='va'>weights</span>,
sparse <span class='op'>=</span> <span class='cn'>FALSE</span>, sparseStop <span class='op'>=</span> <span class='cn'>TRUE</span>, naive <span class='op'>=</span> <span class='cn'>FALSE</span>,verbose<span class='op'>=</span><span class='cn'>TRUE</span><span class='op'>)</span>
<span class='co'># S3 method for formula</span>
<span class='fu'>plsRmodel</span><span class='op'>(</span><span class='va'>formula</span>, <span class='va'>data</span>, nt <span class='op'>=</span> <span class='fl'>2</span>, limQ2set <span class='op'>=</span> <span class='fl'>0.0975</span>,
<span class='va'>dataPredictY</span>, modele <span class='op'>=</span> <span class='st'>"pls"</span>, family <span class='op'>=</span> <span class='cn'>NULL</span>, typeVC <span class='op'>=</span> <span class='st'>"none"</span>,
EstimXNA <span class='op'>=</span> <span class='cn'>FALSE</span>, scaleX <span class='op'>=</span> <span class='cn'>TRUE</span>, scaleY <span class='op'>=</span> <span class='cn'>NULL</span>, pvals.expli <span class='op'>=</span> <span class='cn'>FALSE</span>, 
alpha.pvals.expli <span class='op'>=</span> <span class='fl'>0.05</span>, MClassed <span class='op'>=</span> <span class='cn'>FALSE</span>, tol_Xi <span class='op'>=</span> <span class='fl'>10</span><span class='op'>^</span><span class='op'>(</span><span class='op'>-</span><span class='fl'>12</span><span class='op'>)</span>, <span class='va'>weights</span>,
<span class='va'>subset</span>, contrasts <span class='op'>=</span> <span class='cn'>NULL</span>, sparse <span class='op'>=</span> <span class='cn'>FALSE</span>, sparseStop <span class='op'>=</span> <span class='cn'>TRUE</span>, naive <span class='op'>=</span> <span class='cn'>FALSE</span>,
verbose<span class='op'>=</span><span class='cn'>TRUE</span><span class='op'>)</span>
<span class='fu'>PLS_lm</span><span class='op'>(</span><span class='va'>dataY</span>, <span class='va'>dataX</span>, nt <span class='op'>=</span> <span class='fl'>2</span>, limQ2set <span class='op'>=</span> <span class='fl'>0.0975</span>, dataPredictY <span class='op'>=</span> <span class='va'>dataX</span>, 
modele <span class='op'>=</span> <span class='st'>"pls"</span>, family <span class='op'>=</span> <span class='cn'>NULL</span>, typeVC <span class='op'>=</span> <span class='st'>"none"</span>, EstimXNA <span class='op'>=</span> <span class='cn'>FALSE</span>, 
scaleX <span class='op'>=</span> <span class='cn'>TRUE</span>, scaleY <span class='op'>=</span> <span class='cn'>NULL</span>, pvals.expli <span class='op'>=</span> <span class='cn'>FALSE</span>, 
alpha.pvals.expli <span class='op'>=</span> <span class='fl'>0.05</span>, MClassed <span class='op'>=</span> <span class='cn'>FALSE</span>, tol_Xi <span class='op'>=</span> <span class='fl'>10</span><span class='op'>^</span><span class='op'>(</span><span class='op'>-</span><span class='fl'>12</span><span class='op'>)</span>,
<span class='va'>weights</span>,sparse<span class='op'>=</span><span class='cn'>FALSE</span>,sparseStop<span class='op'>=</span><span class='cn'>FALSE</span>,naive<span class='op'>=</span><span class='cn'>FALSE</span>,verbose<span class='op'>=</span><span class='cn'>TRUE</span><span class='op'>)</span>
<span class='fu'>PLS_lm_formula</span><span class='op'>(</span><span class='va'>formula</span>,data<span class='op'>=</span><span class='cn'>NULL</span>,nt<span class='op'>=</span><span class='fl'>2</span>,limQ2set<span class='op'>=</span><span class='fl'>.0975</span>,dataPredictY<span class='op'>=</span><span class='va'>dataX</span>,
modele<span class='op'>=</span><span class='st'>"pls"</span>,family<span class='op'>=</span><span class='cn'>NULL</span>,typeVC<span class='op'>=</span><span class='st'>"none"</span>,EstimXNA<span class='op'>=</span><span class='cn'>FALSE</span>,scaleX<span class='op'>=</span><span class='cn'>TRUE</span>,
scaleY<span class='op'>=</span><span class='cn'>NULL</span>,pvals.expli<span class='op'>=</span><span class='cn'>FALSE</span>,alpha.pvals.expli<span class='op'>=</span><span class='fl'>.05</span>,MClassed<span class='op'>=</span><span class='cn'>FALSE</span>,
tol_Xi<span class='op'>=</span><span class='fl'>10</span><span class='op'>^</span><span class='op'>(</span><span class='op'>-</span><span class='fl'>12</span><span class='op'>)</span>,<span class='va'>weights</span>,<span class='va'>subset</span>,contrasts<span class='op'>=</span><span class='cn'>NULL</span>,sparse<span class='op'>=</span><span class='cn'>FALSE</span>,
sparseStop<span class='op'>=</span><span class='cn'>FALSE</span>,naive<span class='op'>=</span><span class='cn'>FALSE</span>,verbose<span class='op'>=</span><span class='cn'>TRUE</span><span class='op'>)</span></pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>x</th>
      <td><p>a formula or a response (training) dataset</p></td>
    </tr>
    <tr>
      <th>dataY</th>
      <td><p>response (training) dataset</p></td>
    </tr>
    <tr>
      <th>dataX</th>
      <td><p>predictor(s) (training) dataset</p></td>
    </tr>
    <tr>
      <th>formula</th>
      <td><p>an object of class "<code><a href='https://rdrr.io/r/stats/formula.html'>formula</a></code>" (or one that can be coerced to that class): a symbolic description of the model to be fitted. The details of model specification are given under 'Details'.</p></td>
    </tr>
    <tr>
      <th>data</th>
      <td><p>an optional data frame, list or environment (or object coercible by <code><a href='https://rdrr.io/r/base/as.data.frame.html'>as.data.frame</a></code> to a data frame) containing the variables in the model. If not found in <code>data</code>, the variables are taken from <code><a href='https://rdrr.io/r/base/environment.html'>environment(formula)</a></code>, typically the environment from which <code>plsR</code> is called.</p></td>
    </tr>
    <tr>
      <th>nt</th>
      <td><p>number of components to be extracted</p></td>
    </tr>
    <tr>
      <th>limQ2set</th>
      <td><p>limit value for the Q2</p></td>
    </tr>
    <tr>
      <th>dataPredictY</th>
      <td><p>predictor(s) (testing) dataset</p></td>
    </tr>
    <tr>
      <th>modele</th>
      <td><p>name of the PLS model to be fitted, only (<code>"pls"</code> available for this fonction.</p></td>
    </tr>
    <tr>
      <th>family</th>
      <td><p>for the present moment the family argument is ignored and set thanks to the value of modele.</p></td>
    </tr>
    <tr>
      <th>typeVC</th>
      <td><p>type of leave one out cross validation. Several procedures are available. If cross validation is required, one needs to selects the way of predicting the response for left out observations. For complete rows, without any missing value, there are two different ways of computing these predictions. As a consequence, for mixed datasets, with complete and incomplete rows, there are two ways of computing prediction : either predicts any row as if there were missing values in it (<code>missingdata</code>) or selects the prediction method accordingly to the completeness of the row (<code>adaptative</code>).</p><dl>
      <dt><code>none</code></dt><dd><p>no cross validation</p></dd>
      <dt><code>standard</code></dt><dd><p>as in SIMCA for datasets without any missing value. For datasets with any missing value, it is the as using <code>missingdata</code></p></dd>
      <dt><code>missingdata</code></dt><dd><p>all values predicted as those with missing values for datasets with any missing values</p></dd>
      <dt><code>adaptative</code></dt><dd><p>predict a response value for an x with any missing value as those with missing values and for an x without any missing value as those without missing values.</p></dd>
      
</dl><p></p></td>
    </tr>
    <tr>
      <th>EstimXNA</th>
      <td><p>only for <code>modele="pls"</code>. Set whether the missing X values have to be estimated.</p></td>
    </tr>
    <tr>
      <th>scaleX</th>
      <td><p>scale the predictor(s) : must be set to TRUE for <code>modele="pls"</code> and should be for glms pls.</p></td>
    </tr>
    <tr>
      <th>scaleY</th>
      <td><p>scale the response : Yes/No. Ignored since non always possible for glm responses.</p></td>
    </tr>
    <tr>
      <th>pvals.expli</th>
      <td><p>should individual p-values be reported to tune model selection ?</p></td>
    </tr>
    <tr>
      <th>alpha.pvals.expli</th>
      <td><p>level of significance for predictors when pvals.expli=TRUE</p></td>
    </tr>
    <tr>
      <th>MClassed</th>
      <td><p>number of missclassified cases, should only be used for binary responses</p></td>
    </tr>
    <tr>
      <th>tol_Xi</th>
      <td><p>minimal value for Norm2(Xi) and \(\mathrm{det}(pp' \times pp)\) if there is any missing value in the <code>dataX</code>. It defaults to \(10^{-12}\)</p></td>
    </tr>
    <tr>
      <th>weights</th>
      <td><p>an optional vector of 'prior weights' to be used in the fitting process. Should be <code>NULL</code> or a numeric vector.</p></td>
    </tr>
    <tr>
      <th>subset</th>
      <td><p>an optional vector specifying a subset of observations to be used in the fitting process.</p></td>
    </tr>
    <tr>
      <th>contrasts</th>
      <td><p>an optional list. See the <code>contrasts.arg</code> of <code>model.matrix.default</code>.</p></td>
    </tr>
    <tr>
      <th>sparse</th>
      <td><p>should the coefficients of non-significant predictors (&lt;<code>alpha.pvals.expli</code>) be set to 0</p></td>
    </tr>
    <tr>
      <th>sparseStop</th>
      <td><p>should component extraction stop when no significant predictors (&lt;<code>alpha.pvals.expli</code>) are found</p></td>
    </tr>
    <tr>
      <th>naive</th>
      <td><p>Use the naive estimates for the Degrees of Freedom in plsR? Default is <code>FALSE</code>.</p></td>
    </tr>
    <tr>
      <th>verbose</th>
      <td><p>should info messages be displayed ?</p></td>
    </tr>
    <tr>
      <th>...</th>
      <td><p>arguments to pass to <code>plsRmodel.default</code> or to <code>plsRmodel.formula</code></p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>There are several ways to deal with missing values that leads to different computations of leave one out cross validation criteria.</p>
<p>A typical predictor has the form response ~ terms where response is the (numeric) response vector and terms is a series of terms which specifies a linear predictor for response. A terms specification of the form first + second indicates all the terms in first together with all the terms in second with any duplicates removed.</p>
<p>A specification of the form first:second indicates the the set of terms obtained by taking the interactions of all terms in first with all terms in second. The specification first*second indicates the cross of first and second. This is the same as first + second + first:second.</p>
<p>The terms in the formula will be re-ordered so that main effects come first, followed by the interactions, all second-order, all third-order and so on: to avoid this pass a terms object as the formula.</p>
<p>Non-NULL weights can be used to indicate that different observations have different dispersions (with the values in weights being inversely proportional to the dispersions); or equivalently, when the elements of weights are positive integers w_i, that each response y_i is the mean of w_i unit-weight observations.</p>
<p>The default estimator for Degrees of Freedom is the Kramer and Sugiyama's one. Information criteria are computed accordingly to these estimations. Naive Degrees of Freedom and Information Criteria are also provided for comparison purposes. For more details, see N. Kraemer and M. Sugiyama. (2011). The Degrees of Freedom of Partial Least Squares Regression. <em>Journal of the American Statistical Association</em>, 106(494), 697-705, 2011.</p>
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p></p>
<dt>nr</dt><dd><p>Number of observations</p></dd>
  <dt>nc</dt><dd><p>Number of predictors</p></dd>
  <dt>nt</dt><dd><p>Number of requested components</p></dd>
  <dt>ww</dt><dd><p>raw weights (before L2-normalization)</p></dd>
  <dt>wwnorm</dt><dd><p>L2 normed weights (to be used with deflated matrices of predictor variables)</p></dd>
  <dt>wwetoile</dt><dd><p>modified weights (to be used with original matrix of predictor variables)</p></dd>
  <dt>tt</dt><dd><p>PLS components</p></dd>
  <dt>pp</dt><dd><p>loadings of the predictor variables</p></dd>
  <dt>CoeffC</dt><dd><p>coefficients of the PLS components</p></dd>
  <dt>uscores</dt><dd><p>scores of the response variable</p></dd>
  <dt>YChapeau</dt><dd><p>predicted response values for the dataX set</p></dd>
  <dt>residYChapeau</dt><dd><p>residuals of the deflated response on the standardized scale</p></dd>
  <dt>RepY</dt><dd><p>scaled response vector</p></dd>
  <dt>na.miss.Y</dt><dd><p>is there any NA value in the response vector</p></dd>
  <dt>YNA</dt><dd><p>indicatrix vector of missing values in RepY</p></dd>
  <dt>residY</dt><dd><p>deflated scaled response vector</p></dd>
  <dt>ExpliX</dt><dd><p>scaled matrix of predictors</p></dd>
  <dt>na.miss.X</dt><dd><p>is there any NA value in the predictor matrix</p></dd>
  <dt>XXNA</dt><dd><p>indicator of non-NA values in the predictor matrix</p></dd>
  <dt>residXX</dt><dd><p>deflated predictor matrix</p></dd>
  <dt>PredictY</dt><dd><p>response values with NA replaced with 0</p></dd>
  <dt>press.ind</dt><dd><p>individual PRESS value for each observation (scaled scale)</p></dd>
  <dt>press.tot</dt><dd><p>total PRESS value for all observations (scaled scale)</p></dd>
  <dt>family</dt><dd><p>glm family used to fit PLSGLR model</p></dd>
  <dt>ttPredictY</dt><dd><p>PLS components for the dataset on which prediction was requested</p></dd>
  <dt>typeVC</dt><dd><p>type of leave one out cross-validation used</p></dd>
  <dt>dataX</dt><dd><p>predictor values</p></dd>
  <dt>dataY</dt><dd><p>response values</p></dd>
  <dt>computed_nt</dt><dd><p>number of components that were computed</p></dd>
  <dt>CoeffCFull</dt><dd><p>matrix of the coefficients of the predictors</p></dd>
  <dt>CoeffConstante</dt><dd><p>value of the intercept (scaled scale)</p></dd>
  <dt>Std.Coeffs</dt><dd><p>Vector of standardized regression coefficients</p></dd>
  <dt>press.ind2</dt><dd><p>individual PRESS value for each observation (original scale)</p></dd>
  <dt>RSSresidY</dt><dd><p>residual sum of squares (scaled scale)</p></dd>
  <dt>Coeffs</dt><dd><p>Vector of regression coefficients (used with the original data scale)</p></dd>
  <dt>Yresidus</dt><dd><p>residuals of the PLS model</p></dd>
  <dt>RSS</dt><dd><p>residual sum of squares (original scale)</p></dd>
  <dt>residusY</dt><dd><p>residuals of the deflated response on the standardized scale</p></dd>
  <dt>AIC.std</dt><dd><p>AIC.std vs number of components (AIC computed for the standardized model</p></dd>
  <dt>AIC</dt><dd><p>AIC vs number of components</p></dd>
  <dt>optional</dt><dd><p>If the response is assumed to be binary:<br />
        i.e. <code>MClassed=TRUE</code>.    
  <dl>
  <dt><code>MissClassed</code></dt><dd><p>Number of miss classed results</p></dd>
  <dt><code>Probs</code></dt><dd><p>"Probability" predicted by the model. These are not true probabilities since they may lay outside of [0,1]</p></dd>
  <dt><code>Probs.trc</code></dt><dd><p>Probability predicted by the model and constrained to belong to [0,1]</p></dd></dl></p></dd>
  <dt>ttPredictFittedMissingY</dt><dd><p>Description of 'comp2'</p></dd>
  <dt>optional</dt><dd><p>If cross validation was requested:<br />
        i.e. <code>typeVC="standard"</code>, <code>typeVC="missingdata"</code> or <code>typeVC="adaptative"</code>.
  <dl>
  <dt><code>R2residY</code></dt><dd><p>R2 coefficient value on the standardized scale</p></dd>
  <dt><code>R2</code></dt><dd><p>R2 coefficient value on the original scale</p></dd>
  <dt><code>press.tot2</code></dt><dd><p>total PRESS value for all observations (original scale)</p></dd>
  <dt><code>Q2</code></dt><dd><p>Q2 value (standardized scale)</p></dd>
  <dt><code>limQ2</code></dt><dd><p>limit of the Q2 value</p></dd>
  <dt><code>Q2_2</code></dt><dd><p>Q2 value (original scale)</p></dd>
  <dt><code>Q2cum</code></dt><dd><p>cumulated Q2 (standardized scale)</p></dd>
  <dt><code>Q2cum_2</code></dt><dd><p>cumulated Q2 (original scale)</p></dd></dl></p></dd>
  <dt>InfCrit</dt><dd><p>table of Information Criteria</p></dd>
  <dt>Std.ValsPredictY</dt><dd><p>predicted response values for supplementary dataset (standardized scale)</p></dd>
  <dt>ValsPredictY</dt><dd><p>predicted response values for supplementary dataset (original scale)</p></dd>
  <dt>Std.XChapeau</dt><dd><p>estimated values for missing values in the predictor matrix (standardized scale)</p></dd>
  <dt>XXwotNA</dt><dd><p>predictor matrix with missing values replaced with 0</p></dd>

    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Nicolas Meyer, Myriam Maumy-Bertrand et Frederic Bertrand (2010). Comparing the linear and the logistic PLS regression with qualitative predictors: application to allelotyping data. <em>Journal de la Societe Francaise de Statistique</em>, 151(2), pages 1-18.
<a href='http://publications-sfds.math.cnrs.fr/index.php/J-SFdS/article/view/47'>http://publications-sfds.math.cnrs.fr/index.php/J-SFdS/article/view/47</a></p>
    <h2 class="hasAnchor" id="author"><a class="anchor" href="#author"></a>Author</h2>

    <p>Frederic Bertrand<br />
<a href='mailto:frederic.bertrand@math.unistra.fr'>frederic.bertrand@math.unistra.fr</a><br />
<a href='http://www-irma.u-strasbg.fr/~fbertran/'>http://www-irma.u-strasbg.fr/~fbertran/</a></p>
    <h2 class="hasAnchor" id="note"><a class="anchor" href="#note"></a>Note</h2>

    <p>Use <code><a href='cv.plsR.html'>cv.plsR</a></code> to cross-validate the plsRglm models and <code><a href='bootpls.html'>bootpls</a></code> to bootstrap them.</p>
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p>See also <code><a href='plsRglm.html'>plsRglm</a></code> to fit PLSGLR models.</p></div>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='fu'><a href='https://rdrr.io/r/utils/data.html'>data</a></span><span class='op'>(</span><span class='va'>Cornell</span><span class='op'>)</span>
<span class='va'>XCornell</span><span class='op'>&lt;-</span><span class='va'>Cornell</span><span class='op'>[</span>,<span class='fl'>1</span><span class='op'>:</span><span class='fl'>7</span><span class='op'>]</span>
<span class='va'>yCornell</span><span class='op'>&lt;-</span><span class='va'>Cornell</span><span class='op'>[</span>,<span class='fl'>8</span><span class='op'>]</span>

<span class='co'>#maximum 6 components could be extracted from this dataset</span>
<span class='co'>#trying 10 to trigger automatic stopping criterion</span>
<span class='va'>modpls10</span><span class='op'>&lt;-</span><span class='fu'>plsR</span><span class='op'>(</span><span class='va'>yCornell</span>,<span class='va'>XCornell</span>,<span class='fl'>10</span><span class='op'>)</span>
</div><div class='output co'>#&gt; ____************************************************____
#&gt; ____Component____ 1 ____
#&gt; ____Component____ 2 ____
#&gt; ____Component____ 3 ____
#&gt; ____Component____ 4 ____
#&gt; ____Component____ 5 ____
#&gt; ____Component____ 6 ____
#&gt; Warning : 1 2 3 4 5 6 7 &lt; 10^{-12}
#&gt; Warning only 6 components could thus be extracted
#&gt; ____Predicting X without NA neither in X nor in Y____
#&gt; ****________________________________________________****
#&gt; </div><div class='input'><span class='va'>modpls10</span>
</div><div class='output co'>#&gt; Number of required components:
#&gt; [1] 10
#&gt; Number of successfully computed components:
#&gt; [1] 6
#&gt; Coefficients:
#&gt;                  [,1]
#&gt; Intercept  88.7107982
#&gt; X1        -54.3905712
#&gt; X2         -2.7879678
#&gt; X3         52.5411315
#&gt; X4        -11.5306977
#&gt; X5         -0.9605822
#&gt; X6         11.5900307
#&gt; X7         28.2104803
#&gt; Information criteria and Fit statistics:
#&gt;                AIC      RSS_Y      R2_Y R2_residY  RSS_residY    AIC.std
#&gt; Nb_Comp_0 82.01205 467.796667        NA        NA 11.00000000  37.010388
#&gt; Nb_Comp_1 53.15173  35.742486 0.9235940 0.9235940  0.84046633   8.150064
#&gt; Nb_Comp_2 41.08283  11.066606 0.9763431 0.9763431  0.26022559  -3.918831
#&gt; Nb_Comp_3 32.06411   4.418081 0.9905556 0.9905556  0.10388893 -12.937550
#&gt; Nb_Comp_4 33.76477   4.309235 0.9907882 0.9907882  0.10132947 -11.236891
#&gt; Nb_Comp_5 33.34373   3.521924 0.9924713 0.9924713  0.08281624 -11.657929
#&gt; Nb_Comp_6 35.25533   3.496074 0.9925265 0.9925265  0.08220840  -9.746328
#&gt;            DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof DoF.naive
#&gt; Nb_Comp_0 1.000000    6.5212706 46.0708838 47.7893514 27.59461         1
#&gt; Nb_Comp_1 2.740749    1.8665281  4.5699686  4.9558156 21.34020         2
#&gt; Nb_Comp_2 5.085967    1.1825195  2.1075461  2.3949331 27.40202         3
#&gt; Nb_Comp_3 5.121086    0.7488308  0.8467795  0.9628191 24.40842         4
#&gt; Nb_Comp_4 5.103312    0.7387162  0.8232505  0.9357846 24.23105         5
#&gt; Nb_Comp_5 6.006316    0.7096382  0.7976101  0.9198348 28.21184         6
#&gt; Nb_Comp_6 7.000002    0.7633343  0.9711322  1.1359501 33.18348         7
#&gt;           sigmahat.naive  AIC.naive  BIC.naive GMDL.naive
#&gt; Nb_Comp_0      6.5212706 46.0708838 47.7893514   27.59461
#&gt; Nb_Comp_1      1.8905683  4.1699567  4.4588195   18.37545
#&gt; Nb_Comp_2      1.1088836  1.5370286  1.6860917   17.71117
#&gt; Nb_Comp_3      0.7431421  0.7363469  0.8256118   19.01033
#&gt; Nb_Comp_4      0.7846050  0.8721072  0.9964867   24.16510
#&gt; Nb_Comp_5      0.7661509  0.8804809  1.0227979   28.64206
#&gt; Nb_Comp_6      0.8361907  1.1070902  1.3048716   33.63927</div><div class='input'>
<span class='co'>#With iterated leave one out CV PRESS</span>
<span class='va'>modpls6cv</span><span class='op'>&lt;-</span><span class='fu'>plsR</span><span class='op'>(</span><span class='va'>Y</span><span class='op'>~</span><span class='va'>.</span>,data<span class='op'>=</span><span class='va'>Cornell</span>,<span class='fl'>6</span>,typeVC<span class='op'>=</span><span class='st'>"standard"</span><span class='op'>)</span>
</div><div class='output co'>#&gt; ____************************************************____
#&gt; ____TypeVC____ standard ____
#&gt; ____Component____ 1 ____
#&gt; ____Component____ 2 ____
#&gt; ____Component____ 3 ____
#&gt; ____Component____ 4 ____
#&gt; ____Component____ 5 ____
#&gt; ____Component____ 6 ____
#&gt; ____Predicting X without NA neither in X nor in Y____
#&gt; ****________________________________________________****
#&gt; </div><div class='input'><span class='va'>modpls6cv</span>
</div><div class='output co'>#&gt; Number of required components:
#&gt; [1] 6
#&gt; Number of successfully computed components:
#&gt; [1] 6
#&gt; Coefficients:
#&gt;                  [,1]
#&gt; Intercept  88.7107982
#&gt; X1        -54.3905712
#&gt; X2         -2.7879678
#&gt; X3         52.5411315
#&gt; X4        -11.5306977
#&gt; X5         -0.9605822
#&gt; X6         11.5900307
#&gt; X7         28.2104803
#&gt; Leave one out cross validated PRESS, Information criteria and Fit statistics:
#&gt;                AIC   Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y      RSS_Y      R2_Y
#&gt; Nb_Comp_0 82.01205        NA      NA          NA        NA 467.796667        NA
#&gt; Nb_Comp_1 53.15173 0.8966556  0.0975  0.89665563 48.344150  35.742486 0.9235940
#&gt; Nb_Comp_2 41.08283 0.9175426  0.0975  0.20210989 28.518576  11.066606 0.9763431
#&gt; Nb_Comp_3 32.06411 0.9399676  0.0975  0.27195907  8.056942   4.418081 0.9905556
#&gt; Nb_Comp_4 33.76477 0.9197009  0.0975 -0.33759604  5.909608   4.309235 0.9907882
#&gt; Nb_Comp_5 33.34373 0.9281373  0.0975  0.10506161  3.856500   3.521924 0.9924713
#&gt; Nb_Comp_6 35.25533 0.9232562  0.0975 -0.06792167  3.761138   3.496074 0.9925265
#&gt;           R2_residY  RSS_residY PRESS_residY   Q2_residY  LimQ2 Q2cum_residY
#&gt; Nb_Comp_0        NA 11.00000000           NA          NA     NA           NA
#&gt; Nb_Comp_1 0.9235940  0.84046633   1.13678803  0.89665563 0.0975    0.8966556
#&gt; Nb_Comp_2 0.9763431  0.26022559   0.67059977  0.20210989 0.0975    0.9175426
#&gt; Nb_Comp_3 0.9905556  0.10388893   0.18945488  0.27195907 0.0975    0.9399676
#&gt; Nb_Comp_4 0.9907882  0.10132947   0.13896142 -0.33759604 0.0975    0.9197009
#&gt; Nb_Comp_5 0.9924713  0.08281624   0.09068364  0.10506161 0.0975    0.9281373
#&gt; Nb_Comp_6 0.9925265  0.08220840   0.08844125 -0.06792167 0.0975    0.9232562
#&gt;              AIC.std  DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof
#&gt; Nb_Comp_0  37.010388 1.000000    6.5212706 46.0708838 47.7893514 27.59461
#&gt; Nb_Comp_1   8.150064 2.740749    1.8665281  4.5699686  4.9558156 21.34020
#&gt; Nb_Comp_2  -3.918831 5.085967    1.1825195  2.1075461  2.3949331 27.40202
#&gt; Nb_Comp_3 -12.937550 5.121086    0.7488308  0.8467795  0.9628191 24.40842
#&gt; Nb_Comp_4 -11.236891 5.103312    0.7387162  0.8232505  0.9357846 24.23105
#&gt; Nb_Comp_5 -11.657929 6.006316    0.7096382  0.7976101  0.9198348 28.21184
#&gt; Nb_Comp_6  -9.746328 7.000002    0.7633343  0.9711322  1.1359501 33.18348
#&gt;           DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive
#&gt; Nb_Comp_0         1      6.5212706 46.0708838 47.7893514   27.59461
#&gt; Nb_Comp_1         2      1.8905683  4.1699567  4.4588195   18.37545
#&gt; Nb_Comp_2         3      1.1088836  1.5370286  1.6860917   17.71117
#&gt; Nb_Comp_3         4      0.7431421  0.7363469  0.8256118   19.01033
#&gt; Nb_Comp_4         5      0.7846050  0.8721072  0.9964867   24.16510
#&gt; Nb_Comp_5         6      0.7661509  0.8804809  1.0227979   28.64206
#&gt; Nb_Comp_6         7      0.8361907  1.1070902  1.3048716   33.63927</div><div class='input'><span class='va'>cv.modpls</span><span class='op'>&lt;-</span><span class='fu'><a href='cv.plsR.html'>cv.plsR</a></span><span class='op'>(</span><span class='va'>Y</span><span class='op'>~</span><span class='va'>.</span>,data<span class='op'>=</span><span class='va'>Cornell</span>,<span class='fl'>6</span>,NK<span class='op'>=</span><span class='fl'>100</span>, verbose<span class='op'>=</span><span class='cn'>FALSE</span><span class='op'>)</span>
<span class='va'>res.cv.modpls</span><span class='op'>&lt;-</span><span class='fu'><a href='cvtable.html'>cvtable</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>cv.modpls</span><span class='op'>)</span><span class='op'>)</span>
</div><div class='output co'>#&gt; ____************************************************____
#&gt; ____Component____ 1 ____
#&gt; ____Component____ 2 ____
#&gt; ____Component____ 3 ____
#&gt; ____Component____ 4 ____
#&gt; ____Component____ 5 ____
#&gt; ____Component____ 6 ____
#&gt; ____Predicting X without NA neither in X nor in Y____
#&gt; ****________________________________________________****
#&gt; 
#&gt; 
#&gt; NK: 1,  2,  3,  4,  5,  6,  7,  8,  9,  10
#&gt; NK: 11,  12,  13,  14,  15,  16,  17,  18,  19,  20
#&gt; NK: 21,  22,  23,  24,  25,  26,  27,  28,  29,  30
#&gt; NK: 31,  32,  33,  34,  35,  36,  37,  38,  39,  40
#&gt; NK: 41,  42,  43,  44,  45,  46,  47,  48,  49,  50
#&gt; NK: 51,  52,  53,  54,  55,  56,  57,  58,  59,  60
#&gt; NK: 61,  62,  63,  64,  65,  66,  67,  68,  69,  70
#&gt; NK: 71,  72,  73,  74,  75,  76,  77,  78,  79,  80
#&gt; NK: 81,  82,  83,  84,  85,  86,  87,  88,  89,  90
#&gt; NK: 91,  92,  93,  94,  95,  96,  97,  98,  99,  100
#&gt; 
#&gt; CV Q2 criterion:
#&gt;  0  1  2 
#&gt;  0 86 14 
#&gt; 
#&gt; CV Press criterion:
#&gt;  1  2  3  4  5 
#&gt;  0  1 31 52 16 </div><div class='input'><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>res.cv.modpls</span><span class='op'>)</span>
</div><div class='img'><img src='plsR-1.png' alt='' width='700' height='433' /></div><div class='input'>
<span class='fu'><a href='https://rdrr.io/r/base/rm.html'>rm</a></span><span class='op'>(</span>list<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"XCornell"</span>,<span class='st'>"yCornell"</span>,<span class='st'>"modpls10"</span>,<span class='st'>"modpls6cv"</span><span class='op'>)</span><span class='op'>)</span>

<span class='co'># \donttest{</span>
<span class='co'>#A binary response example</span>
<span class='fu'><a href='https://rdrr.io/r/utils/data.html'>data</a></span><span class='op'>(</span><span class='va'>aze_compl</span><span class='op'>)</span>
<span class='va'>Xaze_compl</span><span class='op'>&lt;-</span><span class='va'>aze_compl</span><span class='op'>[</span>,<span class='fl'>2</span><span class='op'>:</span><span class='fl'>34</span><span class='op'>]</span>
<span class='va'>yaze_compl</span><span class='op'>&lt;-</span><span class='va'>aze_compl</span><span class='op'>$</span><span class='va'>y</span>
<span class='va'>modpls.aze</span> <span class='op'>&lt;-</span> <span class='fu'>plsR</span><span class='op'>(</span><span class='va'>yaze_compl</span>,<span class='va'>Xaze_compl</span>,<span class='fl'>10</span>,MClassed<span class='op'>=</span><span class='cn'>TRUE</span>,typeVC<span class='op'>=</span><span class='st'>"standard"</span><span class='op'>)</span>
</div><div class='output co'>#&gt; ____************************************************____
#&gt; ____TypeVC____ standard ____
#&gt; ____Component____ 1 ____
#&gt; ____Component____ 2 ____
#&gt; ____Component____ 3 ____
#&gt; ____Component____ 4 ____
#&gt; ____Component____ 5 ____
#&gt; ____Component____ 6 ____
#&gt; ____Component____ 7 ____
#&gt; ____Component____ 8 ____
#&gt; ____Component____ 9 ____
#&gt; ____Component____ 10 ____
#&gt; ____Predicting X without NA neither in X nor in Y____
#&gt; ****________________________________________________****
#&gt; </div><div class='input'><span class='va'>modpls.aze</span>
</div><div class='output co'>#&gt; Number of required components:
#&gt; [1] 10
#&gt; Number of successfully computed components:
#&gt; [1] 10
#&gt; Coefficients:
#&gt;                   [,1]
#&gt; Intercept  0.308019808
#&gt; D2S138    -0.131218617
#&gt; D18S61     0.450219840
#&gt; D16S422   -0.183848373
#&gt; D17S794    0.269084083
#&gt; D6S264     0.105061098
#&gt; D14S65    -0.052837918
#&gt; D18S53     0.008489326
#&gt; D17S790   -0.213122117
#&gt; D1S225     0.046277290
#&gt; D3S1282   -0.095666162
#&gt; D9S179     0.054547887
#&gt; D5S430    -0.126491043
#&gt; D8S283     0.106373432
#&gt; D11S916    0.111623381
#&gt; D2S159     0.056759714
#&gt; D16S408    0.010288859
#&gt; D5S346     0.233674850
#&gt; D10S191    0.010715856
#&gt; D13S173    0.074148740
#&gt; D6S275    -0.123145693
#&gt; D15S127    0.064566148
#&gt; D1S305     0.190500469
#&gt; D4S394    -0.142585807
#&gt; D20S107   -0.184483600
#&gt; D1S197    -0.284373695
#&gt; D1S207     0.186728597
#&gt; D10S192    0.195516079
#&gt; D3S1283   -0.096309755
#&gt; D4S414     0.017960975
#&gt; D8S264     0.121051206
#&gt; D22S928   -0.049091794
#&gt; TP53      -0.391965015
#&gt; D9S171    -0.012315197
#&gt; Leave one out cross validated PRESS, Information criteria and Fit statistics:
#&gt;                 AIC      Q2cum_Y LimQ2_Y        Q2_Y  PRESS_Y    RSS_Y
#&gt; Nb_Comp_0  154.6179           NA      NA          NA       NA 25.91346
#&gt; Nb_Comp_1  126.4083  -0.09840016  0.0975 -0.09840016 28.46335 19.38086
#&gt; Nb_Comp_2  119.3375  -0.19018163  0.0975 -0.08355923 21.00031 17.76209
#&gt; Nb_Comp_3  114.2313  -0.77332918  0.0975 -0.48996518 26.46489 16.58896
#&gt; Nb_Comp_4  112.3463  -1.64635954  0.0975 -0.49231150 24.75590 15.98071
#&gt; Nb_Comp_5  113.2362  -2.74242209  0.0975 -0.41417749 22.59955 15.81104
#&gt; Nb_Comp_6  114.7620  -4.46009228  0.0975 -0.45897286 23.06788 15.73910
#&gt; Nb_Comp_7  116.5264  -7.36664482  0.0975 -0.53232663 24.11744 15.70350
#&gt; Nb_Comp_8  118.4601 -11.80011367  0.0975 -0.52989806 24.02475 15.69348
#&gt; Nb_Comp_9  120.4452 -17.90787273  0.0975 -0.47716444 23.18185 15.69123
#&gt; Nb_Comp_10 122.4395 -26.50536212  0.0975 -0.45470421 22.82610 15.69037
#&gt;                 R2_Y MissClassed R2_residY RSS_residY PRESS_residY   Q2_residY
#&gt; Nb_Comp_0         NA          49        NA  103.00000           NA          NA
#&gt; Nb_Comp_1  0.2520929          27 0.2520929   77.03443    113.13522 -0.09840016
#&gt; Nb_Comp_2  0.3145613          25 0.3145613   70.60018     83.47137 -0.08355923
#&gt; Nb_Comp_3  0.3598323          27 0.3598323   65.93728    105.19181 -0.48996518
#&gt; Nb_Comp_4  0.3833049          23 0.3833049   63.51960     98.39895 -0.49231150
#&gt; Nb_Comp_5  0.3898523          22 0.3898523   62.84522     89.82798 -0.41417749
#&gt; Nb_Comp_6  0.3926285          21 0.3926285   62.55927     91.68947 -0.45897286
#&gt; Nb_Comp_7  0.3940024          20 0.3940024   62.41775     95.86123 -0.53232663
#&gt; Nb_Comp_8  0.3943888          20 0.3943888   62.37795     95.49280 -0.52989806
#&gt; Nb_Comp_9  0.3944758          19 0.3944758   62.36900     92.14249 -0.47716444
#&gt; Nb_Comp_10 0.3945088          19 0.3945088   62.36560     90.72844 -0.45470421
#&gt;             LimQ2 Q2cum_residY  AIC.std  DoF.dof sigmahat.dof   AIC.dof
#&gt; Nb_Comp_0      NA           NA 298.1344  1.00000    0.5015845 0.2540061
#&gt; Nb_Comp_1  0.0975  -0.09840016 269.9248 22.55372    0.4848429 0.2883114
#&gt; Nb_Comp_2  0.0975  -0.19018163 262.8540 27.31542    0.4781670 0.2908950
#&gt; Nb_Comp_3  0.0975  -0.77332918 257.7478 30.52370    0.4719550 0.2902572
#&gt; Nb_Comp_4  0.0975  -1.64635954 255.8628 34.00000    0.4744263 0.3008285
#&gt; Nb_Comp_5  0.0975  -2.74242209 256.7527 34.00000    0.4719012 0.2976347
#&gt; Nb_Comp_6  0.0975  -4.46009228 258.2785 34.00000    0.4708264 0.2962804
#&gt; Nb_Comp_7  0.0975  -7.36664482 260.0429 33.71066    0.4693382 0.2937976
#&gt; Nb_Comp_8  0.0975 -11.80011367 261.9766 34.00000    0.4701436 0.2954217
#&gt; Nb_Comp_9  0.0975 -17.90787273 263.9617 33.87284    0.4696894 0.2945815
#&gt; Nb_Comp_10 0.0975 -26.50536212 265.9560 34.00000    0.4700970 0.2953632
#&gt;              BIC.dof  GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive
#&gt; Nb_Comp_0  0.2604032 -67.17645         1      0.5015845 0.2540061 0.2604032
#&gt; Nb_Comp_1  0.4231184 -53.56607         2      0.4358996 0.1936625 0.2033251
#&gt; Nb_Comp_2  0.4496983 -52.42272         3      0.4193593 0.1809352 0.1943501
#&gt; Nb_Comp_3  0.4631316 -51.93343         4      0.4072955 0.1722700 0.1891422
#&gt; Nb_Comp_4  0.4954133 -50.37079         5      0.4017727 0.1691819 0.1897041
#&gt; Nb_Comp_5  0.4901536 -50.65724         6      0.4016679 0.1706451 0.1952588
#&gt; Nb_Comp_6  0.4879234 -50.78005         7      0.4028135 0.1731800 0.2020601
#&gt; Nb_Comp_7  0.4826103 -51.05525         8      0.4044479 0.1761610 0.2094352
#&gt; Nb_Comp_8  0.4865092 -50.85833         9      0.4064413 0.1794902 0.2172936
#&gt; Nb_Comp_9  0.4845867 -50.95616        10      0.4085682 0.1829787 0.2254232
#&gt; Nb_Comp_10 0.4864128 -50.86368        11      0.4107477 0.1865584 0.2337468
#&gt;            GMDL.naive
#&gt; Nb_Comp_0   -67.17645
#&gt; Nb_Comp_1   -79.67755
#&gt; Nb_Comp_2   -81.93501
#&gt; Nb_Comp_3   -83.31503
#&gt; Nb_Comp_4   -83.23369
#&gt; Nb_Comp_5   -81.93513
#&gt; Nb_Comp_6   -80.42345
#&gt; Nb_Comp_7   -78.87607
#&gt; Nb_Comp_8   -77.31942
#&gt; Nb_Comp_9   -75.80069
#&gt; Nb_Comp_10  -74.33325</div><div class='input'>
<span class='co'>#Direct access to not cross-validated values</span>
<span class='va'>modpls.aze</span><span class='op'>$</span><span class='va'>AIC</span>
</div><div class='output co'>#&gt;          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]    [,7]     [,8]
#&gt; [1,] 154.6179 126.4083 119.3375 114.2313 112.3463 113.2362 114.762 116.5264
#&gt;          [,9]    [,10]    [,11]
#&gt; [1,] 118.4601 120.4452 122.4395</div><div class='input'><span class='va'>modpls.aze</span><span class='op'>$</span><span class='va'>AIC.std</span>
</div><div class='output co'>#&gt;          [,1]     [,2]    [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
#&gt; [1,] 298.1344 269.9248 262.854 257.7478 255.8628 256.7527 258.2785 260.0429
#&gt;          [,9]    [,10]   [,11]
#&gt; [1,] 261.9766 263.9617 265.956</div><div class='input'><span class='va'>modpls.aze</span><span class='op'>$</span><span class='va'>MissClassed</span>
</div><div class='output co'>#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11]
#&gt; [1,]   49   27   25   27   23   22   21   20   20    19    19</div><div class='input'>
<span class='co'>#Raw predicted values (not really probabily since not constrained in [0,1]</span>
<span class='va'>modpls.aze</span><span class='op'>$</span><span class='va'>Probs</span>
</div><div class='output co'>#&gt;          [,1]        [,2]        [,3]        [,4]        [,5]        [,6]
#&gt; 1   0.4711538  0.46105744  0.63458141  0.67961627  0.69452246  0.64534767
#&gt; 2   0.4711538  0.26911816  0.26581497  0.16989268  0.11760783  0.18096700
#&gt; 3   0.4711538 -0.09080494 -0.05104846 -0.17166916 -0.21455242 -0.21725391
#&gt; 4   0.4711538  0.36370490  0.54112657  0.50724821  0.55508565  0.57773785
#&gt; 5   0.4711538 -0.04408124  0.07399231 -0.07129909 -0.24018962 -0.23445282
#&gt; 6   0.4711538 -0.03776963  0.17275288  0.01806190 -0.02597539 -0.06284454
#&gt; 7   0.4711538 -0.06930728 -0.19928456 -0.09137261  0.01116043  0.06506517
#&gt; 8   0.4711538  0.27158233  0.24933653  0.11611522  0.12804487  0.04118115
#&gt; 9   0.4711538  0.76949497  0.60296556  0.47237794  0.51581382  0.49885092
#&gt; 10  0.4711538  0.22096539  0.34482052  0.34660816  0.38580378  0.43528451
#&gt; 11  0.4711538  0.87147914  0.84865348  0.76372713  0.73582307  0.76725258
#&gt; 12  0.4711538  0.79792975  0.67828859  0.73747065  0.67844373  0.67908585
#&gt; 13  0.4711538  0.09432664 -0.04344681  0.10780023  0.22488457  0.26144110
#&gt; 14  0.4711538  0.28543133  0.29293086  0.37385135  0.37961001  0.30207755
#&gt; 15  0.4711538  0.30637401  0.27816310  0.18074751  0.01510565  0.05074255
#&gt; 16  0.4711538  0.12893721 -0.07276258 -0.05146556 -0.09988241 -0.06790398
#&gt; 17  0.4711538  0.59910292  0.41302582  0.40055026  0.32477692  0.32429673
#&gt; 18  0.4711538  0.60665328  0.51461671  0.70351041  0.63093215  0.60232625
#&gt; 19  0.4711538  0.18381206  0.36596047  0.33591603  0.25289460  0.21859872
#&gt; 20  0.4711538  0.28422822  0.15202852  0.29980632  0.42075827  0.43463142
#&gt; 21  0.4711538  0.35982960  0.40300075  0.63220247  0.58056075  0.55273462
#&gt; 22  0.4711538  0.31574837  0.28422517  0.37116719  0.27156145  0.25529246
#&gt; 23  0.4711538  0.41682757  0.36900849  0.23791176  0.25730930  0.24221472
#&gt; 24  0.4711538  0.30288056  0.15972272  0.19362318  0.07194768  0.07250435
#&gt; 25  0.4711538  0.29650015  0.48867070  0.61025747  0.59737342  0.67704212
#&gt; 26  0.4711538  0.23008536  0.32001822  0.15862645  0.26312675  0.22513847
#&gt; 27  0.4711538  0.67526360  0.68123526  0.58796740  0.51309143  0.44381568
#&gt; 28  0.4711538  0.15222775  0.13544964  0.15605402  0.15868232  0.10574096
#&gt; 29  0.4711538  0.43138914  0.29576924  0.29706087  0.35294305  0.40257625
#&gt; 30  0.4711538  0.13910581  0.26763382  0.10182481  0.12169881  0.13543560
#&gt; 31  0.4711538  0.40295972  0.43810789  0.28684877  0.41632594  0.45388666
#&gt; 32  0.4711538  0.58422149  0.44366239  0.16615851  0.15367980  0.18291151
#&gt; 33  0.4711538  0.69889100  0.72592310  0.57845537  0.50185886  0.51841164
#&gt; 34  0.4711538  0.35960908  0.24234167  0.09364940  0.08428214  0.10528276
#&gt; 35  0.4711538  0.27914959  0.03731133 -0.08896074 -0.06232370 -0.08231459
#&gt; 36  0.4711538  0.38865989  0.39024480  0.44138316  0.47508801  0.42329842
#&gt; 37  0.4711538  0.62200134  0.42145828  0.38142396  0.29675933  0.28947211
#&gt; 38  0.4711538  0.41311694  0.19970983  0.16702613  0.17059545  0.17073272
#&gt; 39  0.4711538  0.31755422  0.28395547  0.17609314  0.23875966  0.25763504
#&gt; 40  0.4711538  0.62628933  0.51627261  0.52025889  0.47789760  0.47304606
#&gt; 41  0.4711538  0.14894845  0.14069540  0.13906223  0.05976750  0.13670893
#&gt; 42  0.4711538  0.64041121  0.49727655  0.49380105  0.53239359  0.51394469
#&gt; 43  0.4711538  0.38696544  0.54930653  0.62650411  0.65244562  0.56755351
#&gt; 44  0.4711538  0.24204195  0.05825611  0.02230584 -0.01790809 -0.03785626
#&gt; 45  0.4711538  0.10349021  0.14957660  0.16304594  0.15564790  0.17065395
#&gt; 46  0.4711538  0.63322787  0.64625855  0.55541948  0.65203351  0.63670168
#&gt; 47  0.4711538  0.20557889  0.23864853  0.24328712  0.13063078  0.09743813
#&gt; 48  0.4711538  0.32352238  0.34894312  0.21162810  0.20487572  0.16461876
#&gt; 49  0.4711538  0.64888519  0.52290405  0.50926772  0.62061797  0.59597941
#&gt; 50  0.4711538  0.44153005  0.49754241  0.32749149  0.24840605  0.32456388
#&gt; 51  0.4711538  0.32562433  0.23887414  0.26764033  0.24950898  0.30432045
#&gt; 52  0.4711538 -0.23250098 -0.28713647 -0.09216174 -0.12709475 -0.18324647
#&gt; 53  0.4711538  0.53388610  0.47710127  0.60836140  0.48273912  0.43334108
#&gt; 54  0.4711538  0.64191356  0.44931093  0.46371798  0.45275305  0.46653696
#&gt; 55  0.4711538  0.05279255  0.06829351  0.15306458  0.25200214  0.21249173
#&gt; 56  0.4711538  0.59808020  0.64333345  0.53741245  0.64108173  0.57876914
#&gt; 57  0.4711538  0.53093147  0.62138656  0.92046148  0.93004391  0.95130430
#&gt; 58  0.4711538  0.64943097  0.57141374  0.66800038  0.64835800  0.65566321
#&gt; 59  0.4711538  0.42541400  0.43027409  0.30117492  0.36183156  0.29992796
#&gt; 60  0.4711538  0.24537249  0.29963849  0.42931558  0.51048830  0.58927966
#&gt; 61  0.4711538  0.64269314  0.62785202  0.75163561  0.68045267  0.67000184
#&gt; 62  0.4711538  0.51277761  0.60877778  0.75493489  0.66735142  0.63862193
#&gt; 63  0.4711538  0.53377378  0.53228159  0.56245626  0.58414332  0.61176055
#&gt; 64  0.4711538  0.79099666  0.90572246  0.92244949  0.93001276  0.93454809
#&gt; 65  0.4711538  0.73768777  0.61339931  0.72362105  0.70536287  0.69970096
#&gt; 66  0.4711538  0.70767466  0.53408924  0.50675818  0.52181506  0.54559559
#&gt; 67  0.4711538  0.96312042  1.17012215  1.08116795  1.22497425  1.21728258
#&gt; 68  0.4711538  0.31575995  0.57179559  0.77297374  0.78532935  0.78484987
#&gt; 69  0.4711538  0.69505872  0.78176548  0.74300700  0.72711033  0.70750770
#&gt; 70  0.4711538  0.72276362  0.90232185  0.89364576  0.84428623  0.92659977
#&gt; 71  0.4711538  0.50950893  0.39503961  0.45591683  0.38297596  0.35086204
#&gt; 72  0.4711538  0.14720074  0.13538571 -0.04473829 -0.05529233  0.02748516
#&gt; 73  0.4711538  0.49275110  0.44937896  0.41856171  0.62470016  0.61654596
#&gt; 74  0.4711538  0.65674324  0.69439259  0.75479685  0.88511667  0.92560996
#&gt; 75  0.4711538  0.68716407  0.57541914  0.59945962  0.54581071  0.55228791
#&gt; 76  0.4711538  0.54839542  0.50508123  0.52627725  0.55765709  0.52543838
#&gt; 77  0.4711538  0.77317727  0.79812663  0.93073165  1.10301473  1.08723742
#&gt; 78  0.4711538  0.85322027  0.76128342  0.81061207  0.85796753  0.87947603
#&gt; 79  0.4711538  0.81659194  0.90228252  0.80744839  0.70383361  0.68468090
#&gt; 80  0.4711538  0.55964651  0.44326524  0.39507689  0.36149039  0.32071350
#&gt; 81  0.4711538  0.87105473  0.86695796  0.89177640  0.74816339  0.69831750
#&gt; 82  0.4711538  0.47715869  0.68930595  0.71280202  0.73606020  0.78321326
#&gt; 83  0.4711538  0.80974821  0.87138779  0.97466313  0.93082943  0.95560886
#&gt; 84  0.4711538  0.67739807  0.85743609  0.98894432  0.96011041  0.90800271
#&gt; 85  0.4711538  0.57131444  0.34250950  0.33855791  0.31118498  0.31383288
#&gt; 86  0.4711538  0.84958765  0.97611051  0.93090902  0.91560248  0.86222031
#&gt; 87  0.4711538  0.57644613  0.41449248  0.48714466  0.54811918  0.57041511
#&gt; 88  0.4711538  0.75932310  0.71214369  0.52234742  0.59011684  0.59023780
#&gt; 89  0.4711538  0.53031516  0.47090892  0.42433053  0.38847912  0.39218094
#&gt; 90  0.4711538  0.76770402  1.07649866  1.00864429  1.06363018  1.09017457
#&gt; 91  0.4711538  0.38643842  0.37696993  0.44452861  0.49450298  0.46628856
#&gt; 92  0.4711538  0.92591633  1.03707888  0.96084369  0.95688931  0.93400393
#&gt; 93  0.4711538  0.66726042  0.89247800  0.87390628  0.87335977  0.95801535
#&gt; 94  0.4711538  0.32634752  0.41373057  0.48066349  0.67273089  0.62115180
#&gt; 95  0.4711538  0.50472276  0.77159222  0.71730564  0.62350221  0.64335334
#&gt; 96  0.4711538  0.34622269  0.33150717  0.49412629  0.44574013  0.46889514
#&gt; 97  0.4711538  0.55805257  0.50280611  0.58541977  0.52239953  0.53556273
#&gt; 98  0.4711538  0.78090964  0.73429355  0.79385683  0.86651416  0.88151677
#&gt; 99  0.4711538  0.21116352  0.10917861  0.02565398  0.18342015  0.15222876
#&gt; 100 0.4711538  0.66672702  0.78264411  0.86306662  0.75733969  0.77632472
#&gt; 101 0.4711538  0.45317545  0.50149615  0.62617428  0.70904267  0.78134354
#&gt; 102 0.4711538  0.74435376  0.66135006  0.72568147  0.70203564  0.77593538
#&gt; 103 0.4711538  0.34690226  0.56605434  0.52782336  0.50951738  0.46795757
#&gt; 104 0.4711538  0.69496014  0.80515138  0.78871059  0.78008789  0.78042831
#&gt;            [,7]         [,8]         [,9]       [,10]       [,11]
#&gt; 1    0.64037279  0.627340571  0.651243676  0.65354280  0.65838797
#&gt; 2    0.21304385  0.202666528  0.206463548  0.21046038  0.20470356
#&gt; 3   -0.22444089 -0.193652144 -0.201652437 -0.20167289 -0.20081532
#&gt; 4    0.58413761  0.600377920  0.608768219  0.60784745  0.60193905
#&gt; 5   -0.26327049 -0.311781941 -0.310765976 -0.31066830 -0.31401382
#&gt; 6   -0.10341096 -0.076840858 -0.080016598 -0.08436785 -0.08777135
#&gt; 7    0.10261786  0.132750517  0.144750243  0.13944940  0.14173177
#&gt; 8    0.04809780  0.063736599  0.063261540  0.07570783  0.07715150
#&gt; 9    0.44543808  0.444943670  0.447021225  0.44582742  0.44748513
#&gt; 10   0.43490588  0.407005593  0.413663760  0.41349216  0.41350336
#&gt; 11   0.78695284  0.777623618  0.783734315  0.78262765  0.77949531
#&gt; 12   0.65654818  0.642154505  0.633436560  0.63197252  0.62875264
#&gt; 13   0.21708341  0.187509114  0.186533541  0.17822088  0.17842513
#&gt; 14   0.28651410  0.260501290  0.279081223  0.27196942  0.26996735
#&gt; 15   0.05784774  0.095949877  0.090894676  0.08865039  0.09080522
#&gt; 16  -0.06239212 -0.039505632 -0.023469898 -0.02045198 -0.02715190
#&gt; 17   0.33482409  0.336193547  0.335468481  0.33501592  0.33670840
#&gt; 18   0.59257402  0.580678556  0.581449676  0.58013547  0.57927640
#&gt; 19   0.24272344  0.246701307  0.240991178  0.23822863  0.23157123
#&gt; 20   0.40555564  0.386074751  0.400419290  0.40843493  0.40860630
#&gt; 21   0.53582205  0.549336181  0.539598759  0.54139679  0.54098845
#&gt; 22   0.27214775  0.265323031  0.262889367  0.27124503  0.27372049
#&gt; 23   0.26310951  0.254264842  0.244111736  0.24044626  0.24169731
#&gt; 24   0.10789143  0.136298989  0.142908568  0.14863967  0.15404679
#&gt; 25   0.62754156  0.650367844  0.644944061  0.64644697  0.64416177
#&gt; 26   0.18477380  0.190402191  0.199245619  0.20152378  0.20582432
#&gt; 27   0.44358238  0.454283166  0.446210009  0.43311399  0.43568840
#&gt; 28   0.13769251  0.118081488  0.117589648  0.11048814  0.11155803
#&gt; 29   0.42759376  0.424018002  0.417256036  0.42362830  0.42160066
#&gt; 30   0.10952676  0.168692282  0.174041713  0.17387211  0.17480429
#&gt; 31   0.45876287  0.432435790  0.425259491  0.43329412  0.43856907
#&gt; 32   0.11742399  0.116981896  0.108778824  0.10636129  0.10689920
#&gt; 33   0.47697376  0.450738829  0.452062165  0.44881973  0.44992624
#&gt; 34   0.09863470  0.095862956  0.092253997  0.09980718  0.10084230
#&gt; 35  -0.08390506 -0.085155814 -0.086690885 -0.08262604 -0.08272575
#&gt; 36   0.45381739  0.433667887  0.449594388  0.44854107  0.44960414
#&gt; 37   0.30022320  0.311627620  0.315020647  0.31958491  0.32067580
#&gt; 38   0.15959719  0.160997289  0.151222415  0.15079738  0.14817778
#&gt; 39   0.27800144  0.253643110  0.255071837  0.25875102  0.25674198
#&gt; 40   0.51555833  0.530347073  0.528402618  0.52790558  0.52538704
#&gt; 41   0.09275154  0.101869980  0.090604733  0.09445259  0.09150467
#&gt; 42   0.50207194  0.483136866  0.487491071  0.48860245  0.49212211
#&gt; 43   0.57336835  0.573091866  0.546609274  0.54001848  0.54366888
#&gt; 44  -0.01451487 -0.004369241 -0.002647953 -0.00844687 -0.01073887
#&gt; 45   0.19657318  0.164988597  0.170522098  0.16781405  0.16715155
#&gt; 46   0.65287559  0.645084587  0.651535848  0.65177845  0.65178893
#&gt; 47   0.12452036  0.119913760  0.117053912  0.11873700  0.11591426
#&gt; 48   0.18275993  0.166998459  0.160605969  0.16869180  0.16855238
#&gt; 49   0.58006784  0.613009102  0.608873759  0.60785525  0.61021103
#&gt; 50   0.33208894  0.314978063  0.311974842  0.30517646  0.31174053
#&gt; 51   0.32816749  0.318321881  0.320797741  0.31281691  0.31540371
#&gt; 52  -0.19584259 -0.184768370 -0.177691131 -0.18225253 -0.18172040
#&gt; 53   0.40794213  0.415136651  0.416044038  0.42408314  0.42075636
#&gt; 54   0.46480524  0.479688395  0.471302624  0.46613648  0.46656474
#&gt; 55   0.23097197  0.213772954  0.189358085  0.18930563  0.19050731
#&gt; 56   0.57331393  0.574558380  0.579775660  0.57922184  0.57800858
#&gt; 57   0.96183872  0.975414458  0.968855613  0.96385549  0.96028958
#&gt; 58   0.64361788  0.631632631  0.641013340  0.63785489  0.64045306
#&gt; 59   0.28643229  0.289148607  0.278791345  0.28784917  0.28782462
#&gt; 60   0.55978204  0.559023840  0.561630138  0.55671889  0.55726966
#&gt; 61   0.65787202  0.659412106  0.650588243  0.64930310  0.65091617
#&gt; 62   0.60705201  0.603977438  0.589826600  0.58812271  0.58793743
#&gt; 63   0.63813827  0.617717657  0.614454772  0.61166047  0.60985403
#&gt; 64   1.00166279  1.008968255  1.008852814  1.01022555  1.00666729
#&gt; 65   0.69297263  0.697694744  0.689810628  0.69214943  0.69038662
#&gt; 66   0.53663407  0.532369158  0.535934708  0.53171176  0.53102146
#&gt; 67   1.22111150  1.202569147  1.194030443  1.19310867  1.19228184
#&gt; 68   0.80071187  0.812462410  0.796883689  0.80360414  0.80689017
#&gt; 69   0.74791867  0.774669023  0.764357440  0.76435231  0.76730276
#&gt; 70   0.93952180  0.926356875  0.916496158  0.91637035  0.92383169
#&gt; 71   0.31179970  0.319584982  0.342996678  0.34334588  0.34349096
#&gt; 72   0.08069763  0.064883087  0.053282640  0.04500807  0.04571864
#&gt; 73   0.63914960  0.656024336  0.647841400  0.64971036  0.64930911
#&gt; 74   0.94540783  0.945531101  0.947433351  0.95548576  0.95086945
#&gt; 75   0.56609663  0.581051527  0.586510546  0.58350518  0.58195688
#&gt; 76   0.49807985  0.507124137  0.503700114  0.50352891  0.50289031
#&gt; 77   1.06463806  1.090636226  1.099163425  1.09692704  1.09684987
#&gt; 78   0.88947890  0.914074686  0.921993535  0.92611779  0.92473772
#&gt; 79   0.70672170  0.689699520  0.693322761  0.69306283  0.69031633
#&gt; 80   0.30181332  0.296560012  0.282907508  0.28672758  0.28334638
#&gt; 81   0.69871492  0.692603330  0.692711040  0.69448149  0.69353087
#&gt; 82   0.73754433  0.755515607  0.753806256  0.76075515  0.76006115
#&gt; 83   0.95554583  0.981114506  0.967899112  0.96789876  0.97167928
#&gt; 84   0.92460814  0.928255751  0.934569121  0.93157477  0.93560641
#&gt; 85   0.31932547  0.326702214  0.334191767  0.33780085  0.33863677
#&gt; 86   0.82950069  0.806588554  0.823792983  0.82202715  0.81981455
#&gt; 87   0.56750119  0.560439488  0.549720853  0.54609905  0.54656224
#&gt; 88   0.57484476  0.588841816  0.582284530  0.57334028  0.57098492
#&gt; 89   0.44028895  0.455790854  0.462215323  0.46149391  0.46635298
#&gt; 90   1.08703587  1.113909884  1.123382027  1.12669615  1.12559691
#&gt; 91   0.50591629  0.528734399  0.542033081  0.53789411  0.54025902
#&gt; 92   0.95078882  0.944122848  0.933909143  0.93429933  0.92818920
#&gt; 93   0.95048831  0.984993815  0.999870929  0.99916201  0.99970721
#&gt; 94   0.63222931  0.617803323  0.604620965  0.60316670  0.59998131
#&gt; 95   0.60173453  0.598838861  0.615665753  0.61062288  0.61003734
#&gt; 96   0.42461082  0.393735123  0.382307431  0.38698306  0.38928062
#&gt; 97   0.55493331  0.545341350  0.548945997  0.55196226  0.55110104
#&gt; 98   0.84875293  0.849088124  0.833445596  0.82896512  0.82882885
#&gt; 99   0.12817884  0.125184677  0.142524174  0.14250387  0.14467219
#&gt; 100  0.76010896  0.740234308  0.744642249  0.75159300  0.75722807
#&gt; 101  0.80270481  0.778624924  0.777761525  0.78102072  0.77766043
#&gt; 102  0.77647730  0.755860583  0.764875857  0.76840548  0.77181270
#&gt; 103  0.50588630  0.488855008  0.495423757  0.50188675  0.50526664
#&gt; 104  0.81071639  0.804180721  0.825464815  0.81861016  0.81635531</div><div class='input'><span class='co'>#Truncated to [0;1] predicted values (true probabilities)</span>
<span class='va'>modpls.aze</span><span class='op'>$</span><span class='va'>Probs.trc</span>
</div><div class='output co'>#&gt;          [,1]       [,2]       [,3]       [,4]       [,5]       [,6]       [,7]
#&gt; 1   0.4711538 0.46105744 0.63458141 0.67961627 0.69452246 0.64534767 0.64037279
#&gt; 2   0.4711538 0.26911816 0.26581497 0.16989268 0.11760783 0.18096700 0.21304385
#&gt; 3   0.4711538 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 4   0.4711538 0.36370490 0.54112657 0.50724821 0.55508565 0.57773785 0.58413761
#&gt; 5   0.4711538 0.00000000 0.07399231 0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 6   0.4711538 0.00000000 0.17275288 0.01806190 0.00000000 0.00000000 0.00000000
#&gt; 7   0.4711538 0.00000000 0.00000000 0.00000000 0.01116043 0.06506517 0.10261786
#&gt; 8   0.4711538 0.27158233 0.24933653 0.11611522 0.12804487 0.04118115 0.04809780
#&gt; 9   0.4711538 0.76949497 0.60296556 0.47237794 0.51581382 0.49885092 0.44543808
#&gt; 10  0.4711538 0.22096539 0.34482052 0.34660816 0.38580378 0.43528451 0.43490588
#&gt; 11  0.4711538 0.87147914 0.84865348 0.76372713 0.73582307 0.76725258 0.78695284
#&gt; 12  0.4711538 0.79792975 0.67828859 0.73747065 0.67844373 0.67908585 0.65654818
#&gt; 13  0.4711538 0.09432664 0.00000000 0.10780023 0.22488457 0.26144110 0.21708341
#&gt; 14  0.4711538 0.28543133 0.29293086 0.37385135 0.37961001 0.30207755 0.28651410
#&gt; 15  0.4711538 0.30637401 0.27816310 0.18074751 0.01510565 0.05074255 0.05784774
#&gt; 16  0.4711538 0.12893721 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 17  0.4711538 0.59910292 0.41302582 0.40055026 0.32477692 0.32429673 0.33482409
#&gt; 18  0.4711538 0.60665328 0.51461671 0.70351041 0.63093215 0.60232625 0.59257402
#&gt; 19  0.4711538 0.18381206 0.36596047 0.33591603 0.25289460 0.21859872 0.24272344
#&gt; 20  0.4711538 0.28422822 0.15202852 0.29980632 0.42075827 0.43463142 0.40555564
#&gt; 21  0.4711538 0.35982960 0.40300075 0.63220247 0.58056075 0.55273462 0.53582205
#&gt; 22  0.4711538 0.31574837 0.28422517 0.37116719 0.27156145 0.25529246 0.27214775
#&gt; 23  0.4711538 0.41682757 0.36900849 0.23791176 0.25730930 0.24221472 0.26310951
#&gt; 24  0.4711538 0.30288056 0.15972272 0.19362318 0.07194768 0.07250435 0.10789143
#&gt; 25  0.4711538 0.29650015 0.48867070 0.61025747 0.59737342 0.67704212 0.62754156
#&gt; 26  0.4711538 0.23008536 0.32001822 0.15862645 0.26312675 0.22513847 0.18477380
#&gt; 27  0.4711538 0.67526360 0.68123526 0.58796740 0.51309143 0.44381568 0.44358238
#&gt; 28  0.4711538 0.15222775 0.13544964 0.15605402 0.15868232 0.10574096 0.13769251
#&gt; 29  0.4711538 0.43138914 0.29576924 0.29706087 0.35294305 0.40257625 0.42759376
#&gt; 30  0.4711538 0.13910581 0.26763382 0.10182481 0.12169881 0.13543560 0.10952676
#&gt; 31  0.4711538 0.40295972 0.43810789 0.28684877 0.41632594 0.45388666 0.45876287
#&gt; 32  0.4711538 0.58422149 0.44366239 0.16615851 0.15367980 0.18291151 0.11742399
#&gt; 33  0.4711538 0.69889100 0.72592310 0.57845537 0.50185886 0.51841164 0.47697376
#&gt; 34  0.4711538 0.35960908 0.24234167 0.09364940 0.08428214 0.10528276 0.09863470
#&gt; 35  0.4711538 0.27914959 0.03731133 0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 36  0.4711538 0.38865989 0.39024480 0.44138316 0.47508801 0.42329842 0.45381739
#&gt; 37  0.4711538 0.62200134 0.42145828 0.38142396 0.29675933 0.28947211 0.30022320
#&gt; 38  0.4711538 0.41311694 0.19970983 0.16702613 0.17059545 0.17073272 0.15959719
#&gt; 39  0.4711538 0.31755422 0.28395547 0.17609314 0.23875966 0.25763504 0.27800144
#&gt; 40  0.4711538 0.62628933 0.51627261 0.52025889 0.47789760 0.47304606 0.51555833
#&gt; 41  0.4711538 0.14894845 0.14069540 0.13906223 0.05976750 0.13670893 0.09275154
#&gt; 42  0.4711538 0.64041121 0.49727655 0.49380105 0.53239359 0.51394469 0.50207194
#&gt; 43  0.4711538 0.38696544 0.54930653 0.62650411 0.65244562 0.56755351 0.57336835
#&gt; 44  0.4711538 0.24204195 0.05825611 0.02230584 0.00000000 0.00000000 0.00000000
#&gt; 45  0.4711538 0.10349021 0.14957660 0.16304594 0.15564790 0.17065395 0.19657318
#&gt; 46  0.4711538 0.63322787 0.64625855 0.55541948 0.65203351 0.63670168 0.65287559
#&gt; 47  0.4711538 0.20557889 0.23864853 0.24328712 0.13063078 0.09743813 0.12452036
#&gt; 48  0.4711538 0.32352238 0.34894312 0.21162810 0.20487572 0.16461876 0.18275993
#&gt; 49  0.4711538 0.64888519 0.52290405 0.50926772 0.62061797 0.59597941 0.58006784
#&gt; 50  0.4711538 0.44153005 0.49754241 0.32749149 0.24840605 0.32456388 0.33208894
#&gt; 51  0.4711538 0.32562433 0.23887414 0.26764033 0.24950898 0.30432045 0.32816749
#&gt; 52  0.4711538 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 53  0.4711538 0.53388610 0.47710127 0.60836140 0.48273912 0.43334108 0.40794213
#&gt; 54  0.4711538 0.64191356 0.44931093 0.46371798 0.45275305 0.46653696 0.46480524
#&gt; 55  0.4711538 0.05279255 0.06829351 0.15306458 0.25200214 0.21249173 0.23097197
#&gt; 56  0.4711538 0.59808020 0.64333345 0.53741245 0.64108173 0.57876914 0.57331393
#&gt; 57  0.4711538 0.53093147 0.62138656 0.92046148 0.93004391 0.95130430 0.96183872
#&gt; 58  0.4711538 0.64943097 0.57141374 0.66800038 0.64835800 0.65566321 0.64361788
#&gt; 59  0.4711538 0.42541400 0.43027409 0.30117492 0.36183156 0.29992796 0.28643229
#&gt; 60  0.4711538 0.24537249 0.29963849 0.42931558 0.51048830 0.58927966 0.55978204
#&gt; 61  0.4711538 0.64269314 0.62785202 0.75163561 0.68045267 0.67000184 0.65787202
#&gt; 62  0.4711538 0.51277761 0.60877778 0.75493489 0.66735142 0.63862193 0.60705201
#&gt; 63  0.4711538 0.53377378 0.53228159 0.56245626 0.58414332 0.61176055 0.63813827
#&gt; 64  0.4711538 0.79099666 0.90572246 0.92244949 0.93001276 0.93454809 1.00000000
#&gt; 65  0.4711538 0.73768777 0.61339931 0.72362105 0.70536287 0.69970096 0.69297263
#&gt; 66  0.4711538 0.70767466 0.53408924 0.50675818 0.52181506 0.54559559 0.53663407
#&gt; 67  0.4711538 0.96312042 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000
#&gt; 68  0.4711538 0.31575995 0.57179559 0.77297374 0.78532935 0.78484987 0.80071187
#&gt; 69  0.4711538 0.69505872 0.78176548 0.74300700 0.72711033 0.70750770 0.74791867
#&gt; 70  0.4711538 0.72276362 0.90232185 0.89364576 0.84428623 0.92659977 0.93952180
#&gt; 71  0.4711538 0.50950893 0.39503961 0.45591683 0.38297596 0.35086204 0.31179970
#&gt; 72  0.4711538 0.14720074 0.13538571 0.00000000 0.00000000 0.02748516 0.08069763
#&gt; 73  0.4711538 0.49275110 0.44937896 0.41856171 0.62470016 0.61654596 0.63914960
#&gt; 74  0.4711538 0.65674324 0.69439259 0.75479685 0.88511667 0.92560996 0.94540783
#&gt; 75  0.4711538 0.68716407 0.57541914 0.59945962 0.54581071 0.55228791 0.56609663
#&gt; 76  0.4711538 0.54839542 0.50508123 0.52627725 0.55765709 0.52543838 0.49807985
#&gt; 77  0.4711538 0.77317727 0.79812663 0.93073165 1.00000000 1.00000000 1.00000000
#&gt; 78  0.4711538 0.85322027 0.76128342 0.81061207 0.85796753 0.87947603 0.88947890
#&gt; 79  0.4711538 0.81659194 0.90228252 0.80744839 0.70383361 0.68468090 0.70672170
#&gt; 80  0.4711538 0.55964651 0.44326524 0.39507689 0.36149039 0.32071350 0.30181332
#&gt; 81  0.4711538 0.87105473 0.86695796 0.89177640 0.74816339 0.69831750 0.69871492
#&gt; 82  0.4711538 0.47715869 0.68930595 0.71280202 0.73606020 0.78321326 0.73754433
#&gt; 83  0.4711538 0.80974821 0.87138779 0.97466313 0.93082943 0.95560886 0.95554583
#&gt; 84  0.4711538 0.67739807 0.85743609 0.98894432 0.96011041 0.90800271 0.92460814
#&gt; 85  0.4711538 0.57131444 0.34250950 0.33855791 0.31118498 0.31383288 0.31932547
#&gt; 86  0.4711538 0.84958765 0.97611051 0.93090902 0.91560248 0.86222031 0.82950069
#&gt; 87  0.4711538 0.57644613 0.41449248 0.48714466 0.54811918 0.57041511 0.56750119
#&gt; 88  0.4711538 0.75932310 0.71214369 0.52234742 0.59011684 0.59023780 0.57484476
#&gt; 89  0.4711538 0.53031516 0.47090892 0.42433053 0.38847912 0.39218094 0.44028895
#&gt; 90  0.4711538 0.76770402 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000
#&gt; 91  0.4711538 0.38643842 0.37696993 0.44452861 0.49450298 0.46628856 0.50591629
#&gt; 92  0.4711538 0.92591633 1.00000000 0.96084369 0.95688931 0.93400393 0.95078882
#&gt; 93  0.4711538 0.66726042 0.89247800 0.87390628 0.87335977 0.95801535 0.95048831
#&gt; 94  0.4711538 0.32634752 0.41373057 0.48066349 0.67273089 0.62115180 0.63222931
#&gt; 95  0.4711538 0.50472276 0.77159222 0.71730564 0.62350221 0.64335334 0.60173453
#&gt; 96  0.4711538 0.34622269 0.33150717 0.49412629 0.44574013 0.46889514 0.42461082
#&gt; 97  0.4711538 0.55805257 0.50280611 0.58541977 0.52239953 0.53556273 0.55493331
#&gt; 98  0.4711538 0.78090964 0.73429355 0.79385683 0.86651416 0.88151677 0.84875293
#&gt; 99  0.4711538 0.21116352 0.10917861 0.02565398 0.18342015 0.15222876 0.12817884
#&gt; 100 0.4711538 0.66672702 0.78264411 0.86306662 0.75733969 0.77632472 0.76010896
#&gt; 101 0.4711538 0.45317545 0.50149615 0.62617428 0.70904267 0.78134354 0.80270481
#&gt; 102 0.4711538 0.74435376 0.66135006 0.72568147 0.70203564 0.77593538 0.77647730
#&gt; 103 0.4711538 0.34690226 0.56605434 0.52782336 0.50951738 0.46795757 0.50588630
#&gt; 104 0.4711538 0.69496014 0.80515138 0.78871059 0.78008789 0.78042831 0.81071639
#&gt;           [,8]       [,9]      [,10]      [,11]
#&gt; 1   0.62734057 0.65124368 0.65354280 0.65838797
#&gt; 2   0.20266653 0.20646355 0.21046038 0.20470356
#&gt; 3   0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 4   0.60037792 0.60876822 0.60784745 0.60193905
#&gt; 5   0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 6   0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 7   0.13275052 0.14475024 0.13944940 0.14173177
#&gt; 8   0.06373660 0.06326154 0.07570783 0.07715150
#&gt; 9   0.44494367 0.44702123 0.44582742 0.44748513
#&gt; 10  0.40700559 0.41366376 0.41349216 0.41350336
#&gt; 11  0.77762362 0.78373432 0.78262765 0.77949531
#&gt; 12  0.64215450 0.63343656 0.63197252 0.62875264
#&gt; 13  0.18750911 0.18653354 0.17822088 0.17842513
#&gt; 14  0.26050129 0.27908122 0.27196942 0.26996735
#&gt; 15  0.09594988 0.09089468 0.08865039 0.09080522
#&gt; 16  0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 17  0.33619355 0.33546848 0.33501592 0.33670840
#&gt; 18  0.58067856 0.58144968 0.58013547 0.57927640
#&gt; 19  0.24670131 0.24099118 0.23822863 0.23157123
#&gt; 20  0.38607475 0.40041929 0.40843493 0.40860630
#&gt; 21  0.54933618 0.53959876 0.54139679 0.54098845
#&gt; 22  0.26532303 0.26288937 0.27124503 0.27372049
#&gt; 23  0.25426484 0.24411174 0.24044626 0.24169731
#&gt; 24  0.13629899 0.14290857 0.14863967 0.15404679
#&gt; 25  0.65036784 0.64494406 0.64644697 0.64416177
#&gt; 26  0.19040219 0.19924562 0.20152378 0.20582432
#&gt; 27  0.45428317 0.44621001 0.43311399 0.43568840
#&gt; 28  0.11808149 0.11758965 0.11048814 0.11155803
#&gt; 29  0.42401800 0.41725604 0.42362830 0.42160066
#&gt; 30  0.16869228 0.17404171 0.17387211 0.17480429
#&gt; 31  0.43243579 0.42525949 0.43329412 0.43856907
#&gt; 32  0.11698190 0.10877882 0.10636129 0.10689920
#&gt; 33  0.45073883 0.45206217 0.44881973 0.44992624
#&gt; 34  0.09586296 0.09225400 0.09980718 0.10084230
#&gt; 35  0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 36  0.43366789 0.44959439 0.44854107 0.44960414
#&gt; 37  0.31162762 0.31502065 0.31958491 0.32067580
#&gt; 38  0.16099729 0.15122241 0.15079738 0.14817778
#&gt; 39  0.25364311 0.25507184 0.25875102 0.25674198
#&gt; 40  0.53034707 0.52840262 0.52790558 0.52538704
#&gt; 41  0.10186998 0.09060473 0.09445259 0.09150467
#&gt; 42  0.48313687 0.48749107 0.48860245 0.49212211
#&gt; 43  0.57309187 0.54660927 0.54001848 0.54366888
#&gt; 44  0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 45  0.16498860 0.17052210 0.16781405 0.16715155
#&gt; 46  0.64508459 0.65153585 0.65177845 0.65178893
#&gt; 47  0.11991376 0.11705391 0.11873700 0.11591426
#&gt; 48  0.16699846 0.16060597 0.16869180 0.16855238
#&gt; 49  0.61300910 0.60887376 0.60785525 0.61021103
#&gt; 50  0.31497806 0.31197484 0.30517646 0.31174053
#&gt; 51  0.31832188 0.32079774 0.31281691 0.31540371
#&gt; 52  0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 53  0.41513665 0.41604404 0.42408314 0.42075636
#&gt; 54  0.47968839 0.47130262 0.46613648 0.46656474
#&gt; 55  0.21377295 0.18935809 0.18930563 0.19050731
#&gt; 56  0.57455838 0.57977566 0.57922184 0.57800858
#&gt; 57  0.97541446 0.96885561 0.96385549 0.96028958
#&gt; 58  0.63163263 0.64101334 0.63785489 0.64045306
#&gt; 59  0.28914861 0.27879135 0.28784917 0.28782462
#&gt; 60  0.55902384 0.56163014 0.55671889 0.55726966
#&gt; 61  0.65941211 0.65058824 0.64930310 0.65091617
#&gt; 62  0.60397744 0.58982660 0.58812271 0.58793743
#&gt; 63  0.61771766 0.61445477 0.61166047 0.60985403
#&gt; 64  1.00000000 1.00000000 1.00000000 1.00000000
#&gt; 65  0.69769474 0.68981063 0.69214943 0.69038662
#&gt; 66  0.53236916 0.53593471 0.53171176 0.53102146
#&gt; 67  1.00000000 1.00000000 1.00000000 1.00000000
#&gt; 68  0.81246241 0.79688369 0.80360414 0.80689017
#&gt; 69  0.77466902 0.76435744 0.76435231 0.76730276
#&gt; 70  0.92635688 0.91649616 0.91637035 0.92383169
#&gt; 71  0.31958498 0.34299668 0.34334588 0.34349096
#&gt; 72  0.06488309 0.05328264 0.04500807 0.04571864
#&gt; 73  0.65602434 0.64784140 0.64971036 0.64930911
#&gt; 74  0.94553110 0.94743335 0.95548576 0.95086945
#&gt; 75  0.58105153 0.58651055 0.58350518 0.58195688
#&gt; 76  0.50712414 0.50370011 0.50352891 0.50289031
#&gt; 77  1.00000000 1.00000000 1.00000000 1.00000000
#&gt; 78  0.91407469 0.92199353 0.92611779 0.92473772
#&gt; 79  0.68969952 0.69332276 0.69306283 0.69031633
#&gt; 80  0.29656001 0.28290751 0.28672758 0.28334638
#&gt; 81  0.69260333 0.69271104 0.69448149 0.69353087
#&gt; 82  0.75551561 0.75380626 0.76075515 0.76006115
#&gt; 83  0.98111451 0.96789911 0.96789876 0.97167928
#&gt; 84  0.92825575 0.93456912 0.93157477 0.93560641
#&gt; 85  0.32670221 0.33419177 0.33780085 0.33863677
#&gt; 86  0.80658855 0.82379298 0.82202715 0.81981455
#&gt; 87  0.56043949 0.54972085 0.54609905 0.54656224
#&gt; 88  0.58884182 0.58228453 0.57334028 0.57098492
#&gt; 89  0.45579085 0.46221532 0.46149391 0.46635298
#&gt; 90  1.00000000 1.00000000 1.00000000 1.00000000
#&gt; 91  0.52873440 0.54203308 0.53789411 0.54025902
#&gt; 92  0.94412285 0.93390914 0.93429933 0.92818920
#&gt; 93  0.98499381 0.99987093 0.99916201 0.99970721
#&gt; 94  0.61780332 0.60462097 0.60316670 0.59998131
#&gt; 95  0.59883886 0.61566575 0.61062288 0.61003734
#&gt; 96  0.39373512 0.38230743 0.38698306 0.38928062
#&gt; 97  0.54534135 0.54894600 0.55196226 0.55110104
#&gt; 98  0.84908812 0.83344560 0.82896512 0.82882885
#&gt; 99  0.12518468 0.14252417 0.14250387 0.14467219
#&gt; 100 0.74023431 0.74464225 0.75159300 0.75722807
#&gt; 101 0.77862492 0.77776152 0.78102072 0.77766043
#&gt; 102 0.75586058 0.76487586 0.76840548 0.77181270
#&gt; 103 0.48885501 0.49542376 0.50188675 0.50526664
#&gt; 104 0.80418072 0.82546481 0.81861016 0.81635531</div><div class='input'><span class='va'>modpls.aze</span><span class='op'>$</span><span class='va'>Probs</span><span class='op'>-</span><span class='va'>modpls.aze</span><span class='op'>$</span><span class='va'>Probs.trc</span>
</div><div class='output co'>#&gt;     [,1]        [,2]        [,3]         [,4]        [,5]        [,6]
#&gt; 1      0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 2      0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 3      0 -0.09080494 -0.05104846 -0.171669164 -0.21455242 -0.21725391
#&gt; 4      0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 5      0 -0.04408124  0.00000000 -0.071299085 -0.24018962 -0.23445282
#&gt; 6      0 -0.03776963  0.00000000  0.000000000 -0.02597539 -0.06284454
#&gt; 7      0 -0.06930728 -0.19928456 -0.091372612  0.00000000  0.00000000
#&gt; 8      0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 9      0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 10     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 11     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 12     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 13     0  0.00000000 -0.04344681  0.000000000  0.00000000  0.00000000
#&gt; 14     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 15     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 16     0  0.00000000 -0.07276258 -0.051465557 -0.09988241 -0.06790398
#&gt; 17     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 18     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 19     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 20     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 21     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 22     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 23     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 24     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 25     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 26     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 27     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 28     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 29     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 30     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 31     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 32     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 33     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 34     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 35     0  0.00000000  0.00000000 -0.088960742 -0.06232370 -0.08231459
#&gt; 36     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 37     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 38     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 39     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 40     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 41     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 42     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 43     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 44     0  0.00000000  0.00000000  0.000000000 -0.01790809 -0.03785626
#&gt; 45     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 46     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 47     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 48     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 49     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 50     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 51     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 52     0 -0.23250098 -0.28713647 -0.092161735 -0.12709475 -0.18324647
#&gt; 53     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 54     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 55     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 56     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 57     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 58     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 59     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 60     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 61     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 62     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 63     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 64     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 65     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 66     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 67     0  0.00000000  0.17012215  0.081167947  0.22497425  0.21728258
#&gt; 68     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 69     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 70     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 71     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 72     0  0.00000000  0.00000000 -0.044738287 -0.05529233  0.00000000
#&gt; 73     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 74     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 75     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 76     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 77     0  0.00000000  0.00000000  0.000000000  0.10301473  0.08723742
#&gt; 78     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 79     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 80     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 81     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 82     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 83     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 84     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 85     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 86     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 87     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 88     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 89     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 90     0  0.00000000  0.07649866  0.008644293  0.06363018  0.09017457
#&gt; 91     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 92     0  0.00000000  0.03707888  0.000000000  0.00000000  0.00000000
#&gt; 93     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 94     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 95     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 96     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 97     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 98     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 99     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 100    0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 101    0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 102    0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 103    0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 104    0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt;             [,7]         [,8]         [,9]       [,10]        [,11]
#&gt; 1    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 2    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 3   -0.224440890 -0.193652144 -0.201652437 -0.20167289 -0.200815325
#&gt; 4    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 5   -0.263270486 -0.311781941 -0.310765976 -0.31066830 -0.314013823
#&gt; 6   -0.103410961 -0.076840858 -0.080016598 -0.08436785 -0.087771351
#&gt; 7    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 8    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 9    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 10   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 11   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 12   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 13   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 14   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 15   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 16  -0.062392124 -0.039505632 -0.023469898 -0.02045198 -0.027151896
#&gt; 17   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 18   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 19   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 20   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 21   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 22   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 23   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 24   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 25   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 26   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 27   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 28   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 29   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 30   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 31   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 32   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 33   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 34   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 35  -0.083905063 -0.085155814 -0.086690885 -0.08262604 -0.082725745
#&gt; 36   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 37   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 38   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 39   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 40   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 41   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 42   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 43   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 44  -0.014514870 -0.004369241 -0.002647953 -0.00844687 -0.010738872
#&gt; 45   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 46   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 47   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 48   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 49   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 50   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 51   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 52  -0.195842587 -0.184768370 -0.177691131 -0.18225253 -0.181720401
#&gt; 53   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 54   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 55   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 56   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 57   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 58   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 59   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 60   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 61   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 62   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 63   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 64   0.001662791  0.008968255  0.008852814  0.01022555  0.006667285
#&gt; 65   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 66   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 67   0.221111495  0.202569147  0.194030443  0.19310867  0.192281835
#&gt; 68   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 69   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 70   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 71   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 72   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 73   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 74   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 75   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 76   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 77   0.064638063  0.090636226  0.099163425  0.09692704  0.096849873
#&gt; 78   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 79   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 80   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 81   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 82   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 83   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 84   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 85   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 86   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 87   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 88   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 89   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 90   0.087035865  0.113909884  0.123382027  0.12669615  0.125596908
#&gt; 91   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 92   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 93   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 94   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 95   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 96   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 97   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 98   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 99   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 100  0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 101  0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 102  0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 103  0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 104  0.000000000  0.000000000  0.000000000  0.00000000  0.000000000</div><div class='input'>
<span class='co'>#Repeated cross validation of the model (NK=100 times)</span>
<span class='va'>cv.modpls.aze</span><span class='op'>&lt;-</span><span class='fu'><a href='cv.plsR.html'>cv.plsR</a></span><span class='op'>(</span><span class='va'>y</span><span class='op'>~</span><span class='va'>.</span>,data<span class='op'>=</span><span class='va'>aze_compl</span>,<span class='fl'>10</span>,NK<span class='op'>=</span><span class='fl'>100</span>, verbose<span class='op'>=</span><span class='cn'>FALSE</span><span class='op'>)</span>
<span class='va'>res.cv.modpls.aze</span><span class='op'>&lt;-</span><span class='fu'><a href='cvtable.html'>cvtable</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>cv.modpls.aze</span>,MClassed<span class='op'>=</span><span class='cn'>TRUE</span><span class='op'>)</span><span class='op'>)</span>
</div><div class='output co'>#&gt; ____************************************************____
#&gt; ____Component____ 1 ____
#&gt; ____Component____ 2 ____
#&gt; ____Component____ 3 ____
#&gt; ____Component____ 4 ____
#&gt; ____Component____ 5 ____
#&gt; ____Component____ 6 ____
#&gt; ____Component____ 7 ____
#&gt; ____Component____ 8 ____
#&gt; ____Component____ 9 ____
#&gt; ____Component____ 10 ____
#&gt; ____Predicting X without NA neither in X nor in Y____
#&gt; ****________________________________________________****
#&gt; 
#&gt; 
#&gt; NK: 1,  2,  3,  4,  5,  6,  7,  8,  9,  10
#&gt; NK: 11,  12,  13,  14,  15,  16,  17,  18,  19,  20
#&gt; NK: 21,  22,  23,  24,  25,  26,  27,  28,  29,  30
#&gt; NK: 31,  32,  33,  34,  35,  36,  37,  38,  39,  40
#&gt; NK: 41,  42,  43,  44,  45,  46,  47,  48,  49,  50
#&gt; NK: 51,  52,  53,  54,  55,  56,  57,  58,  59,  60
#&gt; NK: 61,  62,  63,  64,  65,  66,  67,  68,  69,  70
#&gt; NK: 71,  72,  73,  74,  75,  76,  77,  78,  79,  80
#&gt; NK: 81,  82,  83,  84,  85,  86,  87,  88,  89,  90
#&gt; NK: 91,  92,  93,  94,  95,  96,  97,  98,  99,  100
#&gt; 
#&gt; CV MissClassed criterion:
#&gt;  1  2  3  4  5  6  7  8  9 10 
#&gt; 24 10 25 11  5  5  7  8  2  3 
#&gt; 
#&gt; CV Q2 criterion:
#&gt;   0 
#&gt; 100 
#&gt; 
#&gt; CV Press criterion:
#&gt;  1  2 
#&gt; 81 19 </div><div class='input'><span class='co'>#High discrepancy in the number of component choice using repeated cross validation</span>
<span class='co'>#and missclassed criterion</span>
<span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>res.cv.modpls.aze</span><span class='op'>)</span>
</div><div class='img'><img src='plsR-2.png' alt='' width='700' height='433' /></div><div class='input'>
<span class='fu'><a href='https://rdrr.io/r/base/rm.html'>rm</a></span><span class='op'>(</span>list<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"Xaze_compl"</span>,<span class='st'>"yaze_compl"</span>,<span class='st'>"modpls.aze"</span>,<span class='st'>"cv.modpls.aze"</span>,<span class='st'>"res.cv.modpls.aze"</span><span class='op'>)</span><span class='op'>)</span>

<span class='co'>#24 predictors</span>
<span class='va'>dimX</span> <span class='op'>&lt;-</span> <span class='fl'>24</span>
<span class='co'>#2 components</span>
<span class='va'>Astar</span> <span class='op'>&lt;-</span> <span class='fl'>2</span>
<span class='fu'><a href='simul_data_UniYX.html'>simul_data_UniYX</a></span><span class='op'>(</span><span class='va'>dimX</span>,<span class='va'>Astar</span><span class='op'>)</span>
</div><div class='output co'>#&gt;          Y         X1         X2         X3         X4         X5         X6 
#&gt; 11.6445768  0.6175008  0.6056228  5.1301635  0.6107449  0.6138664  5.1302654 
#&gt;         X7         X8         X9        X10        X11        X12        X13 
#&gt;  0.6402793  0.6103912  5.1466522  0.6048168  0.6205430  5.1257361  0.6101874 
#&gt;        X14        X15        X16        X17        X18        X19        X20 
#&gt;  0.6103582  5.1152508  0.6286553  0.6139872  5.1205242  0.6145876  0.6165494 
#&gt;        X21        X22        X23        X24 
#&gt;  5.1176202  0.6228756  0.6110989  5.1274519 </div><div class='input'><span class='va'>dataAstar2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/t.html'>t</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/lapply.html'>replicate</a></span><span class='op'>(</span><span class='fl'>250</span>,<span class='fu'><a href='simul_data_UniYX.html'>simul_data_UniYX</a></span><span class='op'>(</span><span class='va'>dimX</span>,<span class='va'>Astar</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
<span class='va'>modpls.A2</span><span class='op'>&lt;-</span> <span class='fu'>plsR</span><span class='op'>(</span><span class='va'>Y</span><span class='op'>~</span><span class='va'>.</span>,data<span class='op'>=</span><span class='va'>dataAstar2</span>,<span class='fl'>10</span>,typeVC<span class='op'>=</span><span class='st'>"standard"</span><span class='op'>)</span>
</div><div class='output co'>#&gt; ____************************************************____
#&gt; ____TypeVC____ standard ____
#&gt; ____Component____ 1 ____
#&gt; ____Component____ 2 ____
#&gt; ____Component____ 3 ____
#&gt; ____Component____ 4 ____
#&gt; ____Component____ 5 ____
#&gt; ____Component____ 6 ____
#&gt; ____Component____ 7 ____
#&gt; ____Component____ 8 ____
#&gt; ____Component____ 9 ____
#&gt; ____Component____ 10 ____
#&gt; ____Predicting X without NA neither in X nor in Y____
#&gt; ****________________________________________________****
#&gt; </div><div class='input'><span class='va'>modpls.A2</span>
</div><div class='output co'>#&gt; Number of required components:
#&gt; [1] 10
#&gt; Number of successfully computed components:
#&gt; [1] 10
#&gt; Coefficients:
#&gt;                   [,1]
#&gt; Intercept -0.009308745
#&gt; X1        -1.252039537
#&gt; X2         0.251769360
#&gt; X3         1.069303144
#&gt; X4        -1.523206574
#&gt; X5         0.429339251
#&gt; X6        -0.103727035
#&gt; X7         0.514838746
#&gt; X8        -0.008132813
#&gt; X9        -1.109769998
#&gt; X10        0.697707208
#&gt; X11        0.110179634
#&gt; X12        0.263432702
#&gt; X13        0.048981023
#&gt; X14        1.102957195
#&gt; X15        2.998639072
#&gt; X16       -1.030175931
#&gt; X17        0.005090035
#&gt; X18       -0.108388491
#&gt; X19        1.071595090
#&gt; X20        0.619985470
#&gt; X21       -0.996526239
#&gt; X22       -0.639107098
#&gt; X23        0.152756799
#&gt; X24        0.266087715
#&gt; Leave one out cross validated PRESS, Information criteria and Fit statistics:
#&gt;                  AIC   Q2cum_Y LimQ2_Y        Q2_Y     PRESS_Y        RSS_Y
#&gt; Nb_Comp_0  1707.6611        NA      NA          NA          NA 13336.080111
#&gt; Nb_Comp_1  1268.8401 0.8246912  0.0975  0.82469120 2337.932230  2286.881298
#&gt; Nb_Comp_2  -202.5201 0.9995127  0.0975  0.99722014    6.357207     6.306012
#&gt; Nb_Comp_3  -219.4997 0.9994751  0.0975 -0.07700506    6.791607     5.844991
#&gt; Nb_Comp_4  -219.7889 0.9993831  0.0975 -0.17536483    6.869997     5.791713
#&gt; Nb_Comp_5  -218.0111 0.9992724  0.0975 -0.17939626    6.830725     5.786567
#&gt; Nb_Comp_6  -216.0264 0.9991613  0.0975 -0.15268975    6.670117     5.786214
#&gt; Nb_Comp_7  -214.0278 0.9990390  0.0975 -0.14581108    6.629908     5.786181
#&gt; Nb_Comp_8  -212.0280 0.9989079  0.0975 -0.13650388    6.576018     5.786178
#&gt; Nb_Comp_9  -210.0280 0.9987662  0.0975 -0.12969385    6.536609     5.786177
#&gt; Nb_Comp_10 -208.0280 0.9986200  0.0975 -0.11849061    6.471785     5.786177
#&gt;                 R2_Y R2_residY  RSS_residY PRESS_residY   Q2_residY  LimQ2
#&gt; Nb_Comp_0         NA        NA 249.0000000           NA          NA     NA
#&gt; Nb_Comp_1  0.8285192 0.8285192  42.6987119   43.6518917  0.82469120 0.0975
#&gt; Nb_Comp_2  0.9995271 0.9995271   0.1177405    0.1186964  0.99722014 0.0975
#&gt; Nb_Comp_3  0.9995617 0.9995617   0.1091327    0.1268071 -0.07700506 0.0975
#&gt; Nb_Comp_4  0.9995657 0.9995657   0.1081380    0.1282708 -0.17536483 0.0975
#&gt; Nb_Comp_5  0.9995661 0.9995661   0.1080419    0.1275375 -0.17939626 0.0975
#&gt; Nb_Comp_6  0.9995661 0.9995661   0.1080353    0.1245388 -0.15268975 0.0975
#&gt; Nb_Comp_7  0.9995661 0.9995661   0.1080347    0.1237880 -0.14581108 0.0975
#&gt; Nb_Comp_8  0.9995661 0.9995661   0.1080346    0.1227818 -0.13650388 0.0975
#&gt; Nb_Comp_9  0.9995661 0.9995661   0.1080346    0.1220460 -0.12969385 0.0975
#&gt; Nb_Comp_10 0.9995661 0.9995661   0.1080346    0.1208357 -0.11849061 0.0975
#&gt;            Q2cum_residY    AIC.std   DoF.dof sigmahat.dof     AIC.dof
#&gt; Nb_Comp_0            NA   712.4673  1.000000    7.3183710 53.77278888
#&gt; Nb_Comp_1     0.8246912   273.6462  2.555426    3.0339405  9.33570257
#&gt; Nb_Comp_2     0.9995127 -1197.7140  3.000068    0.1594599  0.02583432
#&gt; Nb_Comp_3     0.9994751 -1214.6936 22.575219    0.1599633  0.02800125
#&gt; Nb_Comp_4     0.9993831 -1214.9828 24.267880    0.1598258  0.02812610
#&gt; Nb_Comp_5     0.9992724 -1213.2050 23.899177    0.1596251  0.02801791
#&gt; Nb_Comp_6     0.9991613 -1211.2203 23.710185    0.1595538  0.02797366
#&gt; Nb_Comp_7     0.9990390 -1209.2217 23.765548    0.1595728  0.02798596
#&gt; Nb_Comp_8     0.9989079 -1207.2219 23.745431    0.1595657  0.02798141
#&gt; Nb_Comp_9     0.9987662 -1205.2219 23.870698    0.1596097  0.02800961
#&gt; Nb_Comp_10    0.9986200 -1203.2219 24.019892    0.1596621  0.02804323
#&gt;                BIC.dof  GMDL.dof DoF.naive sigmahat.naive   AIC.naive
#&gt; Nb_Comp_0  54.52720631  499.7901         1      7.3183710 53.77278888
#&gt; Nb_Comp_1   9.66703221  288.0890         2      3.0366586  9.29506592
#&gt; Nb_Comp_2   0.02690885 -438.1210         3      0.1597824  0.02583678
#&gt; Nb_Comp_3   0.03613808 -342.0258         4      0.1541432  0.02414029
#&gt; Nb_Comp_4   0.03685800 -334.5933         5      0.1537519  0.02411244
#&gt; Nb_Comp_5   0.03659556 -336.5338         6      0.1539982  0.02428461
#&gt; Nb_Comp_6   0.03647588 -337.4853         7      0.1543100  0.02447830
#&gt; Nb_Comp_7   0.03651006 -337.2091         8      0.1546281  0.02467496
#&gt; Nb_Comp_8   0.03649754 -337.3097         9      0.1549485  0.02487336
#&gt; Nb_Comp_9   0.03657538 -336.6837        10      0.1552710  0.02507344
#&gt; Nb_Comp_10  0.03666821 -335.9386        11      0.1555955  0.02527518
#&gt;              BIC.naive GMDL.naive
#&gt; Nb_Comp_0  54.52720631   499.7901
#&gt; Nb_Comp_1   9.55484538   286.8472
#&gt; Nb_Comp_2   0.02691563  -437.6224
#&gt; Nb_Comp_3   0.02547901  -441.0025
#&gt; Nb_Comp_4   0.02577736  -436.2568
#&gt; Nb_Comp_5   0.02628892  -430.5960
#&gt; Nb_Comp_6   0.02682615  -424.9195
#&gt; Nb_Comp_7   0.02736928  -419.3100
#&gt; Nb_Comp_8   0.02791705  -413.7646
#&gt; Nb_Comp_9   0.02846940  -408.2768
#&gt; Nb_Comp_10  0.02902638  -402.8412</div><div class='input'><span class='va'>cv.modpls.A2</span><span class='op'>&lt;-</span><span class='fu'><a href='cv.plsR.html'>cv.plsR</a></span><span class='op'>(</span><span class='va'>Y</span><span class='op'>~</span><span class='va'>.</span>,data<span class='op'>=</span><span class='va'>dataAstar2</span>,<span class='fl'>10</span>,NK<span class='op'>=</span><span class='fl'>100</span>, verbose<span class='op'>=</span><span class='cn'>FALSE</span><span class='op'>)</span>
<span class='va'>res.cv.modpls.A2</span><span class='op'>&lt;-</span><span class='fu'><a href='cvtable.html'>cvtable</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>cv.modpls.A2</span>,verbose<span class='op'>=</span><span class='cn'>FALSE</span><span class='op'>)</span><span class='op'>)</span>
</div><div class='output co'>#&gt; <span class='error'>Error in is.data.frame(data): objet 'dataAstar2' introuvable</span></div><div class='input'><span class='co'>#Perfect choice for the Q2 criterion in PLSR</span>
<span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>res.cv.modpls.A2</span><span class='op'>)</span>
</div><div class='output co'>#&gt; <span class='error'>Error in plot(res.cv.modpls.A2): objet 'res.cv.modpls.A2' introuvable</span></div><div class='input'>
<span class='co'>#Binarized data.frame</span>
<span class='va'>simbin1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span><span class='fu'><a href='dicho.html'>dicho</a></span><span class='op'>(</span><span class='va'>dataAstar2</span><span class='op'>)</span><span class='op'>)</span>
<span class='va'>modpls.B2</span> <span class='op'>&lt;-</span> <span class='fu'>plsR</span><span class='op'>(</span><span class='va'>Y</span><span class='op'>~</span><span class='va'>.</span>,data<span class='op'>=</span><span class='va'>simbin1</span>,<span class='fl'>10</span>,typeVC<span class='op'>=</span><span class='st'>"standard"</span>,MClassed<span class='op'>=</span><span class='cn'>TRUE</span>, verbose<span class='op'>=</span><span class='cn'>FALSE</span><span class='op'>)</span>
<span class='va'>modpls.B2</span>
</div><div class='output co'>#&gt; Number of required components:
#&gt; [1] 10
#&gt; Number of successfully computed components:
#&gt; [1] 8
#&gt; Coefficients:
#&gt;                    [,1]
#&gt; Intercept -2.232996e-02
#&gt; X1        -2.564600e-04
#&gt; X2         1.827582e-02
#&gt; X3         3.200076e-01
#&gt; X4         1.827582e-02
#&gt; X5         8.548667e-05
#&gt; X6        -7.441941e-02
#&gt; X7         1.827582e-02
#&gt; X8         8.548667e-05
#&gt; X9         1.600038e-01
#&gt; X10       -6.653264e-03
#&gt; X11        1.794648e-02
#&gt; X12        5.540587e-01
#&gt; X13        1.794648e-02
#&gt; X14       -6.307629e-03
#&gt; X15       -7.441941e-02
#&gt; X16        1.827582e-02
#&gt; X17        1.827582e-02
#&gt; X18       -7.441941e-02
#&gt; X19       -1.961416e-02
#&gt; X20       -6.653264e-03
#&gt; X21       -7.441941e-02
#&gt; X22        8.548667e-05
#&gt; X23        1.827582e-02
#&gt; X24        1.600038e-01
#&gt; Leave one out cross validated PRESS, Information criteria and Fit statistics:
#&gt;                 AIC   Q2cum_Y LimQ2_Y          Q2_Y   PRESS_Y     RSS_Y
#&gt; Nb_Comp_0 366.87968        NA      NA            NA        NA 62.496000
#&gt; Nb_Comp_1  26.83779 0.7381855  0.0975  0.7381855034 16.362359 15.909796
#&gt; Nb_Comp_2 -76.52049 0.8252118  0.0975  0.3323966613 10.621433 10.438510
#&gt; Nb_Comp_3 -91.51975 0.8283713  0.0975  0.0180764406 10.249819  9.752317
#&gt; Nb_Comp_4 -89.75294 0.8284216  0.0975  0.0002930630  9.749459  9.743224
#&gt; Nb_Comp_5 -87.81866 0.8284417  0.0975  0.0001171978  9.742083  9.740663
#&gt; Nb_Comp_6 -85.82121 0.8284216  0.0975 -0.0001170090  9.741803  9.740564
#&gt; Nb_Comp_7 -83.82127 0.8283970  0.0975 -0.0001436374  9.741963  9.740562
#&gt; Nb_Comp_8 -81.82127 0.8283740  0.0975 -0.0001343106  9.741870  9.740562
#&gt;                R2_Y MissClassed R2_residY RSS_residY PRESS_residY     Q2_residY
#&gt; Nb_Comp_0        NA         124        NA  249.00000           NA            NA
#&gt; Nb_Comp_1 0.7454270          11 0.7454270   63.38868     65.19181  0.7381855034
#&gt; Nb_Comp_2 0.8329731          13 0.8329731   41.58969     42.31850  0.3323966613
#&gt; Nb_Comp_3 0.8439529          11 0.8439529   38.85572     40.83789  0.0180764406
#&gt; Nb_Comp_4 0.8440984          11 0.8440984   38.81949     38.84433  0.0002930630
#&gt; Nb_Comp_5 0.8441394          11 0.8441394   38.80929     38.81494  0.0001171978
#&gt; Nb_Comp_6 0.8441410          11 0.8441410   38.80889     38.81383 -0.0001170090
#&gt; Nb_Comp_7 0.8441410          11 0.8441410   38.80888     38.81447 -0.0001436374
#&gt; Nb_Comp_8 0.8441410          11 0.8441410   38.80888     38.81409 -0.0001343106
#&gt;            LimQ2 Q2cum_residY  AIC.std   DoF.dof sigmahat.dof    AIC.dof
#&gt; Nb_Comp_0     NA           NA 712.4673  1.000000    0.5009870 0.25199190
#&gt; Nb_Comp_1 0.0975    0.7381855 372.4254  3.112471    0.2533407 0.06523729
#&gt; Nb_Comp_2 0.0975    0.8252118 269.0671  3.041696    0.2051776 0.04277843
#&gt; Nb_Comp_3 0.0975    0.8283713 254.0678 10.053091    0.2011839 0.04226445
#&gt; Nb_Comp_4 0.0975    0.8284216 255.8346  8.294626    0.2003603 0.04163675
#&gt; Nb_Comp_5 0.0975    0.8284417 257.7689  8.533335    0.2004325 0.04170515
#&gt; Nb_Comp_6 0.0975    0.8284216 259.7664  8.830099    0.2005543 0.04180357
#&gt; Nb_Comp_7 0.0975    0.8283970 261.7663  8.985473    0.2006186 0.04185541
#&gt; Nb_Comp_8 0.0975    0.8283740 263.7663  8.999852    0.2006246 0.04186022
#&gt;              BIC.dof  GMDL.dof DoF.naive sigmahat.naive  AIC.naive  BIC.naive
#&gt; Nb_Comp_0 0.25552728 -167.2823         1      0.5009870 0.25199190 0.25552728
#&gt; Nb_Comp_1 0.06805112 -330.7000         2      0.2532832 0.06466562 0.06647290
#&gt; Nb_Comp_2 0.04458211 -382.8861         3      0.2055752 0.04276831 0.04455416
#&gt; Nb_Comp_3 0.04799596 -369.7858         4      0.1991069 0.04027786 0.04251151
#&gt; Nb_Comp_4 0.04632708 -374.9363         5      0.1994198 0.04056363 0.04336448
#&gt; Nb_Comp_5 0.04653393 -374.2734         6      0.1998018 0.04087885 0.04425275
#&gt; Nb_Comp_6 0.04680636 -373.4159         7      0.2002115 0.04120700 0.04515938
#&gt; Nb_Comp_7 0.04694950 -372.9684         8      0.2006247 0.04153826 0.04607393
#&gt; Nb_Comp_8 0.04696276 -372.9271         9      0.2010405 0.04187229 0.04699609
#&gt;           GMDL.naive
#&gt; Nb_Comp_0  -167.2823
#&gt; Nb_Comp_1  -333.8147
#&gt; Nb_Comp_2  -382.5286
#&gt; Nb_Comp_3  -387.5578
#&gt; Nb_Comp_4  -384.4408
#&gt; Nb_Comp_5  -381.3439
#&gt; Nb_Comp_6  -378.3019
#&gt; Nb_Comp_7  -375.3325
#&gt; Nb_Comp_8  -372.4277</div><div class='input'><span class='va'>modpls.B2</span><span class='op'>$</span><span class='va'>Probs</span>
</div><div class='output co'>#&gt;      [,1]        [,2]         [,3]          [,4]        [,5]         [,6]
#&gt; 1   0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 2   0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 3   0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 4   0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 5   0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 6   0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 7   0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 8   0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 9   0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 10  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 11  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 12  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 13  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 14  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 15  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 16  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 17  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 18  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 19  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 20  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 21  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 22  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 23  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 24  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 25  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 26  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 27  0.496  0.03606045  0.002955833  0.0001432602 -0.01599899  0.007925162
#&gt; 28  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 29  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 30  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 31  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 32  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 33  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 34  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 35  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 36  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 37  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 38  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 39  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 40  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 41  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 42  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 43  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 44  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 45  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 46  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 47  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 48  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 49  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 50  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 51  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 52  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 53  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 54  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 55  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 56  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 57  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 58  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 59  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 60  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 61  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 62  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 63  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 64  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 65  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 66  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 67  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 68  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 69  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 70  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 71  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 72  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 73  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 74  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 75  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 76  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 77  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 78  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 79  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 80  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 81  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 82  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 83  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 84  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 85  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 86  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 87  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 88  0.496  1.00500492  0.973254333  1.0029362526  0.99021061  0.997293320
#&gt; 89  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 90  0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 91  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 92  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 93  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 94  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 95  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 96  0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 97  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 98  0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 99  0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 100 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 101 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 102 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 103 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 104 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 105 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 106 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 107 0.496  0.90947840  0.945577585  1.0369797504  0.97619695  0.995322751
#&gt; 108 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 109 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 110 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 111 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 112 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 113 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 114 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 115 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 116 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 117 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 118 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 119 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 120 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 121 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 122 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 123 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 124 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 125 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 126 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 127 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 128 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 129 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 130 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 131 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 132 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 133 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 134 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 135 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 136 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 137 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 138 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 139 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 140 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 141 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 142 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 143 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 144 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 145 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 146 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 147 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 148 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 149 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 150 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 151 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 152 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 153 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 154 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 155 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 156 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 157 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 158 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 159 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 160 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 161 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 162 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 163 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 164 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 165 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 166 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 167 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 168 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 169 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 170 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 171 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 172 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 173 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 174 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 175 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 176 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 177 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 178 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 179 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 180 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 181 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 182 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 183 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 184 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 185 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 186 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 187 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 188 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 189 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 190 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 191 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 192 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 193 0.496  0.45907245  0.636656724  0.0755600483  0.02597481  0.001514519
#&gt; 194 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 195 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 196 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 197 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 198 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 199 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 200 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 201 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 202 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 203 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 204 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 205 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 206 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 207 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 208 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 209 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 210 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 211 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 212 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 213 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 214 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 215 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 216 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 217 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 218 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 219 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 220 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 221 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 222 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 223 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 224 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 225 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 226 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 227 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 228 0.496  0.95759591  0.959727077  0.9862193637  1.01721602  0.999177807
#&gt; 229 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 230 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 231 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 232 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 233 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 234 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 235 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 236 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 237 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 238 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 239 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 240 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 241 0.496  0.36839434  0.524751547 -0.0668244029 -0.02771783 -0.002376501
#&gt; 242 0.496  0.64117170  0.862240206  0.8736969788  0.87418616  0.874112455
#&gt; 243 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 244 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt; 245 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 246 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 247 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 248 0.496  0.30502486  0.086944139  0.0840816281  0.08415168  0.083947110
#&gt; 249 0.496  1.02826346  0.979507152  0.9800896768  0.98049332  0.980469640
#&gt; 250 0.496 -0.08206690 -0.030322806 -0.0223110698 -0.02215549 -0.022410075
#&gt;              [,7]          [,8]          [,9]
#&gt; 1    8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 2    9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 3    9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 4    8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 5    9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 6    9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 7    8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 8   -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 9   -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 10   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 11  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 12   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 13  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 14   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 15  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 16   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 17   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 18  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 19   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 20   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 21   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 22   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 23   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 24  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 25   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 26   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 27   1.814101e-04 -9.424424e-05  5.551115e-16
#&gt; 28   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 29   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 30  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 31   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 32   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 33   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 34  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 35   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 36   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 37   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 38  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 39  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 40  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 41   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 42   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 43   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 44   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 45   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 46  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 47   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 48   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 49   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 50   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 51   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 52  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 53   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 54   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 55   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 56   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 57   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 58   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 59  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 60   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 61   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 62   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 63  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 64  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 65   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 66   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 67   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 68  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 69   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 70  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 71   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 72   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 73  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 74   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 75  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 76   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 77   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 78   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 79   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 80   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 81   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 82   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 83   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 84   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 85   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 86   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 87   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 88   9.986012e-01  9.998504e-01  1.000000e+00
#&gt; 89   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 90   8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 91   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 92  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 93  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 94  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 95   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 96   8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 97  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 98  -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 99   9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 100  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 101  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 102  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 103  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 104 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 105  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 106 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 107  1.000509e+00  9.999525e-01  1.000000e+00
#&gt; 108  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 109  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 110 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 111  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 112  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 113  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 114  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 115  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 116  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 117  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 118 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 119  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 120  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 121 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 122  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 123 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 124  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 125  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 126  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 127  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 128  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 129  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 130  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 131  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 132  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 133  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 134  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 135  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 136  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 137  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 138  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 139  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 140 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 141 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 142 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 143  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 144  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 145  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 146  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 147  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 148  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 149 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 150  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 151 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 152 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 153 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 154  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 155  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 156  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 157 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 158  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 159 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 160 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 161  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 162 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 163 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 164  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 165  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 166  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 167 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 168  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 169  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 170  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 171  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 172  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 173  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 174  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 175  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 176 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 177  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 178  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 179 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 180 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 181  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 182  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 183  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 184  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 185 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 186  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 187  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 188  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 189  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 190 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 191  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 192 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 193 -4.099320e-05 -1.534115e-05  2.775558e-16
#&gt; 194  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 195  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 196  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 197  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 198  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 199  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 200 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 201  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 202  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 203  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 204  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 205  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 206 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 207  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 208  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 209 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 210  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 211  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 212 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 213  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 214  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 215  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 216  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 217  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 218  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 219 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 220  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 221 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 222  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 223  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 224 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 225  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 226  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 227 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 228  1.000372e+00  9.997744e-01  1.000000e+00
#&gt; 229  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 230  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 231 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 232  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 233 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 234  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 235 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 236 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 237  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 238  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 239  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 240  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 241  5.931236e-05 -7.182277e-06  6.661338e-16
#&gt; 242  8.740665e-01  8.740690e-01  8.740663e-01
#&gt; 243  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 244 -2.233453e-02 -2.232974e-02 -2.232996e-02
#&gt; 245  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 246  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 247  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 248  8.399153e-02  8.399119e-02  8.398958e-02
#&gt; 249  9.803926e-01  9.803899e-01  9.803858e-01
#&gt; 250 -2.233453e-02 -2.232974e-02 -2.232996e-02</div><div class='input'><span class='va'>modpls.B2</span><span class='op'>$</span><span class='va'>Probs.trc</span>
</div><div class='output co'>#&gt;      [,1]       [,2]        [,3]         [,4]       [,5]        [,6]
#&gt; 1   0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 2   0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 3   0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 4   0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 5   0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 6   0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 7   0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 8   0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 9   0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 10  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 11  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 12  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 13  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 14  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 15  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 16  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 17  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 18  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 19  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 20  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 21  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 22  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 23  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 24  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 25  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 26  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 27  0.496 0.03606045 0.002955833 0.0001432602 0.00000000 0.007925162
#&gt; 28  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 29  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 30  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 31  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 32  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 33  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 34  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 35  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 36  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 37  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 38  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 39  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 40  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 41  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 42  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 43  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 44  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 45  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 46  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 47  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 48  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 49  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 50  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 51  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 52  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 53  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 54  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 55  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 56  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 57  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 58  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 59  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 60  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 61  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 62  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 63  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 64  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 65  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 66  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 67  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 68  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 69  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 70  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 71  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 72  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 73  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 74  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 75  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 76  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 77  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 78  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 79  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 80  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 81  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 82  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 83  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 84  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 85  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 86  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 87  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 88  0.496 1.00000000 0.973254333 1.0000000000 0.99021061 0.997293320
#&gt; 89  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 90  0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 91  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 92  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 93  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 94  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 95  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 96  0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 97  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 98  0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 99  0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 100 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 101 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 102 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 103 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 104 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 105 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 106 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 107 0.496 0.90947840 0.945577585 1.0000000000 0.97619695 0.995322751
#&gt; 108 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 109 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 110 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 111 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 112 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 113 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 114 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 115 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 116 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 117 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 118 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 119 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 120 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 121 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 122 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 123 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 124 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 125 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 126 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 127 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 128 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 129 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 130 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 131 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 132 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 133 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 134 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 135 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 136 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 137 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 138 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 139 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 140 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 141 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 142 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 143 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 144 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 145 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 146 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 147 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 148 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 149 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 150 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 151 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 152 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 153 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 154 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 155 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 156 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 157 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 158 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 159 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 160 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 161 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 162 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 163 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 164 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 165 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 166 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 167 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 168 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 169 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 170 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 171 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 172 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 173 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 174 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 175 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 176 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 177 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 178 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 179 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 180 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 181 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 182 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 183 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 184 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 185 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 186 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 187 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 188 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 189 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 190 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 191 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 192 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 193 0.496 0.45907245 0.636656724 0.0755600483 0.02597481 0.001514519
#&gt; 194 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 195 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 196 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 197 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 198 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 199 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 200 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 201 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 202 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 203 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 204 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 205 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 206 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 207 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 208 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 209 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 210 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 211 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 212 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 213 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 214 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 215 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 216 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 217 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 218 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 219 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 220 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 221 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 222 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 223 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 224 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 225 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 226 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 227 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 228 0.496 0.95759591 0.959727077 0.9862193637 1.00000000 0.999177807
#&gt; 229 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 230 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 231 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 232 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 233 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 234 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 235 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 236 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 237 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 238 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 239 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 240 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 241 0.496 0.36839434 0.524751547 0.0000000000 0.00000000 0.000000000
#&gt; 242 0.496 0.64117170 0.862240206 0.8736969788 0.87418616 0.874112455
#&gt; 243 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 244 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt; 245 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 246 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 247 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 248 0.496 0.30502486 0.086944139 0.0840816281 0.08415168 0.083947110
#&gt; 249 0.496 1.00000000 0.979507152 0.9800896768 0.98049332 0.980469640
#&gt; 250 0.496 0.00000000 0.000000000 0.0000000000 0.00000000 0.000000000
#&gt;             [,7]       [,8]         [,9]
#&gt; 1   8.740665e-01 0.87406897 8.740663e-01
#&gt; 2   9.803926e-01 0.98038990 9.803858e-01
#&gt; 3   9.803926e-01 0.98038990 9.803858e-01
#&gt; 4   8.740665e-01 0.87406897 8.740663e-01
#&gt; 5   9.803926e-01 0.98038990 9.803858e-01
#&gt; 6   9.803926e-01 0.98038990 9.803858e-01
#&gt; 7   8.740665e-01 0.87406897 8.740663e-01
#&gt; 8   0.000000e+00 0.00000000 0.000000e+00
#&gt; 9   0.000000e+00 0.00000000 0.000000e+00
#&gt; 10  9.803926e-01 0.98038990 9.803858e-01
#&gt; 11  0.000000e+00 0.00000000 0.000000e+00
#&gt; 12  9.803926e-01 0.98038990 9.803858e-01
#&gt; 13  0.000000e+00 0.00000000 0.000000e+00
#&gt; 14  8.740665e-01 0.87406897 8.740663e-01
#&gt; 15  0.000000e+00 0.00000000 0.000000e+00
#&gt; 16  8.399153e-02 0.08399119 8.398958e-02
#&gt; 17  9.803926e-01 0.98038990 9.803858e-01
#&gt; 18  0.000000e+00 0.00000000 0.000000e+00
#&gt; 19  8.399153e-02 0.08399119 8.398958e-02
#&gt; 20  8.399153e-02 0.08399119 8.398958e-02
#&gt; 21  9.803926e-01 0.98038990 9.803858e-01
#&gt; 22  8.399153e-02 0.08399119 8.398958e-02
#&gt; 23  8.399153e-02 0.08399119 8.398958e-02
#&gt; 24  0.000000e+00 0.00000000 0.000000e+00
#&gt; 25  9.803926e-01 0.98038990 9.803858e-01
#&gt; 26  9.803926e-01 0.98038990 9.803858e-01
#&gt; 27  1.814101e-04 0.00000000 5.551115e-16
#&gt; 28  8.740665e-01 0.87406897 8.740663e-01
#&gt; 29  9.803926e-01 0.98038990 9.803858e-01
#&gt; 30  0.000000e+00 0.00000000 0.000000e+00
#&gt; 31  9.803926e-01 0.98038990 9.803858e-01
#&gt; 32  9.803926e-01 0.98038990 9.803858e-01
#&gt; 33  8.740665e-01 0.87406897 8.740663e-01
#&gt; 34  0.000000e+00 0.00000000 0.000000e+00
#&gt; 35  8.740665e-01 0.87406897 8.740663e-01
#&gt; 36  9.803926e-01 0.98038990 9.803858e-01
#&gt; 37  9.803926e-01 0.98038990 9.803858e-01
#&gt; 38  0.000000e+00 0.00000000 0.000000e+00
#&gt; 39  0.000000e+00 0.00000000 0.000000e+00
#&gt; 40  0.000000e+00 0.00000000 0.000000e+00
#&gt; 41  8.740665e-01 0.87406897 8.740663e-01
#&gt; 42  8.399153e-02 0.08399119 8.398958e-02
#&gt; 43  8.740665e-01 0.87406897 8.740663e-01
#&gt; 44  8.399153e-02 0.08399119 8.398958e-02
#&gt; 45  8.740665e-01 0.87406897 8.740663e-01
#&gt; 46  0.000000e+00 0.00000000 0.000000e+00
#&gt; 47  9.803926e-01 0.98038990 9.803858e-01
#&gt; 48  8.740665e-01 0.87406897 8.740663e-01
#&gt; 49  8.740665e-01 0.87406897 8.740663e-01
#&gt; 50  8.399153e-02 0.08399119 8.398958e-02
#&gt; 51  8.399153e-02 0.08399119 8.398958e-02
#&gt; 52  0.000000e+00 0.00000000 0.000000e+00
#&gt; 53  9.803926e-01 0.98038990 9.803858e-01
#&gt; 54  8.740665e-01 0.87406897 8.740663e-01
#&gt; 55  9.803926e-01 0.98038990 9.803858e-01
#&gt; 56  9.803926e-01 0.98038990 9.803858e-01
#&gt; 57  9.803926e-01 0.98038990 9.803858e-01
#&gt; 58  8.399153e-02 0.08399119 8.398958e-02
#&gt; 59  0.000000e+00 0.00000000 0.000000e+00
#&gt; 60  9.803926e-01 0.98038990 9.803858e-01
#&gt; 61  8.740665e-01 0.87406897 8.740663e-01
#&gt; 62  8.740665e-01 0.87406897 8.740663e-01
#&gt; 63  0.000000e+00 0.00000000 0.000000e+00
#&gt; 64  0.000000e+00 0.00000000 0.000000e+00
#&gt; 65  9.803926e-01 0.98038990 9.803858e-01
#&gt; 66  9.803926e-01 0.98038990 9.803858e-01
#&gt; 67  9.803926e-01 0.98038990 9.803858e-01
#&gt; 68  0.000000e+00 0.00000000 0.000000e+00
#&gt; 69  8.399153e-02 0.08399119 8.398958e-02
#&gt; 70  0.000000e+00 0.00000000 0.000000e+00
#&gt; 71  8.399153e-02 0.08399119 8.398958e-02
#&gt; 72  8.399153e-02 0.08399119 8.398958e-02
#&gt; 73  0.000000e+00 0.00000000 0.000000e+00
#&gt; 74  8.399153e-02 0.08399119 8.398958e-02
#&gt; 75  0.000000e+00 0.00000000 0.000000e+00
#&gt; 76  8.740665e-01 0.87406897 8.740663e-01
#&gt; 77  8.399153e-02 0.08399119 8.398958e-02
#&gt; 78  8.399153e-02 0.08399119 8.398958e-02
#&gt; 79  9.803926e-01 0.98038990 9.803858e-01
#&gt; 80  8.740665e-01 0.87406897 8.740663e-01
#&gt; 81  8.740665e-01 0.87406897 8.740663e-01
#&gt; 82  8.740665e-01 0.87406897 8.740663e-01
#&gt; 83  8.399153e-02 0.08399119 8.398958e-02
#&gt; 84  8.740665e-01 0.87406897 8.740663e-01
#&gt; 85  8.399153e-02 0.08399119 8.398958e-02
#&gt; 86  8.399153e-02 0.08399119 8.398958e-02
#&gt; 87  9.803926e-01 0.98038990 9.803858e-01
#&gt; 88  9.986012e-01 0.99985040 1.000000e+00
#&gt; 89  9.803926e-01 0.98038990 9.803858e-01
#&gt; 90  8.740665e-01 0.87406897 8.740663e-01
#&gt; 91  8.399153e-02 0.08399119 8.398958e-02
#&gt; 92  0.000000e+00 0.00000000 0.000000e+00
#&gt; 93  0.000000e+00 0.00000000 0.000000e+00
#&gt; 94  0.000000e+00 0.00000000 0.000000e+00
#&gt; 95  9.803926e-01 0.98038990 9.803858e-01
#&gt; 96  8.399153e-02 0.08399119 8.398958e-02
#&gt; 97  0.000000e+00 0.00000000 0.000000e+00
#&gt; 98  0.000000e+00 0.00000000 0.000000e+00
#&gt; 99  9.803926e-01 0.98038990 9.803858e-01
#&gt; 100 8.740665e-01 0.87406897 8.740663e-01
#&gt; 101 9.803926e-01 0.98038990 9.803858e-01
#&gt; 102 8.399153e-02 0.08399119 8.398958e-02
#&gt; 103 9.803926e-01 0.98038990 9.803858e-01
#&gt; 104 0.000000e+00 0.00000000 0.000000e+00
#&gt; 105 9.803926e-01 0.98038990 9.803858e-01
#&gt; 106 0.000000e+00 0.00000000 0.000000e+00
#&gt; 107 1.000000e+00 0.99995246 1.000000e+00
#&gt; 108 8.740665e-01 0.87406897 8.740663e-01
#&gt; 109 8.399153e-02 0.08399119 8.398958e-02
#&gt; 110 0.000000e+00 0.00000000 0.000000e+00
#&gt; 111 9.803926e-01 0.98038990 9.803858e-01
#&gt; 112 9.803926e-01 0.98038990 9.803858e-01
#&gt; 113 8.740665e-01 0.87406897 8.740663e-01
#&gt; 114 8.399153e-02 0.08399119 8.398958e-02
#&gt; 115 9.803926e-01 0.98038990 9.803858e-01
#&gt; 116 8.740665e-01 0.87406897 8.740663e-01
#&gt; 117 8.740665e-01 0.87406897 8.740663e-01
#&gt; 118 0.000000e+00 0.00000000 0.000000e+00
#&gt; 119 8.399153e-02 0.08399119 8.398958e-02
#&gt; 120 9.803926e-01 0.98038990 9.803858e-01
#&gt; 121 0.000000e+00 0.00000000 0.000000e+00
#&gt; 122 8.740665e-01 0.87406897 8.740663e-01
#&gt; 123 0.000000e+00 0.00000000 0.000000e+00
#&gt; 124 8.399153e-02 0.08399119 8.398958e-02
#&gt; 125 8.399153e-02 0.08399119 8.398958e-02
#&gt; 126 9.803926e-01 0.98038990 9.803858e-01
#&gt; 127 9.803926e-01 0.98038990 9.803858e-01
#&gt; 128 9.803926e-01 0.98038990 9.803858e-01
#&gt; 129 9.803926e-01 0.98038990 9.803858e-01
#&gt; 130 8.399153e-02 0.08399119 8.398958e-02
#&gt; 131 9.803926e-01 0.98038990 9.803858e-01
#&gt; 132 8.399153e-02 0.08399119 8.398958e-02
#&gt; 133 9.803926e-01 0.98038990 9.803858e-01
#&gt; 134 8.740665e-01 0.87406897 8.740663e-01
#&gt; 135 9.803926e-01 0.98038990 9.803858e-01
#&gt; 136 8.740665e-01 0.87406897 8.740663e-01
#&gt; 137 9.803926e-01 0.98038990 9.803858e-01
#&gt; 138 8.740665e-01 0.87406897 8.740663e-01
#&gt; 139 8.399153e-02 0.08399119 8.398958e-02
#&gt; 140 0.000000e+00 0.00000000 0.000000e+00
#&gt; 141 0.000000e+00 0.00000000 0.000000e+00
#&gt; 142 0.000000e+00 0.00000000 0.000000e+00
#&gt; 143 8.740665e-01 0.87406897 8.740663e-01
#&gt; 144 8.740665e-01 0.87406897 8.740663e-01
#&gt; 145 8.740665e-01 0.87406897 8.740663e-01
#&gt; 146 8.399153e-02 0.08399119 8.398958e-02
#&gt; 147 8.740665e-01 0.87406897 8.740663e-01
#&gt; 148 9.803926e-01 0.98038990 9.803858e-01
#&gt; 149 0.000000e+00 0.00000000 0.000000e+00
#&gt; 150 8.740665e-01 0.87406897 8.740663e-01
#&gt; 151 0.000000e+00 0.00000000 0.000000e+00
#&gt; 152 0.000000e+00 0.00000000 0.000000e+00
#&gt; 153 0.000000e+00 0.00000000 0.000000e+00
#&gt; 154 9.803926e-01 0.98038990 9.803858e-01
#&gt; 155 9.803926e-01 0.98038990 9.803858e-01
#&gt; 156 9.803926e-01 0.98038990 9.803858e-01
#&gt; 157 0.000000e+00 0.00000000 0.000000e+00
#&gt; 158 8.399153e-02 0.08399119 8.398958e-02
#&gt; 159 0.000000e+00 0.00000000 0.000000e+00
#&gt; 160 0.000000e+00 0.00000000 0.000000e+00
#&gt; 161 8.399153e-02 0.08399119 8.398958e-02
#&gt; 162 0.000000e+00 0.00000000 0.000000e+00
#&gt; 163 0.000000e+00 0.00000000 0.000000e+00
#&gt; 164 9.803926e-01 0.98038990 9.803858e-01
#&gt; 165 8.399153e-02 0.08399119 8.398958e-02
#&gt; 166 8.740665e-01 0.87406897 8.740663e-01
#&gt; 167 0.000000e+00 0.00000000 0.000000e+00
#&gt; 168 8.740665e-01 0.87406897 8.740663e-01
#&gt; 169 8.399153e-02 0.08399119 8.398958e-02
#&gt; 170 9.803926e-01 0.98038990 9.803858e-01
#&gt; 171 8.399153e-02 0.08399119 8.398958e-02
#&gt; 172 8.740665e-01 0.87406897 8.740663e-01
#&gt; 173 8.399153e-02 0.08399119 8.398958e-02
#&gt; 174 9.803926e-01 0.98038990 9.803858e-01
#&gt; 175 9.803926e-01 0.98038990 9.803858e-01
#&gt; 176 0.000000e+00 0.00000000 0.000000e+00
#&gt; 177 9.803926e-01 0.98038990 9.803858e-01
#&gt; 178 8.740665e-01 0.87406897 8.740663e-01
#&gt; 179 0.000000e+00 0.00000000 0.000000e+00
#&gt; 180 0.000000e+00 0.00000000 0.000000e+00
#&gt; 181 8.399153e-02 0.08399119 8.398958e-02
#&gt; 182 9.803926e-01 0.98038990 9.803858e-01
#&gt; 183 8.399153e-02 0.08399119 8.398958e-02
#&gt; 184 9.803926e-01 0.98038990 9.803858e-01
#&gt; 185 0.000000e+00 0.00000000 0.000000e+00
#&gt; 186 9.803926e-01 0.98038990 9.803858e-01
#&gt; 187 8.740665e-01 0.87406897 8.740663e-01
#&gt; 188 8.740665e-01 0.87406897 8.740663e-01
#&gt; 189 9.803926e-01 0.98038990 9.803858e-01
#&gt; 190 0.000000e+00 0.00000000 0.000000e+00
#&gt; 191 9.803926e-01 0.98038990 9.803858e-01
#&gt; 192 0.000000e+00 0.00000000 0.000000e+00
#&gt; 193 0.000000e+00 0.00000000 2.775558e-16
#&gt; 194 8.740665e-01 0.87406897 8.740663e-01
#&gt; 195 8.399153e-02 0.08399119 8.398958e-02
#&gt; 196 9.803926e-01 0.98038990 9.803858e-01
#&gt; 197 8.740665e-01 0.87406897 8.740663e-01
#&gt; 198 9.803926e-01 0.98038990 9.803858e-01
#&gt; 199 8.740665e-01 0.87406897 8.740663e-01
#&gt; 200 0.000000e+00 0.00000000 0.000000e+00
#&gt; 201 8.740665e-01 0.87406897 8.740663e-01
#&gt; 202 8.399153e-02 0.08399119 8.398958e-02
#&gt; 203 8.740665e-01 0.87406897 8.740663e-01
#&gt; 204 8.740665e-01 0.87406897 8.740663e-01
#&gt; 205 8.399153e-02 0.08399119 8.398958e-02
#&gt; 206 0.000000e+00 0.00000000 0.000000e+00
#&gt; 207 9.803926e-01 0.98038990 9.803858e-01
#&gt; 208 8.399153e-02 0.08399119 8.398958e-02
#&gt; 209 0.000000e+00 0.00000000 0.000000e+00
#&gt; 210 9.803926e-01 0.98038990 9.803858e-01
#&gt; 211 8.399153e-02 0.08399119 8.398958e-02
#&gt; 212 0.000000e+00 0.00000000 0.000000e+00
#&gt; 213 9.803926e-01 0.98038990 9.803858e-01
#&gt; 214 9.803926e-01 0.98038990 9.803858e-01
#&gt; 215 9.803926e-01 0.98038990 9.803858e-01
#&gt; 216 8.399153e-02 0.08399119 8.398958e-02
#&gt; 217 8.399153e-02 0.08399119 8.398958e-02
#&gt; 218 9.803926e-01 0.98038990 9.803858e-01
#&gt; 219 0.000000e+00 0.00000000 0.000000e+00
#&gt; 220 8.399153e-02 0.08399119 8.398958e-02
#&gt; 221 0.000000e+00 0.00000000 0.000000e+00
#&gt; 222 8.399153e-02 0.08399119 8.398958e-02
#&gt; 223 8.740665e-01 0.87406897 8.740663e-01
#&gt; 224 0.000000e+00 0.00000000 0.000000e+00
#&gt; 225 8.740665e-01 0.87406897 8.740663e-01
#&gt; 226 8.740665e-01 0.87406897 8.740663e-01
#&gt; 227 0.000000e+00 0.00000000 0.000000e+00
#&gt; 228 1.000000e+00 0.99977443 1.000000e+00
#&gt; 229 9.803926e-01 0.98038990 9.803858e-01
#&gt; 230 9.803926e-01 0.98038990 9.803858e-01
#&gt; 231 0.000000e+00 0.00000000 0.000000e+00
#&gt; 232 9.803926e-01 0.98038990 9.803858e-01
#&gt; 233 0.000000e+00 0.00000000 0.000000e+00
#&gt; 234 9.803926e-01 0.98038990 9.803858e-01
#&gt; 235 0.000000e+00 0.00000000 0.000000e+00
#&gt; 236 0.000000e+00 0.00000000 0.000000e+00
#&gt; 237 8.399153e-02 0.08399119 8.398958e-02
#&gt; 238 9.803926e-01 0.98038990 9.803858e-01
#&gt; 239 9.803926e-01 0.98038990 9.803858e-01
#&gt; 240 8.740665e-01 0.87406897 8.740663e-01
#&gt; 241 5.931236e-05 0.00000000 6.661338e-16
#&gt; 242 8.740665e-01 0.87406897 8.740663e-01
#&gt; 243 9.803926e-01 0.98038990 9.803858e-01
#&gt; 244 0.000000e+00 0.00000000 0.000000e+00
#&gt; 245 8.399153e-02 0.08399119 8.398958e-02
#&gt; 246 8.399153e-02 0.08399119 8.398958e-02
#&gt; 247 8.399153e-02 0.08399119 8.398958e-02
#&gt; 248 8.399153e-02 0.08399119 8.398958e-02
#&gt; 249 9.803926e-01 0.98038990 9.803858e-01
#&gt; 250 0.000000e+00 0.00000000 0.000000e+00</div><div class='input'><span class='va'>modpls.B2</span><span class='op'>$</span><span class='va'>MissClassed</span>
</div><div class='output co'>#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
#&gt; [1,]  124   11   13   11   11   11   11   11   11</div><div class='input'><span class='fu'>plsR</span><span class='op'>(</span><span class='va'>simbin1</span><span class='op'>$</span><span class='va'>Y</span>,<span class='va'>dataAstar2</span><span class='op'>[</span>,<span class='op'>-</span><span class='fl'>1</span><span class='op'>]</span>,<span class='fl'>10</span>,typeVC<span class='op'>=</span><span class='st'>"standard"</span>,MClassed<span class='op'>=</span><span class='cn'>TRUE</span>,verbose<span class='op'>=</span><span class='cn'>FALSE</span><span class='op'>)</span><span class='op'>$</span><span class='va'>InfCrit</span>
</div><div class='output co'>#&gt;                  AIC     Q2cum_Y LimQ2_Y        Q2_Y  PRESS_Y    RSS_Y
#&gt; Nb_Comp_0  366.87968          NA      NA          NA       NA 62.49600
#&gt; Nb_Comp_1  179.27607  0.52469907  0.0975  0.52469907 29.70441 29.27366
#&gt; Nb_Comp_2  111.50920  0.63784869  0.0975  0.23805890 22.30480 22.14520
#&gt; Nb_Comp_3   92.19471  0.61461931  0.0975 -0.06414274 23.56565 20.33539
#&gt; Nb_Comp_4   92.80958  0.54850120  0.0975 -0.17156571 23.82425 20.22303
#&gt; Nb_Comp_5   94.61150  0.46505988  0.0975 -0.18480962 23.96044 20.20702
#&gt; Nb_Comp_6   96.58935  0.37811037  0.0975 -0.16254065 23.49148 20.20523
#&gt; Nb_Comp_7   98.58715  0.28547861  0.0975 -0.14895208 23.21484 20.20505
#&gt; Nb_Comp_8  100.58707  0.18505584  0.0975 -0.14054551 23.04478 20.20504
#&gt; Nb_Comp_9  102.58707  0.07664463  0.0975 -0.13302900 22.89290 20.20504
#&gt; Nb_Comp_10 104.58707 -0.03839400  0.0975 -0.12458760 22.72234 20.20504
#&gt;                 R2_Y MissClassed R2_residY RSS_residY PRESS_residY   Q2_residY
#&gt; Nb_Comp_0         NA         124        NA  249.00000           NA          NA
#&gt; Nb_Comp_1  0.5315915          30 0.5315915  116.63372    118.34993  0.52469907
#&gt; Nb_Comp_2  0.6456542           6 0.6456542   88.23211     88.86803  0.23805890
#&gt; Nb_Comp_3  0.6746129           8 0.6746129   81.02138     93.89156 -0.06414274
#&gt; Nb_Comp_4  0.6764108          11 0.6764108   80.57372     94.92187 -0.17156571
#&gt; Nb_Comp_5  0.6766671          10 0.6766671   80.50990     95.46452 -0.18480962
#&gt; Nb_Comp_6  0.6766957          10 0.6766957   80.50277     93.59604 -0.16254065
#&gt; Nb_Comp_7  0.6766985          10 0.6766985   80.50206     92.49383 -0.14895208
#&gt; Nb_Comp_8  0.6766986          10 0.6766986   80.50204     91.81627 -0.14054551
#&gt; Nb_Comp_9  0.6766987          10 0.6766987   80.50203     91.21114 -0.13302900
#&gt; Nb_Comp_10 0.6766987          10 0.6766987   80.50203     90.53159 -0.12458760
#&gt;             LimQ2 Q2cum_residY  AIC.std   DoF.dof sigmahat.dof    AIC.dof
#&gt; Nb_Comp_0      NA           NA 712.4673  1.000000    0.5009870 0.25199190
#&gt; Nb_Comp_1  0.0975   0.52469907 524.8637  2.621153    0.3433059 0.11956605
#&gt; Nb_Comp_2  0.0975   0.63784869 457.0968  3.000068    0.2988230 0.09072392
#&gt; Nb_Comp_3  0.0975   0.61461931 437.7823 21.497037    0.2976680 0.09657973
#&gt; Nb_Comp_4  0.0975   0.54850120 438.3972 25.000000    0.2991362 0.09878862
#&gt; Nb_Comp_5  0.0975   0.46505988 440.1991 25.000000    0.2990177 0.09871038
#&gt; Nb_Comp_6  0.0975   0.37811037 442.1769 25.000000    0.2990044 0.09870163
#&gt; Nb_Comp_7  0.0975   0.28547861 444.1747 25.000000    0.2990031 0.09870076
#&gt; Nb_Comp_8  0.0975   0.18505584 446.1747 25.000000    0.2990031 0.09870073
#&gt; Nb_Comp_9  0.0975   0.07664463 448.1747 25.000000    0.2990031 0.09870073
#&gt; Nb_Comp_10 0.0975  -0.03839400 450.1747 25.000000    0.2990031 0.09870073
#&gt;              BIC.dof  GMDL.dof DoF.naive sigmahat.naive  AIC.naive  BIC.naive
#&gt; Nb_Comp_0  0.2555273 -167.2823         1      0.5009870 0.25199190 0.25552728
#&gt; Nb_Comp_1  0.1239175 -257.0188         2      0.3435680 0.11898326 0.12230862
#&gt; Nb_Comp_2  0.0944974 -290.3040         3      0.2994272 0.09073255 0.09452122
#&gt; Nb_Comp_3  0.1234100 -257.2238         4      0.2875138 0.08398681 0.08864439
#&gt; Nb_Comp_4  0.1302995 -250.9899         5      0.2873030 0.08419385 0.09000729
#&gt; Nb_Comp_5  0.1301963 -251.0771         6      0.2877771 0.08480321 0.09180238
#&gt; Nb_Comp_6  0.1301848 -251.0868         7      0.2883558 0.08547725 0.09367583
#&gt; Nb_Comp_7  0.1301836 -251.0878         8      0.2889497 0.08616367 0.09557211
#&gt; Nb_Comp_8  0.1301836 -251.0878         9      0.2895485 0.08685653 0.09748493
#&gt; Nb_Comp_9  0.1301836 -251.0878        10      0.2901511 0.08755518 0.09941372
#&gt; Nb_Comp_10 0.1301836 -251.0878        11      0.2907575 0.08825968 0.10135865
#&gt;            GMDL.naive
#&gt; Nb_Comp_0   -167.2823
#&gt; Nb_Comp_1   -258.3373
#&gt; Nb_Comp_2   -289.8052
#&gt; Nb_Comp_3   -297.3647
#&gt; Nb_Comp_4   -295.2257
#&gt; Nb_Comp_5   -292.6062
#&gt; Nb_Comp_6   -289.9866
#&gt; Nb_Comp_7   -287.4310
#&gt; Nb_Comp_8   -284.9391
#&gt; Nb_Comp_9   -282.5049
#&gt; Nb_Comp_10  -280.1229</div><div class='input'><span class='va'>cv.modpls.B2</span><span class='op'>&lt;-</span><span class='fu'><a href='cv.plsR.html'>cv.plsR</a></span><span class='op'>(</span><span class='va'>Y</span><span class='op'>~</span><span class='va'>.</span>,data<span class='op'>=</span><span class='va'>simbin1</span>,<span class='fl'>2</span>,NK<span class='op'>=</span><span class='fl'>100</span>,verbose<span class='op'>=</span><span class='cn'>FALSE</span><span class='op'>)</span>
<span class='va'>res.cv.modpls.B2</span><span class='op'>&lt;-</span><span class='fu'><a href='cvtable.html'>cvtable</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>cv.modpls.B2</span>,MClassed<span class='op'>=</span><span class='cn'>TRUE</span><span class='op'>)</span><span class='op'>)</span>
</div><div class='output co'>#&gt; ____************************************************____</div><div class='output co'>#&gt; <span class='error'>Error in is.data.frame(data): objet 'simbin1' introuvable</span></div><div class='input'><span class='co'>#Only one component found by repeated CV missclassed criterion</span>
<span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>res.cv.modpls.B2</span><span class='op'>)</span>
</div><div class='output co'>#&gt; <span class='error'>Error in plot(res.cv.modpls.B2): objet 'res.cv.modpls.B2' introuvable</span></div><div class='input'>
<span class='fu'><a href='https://rdrr.io/r/base/rm.html'>rm</a></span><span class='op'>(</span>list<span class='op'>=</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"dimX"</span>,<span class='st'>"Astar"</span>,<span class='st'>"dataAstar2"</span>,<span class='st'>"modpls.A2"</span>,<span class='st'>"cv.modpls.A2"</span>,
<span class='st'>"res.cv.modpls.A2"</span>,<span class='st'>"simbin1"</span>,<span class='st'>"modpls.B2"</span>,<span class='st'>"cv.modpls.B2"</span>,<span class='st'>"res.cv.modpls.B2"</span><span class='op'>)</span><span class='op'>)</span>
</div><div class='output co'>#&gt; <span class='warning'>Warning: objet 'res.cv.modpls.A2' introuvable</span></div><div class='output co'>#&gt; <span class='warning'>Warning: objet 'res.cv.modpls.B2' introuvable</span></div><div class='input'><span class='co'># }</span>
</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Frederic Bertrand, Myriam Maumy-Bertrand.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


